
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 491520/170498071 [00:00<00:34, 4912955.71it/s]
      4% 6488064/170498071 [00:00<00:04, 36895958.96it/s]
      8% 14254080/170498071 [00:00<00:02, 54980318.15it/s]
     13% 22052864/170498071 [00:00<00:02, 63476471.17it/s]
     17% 29818880/170498071 [00:00<00:02, 68500526.39it/s]
     22% 37421056/170498071 [00:00<00:01, 71015466.45it/s]
     26% 44957696/170498071 [00:00<00:01, 72421166.80it/s]
     31% 52723712/170498071 [00:00<00:01, 74048917.84it/s]
     36% 60653568/170498071 [00:00<00:01, 75545467.31it/s]
     40% 68648960/170498071 [00:01<00:01, 76780607.40it/s]
     45% 76677120/170498071 [00:01<00:01, 77795208.46it/s]
     50% 84606976/170498071 [00:01<00:01, 78221646.91it/s]
     54% 92504064/170498071 [00:01<00:00, 78389893.87it/s]
     59% 100597760/170498071 [00:01<00:00, 79146635.47it/s]
     64% 108822528/170498071 [00:01<00:00, 79988540.15it/s]
     69% 117112832/170498071 [00:01<00:00, 80795548.14it/s]
     74% 125632512/170498071 [00:01<00:00, 81926509.31it/s]
     79% 134217728/170498071 [00:01<00:00, 83090323.87it/s]
     84% 142802944/170498071 [00:01<00:00, 83850403.18it/s]
     89% 151552000/170498071 [00:02<00:00, 84798901.04it/s]
     94% 160333824/170498071 [00:02<00:00, 85687376.74it/s]
     99% 169246720/170498071 [00:02<00:00, 86661621.00it/s]
    100% 170498071/170498071 [00:02<00:00, 76665942.07it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-06-27 19:46:56,612 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-06-27 19:46:56,746 INFO worker.py:1625 -- Started a local Ray instance.
    2023-06-27 19:46:58,096 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-06-27 19:47:02 (running for 00:00:03.66)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | PENDING  |                 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | PENDING  |                 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | PENDING  |                 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | PENDING  |                 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | PENDING  |                 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | PENDING  |                 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | PENDING  |                 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2705) Files already downloaded and verified
    (func pid=2705) Files already downloaded and verified
    == Status ==
    Current time: 2023-06-27 19:47:07 (running for 00:00:08.71)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2799) Files already downloaded and verified [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-06-27 19:47:12 (running for 00:00:13.72)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-06-27 19:47:17 (running for 00:00:18.73)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2799) [1,  2000] loss: 2.404
    (func pid=2803) Files already downloaded and verified [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-27 19:47:22 (running for 00:00:23.74)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2801) [1,  2000] loss: 2.309 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-27 19:47:27 (running for 00:00:28.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.151
      date: 2023-06-27_19-47-28
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.295087289428711
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 26.582152128219604
      time_this_iter_s: 26.582152128219604
      time_total_s: 26.582152128219604
      timestamp: 1687895248
      training_iteration: 1
      trial_id: '60711_00000'
  
    (func pid=2797) [1,  4000] loss: 1.153 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:47:33 (running for 00:00:35.27)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.295087289428711
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING  | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      1 |          26.5822 | 2.29509 |      0.151 |
    | train_cifar_60711_00001 | RUNNING  | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |        |                  |         |            |
    | train_cifar_60711_00002 | RUNNING  | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING  | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00004 | RUNNING  | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING  | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |        |                  |         |            |
    | train_cifar_60711_00006 | RUNNING  | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |        |                  |         |            |
    | train_cifar_60711_00007 | RUNNING  | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |        |                  |         |            |
    | train_cifar_60711_00008 | PENDING  |                 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | PENDING  |                 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00004:
      accuracy: 0.1006
      date: 2023-06-27_19-47-34
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.3103939643859865
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 27.57808232307434
      time_this_iter_s: 27.57808232307434
      time_total_s: 27.57808232307434
      timestamp: 1687895254
      training_iteration: 1
      trial_id: '60711_00004'
  
    Trial train_cifar_60711_00004 completed.
    Result for train_cifar_60711_00007:
      accuracy: 0.3668
      date: 2023-06-27_19-47-34
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 1.6899975929260254
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 27.949591875076294
      time_this_iter_s: 27.949591875076294
      time_total_s: 27.949591875076294
      timestamp: 1687895254
      training_iteration: 1
      trial_id: '60711_00007'
  
    (func pid=2801) Files already downloaded and verified
    (func pid=2801) Files already downloaded and verified
    (func pid=2805) [1,  4000] loss: 1.046 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:47:39 (running for 00:00:40.95)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.295087289428711
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      1 |          26.5822 | 2.29509 |     0.151  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |        |                  |         |            |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |        |                  |         |            |
    | train_cifar_60711_00006 | RUNNING    | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |        |                  |         |            |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      1 |          27.9496 | 1.69    |     0.3668 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | PENDING    |                 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [1,  6000] loss: 0.769 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:47:44 (running for 00:00:45.97)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.295087289428711
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      1 |          26.5822 | 2.29509 |     0.151  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |        |                  |         |            |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |        |                  |         |            |
    | train_cifar_60711_00006 | RUNNING    | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |        |                  |         |            |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      1 |          27.9496 | 1.69    |     0.3668 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | PENDING    |                 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.4489
      date: 2023-06-27_19-47-48
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 1.518245555782318
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 42.44008541107178
      time_this_iter_s: 42.44008541107178
      time_total_s: 42.44008541107178
      timestamp: 1687895268
      training_iteration: 1
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.4349
      date: 2023-06-27_19-47-49
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 1.513870443868637
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 42.82683062553406
      time_this_iter_s: 42.82683062553406
      time_total_s: 42.82683062553406
      timestamp: 1687895269
      training_iteration: 1
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:47:49 (running for 00:00:50.98)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.6899975929260254
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      1 |          26.5822 | 2.29509 |     0.151  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00006 | RUNNING    | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |        |                  |         |            |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      1 |          27.9496 | 1.69    |     0.3668 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | PENDING    |                 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2807) [2,  2000] loss: 1.537 [repeated 3x across cluster]
    Result for train_cifar_60711_00006:
      accuracy: 0.3033
      date: 2023-06-27_19-47-52
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 1.975084494972229
      node_ip: 172.17.0.2
      pid: 2805
      should_checkpoint: true
      time_since_restore: 45.57164740562439
      time_this_iter_s: 45.57164740562439
      time_total_s: 45.57164740562439
      timestamp: 1687895272
      training_iteration: 1
      trial_id: '60711_00006'
  
    Trial train_cifar_60711_00006 completed.
    (func pid=2805) Files already downloaded and verified
    (func pid=2805) Files already downloaded and verified
    Result for train_cifar_60711_00000:
      accuracy: 0.2023
      date: 2023-06-27_19-47-54
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 2
      loss: 2.085761061668396
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 52.323671102523804
      time_this_iter_s: 25.7415189743042
      time_total_s: 52.323671102523804
      timestamp: 1687895274
      training_iteration: 2
      trial_id: '60711_00000'
  
    == Status ==
    Current time: 2023-06-27 19:47:54 (running for 00:00:56.01)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.085761061668396 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      2 |          52.3237 | 2.08576 |     0.2023 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      1 |          27.9496 | 1.69    |     0.3668 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [1,  4000] loss: 1.156 [repeated 3x across cluster]
    Result for train_cifar_60711_00007:
      accuracy: 0.4713
      date: 2023-06-27_19-47-59
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 2
      loss: 1.4593620595932006
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 52.72041440010071
      time_this_iter_s: 24.770822525024414
      time_total_s: 52.72041440010071
      timestamp: 1687895279
      training_iteration: 2
      trial_id: '60711_00007'
  
    (func pid=2803) [2,  2000] loss: 1.495 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:48:04 (running for 00:01:05.71)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7725615606307983 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      2 |          52.3237 | 2.08576 |     0.2023 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      2 |          52.7204 | 1.45936 |     0.4713 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:48:09 (running for 00:01:10.73)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7725615606307983 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      2 |          52.3237 | 2.08576 |     0.2023 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      2 |          52.7204 | 1.45936 |     0.4713 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2705) [3,  2000] loss: 2.052 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-27 19:48:14 (running for 00:01:15.74)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7725615606307983 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      2 |          52.3237 | 2.08576 |     0.2023 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      2 |          52.7204 | 1.45936 |     0.4713 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [1,  8000] loss: 0.577 [repeated 6x across cluster]
    Result for train_cifar_60711_00000:
      accuracy: 0.1966
      date: 2023-06-27_19-48-19
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 3
      loss: 2.0107134647369387
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 76.9652590751648
      time_this_iter_s: 24.64158797264099
      time_total_s: 76.9652590751648
      timestamp: 1687895299
      training_iteration: 3
      trial_id: '60711_00000'
  
    (func pid=2799) [1, 14000] loss: 0.343 [repeated 2x across cluster]
    Result for train_cifar_60711_00007:
      accuracy: 0.505
      date: 2023-06-27_19-48-23
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 3
      loss: 1.3694396515846252
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 77.17353844642639
      time_this_iter_s: 24.453124046325684
      time_total_s: 77.17353844642639
      timestamp: 1687895303
      training_iteration: 3
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:48:23 (running for 00:01:25.17)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7725615606307983 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      3 |          76.9653 | 2.01071 |     0.1966 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      1 |          42.4401 | 1.51825 |     0.4489 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      1 |          42.8268 | 1.51387 |     0.4349 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      3 |          77.1735 | 1.36944 |     0.505  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.506
      date: 2023-06-27_19-48-27
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 2
      loss: 1.3906426497220994
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 81.60747623443604
      time_this_iter_s: 39.16739082336426
      time_total_s: 81.60747623443604
      timestamp: 1687895307
      training_iteration: 2
      trial_id: '60711_00001'
  
    (func pid=2801) [1, 10000] loss: 0.462 [repeated 2x across cluster]
    Result for train_cifar_60711_00005:
      accuracy: 0.5112
      date: 2023-06-27_19-48-28
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 2
      loss: 1.3536276450634002
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 82.41239619255066
      time_this_iter_s: 39.5855655670166
      time_total_s: 82.41239619255066
      timestamp: 1687895308
      training_iteration: 2
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:48:28 (running for 00:01:30.56)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      3 |          76.9653 | 2.01071 |     0.1966 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      3 |          77.1735 | 1.36944 |     0.505  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2799) [1, 16000] loss: 0.300 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:48:33 (running for 00:01:35.58)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      3 |          76.9653 | 2.01071 |     0.1966 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      3 |          77.1735 | 1.36944 |     0.505  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:48:38 (running for 00:01:40.59)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      3 |          76.9653 | 2.01071 |     0.1966 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      3 |          77.1735 | 1.36944 |     0.505  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2807) [4,  2000] loss: 1.337 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-27 19:48:43 (running for 00:01:45.60)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      3 |          76.9653 | 2.01071 |     0.1966 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      3 |          77.1735 | 1.36944 |     0.505  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.2085
      date: 2023-06-27_19-48-44
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 4
      loss: 1.9375626487731934
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 102.20353317260742
      time_this_iter_s: 25.238274097442627
      time_total_s: 102.20353317260742
      timestamp: 1687895324
      training_iteration: 4
      trial_id: '60711_00000'
  
    (func pid=2805) [1, 10000] loss: 0.467 [repeated 5x across cluster]
    Result for train_cifar_60711_00007:
      accuracy: 0.4961
      date: 2023-06-27_19-48-47
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 4
      loss: 1.3934154193878174
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 101.61021542549133
      time_this_iter_s: 24.43667697906494
      time_total_s: 101.61021542549133
      timestamp: 1687895327
      training_iteration: 4
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:48:52 (running for 00:01:54.60)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      4 |         102.204  | 1.93756 |     0.2085 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      4 |         101.61   | 1.39342 |     0.4961 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [1, 18000] loss: 0.256 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:48:57 (running for 00:01:59.62)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      4 |         102.204  | 1.93756 |     0.2085 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      4 |         101.61   | 1.39342 |     0.4961 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [1, 16000] loss: 0.289 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-06-27 19:49:03 (running for 00:02:04.63)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      4 |         102.204  | 1.93756 |     0.2085 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      2 |          81.6075 | 1.39064 |     0.506  |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      2 |          82.4124 | 1.35363 |     0.5112 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      4 |         101.61   | 1.39342 |     0.4961 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [1, 20000] loss: 0.231 [repeated 2x across cluster]
    Result for train_cifar_60711_00001:
      accuracy: 0.5237
      date: 2023-06-27_19-49-06
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 3
      loss: 1.3257854025840758
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 120.77582907676697
      time_this_iter_s: 39.16835284233093
      time_total_s: 120.77582907676697
      timestamp: 1687895346
      training_iteration: 3
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5323
      date: 2023-06-27_19-49-08
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 3
      loss: 1.306439866733551
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 122.12102365493774
      time_this_iter_s: 39.708627462387085
      time_total_s: 122.12102365493774
      timestamp: 1687895348
      training_iteration: 3
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:49:08 (running for 00:02:10.28)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.8325410439491272
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      4 |         102.204  | 1.93756 |     0.2085 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      3 |         120.776  | 1.32579 |     0.5237 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00003 | RUNNING    | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      3 |         122.121  | 1.30644 |     0.5323 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      4 |         101.61   | 1.39342 |     0.4961 |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.1999
      date: 2023-06-27_19-49-09
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 5
      loss: 1.9045727767944336
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 127.30854058265686
      time_this_iter_s: 25.10500741004944
      time_total_s: 127.30854058265686
      timestamp: 1687895349
      training_iteration: 5
      trial_id: '60711_00000'
  
    Result for train_cifar_60711_00007:
      accuracy: 0.522
      date: 2023-06-27_19-49-12
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 5
      loss: 1.3355704026222228
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 126.4055769443512
      time_this_iter_s: 24.795361518859863
      time_total_s: 126.4055769443512
      timestamp: 1687895352
      training_iteration: 5
      trial_id: '60711_00007'
  
    Result for train_cifar_60711_00003:
      accuracy: 0.0982
      date: 2023-06-27_19-49-12
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.4065849930763243
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 126.66957473754883
      time_this_iter_s: 126.66957473754883
      time_total_s: 126.66957473754883
      timestamp: 1687895352
      training_iteration: 1
      trial_id: '60711_00003'
  
    Trial train_cifar_60711_00003 completed.
    (func pid=2805) [1, 16000] loss: 0.292 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-27 19:49:17 (running for 00:02:19.48)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -1.975084494972229
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      5 |         127.309  | 1.90457 |     0.1999 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      3 |         120.776  | 1.32579 |     0.5237 |
    | train_cifar_60711_00002 | RUNNING    | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |        |                  |         |            |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      3 |         122.121  | 1.30644 |     0.5323 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      5 |         126.406  | 1.33557 |     0.522  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00002:
      accuracy: 0.1035
      date: 2023-06-27_19-49-22
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.308182253932953
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 136.13190126419067
      time_this_iter_s: 136.13190126419067
      time_total_s: 136.13190126419067
      timestamp: 1687895362
      training_iteration: 1
      trial_id: '60711_00002'
  
    Trial train_cifar_60711_00002 completed.
    (func pid=2705) [6,  2000] loss: 1.897 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-27 19:49:27 (running for 00:02:29.12)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.13508589220047
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      5 |         127.309  | 1.90457 |     0.1999 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      3 |         120.776  | 1.32579 |     0.5237 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      3 |         122.121  | 1.30644 |     0.5323 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      5 |         126.406  | 1.33557 |     0.522  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [4,  4000] loss: 0.620 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:49:32 (running for 00:02:34.14)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.13508589220047
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      5 |         127.309  | 1.90457 |     0.1999 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      3 |         120.776  | 1.32579 |     0.5237 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      3 |         122.121  | 1.30644 |     0.5323 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      5 |         126.406  | 1.33557 |     0.522  |
    | train_cifar_60711_00008 | RUNNING    | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |        |                  |         |            |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.1997
      date: 2023-06-27_19-49-32
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 6
      loss: 1.8932143394470216
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 150.4739532470703
      time_this_iter_s: 23.165412664413452
      time_total_s: 150.4739532470703
      timestamp: 1687895372
      training_iteration: 6
      trial_id: '60711_00000'
  
    Result for train_cifar_60711_00008:
      accuracy: 0.0928
      date: 2023-06-27_19-49-34
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.312750269365311
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 120.4661819934845
      time_this_iter_s: 120.4661819934845
      time_total_s: 120.4661819934845
      timestamp: 1687895374
      training_iteration: 1
      trial_id: '60711_00008'
  
    Trial train_cifar_60711_00008 completed.
    Result for train_cifar_60711_00007:
      accuracy: 0.5273
      date: 2023-06-27_19-49-35
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 6
      loss: 1.3227106948852538
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 148.98340916633606
      time_this_iter_s: 22.577832221984863
      time_total_s: 148.98340916633606
      timestamp: 1687895375
      training_iteration: 6
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:49:40 (running for 00:02:41.97)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.6654890340805055 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.295087289428711
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      6 |         150.474  | 1.89321 |     0.1997 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      3 |         120.776  | 1.32579 |     0.5237 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      3 |         122.121  | 1.30644 |     0.5323 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      6 |         148.983  | 1.32271 |     0.5273 |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5565
      date: 2023-06-27_19-49-42
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 4
      loss: 1.2612534660100936
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 156.48354244232178
      time_this_iter_s: 35.70771336555481
      time_total_s: 156.48354244232178
      timestamp: 1687895382
      training_iteration: 4
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5436
      date: 2023-06-27_19-49-44
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 4
      loss: 1.264608622121811
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 157.7803816795349
      time_this_iter_s: 35.65935802459717
      time_total_s: 157.7803816795349
      timestamp: 1687895384
      training_iteration: 4
      trial_id: '60711_00005'
  
    (func pid=2705) [7,  2000] loss: 1.888 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:49:49 (running for 00:02:50.93)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.295087289428711
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      6 |         150.474  | 1.89321 |     0.1997 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      4 |         156.484  | 1.26125 |     0.5565 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      4 |         157.78   | 1.26461 |     0.5436 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      6 |         148.983  | 1.32271 |     0.5273 |
    | train_cifar_60711_00009 | RUNNING    | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |        |                  |         |            |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00009:
      accuracy: 0.1005
      date: 2023-06-27_19-49-50
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 1
      loss: 2.3552214175701143
      node_ip: 172.17.0.2
      pid: 2805
      should_checkpoint: true
      time_since_restore: 118.70375657081604
      time_this_iter_s: 118.70375657081604
      time_total_s: 118.70375657081604
      timestamp: 1687895390
      training_iteration: 1
      trial_id: '60711_00009'
  
    Trial train_cifar_60711_00009 completed.
    (func pid=2795) [5,  2000] loss: 1.196 [repeated 2x across cluster]
    Result for train_cifar_60711_00000:
      accuracy: 0.211
      date: 2023-06-27_19-49-54
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 7
      loss: 1.90322094745636
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 171.96285009384155
      time_this_iter_s: 21.48889684677124
      time_total_s: 171.96285009384155
      timestamp: 1687895394
      training_iteration: 7
      trial_id: '60711_00000'
  
    Result for train_cifar_60711_00007:
      accuracy: 0.5474
      date: 2023-06-27_19-49-56
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 7
      loss: 1.2880014256477357
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 169.8680760860443
      time_this_iter_s: 20.884666919708252
      time_total_s: 169.8680760860443
      timestamp: 1687895396
      training_iteration: 7
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:49:56 (running for 00:02:57.85)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      7 |         171.963  | 1.90322 |     0.211  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      4 |         156.484  | 1.26125 |     0.5565 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      4 |         157.78   | 1.26461 |     0.5436 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      7 |         169.868  | 1.288   |     0.5474 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:50:01 (running for 00:03:02.86)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      7 |         171.963  | 1.90322 |     0.211  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      4 |         156.484  | 1.26125 |     0.5565 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      4 |         157.78   | 1.26461 |     0.5436 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      7 |         169.868  | 1.288   |     0.5474 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [5,  4000] loss: 0.608 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:50:06 (running for 00:03:07.87)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      7 |         171.963  | 1.90322 |     0.211  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      4 |         156.484  | 1.26125 |     0.5565 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      4 |         157.78   | 1.26461 |     0.5436 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      7 |         169.868  | 1.288   |     0.5474 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2807) [8,  2000] loss: 1.197 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-27 19:50:11 (running for 00:03:12.88)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      7 |         171.963  | 1.90322 |     0.211  |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      4 |         156.484  | 1.26125 |     0.5565 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      4 |         157.78   | 1.26461 |     0.5436 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      7 |         169.868  | 1.288   |     0.5474 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5809
      date: 2023-06-27_19-50-14
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 5
      loss: 1.1925883640289308
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 187.97322130203247
      time_this_iter_s: 31.489678859710693
      time_total_s: 187.97322130203247
      timestamp: 1687895414
      training_iteration: 5
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00000:
      accuracy: 0.2101
      date: 2023-06-27_19-50-14
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 8
      loss: 1.8771805463790894
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 192.23619556427002
      time_this_iter_s: 20.273345470428467
      time_total_s: 192.23619556427002
      timestamp: 1687895414
      training_iteration: 8
      trial_id: '60711_00000'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5563
      date: 2023-06-27_19-50-15
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 5
      loss: 1.2290185514211656
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 189.3402783870697
      time_this_iter_s: 31.55989670753479
      time_total_s: 189.3402783870697
      timestamp: 1687895415
      training_iteration: 5
      trial_id: '60711_00005'
  
    Result for train_cifar_60711_00007:
      accuracy: 0.5522
      date: 2023-06-27_19-50-16
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 8
      loss: 1.3003132850646972
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 189.80147552490234
      time_this_iter_s: 19.933399438858032
      time_total_s: 189.80147552490234
      timestamp: 1687895416
      training_iteration: 8
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:50:21 (running for 00:03:22.80)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      8 |         192.236  | 1.87718 |     0.2101 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      5 |         187.973  | 1.19259 |     0.5809 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      5 |         189.34   | 1.22902 |     0.5563 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      8 |         189.801  | 1.30031 |     0.5522 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [6,  2000] loss: 1.169
    == Status ==
    Current time: 2023-06-27 19:50:26 (running for 00:03:27.80)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      8 |         192.236  | 1.87718 |     0.2101 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      5 |         187.973  | 1.19259 |     0.5809 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      5 |         189.34   | 1.22902 |     0.5563 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      8 |         189.801  | 1.30031 |     0.5522 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2803) [6,  2000] loss: 1.124
    == Status ==
    Current time: 2023-06-27 19:50:31 (running for 00:03:32.81)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      8 |         192.236  | 1.87718 |     0.2101 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      5 |         187.973  | 1.19259 |     0.5809 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      5 |         189.34   | 1.22902 |     0.5563 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      8 |         189.801  | 1.30031 |     0.5522 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.2194
      date: 2023-06-27_19-50-34
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 9
      loss: 1.8612128543853759
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 212.95205879211426
      time_this_iter_s: 20.71586322784424
      time_total_s: 212.95205879211426
      timestamp: 1687895434
      training_iteration: 9
      trial_id: '60711_00000'
  
    (func pid=2795) [6,  4000] loss: 0.591 [repeated 3x across cluster]
    Result for train_cifar_60711_00007:
      accuracy: 0.5514
      date: 2023-06-27_19-50-35
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 9
      loss: 1.3035659433364868
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 209.42027187347412
      time_this_iter_s: 19.618796348571777
      time_total_s: 209.42027187347412
      timestamp: 1687895435
      training_iteration: 9
      trial_id: '60711_00007'
  
    == Status ==
    Current time: 2023-06-27 19:50:40 (running for 00:03:42.41)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      9 |         212.952  | 1.86121 |     0.2194 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      5 |         187.973  | 1.19259 |     0.5809 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      5 |         189.34   | 1.22902 |     0.5563 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      9 |         209.42   | 1.30357 |     0.5514 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5757
      date: 2023-06-27_19-50-45
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 6
      loss: 1.2051042447090148
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 218.8809516429901
      time_this_iter_s: 30.90773034095764
      time_total_s: 218.8809516429901
      timestamp: 1687895445
      training_iteration: 6
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5746
      date: 2023-06-27_19-50-47
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 6
      loss: 1.1864479997396469
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 220.70547461509705
      time_this_iter_s: 31.365196228027344
      time_total_s: 220.70547461509705
      timestamp: 1687895447
      training_iteration: 6
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:50:47 (running for 00:03:48.85)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      9 |         212.952  | 1.86121 |     0.2194 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      6 |         218.881  | 1.2051  |     0.5757 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      6 |         220.705  | 1.18645 |     0.5746 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      9 |         209.42   | 1.30357 |     0.5514 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2705) [10,  2000] loss: 1.862 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:50:52 (running for 00:03:53.86)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | RUNNING    | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |      9 |         212.952  | 1.86121 |     0.2194 |
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      6 |         218.881  | 1.2051  |     0.5757 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      6 |         220.705  | 1.18645 |     0.5746 |
    | train_cifar_60711_00007 | RUNNING    | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |      9 |         209.42   | 1.30357 |     0.5514 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00000:
      accuracy: 0.221
      date: 2023-06-27_19-50-55
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 10
      loss: 1.8565652458190918
      node_ip: 172.17.0.2
      pid: 2705
      should_checkpoint: true
      time_since_restore: 233.56497502326965
      time_this_iter_s: 20.612916231155396
      time_total_s: 233.56497502326965
      timestamp: 1687895455
      training_iteration: 10
      trial_id: '60711_00000'
  
    Trial train_cifar_60711_00000 completed.
    Result for train_cifar_60711_00007:
      accuracy: 0.5287
      date: 2023-06-27_19-50-55
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 10
      loss: 1.350373654460907
      node_ip: 172.17.0.2
      pid: 2807
      should_checkpoint: true
      time_since_restore: 229.31942415237427
      time_this_iter_s: 19.899152278900146
      time_total_s: 229.31942415237427
      timestamp: 1687895455
      training_iteration: 10
      trial_id: '60711_00007'
  
    Trial train_cifar_60711_00007 completed.
    (func pid=2795) [7,  2000] loss: 1.134 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:51:00 (running for 00:04:02.31)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      6 |         218.881  | 1.2051  |     0.5757 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      6 |         220.705  | 1.18645 |     0.5746 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [7,  4000] loss: 0.576 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:51:05 (running for 00:04:07.32)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      6 |         218.881  | 1.2051  |     0.5757 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      6 |         220.705  | 1.18645 |     0.5746 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:51:10 (running for 00:04:12.33)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      6 |         218.881  | 1.2051  |     0.5757 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      6 |         220.705  | 1.18645 |     0.5746 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5784
      date: 2023-06-27_19-51-12
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 7
      loss: 1.2271354457378387
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 246.72997117042542
      time_this_iter_s: 27.849019527435303
      time_total_s: 246.72997117042542
      timestamp: 1687895472
      training_iteration: 7
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5655
      date: 2023-06-27_19-51-14
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 7
      loss: 1.2378231977820398
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 248.1411488056183
      time_this_iter_s: 27.43567419052124
      time_total_s: 248.1411488056183
      timestamp: 1687895474
      training_iteration: 7
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:51:19 (running for 00:04:21.29)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      7 |         246.73   | 1.22714 |     0.5784 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      7 |         248.141  | 1.23782 |     0.5655 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [8,  2000] loss: 1.111 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:51:24 (running for 00:04:26.30)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      7 |         246.73   | 1.22714 |     0.5784 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      7 |         248.141  | 1.23782 |     0.5655 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:51:29 (running for 00:04:31.31)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      7 |         246.73   | 1.22714 |     0.5784 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      7 |         248.141  | 1.23782 |     0.5655 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [8,  4000] loss: 0.560 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:51:34 (running for 00:04:36.32)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5887469157218934 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      7 |         246.73   | 1.22714 |     0.5784 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      7 |         248.141  | 1.23782 |     0.5655 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5713
      date: 2023-06-27_19-51-38
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 8
      loss: 1.2253247736573218
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 272.67735385894775
      time_this_iter_s: 25.94738268852234
      time_total_s: 272.67735385894775
      timestamp: 1687895498
      training_iteration: 8
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.5931
      date: 2023-06-27_19-51-40
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 8
      loss: 1.1549287165284157
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 274.1655180454254
      time_this_iter_s: 26.02436923980713
      time_total_s: 274.1655180454254
      timestamp: 1687895500
      training_iteration: 8
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:51:40 (running for 00:04:42.31)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      8 |         272.677  | 1.22532 |     0.5713 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      8 |         274.166  | 1.15493 |     0.5931 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:51:45 (running for 00:04:47.32)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      8 |         272.677  | 1.22532 |     0.5713 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      8 |         274.166  | 1.15493 |     0.5931 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [9,  2000] loss: 1.087 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:51:50 (running for 00:04:52.34)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      8 |         272.677  | 1.22532 |     0.5713 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      8 |         274.166  | 1.15493 |     0.5931 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:51:55 (running for 00:04:57.34)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      8 |         272.677  | 1.22532 |     0.5713 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      8 |         274.166  | 1.15493 |     0.5931 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [9,  4000] loss: 0.560 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:52:00 (running for 00:05:02.35)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      8 |         272.677  | 1.22532 |     0.5713 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      8 |         274.166  | 1.15493 |     0.5931 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5899
      date: 2023-06-27_19-52-04
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 9
      loss: 1.197448928272724
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 298.3788299560547
      time_this_iter_s: 25.701476097106934
      time_total_s: 298.3788299560547
      timestamp: 1687895524
      training_iteration: 9
      trial_id: '60711_00001'
  
    Result for train_cifar_60711_00005:
      accuracy: 0.6021
      date: 2023-06-27_19-52-06
      done: false
      hostname: b3f40279dde7
      iterations_since_restore: 9
      loss: 1.1393122973799705
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 300.2247130870819
      time_this_iter_s: 26.059195041656494
      time_total_s: 300.2247130870819
      timestamp: 1687895526
      training_iteration: 9
      trial_id: '60711_00005'
  
    == Status ==
    Current time: 2023-06-27 19:52:06 (running for 00:05:08.37)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      9 |         298.379  | 1.19745 |     0.5899 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      9 |         300.225  | 1.13931 |     0.6021 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:52:11 (running for 00:05:13.38)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      9 |         298.379  | 1.19745 |     0.5899 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      9 |         300.225  | 1.13931 |     0.6021 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [10,  2000] loss: 1.068 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:52:16 (running for 00:05:18.39)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      9 |         298.379  | 1.19745 |     0.5899 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      9 |         300.225  | 1.13931 |     0.6021 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:52:21 (running for 00:05:23.40)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      9 |         298.379  | 1.19745 |     0.5899 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      9 |         300.225  | 1.13931 |     0.6021 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [10,  4000] loss: 0.545 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-27 19:52:26 (running for 00:05:28.41)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00001 | RUNNING    | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |      9 |         298.379  | 1.19745 |     0.5899 |
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |      9 |         300.225  | 1.13931 |     0.6021 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_60711_00001:
      accuracy: 0.5978
      date: 2023-06-27_19-52-30
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 10
      loss: 1.1712237627625466
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 324.26750564575195
      time_this_iter_s: 25.888675689697266
      time_total_s: 324.26750564575195
      timestamp: 1687895550
      training_iteration: 10
      trial_id: '60711_00001'
  
    Trial train_cifar_60711_00001 completed.
    Result for train_cifar_60711_00005:
      accuracy: 0.5949
      date: 2023-06-27_19-52-32
      done: true
      hostname: b3f40279dde7
      iterations_since_restore: 10
      loss: 1.144731771683693
      node_ip: 172.17.0.2
      pid: 2803
      should_checkpoint: true
      time_since_restore: 326.0970547199249
      time_this_iter_s: 25.872341632843018
      time_total_s: 326.0970547199249
      timestamp: 1687895552
      training_iteration: 10
      trial_id: '60711_00005'
  
    Trial train_cifar_60711_00005 completed.
    == Status ==
    Current time: 2023-06-27 19:52:32 (running for 00:05:34.24)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00005 | RUNNING    | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |     10 |         326.097  | 1.14473 |     0.5949 |
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00001 | TERMINATED | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |     10 |         324.268  | 1.17122 |     0.5978 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-27 19:52:32 (running for 00:05:34.25)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2628190293610095 | Iter 4.000: -1.3290120207548142 | Iter 2.000: -1.42500235465765 | Iter 1.000: -2.301634771680832
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-27_19-46-58
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_60711_00000 | TERMINATED | 172.17.0.2:2705 |           16 |    2 |  128 | 0.000225135 |     10 |         233.565  | 1.85657 |     0.221  |
    | train_cifar_60711_00001 | TERMINATED | 172.17.0.2:2795 |            8 |   16 |   32 | 0.00205082  |     10 |         324.268  | 1.17122 |     0.5978 |
    | train_cifar_60711_00002 | TERMINATED | 172.17.0.2:2797 |            2 |  128 |    2 | 0.00287367  |      1 |         136.132  | 2.30818 |     0.1035 |
    | train_cifar_60711_00003 | TERMINATED | 172.17.0.2:2799 |            2 |  128 |    1 | 0.089376    |      1 |         126.67   | 2.40658 |     0.0982 |
    | train_cifar_60711_00004 | TERMINATED | 172.17.0.2:2801 |           16 |    4 |   16 | 0.0517639   |      1 |          27.5781 | 2.31039 |     0.1006 |
    | train_cifar_60711_00005 | TERMINATED | 172.17.0.2:2803 |            8 |   32 |   64 | 0.00122456  |     10 |         326.097  | 1.14473 |     0.5949 |
    | train_cifar_60711_00006 | TERMINATED | 172.17.0.2:2805 |            8 |  256 |  128 | 0.000358709 |      1 |          45.5716 | 1.97508 |     0.3033 |
    | train_cifar_60711_00007 | TERMINATED | 172.17.0.2:2807 |           16 |   32 |    4 | 0.00392051  |     10 |         229.319  | 1.35037 |     0.5287 |
    | train_cifar_60711_00008 | TERMINATED | 172.17.0.2:2801 |            2 |    1 |   64 | 0.00707483  |      1 |         120.466  | 2.31275 |     0.0928 |
    | train_cifar_60711_00009 | TERMINATED | 172.17.0.2:2805 |            2 |    4 |  128 | 0.0295926   |      1 |         118.704  | 2.35522 |     0.1005 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-06-27 19:52:32,639 INFO tune.py:945 -- Total run time: 334.54 seconds (334.25 seconds for the tuning loop).
    Best trial config: {'l1': 32, 'l2': 64, 'lr': 0.0012245636172363763, 'batch_size': 8}
    Best trial final validation loss: 1.144731771683693
    Best trial final validation accuracy: 0.5949
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.6075




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  53.095 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

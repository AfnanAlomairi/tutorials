
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 720896/170498071 [00:00<00:23, 7206406.84it/s]
      4% 6750208/170498071 [00:00<00:04, 38406786.03it/s]
      9% 14548992/170498071 [00:00<00:02, 56390556.94it/s]
     13% 22413312/170498071 [00:00<00:02, 65155917.64it/s]
     18% 30343168/170498071 [00:00<00:01, 70194188.11it/s]
     22% 38338560/170498071 [00:00<00:01, 73407953.53it/s]
     27% 46465024/170498071 [00:00<00:01, 75776326.97it/s]
     32% 54624256/170498071 [00:00<00:01, 77410230.00it/s]
     37% 62783488/170498071 [00:00<00:01, 78639720.12it/s]
     42% 70909952/170498071 [00:01<00:01, 79428837.21it/s]
     46% 79069184/170498071 [00:01<00:01, 80054520.94it/s]
     51% 87425024/170498071 [00:01<00:01, 81074004.77it/s]
     56% 95911936/170498071 [00:01<00:00, 82016227.11it/s]
     61% 104497152/170498071 [00:01<00:00, 83078846.55it/s]
     66% 113246208/170498071 [00:01<00:00, 84239780.32it/s]
     72% 121962496/170498071 [00:01<00:00, 85025108.23it/s]
     77% 130744320/170498071 [00:01<00:00, 85678465.66it/s]
     82% 139591680/170498071 [00:01<00:00, 86411257.03it/s]
     87% 148635648/170498071 [00:01<00:00, 87601176.62it/s]
     93% 157745152/170498071 [00:02<00:00, 88595493.00it/s]
     98% 166920192/170498071 [00:02<00:00, 89421432.93it/s]
    100% 170498071/170498071 [00:02<00:00, 79356653.95it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-06-28 17:06:13,053 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-06-28 17:06:13,295 INFO worker.py:1625 -- Started a local Ray instance.
    2023-06-28 17:06:14,553 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-06-28 17:06:18 (running for 00:00:03.66)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2720) Files already downloaded and verified
    (func pid=2720) Files already downloaded and verified
    == Status ==
    Current time: 2023-06-28 17:06:23 (running for 00:00:08.71)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2802) Files already downloaded and verified [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-06-28 17:06:28 (running for 00:00:13.72)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2720) [1,  2000] loss: 2.321
    (func pid=2814) Files already downloaded and verified [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-28 17:06:33 (running for 00:00:18.73)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2802) [1,  2000] loss: 2.315
    (func pid=2808) [1,  2000] loss: 2.332
    == Status ==
    Current time: 2023-06-28 17:06:38 (running for 00:00:23.74)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-06-28 17:06:43 (running for 00:00:28.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2802) [1,  4000] loss: 1.155 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-06-28 17:06:48 (running for 00:00:33.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2814) [1,  4000] loss: 0.776 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-06-28 17:06:53 (running for 00:00:38.77)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-06-28 17:06:58 (running for 00:00:43.78)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2720) [1,  8000] loss: 0.537 [repeated 4x across cluster]
    Result for train_cifar_16daf_00006:
      accuracy: 0.1347
      date: 2023-06-28_17-07-02
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.3087830116271975
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 39.46677780151367
      time_this_iter_s: 39.46677780151367
      time_total_s: 39.46677780151367
      timestamp: 1687972022
      training_iteration: 1
      trial_id: 16daf_00006
  
    Result for train_cifar_16daf_00003:
      accuracy: 0.2187
      date: 2023-06-28_17-07-03
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.0532518350601197
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 41.060097455978394
      time_this_iter_s: 41.060097455978394
      time_total_s: 41.060097455978394
      timestamp: 1687972023
      training_iteration: 1
      trial_id: 16daf_00003
  
    == Status ==
    Current time: 2023-06-28 17:07:03 (running for 00:00:48.90)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1810174233436586
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.4691
      date: 2023-06-28_17-07-05
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 1.566756452727318
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 43.05467367172241
      time_this_iter_s: 43.05467367172241
      time_total_s: 43.05467367172241
      timestamp: 1687972025
      training_iteration: 1
      trial_id: 16daf_00007
  
    (func pid=2802) [1,  8000] loss: 0.578 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:10 (running for 00:00:56.13)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0532518350601197
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [1,  8000] loss: 0.535 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:15 (running for 00:01:01.14)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0532518350601197
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [1, 12000] loss: 0.338 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:20 (running for 00:01:06.15)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0532518350601197
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:07:25 (running for 00:01:11.16)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0532518350601197
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING  | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00001 | RUNNING  | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING  | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING  | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00004 | RUNNING  | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_16daf_00005 | RUNNING  | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_16daf_00006 | RUNNING  | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING  | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2812) [2,  4000] loss: 1.142 [repeated 2x across cluster]
    Result for train_cifar_16daf_00004:
      accuracy: 0.1023
      date: 2023-06-28_17-07-27
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.321089620399475
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 65.49761366844177
      time_this_iter_s: 65.49761366844177
      time_total_s: 65.49761366844177
      timestamp: 1687972047
      training_iteration: 1
      trial_id: 16daf_00004
  
    Trial train_cifar_16daf_00004 completed.
    Result for train_cifar_16daf_00001:
      accuracy: 0.1021
      date: 2023-06-28_17-07-28
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.306731057548523
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 65.64548182487488
      time_this_iter_s: 65.64548182487488
      time_total_s: 65.64548182487488
      timestamp: 1687972048
      training_iteration: 1
      trial_id: 16daf_00001
  
    Trial train_cifar_16daf_00001 completed.
    Result for train_cifar_16daf_00005:
      accuracy: 0.2759
      date: 2023-06-28_17-07-28
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 1.8724868838787079
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 65.46739888191223
      time_this_iter_s: 65.46739888191223
      time_total_s: 65.46739888191223
      timestamp: 1687972048
      training_iteration: 1
      trial_id: 16daf_00005
  
    (func pid=2808) Files already downloaded and verified
    == Status ==
    Current time: 2023-06-28 17:07:33 (running for 00:01:18.44)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [2,  4000] loss: 0.673 [repeated 4x across cluster]
    (func pid=2808) Files already downloaded and verified [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:38 (running for 00:01:23.45)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      1 |          41.0601 | 2.05325 |     0.2187 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      1 |          39.4668 | 2.30878 |     0.1347 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [1, 16000] loss: 0.245
    (func pid=2810) [2,  2000] loss: 1.813
    Result for train_cifar_16daf_00006:
      accuracy: 0.1343
      date: 2023-06-28_17-07-39
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 2.237128422832489
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 76.80896210670471
      time_this_iter_s: 37.34218430519104
      time_total_s: 76.80896210670471
      timestamp: 1687972059
      training_iteration: 2
      trial_id: 16daf_00006
  
    Result for train_cifar_16daf_00003:
      accuracy: 0.1952
      date: 2023-06-28_17-07-43
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 2.1338038162231445
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 81.42240262031555
      time_this_iter_s: 40.36230516433716
      time_total_s: 81.42240262031555
      timestamp: 1687972063
      training_iteration: 2
      trial_id: 16daf_00003
  
    == Status ==
    Current time: 2023-06-28 17:07:43 (running for 00:01:29.27)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.185466119527817 | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      1 |          43.0547 | 1.56676 |     0.4691 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.53
      date: 2023-06-28_17-07-46
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 1.3110764907836914
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 84.0952639579773
      time_this_iter_s: 41.04059028625488
      time_total_s: 84.0952639579773
      timestamp: 1687972066
      training_iteration: 2
      trial_id: 16daf_00007
  
    (func pid=2720) [1, 18000] loss: 0.219 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:51 (running for 00:01:37.15)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [1, 14000] loss: 0.312 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-28 17:07:56 (running for 00:01:42.17)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:08:01 (running for 00:01:47.18)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2812) [3,  4000] loss: 1.078 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-06-28 17:08:06 (running for 00:01:52.19)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.1799914463043213
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [1, 16000] loss: 0.267 [repeated 2x across cluster]
    Result for train_cifar_16daf_00008:
      accuracy: 0.2106
      date: 2023-06-28_17-08-11
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.0189909918785096
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 43.05054426193237
      time_this_iter_s: 43.05054426193237
      time_total_s: 43.05054426193237
      timestamp: 1687972091
      training_iteration: 1
      trial_id: 16daf_00008
  
    == Status ==
    Current time: 2023-06-28 17:08:16 (running for 00:02:01.34)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      2 |          76.809  | 2.23713 |     0.1343 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00000:
      accuracy: 0.1934
      date: 2023-06-28_17-08-16
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 1.9411277861595153
      node_ip: 172.17.0.2
      pid: 2720
      should_checkpoint: true
      time_since_restore: 118.00849509239197
      time_this_iter_s: 118.00849509239197
      time_total_s: 118.00849509239197
      timestamp: 1687972096
      training_iteration: 1
      trial_id: 16daf_00000
  
    Result for train_cifar_16daf_00006:
      accuracy: 0.2035
      date: 2023-06-28_17-08-17
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 3
      loss: 2.1151227341651917
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 114.33602499961853
      time_this_iter_s: 37.52706289291382
      time_total_s: 114.33602499961853
      timestamp: 1687972097
      training_iteration: 3
      trial_id: 16daf_00006
  
    (func pid=2802) [1, 10000] loss: 0.466 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-28 17:08:22 (running for 00:02:07.47)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      2 |          81.4224 | 2.1338  |     0.1952 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      2 |          84.0953 | 1.31108 |     0.53   |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00003:
      accuracy: 0.2287
      date: 2023-06-28_17-08-24
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 3
      loss: 2.026604787158966
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 122.40385818481445
      time_this_iter_s: 40.9814555644989
      time_total_s: 122.40385818481445
      timestamp: 1687972104
      training_iteration: 3
      trial_id: 16daf_00003
  
    (func pid=2804) [1, 18000] loss: 0.245 [repeated 2x across cluster]
    Result for train_cifar_16daf_00007:
      accuracy: 0.5705
      date: 2023-06-28_17-08-27
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 3
      loss: 1.23697958650589
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 125.05562829971313
      time_this_iter_s: 40.96036434173584
      time_total_s: 125.05562829971313
      timestamp: 1687972107
      training_iteration: 3
      trial_id: 16daf_00007
  
    == Status ==
    Current time: 2023-06-28 17:08:27 (running for 00:02:13.12)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1338038162231445 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      1 |          65.4674 | 1.87249 |     0.2759 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [1, 12000] loss: 0.390 [repeated 3x across cluster]
    Result for train_cifar_16daf_00005:
      accuracy: 0.402
      date: 2023-06-28_17-08-31
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 1.6051035281419754
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 128.89464592933655
      time_this_iter_s: 63.427247047424316
      time_total_s: 128.89464592933655
      timestamp: 1687972111
      training_iteration: 2
      trial_id: 16daf_00005
  
    == Status ==
    Current time: 2023-06-28 17:08:36 (running for 00:02:21.85)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8694536721825599 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [2,  4000] loss: 0.976 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:08:41 (running for 00:02:26.87)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8694536721825599 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [3,  2000] loss: 1.576 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-28 17:08:46 (running for 00:02:31.88)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8694536721825599 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [1, 16000] loss: 0.292 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:08:51 (running for 00:02:36.89)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8694536721825599 | Iter 1.000: -2.0361214134693144
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      3 |         114.336  | 2.11512 |     0.2035 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00008 | RUNNING    | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      1 |          43.0505 | 2.01899 |     0.2106 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00006:
      accuracy: 0.2357
      date: 2023-06-28_17-08-54
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 4
      loss: 2.0243881915092468
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 152.11136555671692
      time_this_iter_s: 37.77534055709839
      time_total_s: 152.11136555671692
      timestamp: 1687972134
      training_iteration: 4
      trial_id: 16daf_00006
  
    Result for train_cifar_16daf_00008:
      accuracy: 0.1968
      date: 2023-06-28_17-08-55
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 2.0452320264816284
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 87.13066387176514
      time_this_iter_s: 44.080119609832764
      time_total_s: 87.13066387176514
      timestamp: 1687972135
      training_iteration: 2
      trial_id: 16daf_00008
  
    Trial train_cifar_16daf_00008 completed.
    (func pid=2814) [4,  4000] loss: 0.582 [repeated 3x across cluster]
    Result for train_cifar_16daf_00002:
      accuracy: 0.189
      date: 2023-06-28_17-08-56
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.1410289043068884
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 154.24057364463806
      time_this_iter_s: 154.24057364463806
      time_total_s: 154.24057364463806
      timestamp: 1687972136
      training_iteration: 1
      trial_id: 16daf_00002
  
    Trial train_cifar_16daf_00002 completed.
    == Status ==
    Current time: 2023-06-28 17:08:56 (running for 00:02:42.11)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00002 | RUNNING    | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:09:01 (running for 00:02:47.14)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00003 | RUNNING    | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      3 |         122.404  | 2.0266  |     0.2287 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      3 |         125.056  | 1.23698 |     0.5705 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [3,  6000] loss: 0.500 [repeated 3x across cluster]
    Result for train_cifar_16daf_00003:
      accuracy: 0.1768
      date: 2023-06-28_17-09-04
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 4
      loss: 2.221662014102936
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 162.3601655960083
      time_this_iter_s: 39.95630741119385
      time_total_s: 162.3601655960083
      timestamp: 1687972144
      training_iteration: 4
      trial_id: 16daf_00003
  
    Trial train_cifar_16daf_00003 completed.
    Result for train_cifar_16daf_00007:
      accuracy: 0.5741
      date: 2023-06-28_17-09-07
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 4
      loss: 1.2204368638277054
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 164.3860523700714
      time_this_iter_s: 39.330424070358276
      time_total_s: 164.3860523700714
      timestamp: 1687972147
      training_iteration: 4
      trial_id: 16daf_00007
  
    == Status ==
    Current time: 2023-06-28 17:09:07 (running for 00:02:52.44)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:09:12 (running for 00:02:57.46)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [3,  8000] loss: 0.372 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-28 17:09:17 (running for 00:03:02.46)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.0532518350601197
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00009 | RUNNING    | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [5,  2000] loss: 1.072 [repeated 3x across cluster]
    Result for train_cifar_16daf_00009:
      accuracy: 0.1023
      date: 2023-06-28_17-09-21
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 1
      loss: 2.318095682191849
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 113.59256911277771
      time_this_iter_s: 113.59256911277771
      time_total_s: 113.59256911277771
      timestamp: 1687972161
      training_iteration: 1
      trial_id: 16daf_00009
  
    Trial train_cifar_16daf_00009 completed.
    == Status ==
    Current time: 2023-06-28 17:09:26 (running for 00:03:11.99)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      2 |         128.895  | 1.6051  |     0.402  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      4 |         152.111  | 2.02439 |     0.2357 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00006:
      accuracy: 0.2639
      date: 2023-06-28_17-09-26
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 5
      loss: 1.9106819994926452
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 184.13689064979553
      time_this_iter_s: 32.02552509307861
      time_total_s: 184.13689064979553
      timestamp: 1687972166
      training_iteration: 5
      trial_id: 16daf_00006
  
    Result for train_cifar_16daf_00005:
      accuracy: 0.465
      date: 2023-06-28_17-09-28
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 3
      loss: 1.4398188601732254
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 186.3085219860077
      time_this_iter_s: 57.41387605667114
      time_total_s: 186.3085219860077
      timestamp: 1687972168
      training_iteration: 3
      trial_id: 16daf_00005
  
    (func pid=2814) [5,  4000] loss: 0.551 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:09:33 (running for 00:03:19.26)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      5 |         184.137  | 1.91068 |     0.2639 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2812) [6,  2000] loss: 1.900 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:09:38 (running for 00:03:24.28)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      5 |         184.137  | 1.91068 |     0.2639 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      4 |         164.386  | 1.22044 |     0.5741 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.5806
      date: 2023-06-28_17-09-40
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 5
      loss: 1.2411181006669998
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 197.54577350616455
      time_this_iter_s: 33.15972113609314
      time_total_s: 197.54577350616455
      timestamp: 1687972180
      training_iteration: 5
      trial_id: 16daf_00007
  
    == Status ==
    Current time: 2023-06-28 17:09:45 (running for 00:03:30.60)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      5 |         184.137  | 1.91068 |     0.2639 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      5 |         197.546  | 1.24112 |     0.5806 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [4,  4000] loss: 0.712 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:09:50 (running for 00:03:35.61)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      5 |         184.137  | 1.91068 |     0.2639 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      5 |         197.546  | 1.24112 |     0.5806 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [6,  2000] loss: 0.993 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:09:55 (running for 00:03:40.62)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0452320264816284 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      1 |         118.008  | 1.94113 |     0.1934 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      5 |         184.137  | 1.91068 |     0.2639 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      5 |         197.546  | 1.24112 |     0.5806 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00006:
      accuracy: 0.2945
      date: 2023-06-28_17-09-56
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 6
      loss: 1.8333383968353272
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 213.9331657886505
      time_this_iter_s: 29.79627513885498
      time_total_s: 213.9331657886505
      timestamp: 1687972196
      training_iteration: 6
      trial_id: 16daf_00006
  
    Result for train_cifar_16daf_00000:
      accuracy: 0.1616
      date: 2023-06-28_17-09-59
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 2
      loss: 1.9936415117740631
      node_ip: 172.17.0.2
      pid: 2720
      should_checkpoint: true
      time_since_restore: 220.9634611606598
      time_this_iter_s: 102.95496606826782
      time_total_s: 220.9634611606598
      timestamp: 1687972199
      training_iteration: 2
      trial_id: 16daf_00000
  
    (func pid=2814) [6,  4000] loss: 0.535 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:10:04 (running for 00:03:49.64)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      6 |         213.933  | 1.83334 |     0.2945 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      5 |         197.546  | 1.24112 |     0.5806 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:10:09 (running for 00:03:54.65)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      6 |         213.933  | 1.83334 |     0.2945 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      5 |         197.546  | 1.24112 |     0.5806 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [4, 10000] loss: 0.276 [repeated 4x across cluster]
    Result for train_cifar_16daf_00007:
      accuracy: 0.576
      date: 2023-06-28_17-10-12
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 6
      loss: 1.2645742503613233
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 229.72494387626648
      time_this_iter_s: 32.17917037010193
      time_total_s: 229.72494387626648
      timestamp: 1687972212
      training_iteration: 6
      trial_id: 16daf_00007
  
    (func pid=2812) [7,  4000] loss: 0.892 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:10:17 (running for 00:04:02.78)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      3 |         186.309  | 1.43982 |     0.465  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      6 |         213.933  | 1.83334 |     0.2945 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      6 |         229.725  | 1.26457 |     0.576  |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00005:
      accuracy: 0.502
      date: 2023-06-28_17-10-18
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 4
      loss: 1.3520801582932471
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 236.14693570137024
      time_this_iter_s: 49.83841371536255
      time_total_s: 236.14693570137024
      timestamp: 1687972218
      training_iteration: 4
      trial_id: 16daf_00005
  
    (func pid=2720) [3,  6000] loss: 0.650
    == Status ==
    Current time: 2023-06-28 17:10:23 (running for 00:04:09.10)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      6 |         213.933  | 1.83334 |     0.2945 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      6 |         229.725  | 1.26457 |     0.576  |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [7,  2000] loss: 0.969
    Result for train_cifar_16daf_00006:
      accuracy: 0.3506
      date: 2023-06-28_17-10-26
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 7
      loss: 1.7461219347000123
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 243.70719528198242
      time_this_iter_s: 29.77402949333191
      time_total_s: 243.70719528198242
      timestamp: 1687972226
      training_iteration: 7
      trial_id: 16daf_00006
  
    (func pid=2720) [3,  8000] loss: 0.491 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:10:31 (running for 00:04:16.83)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      7 |         243.707  | 1.74612 |     0.3506 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      6 |         229.725  | 1.26457 |     0.576  |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:10:36 (running for 00:04:21.84)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      7 |         243.707  | 1.74612 |     0.3506 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      6 |         229.725  | 1.26457 |     0.576  |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2812) [8,  2000] loss: 1.739 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:10:41 (running for 00:04:26.85)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      7 |         243.707  | 1.74612 |     0.3506 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      6 |         229.725  | 1.26457 |     0.576  |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [5,  6000] loss: 0.441 [repeated 2x across cluster]
    Result for train_cifar_16daf_00007:
      accuracy: 0.5819
      date: 2023-06-28_17-10-44
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 7
      loss: 1.294254594707489
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 261.87566089630127
      time_this_iter_s: 32.15071702003479
      time_total_s: 261.87566089630127
      timestamp: 1687972244
      training_iteration: 7
      trial_id: 16daf_00007
  
    == Status ==
    Current time: 2023-06-28 17:10:49 (running for 00:04:34.93)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      7 |         243.707  | 1.74612 |     0.3506 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      7 |         261.876  | 1.29425 |     0.5819 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [5,  8000] loss: 0.332 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:10:54 (running for 00:04:39.94)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      7 |         243.707  | 1.74612 |     0.3506 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      7 |         261.876  | 1.29425 |     0.5819 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00006:
      accuracy: 0.3731
      date: 2023-06-28_17-10-56
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 8
      loss: 1.676734697818756
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 273.62774562835693
      time_this_iter_s: 29.92055034637451
      time_total_s: 273.62774562835693
      timestamp: 1687972256
      training_iteration: 8
      trial_id: 16daf_00006
  
    (func pid=2810) [5, 10000] loss: 0.262 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:11:01 (running for 00:04:46.75)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.676734697818756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      8 |         273.628  | 1.67673 |     0.3731 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      7 |         261.876  | 1.29425 |     0.5819 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:11:06 (running for 00:04:51.76)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.676734697818756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      4 |         236.147  | 1.35208 |     0.502  |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      8 |         273.628  | 1.67673 |     0.3731 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      7 |         261.876  | 1.29425 |     0.5819 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [8,  4000] loss: 0.509 [repeated 2x across cluster]
    Result for train_cifar_16daf_00005:
      accuracy: 0.5111
      date: 2023-06-28_17-11-08
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 5
      loss: 1.3247906695902347
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 285.6422309875488
      time_this_iter_s: 49.49529528617859
      time_total_s: 285.6422309875488
      timestamp: 1687972268
      training_iteration: 5
      trial_id: 16daf_00005
  
    == Status ==
    Current time: 2023-06-28 17:11:13 (running for 00:04:58.60)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.676734697818756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      8 |         273.628  | 1.67673 |     0.3731 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      7 |         261.876  | 1.29425 |     0.5819 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.5623
      date: 2023-06-28_17-11-16
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 8
      loss: 1.3482671243011952
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 293.7901029586792
      time_this_iter_s: 31.91444206237793
      time_total_s: 293.7901029586792
      timestamp: 1687972276
      training_iteration: 8
      trial_id: 16daf_00007
  
    (func pid=2812) [9,  4000] loss: 0.817 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:11:21 (running for 00:05:06.85)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      8 |         273.628  | 1.67673 |     0.3731 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      8 |         293.79   | 1.34827 |     0.5623 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [6,  4000] loss: 0.640 [repeated 3x across cluster]
    Result for train_cifar_16daf_00006:
      accuracy: 0.4026
      date: 2023-06-28_17-11-26
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 9
      loss: 1.6201576930999755
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 303.38657689094543
      time_this_iter_s: 29.7588312625885
      time_total_s: 303.38657689094543
      timestamp: 1687972286
      training_iteration: 9
      trial_id: 16daf_00006
  
    == Status ==
    Current time: 2023-06-28 17:11:31 (running for 00:05:16.52)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      2 |         220.963  | 1.99364 |     0.1616 |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      9 |         303.387  | 1.62016 |     0.4026 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      8 |         293.79   | 1.34827 |     0.5623 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00000:
      accuracy: 0.099
      date: 2023-06-28_17-11-31
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 3
      loss: 2.3095883857250215
      node_ip: 172.17.0.2
      pid: 2720
      should_checkpoint: true
      time_since_restore: 313.23546051979065
      time_this_iter_s: 92.27199935913086
      time_total_s: 313.23546051979065
      timestamp: 1687972291
      training_iteration: 3
      trial_id: 16daf_00000
  
    (func pid=2810) [6,  6000] loss: 0.429 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:11:36 (running for 00:05:21.90)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      9 |         303.387  | 1.62016 |     0.4026 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      8 |         293.79   | 1.34827 |     0.5623 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [4,  2000] loss: 2.306 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:11:41 (running for 00:05:26.91)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      9 |         303.387  | 1.62016 |     0.4026 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      8 |         293.79   | 1.34827 |     0.5623 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2812) [10,  4000] loss: 0.797 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:11:46 (running for 00:05:31.92)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      9 |         303.387  | 1.62016 |     0.4026 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      8 |         293.79   | 1.34827 |     0.5623 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.5494
      date: 2023-06-28_17-11-48
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 9
      loss: 1.3929173778533936
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 325.71677803993225
      time_this_iter_s: 31.92667508125305
      time_total_s: 325.71677803993225
      timestamp: 1687972308
      training_iteration: 9
      trial_id: 16daf_00007
  
    == Status ==
    Current time: 2023-06-28 17:11:53 (running for 00:05:38.77)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      5 |         285.642  | 1.32479 |     0.5111 |
    | train_cifar_16daf_00006 | RUNNING    | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |      9 |         303.387  | 1.62016 |     0.4026 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      9 |         325.717  | 1.39292 |     0.5494 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00006:
      accuracy: 0.4235
      date: 2023-06-28_17-11-55
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 10
      loss: 1.5778083631038666
      node_ip: 172.17.0.2
      pid: 2812
      should_checkpoint: true
      time_since_restore: 333.03025555610657
      time_this_iter_s: 29.643678665161133
      time_total_s: 333.03025555610657
      timestamp: 1687972315
      training_iteration: 10
      trial_id: 16daf_00006
  
    Trial train_cifar_16daf_00006 completed.
    (func pid=2720) [4,  6000] loss: 0.769 [repeated 3x across cluster]
    Result for train_cifar_16daf_00005:
      accuracy: 0.5306
      date: 2023-06-28_17-11-58
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 6
      loss: 1.29856029471457
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 335.5283958911896
      time_this_iter_s: 49.88616490364075
      time_total_s: 335.5283958911896
      timestamp: 1687972318
      training_iteration: 6
      trial_id: 16daf_00005
  
    (func pid=2720) [4,  8000] loss: 0.576 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:03 (running for 00:05:48.48)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      9 |         325.717  | 1.39292 |     0.5494 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:12:08 (running for 00:05:53.50)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      9 |         325.717  | 1.39292 |     0.5494 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2814) [10,  4000] loss: 0.493 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:13 (running for 00:05:58.50)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      9 |         325.717  | 1.39292 |     0.5494 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [4, 12000] loss: 0.384 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:18 (running for 00:06:03.51)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00007 | RUNNING    | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |      9 |         325.717  | 1.39292 |     0.5494 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00007:
      accuracy: 0.5649
      date: 2023-06-28_17-12-18
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 10
      loss: 1.4206189130723477
      node_ip: 172.17.0.2
      pid: 2814
      should_checkpoint: true
      time_since_restore: 355.53072905540466
      time_this_iter_s: 29.813951015472412
      time_total_s: 355.53072905540466
      timestamp: 1687972338
      training_iteration: 10
      trial_id: 16daf_00007
  
    Trial train_cifar_16daf_00007 completed.
    == Status ==
    Current time: 2023-06-28 17:12:23 (running for 00:06:08.59)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [4, 14000] loss: 0.329 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:28 (running for 00:06:13.60)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [4, 16000] loss: 0.288 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:33 (running for 00:06:18.61)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2720) [4, 18000] loss: 0.256 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-28 17:12:38 (running for 00:06:23.61)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      6 |         335.528  | 1.29856 |     0.5306 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00005:
      accuracy: 0.5356
      date: 2023-06-28_17-12-41
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 7
      loss: 1.2730256284117698
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 378.6814720630646
      time_this_iter_s: 43.153076171875
      time_total_s: 378.6814720630646
      timestamp: 1687972361
      training_iteration: 7
      trial_id: 16daf_00005
  
    (func pid=2720) [4, 20000] loss: 0.231
    == Status ==
    Current time: 2023-06-28 17:12:46 (running for 00:06:31.63)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [8,  2000] loss: 1.199
    == Status ==
    Current time: 2023-06-28 17:12:51 (running for 00:06:36.64)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -1.6882341749012468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | RUNNING    | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      3 |         313.235  | 2.30959 |     0.099  |
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00000:
      accuracy: 0.0989
      date: 2023-06-28_17-12-55
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 4
      loss: 2.304513424253464
      node_ip: 172.17.0.2
      pid: 2720
      should_checkpoint: true
      time_since_restore: 397.6242094039917
      time_this_iter_s: 84.38874888420105
      time_total_s: 397.6242094039917
      timestamp: 1687972375
      training_iteration: 4
      trial_id: 16daf_00000
  
    Trial train_cifar_16daf_00000 completed.
    (func pid=2810) [8,  4000] loss: 0.610
    == Status ==
    Current time: 2023-06-28 17:13:00 (running for 00:06:46.30)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [8,  6000] loss: 0.400
    == Status ==
    Current time: 2023-06-28 17:13:05 (running for 00:06:51.31)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [8,  8000] loss: 0.294
    == Status ==
    Current time: 2023-06-28 17:13:10 (running for 00:06:56.31)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:13:16 (running for 00:07:01.32)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [8, 10000] loss: 0.241
    == Status ==
    Current time: 2023-06-28 17:13:21 (running for 00:07:06.33)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.5125009110599756 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      7 |         378.681  | 1.27303 |     0.5356 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00005:
      accuracy: 0.5433
      date: 2023-06-28_17-13-23
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 8
      loss: 1.2723176356643437
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 420.4141683578491
      time_this_iter_s: 41.732696294784546
      time_total_s: 420.4141683578491
      timestamp: 1687972403
      training_iteration: 8
      trial_id: 16daf_00005
  
    == Status ==
    Current time: 2023-06-28 17:13:28 (running for 00:07:13.37)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [9,  2000] loss: 1.163
    == Status ==
    Current time: 2023-06-28 17:13:33 (running for 00:07:18.38)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [9,  4000] loss: 0.586
    == Status ==
    Current time: 2023-06-28 17:13:38 (running for 00:07:23.38)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:13:43 (running for 00:07:28.39)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [9,  6000] loss: 0.388
    == Status ==
    Current time: 2023-06-28 17:13:48 (running for 00:07:33.40)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [9,  8000] loss: 0.294
    == Status ==
    Current time: 2023-06-28 17:13:53 (running for 00:07:38.41)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:13:58 (running for 00:07:43.42)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [9, 10000] loss: 0.233
    == Status ==
    Current time: 2023-06-28 17:14:03 (running for 00:07:48.43)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      8 |         420.414  | 1.27232 |     0.5433 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00005:
      accuracy: 0.5742
      date: 2023-06-28_17-14-03
      done: false
      hostname: ca69dd7559f9
      iterations_since_restore: 9
      loss: 1.180701015111804
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 461.3284020423889
      time_this_iter_s: 40.914233684539795
      time_total_s: 461.3284020423889
      timestamp: 1687972443
      training_iteration: 9
      trial_id: 16daf_00005
  
    == Status ==
    Current time: 2023-06-28 17:14:08 (running for 00:07:54.28)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [10,  2000] loss: 1.155
    == Status ==
    Current time: 2023-06-28 17:14:13 (running for 00:07:59.29)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [10,  4000] loss: 0.571
    == Status ==
    Current time: 2023-06-28 17:14:18 (running for 00:08:04.30)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:14:23 (running for 00:08:09.30)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [10,  6000] loss: 0.383
    == Status ==
    Current time: 2023-06-28 17:14:28 (running for 00:08:14.31)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [10,  8000] loss: 0.287
    == Status ==
    Current time: 2023-06-28 17:14:34 (running for 00:08:19.32)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-28 17:14:39 (running for 00:08:24.33)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2810) [10, 10000] loss: 0.228
    == Status ==
    Current time: 2023-06-28 17:14:44 (running for 00:08:29.33)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00005 | RUNNING    | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |      9 |         461.328  | 1.1807  |     0.5742 |
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_16daf_00005:
      accuracy: 0.5782
      date: 2023-06-28_17-14-45
      done: true
      hostname: ca69dd7559f9
      iterations_since_restore: 10
      loss: 1.1827772866010666
      node_ip: 172.17.0.2
      pid: 2810
      should_checkpoint: true
      time_since_restore: 502.4532449245453
      time_this_iter_s: 41.12484288215637
      time_total_s: 502.4532449245453
      timestamp: 1687972485
      training_iteration: 10
      trial_id: 16daf_00005
  
    Trial train_cifar_16daf_00005 completed.
    == Status ==
    Current time: 2023-06-28 17:14:45 (running for 00:08:30.41)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.3482671243011952 | Iter 4.000: -2.0243881915092468 | Iter 2.000: -2.0194367691278456 | Iter 1.000: -2.097140369683504
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-28_17-06-14
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_16daf_00000 | TERMINATED | 172.17.0.2:2720 |            2 |   16 |    1 | 0.00213327  |      4 |         397.624  | 2.30451 |     0.0989 |
    | train_cifar_16daf_00001 | TERMINATED | 172.17.0.2:2802 |            4 |    1 |    2 | 0.013416    |      1 |          65.6455 | 2.30673 |     0.1021 |
    | train_cifar_16daf_00002 | TERMINATED | 172.17.0.2:2804 |            2 |  256 |   64 | 0.0113784   |      1 |         154.241  | 2.14103 |     0.189  |
    | train_cifar_16daf_00003 | TERMINATED | 172.17.0.2:2806 |            8 |   64 |  256 | 0.0274071   |      4 |         162.36   | 2.22166 |     0.1768 |
    | train_cifar_16daf_00004 | TERMINATED | 172.17.0.2:2808 |            4 |   16 |    2 | 0.056666    |      1 |          65.4976 | 2.32109 |     0.1023 |
    | train_cifar_16daf_00005 | TERMINATED | 172.17.0.2:2810 |            4 |    8 |   64 | 0.000353097 |     10 |         502.453  | 1.18278 |     0.5782 |
    | train_cifar_16daf_00006 | TERMINATED | 172.17.0.2:2812 |            8 |   16 |    4 | 0.000147684 |     10 |         333.03   | 1.57781 |     0.4235 |
    | train_cifar_16daf_00007 | TERMINATED | 172.17.0.2:2814 |            8 |  256 |  256 | 0.00477469  |     10 |         355.531  | 1.42062 |     0.5649 |
    | train_cifar_16daf_00008 | TERMINATED | 172.17.0.2:2808 |            8 |  128 |  256 | 0.0306227   |      2 |          87.1307 | 2.04523 |     0.1968 |
    | train_cifar_16daf_00009 | TERMINATED | 172.17.0.2:2802 |            2 |    2 |   16 | 0.0286986   |      1 |         113.593  | 2.3181  |     0.1023 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-06-28 17:14:45,099 INFO tune.py:945 -- Total run time: 510.55 seconds (510.40 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.1827772866010666
    Best trial final validation accuracy: 0.5782
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5808




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 8 minutes  48.980 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 753664/170498071 [00:00<00:22, 7532408.94it/s]
      4% 6782976/170498071 [00:00<00:04, 38514901.48it/s]
      9% 14516224/170498071 [00:00<00:02, 56177591.54it/s]
     13% 22347776/170498071 [00:00<00:02, 64805104.63it/s]
     18% 30212096/170498071 [00:00<00:02, 69756511.07it/s]
     22% 38273024/170498071 [00:00<00:01, 73281635.13it/s]
     27% 46432256/170498071 [00:00<00:01, 75915609.27it/s]
     32% 54722560/170498071 [00:00<00:01, 78071977.10it/s]
     37% 63111168/170498071 [00:00<00:01, 79867852.49it/s]
     42% 71467008/170498071 [00:01<00:01, 80922817.84it/s]
     47% 79921152/170498071 [00:01<00:01, 81984156.05it/s]
     52% 88539136/170498071 [00:01<00:00, 83196385.94it/s]
     57% 97222656/170498071 [00:01<00:00, 84262742.05it/s]
     62% 106037248/170498071 [00:01<00:00, 85358902.16it/s]
     67% 115015680/170498071 [00:01<00:00, 86645641.16it/s]
     73% 124026880/170498071 [00:01<00:00, 87681065.70it/s]
     78% 133136384/170498071 [00:01<00:00, 88577960.50it/s]
     83% 142278656/170498071 [00:01<00:00, 89391261.70it/s]
     89% 151552000/170498071 [00:01<00:00, 90323580.24it/s]
     94% 160956416/170498071 [00:02<00:00, 91373740.78it/s]
    100% 170491904/170498071 [00:02<00:00, 92504620.61it/s]
    100% 170498071/170498071 [00:02<00:00, 80932889.01it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-08-14 21:48:48,630 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-08-14 21:48:48,770 INFO worker.py:1625 -- Started a local Ray instance.
    2023-08-14 21:48:49,903 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-08-14 21:48:53 (running for 00:00:03.65)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2568) Files already downloaded and verified
    (func pid=2568) Files already downloaded and verified
    == Status ==
    Current time: 2023-08-14 21:48:58 (running for 00:00:08.71)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2670) Files already downloaded and verified [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-08-14 21:49:03 (running for 00:00:13.72)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2568) [1,  2000] loss: 2.321
    (func pid=2672) Files already downloaded and verified [repeated 6x across cluster]
    == Status ==
    Current time: 2023-08-14 21:49:08 (running for 00:00:18.73)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2670) [1,  2000] loss: 2.301
    (func pid=2660) [1,  2000] loss: 2.333
    == Status ==
    Current time: 2023-08-14 21:49:13 (running for 00:00:23.74)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-08-14 21:49:18 (running for 00:00:28.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2670) [1,  4000] loss: 1.116 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-08-14 21:49:23 (running for 00:00:33.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2674) [1,  4000] loss: 0.790 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-08-14 21:49:28 (running for 00:00:38.77)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-08-14 21:49:33 (running for 00:00:43.78)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2568) [1,  8000] loss: 0.552 [repeated 4x across cluster]
    Result for train_cifar_5a724_00006:
      accuracy: 0.1148
      date: 2023-08-14_21-49-38
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.2877997060775757
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 40.314839124679565
      time_this_iter_s: 40.314839124679565
      time_total_s: 40.314839124679565
      timestamp: 1692049778
      training_iteration: 1
      trial_id: 5a724_00006
  
    Result for train_cifar_5a724_00003:
      accuracy: 0.2284
      date: 2023-08-14_21-49-39
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.0295869478225708
      node_ip: 172.17.0.2
      pid: 2658
      should_checkpoint: true
      time_since_restore: 41.79568290710449
      time_this_iter_s: 41.79568290710449
      time_total_s: 41.79568290710449
      timestamp: 1692049779
      training_iteration: 1
      trial_id: 5a724_00003
  
    == Status ==
    Current time: 2023-08-14 21:49:39 (running for 00:00:49.63)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.158693326950073
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.4722
      date: 2023-08-14_21-49-41
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 1.444297995519638
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 43.6463942527771
      time_this_iter_s: 43.6463942527771
      time_total_s: 43.6463942527771
      timestamp: 1692049781
      training_iteration: 1
      trial_id: 5a724_00007
  
    (func pid=2670) [1,  8000] loss: 0.474 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:49:46 (running for 00:00:56.54)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0295869478225708
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2672) [2,  2000] loss: 2.260 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-08-14 21:49:51 (running for 00:01:01.55)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0295869478225708
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:49:56 (running for 00:01:06.56)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0295869478225708
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:50:01 (running for 00:01:11.57)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0295869478225708
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING  | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00001 | RUNNING  | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING  | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING  | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00004 | RUNNING  | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING  | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_5a724_00006 | RUNNING  | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING  | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00001:
      accuracy: 0.0969
      date: 2023-08-14_21-50-03
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.3044109749794006
      node_ip: 172.17.0.2
      pid: 2653
      should_checkpoint: true
      time_since_restore: 66.1166889667511
      time_this_iter_s: 66.1166889667511
      time_total_s: 66.1166889667511
      timestamp: 1692049803
      training_iteration: 1
      trial_id: 5a724_00001
  
    Trial train_cifar_5a724_00001 completed.
    (func pid=2672) [2,  4000] loss: 1.086 [repeated 8x across cluster]
    Result for train_cifar_5a724_00005:
      accuracy: 0.3553
      date: 2023-08-14_21-50-04
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 1.7286851472854614
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 66.62601351737976
      time_this_iter_s: 66.62601351737976
      time_total_s: 66.62601351737976
      timestamp: 1692049804
      training_iteration: 1
      trial_id: 5a724_00005
  
    (func pid=2653) Files already downloaded and verified
    Result for train_cifar_5a724_00004:
      accuracy: 0.0998
      date: 2023-08-14_21-50-05
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.3545295914649964
      node_ip: 172.17.0.2
      pid: 2660
      should_checkpoint: true
      time_since_restore: 67.92333602905273
      time_this_iter_s: 67.92333602905273
      time_total_s: 67.92333602905273
      timestamp: 1692049805
      training_iteration: 1
      trial_id: 5a724_00004
  
    Trial train_cifar_5a724_00004 completed.
    (func pid=2653) Files already downloaded and verified
    (func pid=2674) [2,  4000] loss: 0.678 [repeated 4x across cluster]
    (func pid=2660) Files already downloaded and verified [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:50:10 (running for 00:01:20.52)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.158693326950073
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING    | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:50:15 (running for 00:01:25.53)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.158693326950073
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING    | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      1 |          40.3148 | 2.2878  |     0.1148 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [2,  2000] loss: 1.680
    Result for train_cifar_5a724_00006:
      accuracy: 0.2062
      date: 2023-08-14_21-50-15
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 2.0819006593704223
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 78.04605174064636
      time_this_iter_s: 37.7312126159668
      time_total_s: 78.04605174064636
      timestamp: 1692049815
      training_iteration: 2
      trial_id: 5a724_00006
  
    (func pid=2568) [1, 16000] loss: 0.247
    == Status ==
    Current time: 2023-08-14 21:50:20 (running for 00:01:30.84)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.158693326950073
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00003 | RUNNING    | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      1 |          41.7957 | 2.02959 |     0.2284 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      1 |          43.6464 | 1.4443  |     0.4722 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00003:
      accuracy: 0.1412
      date: 2023-08-14_21-50-21
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 2.2523504061698914
      node_ip: 172.17.0.2
      pid: 2658
      should_checkpoint: true
      time_since_restore: 83.74306297302246
      time_this_iter_s: 41.94738006591797
      time_total_s: 83.74306297302246
      timestamp: 1692049821
      training_iteration: 2
      trial_id: 5a724_00003
  
    Trial train_cifar_5a724_00003 completed.
    (func pid=2656) [1, 12000] loss: 0.369 [repeated 3x across cluster]
    Result for train_cifar_5a724_00007:
      accuracy: 0.544
      date: 2023-08-14_21-50-22
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 1.2725715902805328
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 85.02163243293762
      time_this_iter_s: 41.37523818016052
      time_total_s: 85.02163243293762
      timestamp: 1692049822
      training_iteration: 2
      trial_id: 5a724_00007
  
    == Status ==
    Current time: 2023-08-14 21:50:27 (running for 00:01:37.90)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.158693326950073
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2660) [1,  4000] loss: 1.168 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:50:32 (running for 00:01:42.91)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.158693326950073
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2653) [1,  4000] loss: 1.029 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:50:37 (running for 00:01:47.92)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.158693326950073
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2672) [3,  4000] loss: 0.987 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-08-14 21:50:42 (running for 00:01:52.93)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.158693326950073
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00008:
      accuracy: 0.2277
      date: 2023-08-14_21-50-46
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.0696297052383423
      node_ip: 172.17.0.2
      pid: 2653
      should_checkpoint: true
      time_since_restore: 42.23833751678467
      time_this_iter_s: 42.23833751678467
      time_total_s: 42.23833751678467
      timestamp: 1692049846
      training_iteration: 1
      trial_id: 5a724_00008
  
    (func pid=2660) [1,  8000] loss: 0.584
    (func pid=2670) [2,  8000] loss: 0.382
    Result for train_cifar_5a724_00000:
      accuracy: 0.1979
      date: 2023-08-14_21-50-50
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 1.921699975681305
      node_ip: 172.17.0.2
      pid: 2568
      should_checkpoint: true
      time_since_restore: 117.19508576393127
      time_this_iter_s: 117.19508576393127
      time_total_s: 117.19508576393127
      timestamp: 1692049850
      training_iteration: 1
      trial_id: 5a724_00000
  
    == Status ==
    Current time: 2023-08-14 21:50:50 (running for 00:02:00.86)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      2 |          78.0461 | 2.0819  |     0.2062 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.2835
      date: 2023-08-14_21-50-51
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 3
      loss: 1.8930647084236145
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 113.97356462478638
      time_this_iter_s: 35.927512884140015
      time_total_s: 113.97356462478638
      timestamp: 1692049851
      training_iteration: 3
      trial_id: 5a724_00006
  
    (func pid=2660) [1, 10000] loss: 0.466 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:50:56 (running for 00:02:06.77)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0819006593704223 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      1 |          66.626  | 1.72869 |     0.3553 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      2 |          85.0216 | 1.27257 |     0.544  |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.5766
      date: 2023-08-14_21-51-01
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 3
      loss: 1.1949354170441628
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 123.62014484405518
      time_this_iter_s: 38.598512411117554
      time_total_s: 123.62014484405518
      timestamp: 1692049861
      training_iteration: 3
      trial_id: 5a724_00007
  
    (func pid=2672) [4,  2000] loss: 1.880 [repeated 4x across cluster]
    Result for train_cifar_5a724_00005:
      accuracy: 0.4387
      date: 2023-08-14_21-51-05
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 1.5219153167963029
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 128.39534330368042
      time_this_iter_s: 61.76932978630066
      time_total_s: 128.39534330368042
      timestamp: 1692049865
      training_iteration: 2
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:51:05 (running for 00:02:15.96)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8019079880833626 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [2,  4000] loss: 0.981 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:51:10 (running for 00:02:20.98)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8019079880833626 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2660) [1, 14000] loss: 0.333 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:51:15 (running for 00:02:25.99)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8019079880833626 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:51:20 (running for 00:02:31.00)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8019079880833626 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2660) [1, 16000] loss: 0.292 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-08-14 21:51:25 (running for 00:02:36.01)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8019079880833626 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      3 |         113.974  | 1.89306 |     0.2835 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00008 | RUNNING    | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      1 |          42.2383 | 2.06963 |     0.2277 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.2983
      date: 2023-08-14_21-51-27
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 4
      loss: 1.808588418197632
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 149.45247197151184
      time_this_iter_s: 35.478907346725464
      time_total_s: 149.45247197151184
      timestamp: 1692049887
      training_iteration: 4
      trial_id: 5a724_00006
  
    Result for train_cifar_5a724_00008:
      accuracy: 0.216
      date: 2023-08-14_21-51-28
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 2.053016586780548
      node_ip: 172.17.0.2
      pid: 2653
      should_checkpoint: true
      time_since_restore: 84.38029193878174
      time_this_iter_s: 42.14195442199707
      time_total_s: 84.38029193878174
      timestamp: 1692049888
      training_iteration: 2
      trial_id: 5a724_00008
  
    Trial train_cifar_5a724_00008 completed.
    == Status ==
    Current time: 2023-08-14 21:51:33 (running for 00:02:43.38)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.808588418197632 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.0496083265304565
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00002 | RUNNING    | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      4 |         149.452  | 1.80859 |     0.2983 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      3 |         123.62   | 1.19494 |     0.5766 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2660) [1, 18000] loss: 0.260 [repeated 4x across cluster]
    Result for train_cifar_5a724_00002:
      accuracy: 0.1063
      date: 2023-08-14_21-51-34
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.3195562090158464
      node_ip: 172.17.0.2
      pid: 2656
      should_checkpoint: true
      time_since_restore: 156.3820686340332
      time_this_iter_s: 156.3820686340332
      time_total_s: 156.3820686340332
      timestamp: 1692049894
      training_iteration: 1
      trial_id: 5a724_00002
  
    Trial train_cifar_5a724_00002 completed.
    Result for train_cifar_5a724_00007:
      accuracy: 0.5647
      date: 2023-08-14_21-51-39
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 4
      loss: 1.2745068701028823
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 161.32348823547363
      time_this_iter_s: 37.70334339141846
      time_total_s: 161.32348823547363
      timestamp: 1692049899
      training_iteration: 4
      trial_id: 5a724_00007
  
    == Status ==
    Current time: 2023-08-14 21:51:39 (running for 00:02:49.19)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.0696297052383423
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      4 |         149.452  | 1.80859 |     0.2983 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2660) [1, 20000] loss: 0.233 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-08-14 21:51:44 (running for 00:02:54.21)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.0696297052383423
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      4 |         149.452  | 1.80859 |     0.2983 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:51:49 (running for 00:02:59.22)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.0696297052383423
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      4 |         149.452  | 1.80859 |     0.2983 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2672) [5,  4000] loss: 0.889 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:51:54 (running for 00:03:04.23)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.0696297052383423
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      4 |         149.452  | 1.80859 |     0.2983 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00009 | RUNNING    | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [2, 14000] loss: 0.277 [repeated 2x across cluster]
    Result for train_cifar_5a724_00009:
      accuracy: 0.0997
      date: 2023-08-14_21-51-56
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 1
      loss: 2.334278739786148
      node_ip: 172.17.0.2
      pid: 2660
      should_checkpoint: true
      time_since_restore: 111.33135771751404
      time_this_iter_s: 111.33135771751404
      time_total_s: 111.33135771751404
      timestamp: 1692049916
      training_iteration: 1
      trial_id: 5a724_00009
  
    Trial train_cifar_5a724_00009 completed.
    Result for train_cifar_5a724_00006:
      accuracy: 0.3083
      date: 2023-08-14_21-51-59
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 5
      loss: 1.7593009295463562
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 181.96066284179688
      time_this_iter_s: 32.508190870285034
      time_total_s: 181.96066284179688
      timestamp: 1692049919
      training_iteration: 5
      trial_id: 5a724_00006
  
    == Status ==
    Current time: 2023-08-14 21:51:59 (running for 00:03:09.74)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      2 |         128.395  | 1.52192 |     0.4387 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00005:
      accuracy: 0.4996
      date: 2023-08-14_21-52-02
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 3
      loss: 1.37437628762722
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 184.8482105731964
      time_this_iter_s: 56.45286726951599
      time_total_s: 184.8482105731964
      timestamp: 1692049922
      training_iteration: 3
      trial_id: 5a724_00005
  
    (func pid=2674) [5,  4000] loss: 0.537 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:07 (running for 00:03:17.43)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2672) [6,  2000] loss: 1.751 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:12 (running for 00:03:22.44)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      4 |         161.323  | 1.27451 |     0.5647 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.5841
      date: 2023-08-14_21-52-13
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 5
      loss: 1.2003298552513122
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 195.27728819847107
      time_this_iter_s: 33.95379996299744
      time_total_s: 195.27728819847107
      timestamp: 1692049933
      training_iteration: 5
      trial_id: 5a724_00007
  
    == Status ==
    Current time: 2023-08-14 21:52:18 (running for 00:03:28.15)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      5 |         195.277  | 1.20033 |     0.5841 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [2, 20000] loss: 0.193 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:23 (running for 00:03:33.16)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      5 |         195.277  | 1.20033 |     0.5841 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2674) [6,  2000] loss: 0.980 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:28 (running for 00:03:38.17)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -2.053016586780548 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      1 |         117.195  | 1.9217  |     0.1979 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      5 |         181.961  | 1.7593  |     0.3083 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      5 |         195.277  | 1.20033 |     0.5841 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.3345
      date: 2023-08-14_21-52-29
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 6
      loss: 1.709192813205719
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 212.0046465396881
      time_this_iter_s: 30.043983697891235
      time_total_s: 212.0046465396881
      timestamp: 1692049949
      training_iteration: 6
      trial_id: 5a724_00006
  
    Result for train_cifar_5a724_00000:
      accuracy: 0.2052
      date: 2023-08-14_21-52-32
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 2
      loss: 1.9066259563326835
      node_ip: 172.17.0.2
      pid: 2568
      should_checkpoint: true
      time_since_restore: 218.84641814231873
      time_this_iter_s: 101.65133237838745
      time_total_s: 218.84641814231873
      timestamp: 1692049952
      training_iteration: 2
      trial_id: 5a724_00000
  
    (func pid=2674) [6,  4000] loss: 0.515 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:37 (running for 00:03:47.51)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      6 |         212.005  | 1.70919 |     0.3345 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      5 |         195.277  | 1.20033 |     0.5841 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:52:42 (running for 00:03:52.53)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      6 |         212.005  | 1.70919 |     0.3345 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      5 |         195.277  | 1.20033 |     0.5841 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.5921
      date: 2023-08-14_21-52-46
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 6
      loss: 1.2047605094969274
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 228.16571021080017
      time_this_iter_s: 32.8884220123291
      time_total_s: 228.16571021080017
      timestamp: 1692049966
      training_iteration: 6
      trial_id: 5a724_00007
  
    (func pid=2670) [4, 10000] loss: 0.261 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:51 (running for 00:04:01.04)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5415476441502571 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      3 |         184.848  | 1.37438 |     0.4996 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      6 |         212.005  | 1.70919 |     0.3345 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      6 |         228.166  | 1.20476 |     0.5921 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00005:
      accuracy: 0.5283
      date: 2023-08-14_21-52-53
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 4
      loss: 1.3275055624425411
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 235.87450504302979
      time_this_iter_s: 51.026294469833374
      time_total_s: 235.87450504302979
      timestamp: 1692049973
      training_iteration: 4
      trial_id: 5a724_00005
  
    (func pid=2568) [3,  6000] loss: 0.639 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:52:58 (running for 00:04:08.45)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      6 |         212.005  | 1.70919 |     0.3345 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      6 |         228.166  | 1.20476 |     0.5921 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.3426
      date: 2023-08-14_21-52-59
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 7
      loss: 1.6854533126354219
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 242.02023196220398
      time_this_iter_s: 30.01558542251587
      time_total_s: 242.02023196220398
      timestamp: 1692049979
      training_iteration: 7
      trial_id: 5a724_00006
  
    (func pid=2670) [5,  2000] loss: 1.276 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:53:04 (running for 00:04:14.82)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      7 |         242.02   | 1.68545 |     0.3426 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      6 |         228.166  | 1.20476 |     0.5921 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2674) [7,  4000] loss: 0.499 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:53:09 (running for 00:04:19.83)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      7 |         242.02   | 1.68545 |     0.3426 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      6 |         228.166  | 1.20476 |     0.5921 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:53:14 (running for 00:04:24.84)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      7 |         242.02   | 1.68545 |     0.3426 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      6 |         228.166  | 1.20476 |     0.5921 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.5909
      date: 2023-08-14_21-53-18
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 7
      loss: 1.2238744747400283
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 260.8323690891266
      time_this_iter_s: 32.666658878326416
      time_total_s: 260.8323690891266
      timestamp: 1692049998
      training_iteration: 7
      trial_id: 5a724_00007
  
    (func pid=2670) [5,  6000] loss: 0.416 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-08-14 21:53:23 (running for 00:04:33.70)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      7 |         242.02   | 1.68545 |     0.3426 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      7 |         260.832  | 1.22387 |     0.5909 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [5,  8000] loss: 0.313 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:53:28 (running for 00:04:38.71)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      7 |         242.02   | 1.68545 |     0.3426 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      7 |         260.832  | 1.22387 |     0.5909 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.353
      date: 2023-08-14_21-53-29
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 8
      loss: 1.662950709915161
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 271.77833819389343
      time_this_iter_s: 29.758106231689453
      time_total_s: 271.77833819389343
      timestamp: 1692050009
      training_iteration: 8
      trial_id: 5a724_00006
  
    == Status ==
    Current time: 2023-08-14 21:53:34 (running for 00:04:44.57)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.662950709915161 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      8 |         271.778  | 1.66295 |     0.353  |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      7 |         260.832  | 1.22387 |     0.5909 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [3, 16000] loss: 0.242 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:53:39 (running for 00:04:49.58)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.662950709915161 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      4 |         235.875  | 1.32751 |     0.5283 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      8 |         271.778  | 1.66295 |     0.353  |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      7 |         260.832  | 1.22387 |     0.5909 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2674) [8,  4000] loss: 0.502 [repeated 3x across cluster]
    Result for train_cifar_5a724_00005:
      accuracy: 0.5567
      date: 2023-08-14_21-53-43
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 5
      loss: 1.2251582488566637
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 286.41839385032654
      time_this_iter_s: 50.54388880729675
      time_total_s: 286.41839385032654
      timestamp: 1692050023
      training_iteration: 5
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:53:48 (running for 00:04:58.99)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.662950709915161 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      8 |         271.778  | 1.66295 |     0.353  |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      7 |         260.832  | 1.22387 |     0.5909 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2672) [9,  4000] loss: 0.829 [repeated 2x across cluster]
    Result for train_cifar_5a724_00007:
      accuracy: 0.5717
      date: 2023-08-14_21-53-51
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 8
      loss: 1.2652336354732514
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 293.5869870185852
      time_this_iter_s: 32.75461792945862
      time_total_s: 293.5869870185852
      timestamp: 1692050031
      training_iteration: 8
      trial_id: 5a724_00007
  
    == Status ==
    Current time: 2023-08-14 21:53:56 (running for 00:05:06.46)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      8 |         271.778  | 1.66295 |     0.353  |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      8 |         293.587  | 1.26523 |     0.5717 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.3646
      date: 2023-08-14_21-53-59
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 9
      loss: 1.6235159895896911
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 301.76773166656494
      time_this_iter_s: 29.98939347267151
      time_total_s: 301.76773166656494
      timestamp: 1692050039
      training_iteration: 9
      trial_id: 5a724_00006
  
    (func pid=2670) [6,  4000] loss: 0.610 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:04 (running for 00:05:14.56)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      2 |         218.846  | 1.90663 |     0.2052 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      9 |         301.768  | 1.62352 |     0.3646 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      8 |         293.587  | 1.26523 |     0.5717 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00000:
      accuracy: 0.2024
      date: 2023-08-14_21-54-05
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 3
      loss: 2.0073052349328995
      node_ip: 172.17.0.2
      pid: 2568
      should_checkpoint: true
      time_since_restore: 312.15909814834595
      time_this_iter_s: 93.31268000602722
      time_total_s: 312.15909814834595
      timestamp: 1692050045
      training_iteration: 3
      trial_id: 5a724_00000
  
    (func pid=2672) [10,  2000] loss: 1.627 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:10 (running for 00:05:20.82)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      9 |         301.768  | 1.62352 |     0.3646 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      8 |         293.587  | 1.26523 |     0.5717 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:54:15 (running for 00:05:25.83)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      9 |         301.768  | 1.62352 |     0.3646 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      8 |         293.587  | 1.26523 |     0.5717 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [6,  8000] loss: 0.300 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:20 (running for 00:05:30.84)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      9 |         301.768  | 1.62352 |     0.3646 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      8 |         293.587  | 1.26523 |     0.5717 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00007:
      accuracy: 0.5819
      date: 2023-08-14_21-54-23
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 9
      loss: 1.3609365389347077
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 325.8315849304199
      time_this_iter_s: 32.24459791183472
      time_total_s: 325.8315849304199
      timestamp: 1692050063
      training_iteration: 9
      trial_id: 5a724_00007
  
    (func pid=2670) [6, 10000] loss: 0.241 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:28 (running for 00:05:38.71)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00006 | RUNNING    | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |      9 |         301.768  | 1.62352 |     0.3646 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      9 |         325.832  | 1.36094 |     0.5819 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00006:
      accuracy: 0.3774
      date: 2023-08-14_21-54-29
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 10
      loss: 1.6108942699432374
      node_ip: 172.17.0.2
      pid: 2672
      should_checkpoint: true
      time_since_restore: 331.672559261322
      time_this_iter_s: 29.90482759475708
      time_total_s: 331.672559261322
      timestamp: 1692050069
      training_iteration: 10
      trial_id: 5a724_00006
  
    Trial train_cifar_5a724_00006 completed.
    == Status ==
    Current time: 2023-08-14 21:54:34 (running for 00:05:44.46)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      5 |         286.418  | 1.22516 |     0.5567 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      9 |         325.832  | 1.36094 |     0.5819 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2674) [10,  2000] loss: 0.863 [repeated 2x across cluster]
    Result for train_cifar_5a724_00005:
      accuracy: 0.5563
      date: 2023-08-14_21-54-34
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 6
      loss: 1.2374052251935006
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 337.26545238494873
      time_this_iter_s: 50.84705853462219
      time_total_s: 337.26545238494873
      timestamp: 1692050074
      training_iteration: 6
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:54:39 (running for 00:05:49.84)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      9 |         325.832  | 1.36094 |     0.5819 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [7,  2000] loss: 1.172 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:44 (running for 00:05:54.85)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      9 |         325.832  | 1.36094 |     0.5819 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:54:49 (running for 00:05:59.86)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00007 | RUNNING    | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |      9 |         325.832  | 1.36094 |     0.5819 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [7,  4000] loss: 0.577 [repeated 3x across cluster]
    Result for train_cifar_5a724_00007:
      accuracy: 0.578
      date: 2023-08-14_21-54-53
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 10
      loss: 1.3920280564785004
      node_ip: 172.17.0.2
      pid: 2674
      should_checkpoint: true
      time_since_restore: 355.6681327819824
      time_this_iter_s: 29.8365478515625
      time_total_s: 355.6681327819824
      timestamp: 1692050093
      training_iteration: 10
      trial_id: 5a724_00007
  
    Trial train_cifar_5a724_00007 completed.
    (func pid=2568) [4, 14000] loss: 0.271 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:54:58 (running for 00:06:08.55)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:55:03 (running for 00:06:13.56)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [4, 16000] loss: 0.240 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:55:08 (running for 00:06:18.57)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [4, 18000] loss: 0.212 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-08-14 21:55:13 (running for 00:06:23.58)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:55:18 (running for 00:06:28.59)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      6 |         337.265  | 1.23741 |     0.5563 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2568) [4, 20000] loss: 0.188 [repeated 2x across cluster]
    Result for train_cifar_5a724_00005:
      accuracy: 0.5631
      date: 2023-08-14_21-55-19
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 7
      loss: 1.2263045514538884
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 381.65034890174866
      time_this_iter_s: 44.38489651679993
      time_total_s: 381.65034890174866
      timestamp: 1692050119
      training_iteration: 7
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:55:24 (running for 00:06:34.23)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [8,  2000] loss: 1.150
    == Status ==
    Current time: 2023-08-14 21:55:29 (running for 00:06:39.24)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.3275055624425411 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | RUNNING    | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      3 |         312.159  | 2.00731 |     0.2024 |
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00000:
      accuracy: 0.2366
      date: 2023-08-14_21-55-29
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 4
      loss: 1.966144090436399
      node_ip: 172.17.0.2
      pid: 2568
      should_checkpoint: true
      time_since_restore: 396.2549932003021
      time_this_iter_s: 84.09589505195618
      time_total_s: 396.2549932003021
      timestamp: 1692050129
      training_iteration: 4
      trial_id: 5a724_00000
  
    Trial train_cifar_5a724_00000 completed.
    (func pid=2670) [8,  4000] loss: 0.565
    == Status ==
    Current time: 2023-08-14 21:55:34 (running for 00:06:44.93)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:55:39 (running for 00:06:49.93)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [8,  6000] loss: 0.376
    == Status ==
    Current time: 2023-08-14 21:55:44 (running for 00:06:54.94)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [8,  8000] loss: 0.287
    == Status ==
    Current time: 2023-08-14 21:55:49 (running for 00:06:59.95)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:55:54 (running for 00:07:04.96)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [8, 10000] loss: 0.227
    == Status ==
    Current time: 2023-08-14 21:55:59 (running for 00:07:09.97)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4640921726942062 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      7 |         381.65   | 1.2263  |     0.5631 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00005:
      accuracy: 0.5754
      date: 2023-08-14_21-56-01
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 8
      loss: 1.185288413465023
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 423.7737293243408
      time_this_iter_s: 42.12338042259216
      time_total_s: 423.7737293243408
      timestamp: 1692050161
      training_iteration: 8
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:56:06 (running for 00:07:16.35)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [9,  2000] loss: 1.094
    == Status ==
    Current time: 2023-08-14 21:56:11 (running for 00:07:21.35)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [9,  4000] loss: 0.554
    == Status ==
    Current time: 2023-08-14 21:56:16 (running for 00:07:26.36)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:56:21 (running for 00:07:31.37)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [9,  6000] loss: 0.372
    == Status ==
    Current time: 2023-08-14 21:56:26 (running for 00:07:36.38)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [9,  8000] loss: 0.281
    == Status ==
    Current time: 2023-08-14 21:56:31 (running for 00:07:41.38)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:56:36 (running for 00:07:46.39)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [9, 10000] loss: 0.223
    == Status ==
    Current time: 2023-08-14 21:56:41 (running for 00:07:51.40)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      8 |         423.774  | 1.18529 |     0.5754 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00005:
      accuracy: 0.5946
      date: 2023-08-14_21-56-43
      done: false
      hostname: a3c7fd247794
      iterations_since_restore: 9
      loss: 1.1373512712575495
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 466.0287048816681
      time_this_iter_s: 42.25497555732727
      time_total_s: 466.0287048816681
      timestamp: 1692050203
      training_iteration: 9
      trial_id: 5a724_00005
  
    == Status ==
    Current time: 2023-08-14 21:56:48 (running for 00:07:58.60)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [10,  2000] loss: 1.106
    == Status ==
    Current time: 2023-08-14 21:56:53 (running for 00:08:03.61)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [10,  4000] loss: 0.546
    == Status ==
    Current time: 2023-08-14 21:56:58 (running for 00:08:08.61)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:57:03 (running for 00:08:13.62)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [10,  6000] loss: 0.369
    == Status ==
    Current time: 2023-08-14 21:57:08 (running for 00:08:18.63)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [10,  8000] loss: 0.274
    == Status ==
    Current time: 2023-08-14 21:57:13 (running for 00:08:23.64)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-08-14 21:57:18 (running for 00:08:28.65)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2670) [10, 10000] loss: 0.215
    == Status ==
    Current time: 2023-08-14 21:57:23 (running for 00:08:33.65)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00005 | RUNNING    | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |      9 |         466.029  | 1.13735 |     0.5946 |
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_5a724_00005:
      accuracy: 0.5727
      date: 2023-08-14_21-57-25
      done: true
      hostname: a3c7fd247794
      iterations_since_restore: 10
      loss: 1.2186171413779259
      node_ip: 172.17.0.2
      pid: 2670
      should_checkpoint: true
      time_since_restore: 507.9411222934723
      time_this_iter_s: 41.9124174118042
      time_total_s: 507.9411222934723
      timestamp: 1692050245
      training_iteration: 10
      trial_id: 5a724_00005
  
    Trial train_cifar_5a724_00005 completed.
    == Status ==
    Current time: 2023-08-14 21:57:25 (running for 00:08:35.51)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2652336354732514 | Iter 4.000: -1.5680469903200867 | Iter 2.000: -1.9798212715566157 | Iter 1.000: -2.178714705657959
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-08-14_21-48-49
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_5a724_00000 | TERMINATED | 172.17.0.2:2568 |            2 |   16 |    1 | 0.00213327  |      4 |         396.255  | 1.96614 |     0.2366 |
    | train_cifar_5a724_00001 | TERMINATED | 172.17.0.2:2653 |            4 |    1 |    2 | 0.013416    |      1 |          66.1167 | 2.30441 |     0.0969 |
    | train_cifar_5a724_00002 | TERMINATED | 172.17.0.2:2656 |            2 |  256 |   64 | 0.0113784   |      1 |         156.382  | 2.31956 |     0.1063 |
    | train_cifar_5a724_00003 | TERMINATED | 172.17.0.2:2658 |            8 |   64 |  256 | 0.0274071   |      2 |          83.7431 | 2.25235 |     0.1412 |
    | train_cifar_5a724_00004 | TERMINATED | 172.17.0.2:2660 |            4 |   16 |    2 | 0.056666    |      1 |          67.9233 | 2.35453 |     0.0998 |
    | train_cifar_5a724_00005 | TERMINATED | 172.17.0.2:2670 |            4 |    8 |   64 | 0.000353097 |     10 |         507.941  | 1.21862 |     0.5727 |
    | train_cifar_5a724_00006 | TERMINATED | 172.17.0.2:2672 |            8 |   16 |    4 | 0.000147684 |     10 |         331.673  | 1.61089 |     0.3774 |
    | train_cifar_5a724_00007 | TERMINATED | 172.17.0.2:2674 |            8 |  256 |  256 | 0.00477469  |     10 |         355.668  | 1.39203 |     0.578  |
    | train_cifar_5a724_00008 | TERMINATED | 172.17.0.2:2653 |            8 |  128 |  256 | 0.0306227   |      2 |          84.3803 | 2.05302 |     0.216  |
    | train_cifar_5a724_00009 | TERMINATED | 172.17.0.2:2660 |            2 |    2 |   16 | 0.0286986   |      1 |         111.331  | 2.33428 |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-08-14 21:57:25,502 INFO tune.py:945 -- Total run time: 515.60 seconds (515.51 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.2186171413779259
    Best trial final validation accuracy: 0.5727
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.58




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 8 minutes  53.155 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

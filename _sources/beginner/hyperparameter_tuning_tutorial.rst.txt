
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 425984/170498071 [00:00<00:40, 4198285.62it/s]
      3% 4751360/170498071 [00:00<00:06, 27009129.95it/s]
      7% 12353536/170498071 [00:00<00:03, 49254612.77it/s]
     12% 20021248/170498071 [00:00<00:02, 60016511.47it/s]
     15% 26050560/170498071 [00:00<00:02, 57147392.45it/s]
     20% 33914880/170498071 [00:00<00:02, 64171315.50it/s]
     24% 40402944/170498071 [00:00<00:02, 61809060.35it/s]
     29% 48726016/170498071 [00:00<00:01, 68304639.75it/s]
     34% 58032128/170498071 [00:00<00:01, 75718425.18it/s]
     39% 65667072/170498071 [00:01<00:01, 73516971.60it/s]
     44% 75366400/170498071 [00:01<00:01, 80427669.92it/s]
     49% 83492864/170498071 [00:01<00:01, 79830185.43it/s]
     54% 92176384/170498071 [00:01<00:00, 81837906.51it/s]
     60% 102334464/170498071 [00:01<00:00, 87615246.77it/s]
     65% 111149056/170498071 [00:01<00:00, 81036154.22it/s]
     71% 120553472/170498071 [00:01<00:00, 84502381.04it/s]
     76% 129138688/170498071 [00:01<00:00, 83103065.47it/s]
     81% 137953280/170498071 [00:01<00:00, 84542122.28it/s]
     86% 146735104/170498071 [00:01<00:00, 85355440.49it/s]
     91% 155320320/170498071 [00:02<00:00, 82509652.60it/s]
     97% 165019648/170498071 [00:02<00:00, 86627392.26it/s]
    100% 170498071/170498071 [00:02<00:00, 75101166.37it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2024-03-05 21:48:40,692 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2024-03-05 21:48:40,834 INFO worker.py:1625 -- Started a local Ray instance.
    2024-03-05 21:48:41,999 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    (pid=2679) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
    (pid=2679)   _torch_pytree._register_pytree_node(
    == Status ==
    Current time: 2024-03-05 21:48:47 (running for 00:00:05.40)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2679) Files already downloaded and verified
    (pid=2758)   _torch_pytree._register_pytree_node(
    (pid=2758)   _torch_pytree._register_pytree_node(
    (func pid=2679) Files already downloaded and verified
    == Status ==
    Current time: 2024-03-05 21:48:52 (running for 00:00:10.79)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (8 PENDING, 2 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2758) Files already downloaded and verified [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    (pid=3246) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
    (pid=3246)   _torch_pytree._register_pytree_node(
    == Status ==
    Current time: 2024-03-05 21:48:58 (running for 00:00:16.32)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (7 PENDING, 3 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2679) [1,  2000] loss: 2.328
    (func pid=3246) Files already downloaded and verified [repeated 2x across cluster]
    (pid=3734)   _torch_pytree._register_pytree_node(
    (pid=3734)   _torch_pytree._register_pytree_node(
    == Status ==
    Current time: 2024-03-05 21:49:04 (running for 00:00:21.97)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 PENDING, 4 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2758) [1,  2000] loss: 2.312
    (func pid=3734) Files already downloaded and verified [repeated 2x across cluster]
    (func pid=2679) [1,  4000] loss: 1.152
    (pid=4223) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
    (pid=4223)   _torch_pytree._register_pytree_node(
    == Status ==
    Current time: 2024-03-05 21:49:10 (running for 00:00:27.98)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (5 PENDING, 5 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=4223) Files already downloaded and verified [repeated 2x across cluster]
    (pid=4712)   _torch_pytree._register_pytree_node(
    (pid=4712)   _torch_pytree._register_pytree_node(
    (func pid=2758) [1,  4000] loss: 1.155 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:17 (running for 00:00:35.12)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (4 PENDING, 6 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=4712) Files already downloaded and verified
    (func pid=4712) Files already downloaded and verified
    (pid=5204) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
    (pid=5204)   _torch_pytree._register_pytree_node(
    (func pid=4223) [1,  2000] loss: 2.332 [repeated 3x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:24 (running for 00:00:42.50)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 PENDING, 7 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=5204) Files already downloaded and verified
    (func pid=5204) Files already downloaded and verified
    (pid=5696)   _torch_pytree._register_pytree_node(
    (pid=5696)   _torch_pytree._register_pytree_node(
    (func pid=4712) [1,  2000] loss: 2.304 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:32 (running for 00:00:50.36)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | RUNNING  | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=5696) Files already downloaded and verified
    (func pid=5696) Files already downloaded and verified
    == Status ==
    Current time: 2024-03-05 21:49:37 (running for 00:00:55.37)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | RUNNING  | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2758) [1,  8000] loss: 0.578 [repeated 3x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:42 (running for 00:01:00.38)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_22016_00007 | RUNNING  | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=4712) [1,  4000] loss: 1.139 [repeated 4x across cluster]
    Result for train_cifar_22016_00003:
      accuracy: 0.2024
      date: 2024-03-05_21-49-46
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.046302187347412
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 42.84993362426758
      time_this_iter_s: 42.84993362426758
      time_total_s: 42.84993362426758
      timestamp: 1709675386
      training_iteration: 1
      trial_id: '22016_00003'
  
    (func pid=2679) [1, 12000] loss: 0.384 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:51 (running for 00:01:09.84)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.046302187347412
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |   loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |        |            |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |        |                  |        |            |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |        |            |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463 |     0.2024 |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |        |                  |        |            |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |        |            |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |        |                  |        |            |
    | train_cifar_22016_00007 | RUNNING  | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |        |                  |        |            |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |        |            |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |        |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------+


    (func pid=5204) [1,  4000] loss: 1.161 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:49:56 (running for 00:01:14.85)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.046302187347412
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |   loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------|
    | train_cifar_22016_00000 | RUNNING  | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |        |            |
    | train_cifar_22016_00001 | RUNNING  | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |        |                  |        |            |
    | train_cifar_22016_00002 | RUNNING  | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |        |            |
    | train_cifar_22016_00003 | RUNNING  | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463 |     0.2024 |
    | train_cifar_22016_00004 | RUNNING  | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |        |                  |        |            |
    | train_cifar_22016_00005 | RUNNING  | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |        |            |
    | train_cifar_22016_00006 | RUNNING  | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |        |                  |        |            |
    | train_cifar_22016_00007 | RUNNING  | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |        |                  |        |            |
    | train_cifar_22016_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |        |            |
    | train_cifar_22016_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |        |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+--------+------------+


    Result for train_cifar_22016_00001:
      accuracy: 0.1025
      date: 2024-03-05_21-50-00
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.3057499592781068
      node_ip: 172.17.0.2
      pid: 2758
      should_checkpoint: true
      time_since_restore: 67.69513440132141
      time_this_iter_s: 67.69513440132141
      time_total_s: 67.69513440132141
      timestamp: 1709675400
      training_iteration: 1
      trial_id: '22016_00001'
  
    Trial train_cifar_22016_00001 completed.
    (func pid=2758) Files already downloaded and verified
    (func pid=2679) [1, 14000] loss: 0.329 [repeated 3x across cluster]
    (func pid=2758) Files already downloaded and verified
    == Status ==
    Current time: 2024-03-05 21:50:05 (running for 00:01:23.53)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1760260733127597
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463  |     0.2024 |
    | train_cifar_22016_00004 | RUNNING    | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_22016_00006 | RUNNING    | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |        |                  |         |            |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=5696) [1,  4000] loss: 0.794 [repeated 2x across cluster]
    Result for train_cifar_22016_00006:
      accuracy: 0.0993
      date: 2024-03-05_21-50-09
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.308074133682251
      node_ip: 172.17.0.2
      pid: 5204
      should_checkpoint: true
      time_since_restore: 44.463528633117676
      time_this_iter_s: 44.463528633117676
      time_total_s: 44.463528633117676
      timestamp: 1709675409
      training_iteration: 1
      trial_id: '22016_00006'
  
    Trial train_cifar_22016_00006 completed.
    (func pid=5204) Files already downloaded and verified
    (func pid=5204) Files already downloaded and verified
    (func pid=4223) [1, 10000] loss: 0.467 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:14 (running for 00:01:32.00)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.3057499592781068
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463  |     0.2024 |
    | train_cifar_22016_00004 | RUNNING    | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2758) [1,  2000] loss: 2.115 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:19 (running for 00:01:37.02)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.3057499592781068
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463  |     0.2024 |
    | train_cifar_22016_00004 | RUNNING    | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.4732
      date: 2024-03-05_21-50-20
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 1.4602466898441315
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 48.53140711784363
      time_this_iter_s: 48.53140711784363
      time_total_s: 48.53140711784363
      timestamp: 1709675420
      training_iteration: 1
      trial_id: '22016_00007'
  
    Result for train_cifar_22016_00004:
      accuracy: 0.0963
      date: 2024-03-05_21-50-22
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.3689025406837465
      node_ip: 172.17.0.2
      pid: 4223
      should_checkpoint: true
      time_since_restore: 72.93273162841797
      time_this_iter_s: 72.93273162841797
      time_total_s: 72.93273162841797
      timestamp: 1709675422
      training_iteration: 1
      trial_id: '22016_00004'
  
    Trial train_cifar_22016_00004 completed.
    (func pid=2679) [1, 18000] loss: 0.256 [repeated 3x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:28 (running for 00:01:45.94)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.3057499592781068
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      1 |          42.8499 | 2.0463  |     0.2024 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00003:
      accuracy: 0.238
      date: 2024-03-05_21-50-30
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 2
      loss: 2.0124698051452636
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 86.39863181114197
      time_this_iter_s: 43.54869818687439
      time_total_s: 86.39863181114197
      timestamp: 1709675430
      training_iteration: 2
      trial_id: '22016_00003'
  
    Result for train_cifar_22016_00005:
      accuracy: 0.3523
      date: 2024-03-05_21-50-30
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 1.7401413425922394
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 73.29978632926941
      time_this_iter_s: 73.29978632926941
      time_total_s: 73.29978632926941
      timestamp: 1709675430
      training_iteration: 1
      trial_id: '22016_00005'
  
    (func pid=5204) [1,  4000] loss: 1.170 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:35 (running for 00:01:53.44)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.1760260733127597
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:50:40 (running for 00:01:58.46)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.1760260733127597
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3246) [1, 14000] loss: 0.331 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:45 (running for 00:02:03.47)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.1760260733127597
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | RUNNING    | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00008:
      accuracy: 0.2133
      date: 2024-03-05_21-50-46
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.0672794053077697
      node_ip: 172.17.0.2
      pid: 2758
      should_checkpoint: true
      time_since_restore: 46.07180976867676
      time_this_iter_s: 46.07180976867676
      time_total_s: 46.07180976867676
      timestamp: 1709675446
      training_iteration: 1
      trial_id: '22016_00008'
  
    Result for train_cifar_22016_00000:
      accuracy: 0.0979
      date: 2024-03-05_21-50-50
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.3055123472213745
      node_ip: 172.17.0.2
      pid: 2679
      should_checkpoint: true
      time_since_restore: 123.04017066955566
      time_this_iter_s: 123.04017066955566
      time_total_s: 123.04017066955566
      timestamp: 1709675450
      training_iteration: 1
      trial_id: '22016_00000'
  
    Trial train_cifar_22016_00000 completed.
    (func pid=5696) [2,  4000] loss: 0.687 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:50:55 (running for 00:02:13.47)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3734) [3,  4000] loss: 1.035 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:00 (running for 00:02:18.48)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      1 |          48.5314 | 1.46025 |     0.4732 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5167
      date: 2024-03-05_21-51-02
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 2
      loss: 1.3823197585105895
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 90.47124576568604
      time_this_iter_s: 41.93983864784241
      time_total_s: 90.47124576568604
      timestamp: 1709675462
      training_iteration: 2
      trial_id: '22016_00007'
  
    (func pid=5204) [1, 10000] loss: 0.467 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:07 (running for 00:02:25.85)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6973947818279265 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      2 |          86.3986 | 2.01247 |     0.238  |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3246) [1, 18000] loss: 0.257 [repeated 2x across cluster]
    Result for train_cifar_22016_00003:
      accuracy: 0.2166
      date: 2024-03-05_21-51-11
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 3
      loss: 2.090663930416107
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 127.60246562957764
      time_this_iter_s: 41.20383381843567
      time_total_s: 127.60246562957764
      timestamp: 1709675471
      training_iteration: 3
      trial_id: '22016_00003'
  
    (func pid=4712) [2,  8000] loss: 0.386 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:16 (running for 00:02:34.58)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6973947818279265 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:51:21 (running for 00:02:39.59)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6973947818279265 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3246) [1, 20000] loss: 0.232 [repeated 3x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:26 (running for 00:02:44.60)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6973947818279265 | Iter 1.000: -2.186395876264572
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00008 | RUNNING    | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      1 |          46.0718 | 2.06728 |     0.2133 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00008:
      accuracy: 0.1914
      date: 2024-03-05_21-51-29
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 2
      loss: 2.075262249946594
      node_ip: 172.17.0.2
      pid: 2758
      should_checkpoint: true
      time_since_restore: 89.01283192634583
      time_this_iter_s: 42.94102215766907
      time_total_s: 89.01283192634583
      timestamp: 1709675489
      training_iteration: 2
      trial_id: '22016_00008'
  
    Trial train_cifar_22016_00008 completed.
    (func pid=5696) [3,  4000] loss: 0.635 [repeated 4x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:34 (running for 00:02:52.56)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0124698051452636 | Iter 1.000: -2.186395876264572
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      1 |          73.2998 | 1.74014 |     0.3523 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.4461
      date: 2024-03-05_21-51-35
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 2
      loss: 1.5068195766925812
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 138.06069922447205
      time_this_iter_s: 64.76091289520264
      time_total_s: 138.06069922447205
      timestamp: 1709675495
      training_iteration: 2
      trial_id: '22016_00005'
  
    (func pid=3734) [4,  4000] loss: 1.040 [repeated 2x across cluster]
    Result for train_cifar_22016_00002:
      accuracy: 0.0999
      date: 2024-03-05_21-51-40
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.310527778911591
      node_ip: 172.17.0.2
      pid: 3246
      should_checkpoint: true
      time_since_restore: 161.73515486717224
      time_this_iter_s: 161.73515486717224
      time_total_s: 161.73515486717224
      timestamp: 1709675500
      training_iteration: 1
      trial_id: '22016_00002'
  
    Trial train_cifar_22016_00002 completed.
    == Status ==
    Current time: 2024-03-05 21:51:40 (running for 00:02:58.07)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.3055123472213745
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00002 | RUNNING    | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      2 |          90.4712 | 1.38232 |     0.5167 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5556
      date: 2024-03-05_21-51-42
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 3
      loss: 1.2878537681341171
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 129.87827968597412
      time_this_iter_s: 39.407033920288086
      time_total_s: 129.87827968597412
      timestamp: 1709675502
      training_iteration: 3
      trial_id: '22016_00007'
  
    (func pid=4712) [3,  2000] loss: 1.463 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:51:47 (running for 00:03:05.25)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.3055123472213745
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      3 |         127.602  | 2.09066 |     0.2166 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      3 |         129.878  | 1.28785 |     0.5556 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00003:
      accuracy: 0.2251
      date: 2024-03-05_21-51-50
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 4
      loss: 2.0801571966171264
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 166.87756538391113
      time_this_iter_s: 39.275099754333496
      time_total_s: 166.87756538391113
      timestamp: 1709675510
      training_iteration: 4
      trial_id: '22016_00003'
  
    (func pid=5204) [1, 20000] loss: 0.234
    (func pid=5696) [4,  2000] loss: 1.169
    == Status ==
    Current time: 2024-03-05 21:51:55 (running for 00:03:13.86)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0801571966171264 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.3055123472213745
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      4 |         166.878  | 2.08016 |     0.2251 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      3 |         129.878  | 1.28785 |     0.5556 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:52:00 (running for 00:03:18.87)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0801571966171264 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.3055123472213745
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      4 |         166.878  | 2.08016 |     0.2251 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      3 |         129.878  | 1.28785 |     0.5556 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3734) [5,  2000] loss: 2.066 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:52:05 (running for 00:03:23.88)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.0801571966171264 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.3055123472213745
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      4 |         166.878  | 2.08016 |     0.2251 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      3 |         129.878  | 1.28785 |     0.5556 |
    | train_cifar_22016_00009 | RUNNING    | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00009:
      accuracy: 0.0997
      date: 2024-03-05_21-52-06
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 1
      loss: 2.3423025323867797
      node_ip: 172.17.0.2
      pid: 5204
      should_checkpoint: true
      time_since_restore: 117.73947834968567
      time_this_iter_s: 117.73947834968567
      time_total_s: 117.73947834968567
      timestamp: 1709675526
      training_iteration: 1
      trial_id: '22016_00009'
  
    Trial train_cifar_22016_00009 completed.
    == Status ==
    Current time: 2024-03-05 21:52:11 (running for 00:03:29.77)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -2.0801571966171264 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      4 |         166.878  | 2.08016 |     0.2251 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      3 |         129.878  | 1.28785 |     0.5556 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [3,  8000] loss: 0.345 [repeated 3x across cluster]
    Result for train_cifar_22016_00007:
      accuracy: 0.5665
      date: 2024-03-05_21-52-16
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 4
      loss: 1.2397947546005248
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 164.15322017669678
      time_this_iter_s: 34.274940490722656
      time_total_s: 164.15322017669678
      timestamp: 1709675536
      training_iteration: 4
      trial_id: '22016_00007'
  
    == Status ==
    Current time: 2024-03-05 21:52:21 (running for 00:03:39.52)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      4 |         166.878  | 2.08016 |     0.2251 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      2 |         138.061  | 1.50682 |     0.4461 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      4 |         164.153  | 1.23979 |     0.5665 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [3, 10000] loss: 0.276 [repeated 2x across cluster]
    Result for train_cifar_22016_00003:
      accuracy: 0.2094
      date: 2024-03-05_21-52-25
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 5
      loss: 2.0804858278274536
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 201.43416905403137
      time_this_iter_s: 34.55660367012024
      time_total_s: 201.43416905403137
      timestamp: 1709675545
      training_iteration: 5
      trial_id: '22016_00003'
  
    Result for train_cifar_22016_00005:
      accuracy: 0.4986
      date: 2024-03-05_21-52-30
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 3
      loss: 1.364887326091528
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 193.06418871879578
      time_this_iter_s: 55.00348949432373
      time_total_s: 193.06418871879578
      timestamp: 1709675550
      training_iteration: 3
      trial_id: '22016_00005'
  
    == Status ==
    Current time: 2024-03-05 21:52:30 (running for 00:03:48.20)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      5 |         201.434  | 2.08049 |     0.2094 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      4 |         164.153  | 1.23979 |     0.5665 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:52:35 (running for 00:03:53.21)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      5 |         201.434  | 2.08049 |     0.2094 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      4 |         164.153  | 1.23979 |     0.5665 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3734) [6,  2000] loss: 2.069 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:52:40 (running for 00:03:58.22)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      5 |         201.434  | 2.08049 |     0.2094 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      4 |         164.153  | 1.23979 |     0.5665 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:52:45 (running for 00:04:03.23)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      5 |         201.434  | 2.08049 |     0.2094 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      4 |         164.153  | 1.23979 |     0.5665 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [4,  4000] loss: 0.661 [repeated 3x across cluster]
    Result for train_cifar_22016_00007:
      accuracy: 0.5572
      date: 2024-03-05_21-52-49
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 5
      loss: 1.3204416890859605
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 196.76482963562012
      time_this_iter_s: 32.61160945892334
      time_total_s: 196.76482963562012
      timestamp: 1709675569
      training_iteration: 5
      trial_id: '22016_00007'
  
    == Status ==
    Current time: 2024-03-05 21:52:54 (running for 00:04:12.14)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      5 |         201.434  | 2.08049 |     0.2094 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      5 |         196.765  | 1.32044 |     0.5572 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [4,  6000] loss: 0.441 [repeated 2x across cluster]
    Result for train_cifar_22016_00003:
      accuracy: 0.2276
      date: 2024-03-05_21-52-58
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 6
      loss: 2.035343935775757
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 234.88662266731262
      time_this_iter_s: 33.45245361328125
      time_total_s: 234.88662266731262
      timestamp: 1709675578
      training_iteration: 6
      trial_id: '22016_00003'
  
    == Status ==
    Current time: 2024-03-05 21:53:03 (running for 00:04:21.86)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      5 |         196.765  | 1.32044 |     0.5572 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [4,  8000] loss: 0.333 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:53:08 (running for 00:04:26.88)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      5 |         196.765  | 1.32044 |     0.5572 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=5696) [6,  4000] loss: 0.541 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:53:13 (running for 00:04:31.89)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      5 |         196.765  | 1.32044 |     0.5572 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:53:18 (running for 00:04:36.90)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6599759756088255 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      3 |         193.064  | 1.36489 |     0.4986 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      5 |         196.765  | 1.32044 |     0.5572 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5722
      date: 2024-03-05_21-53-21
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 6
      loss: 1.2617585180878639
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 229.31178760528564
      time_this_iter_s: 32.54695796966553
      time_total_s: 229.31178760528564
      timestamp: 1709675601
      training_iteration: 6
      trial_id: '22016_00007'
  
    Result for train_cifar_22016_00005:
      accuracy: 0.5287
      date: 2024-03-05_21-53-22
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 4
      loss: 1.3156936649560929
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 245.0701560974121
      time_this_iter_s: 52.00596737861633
      time_total_s: 245.0701560974121
      timestamp: 1709675602
      training_iteration: 4
      trial_id: '22016_00005'
  
    (func pid=3734) [7,  4000] loss: 1.031 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:53:27 (running for 00:04:45.21)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [5,  2000] loss: 1.263
    == Status ==
    Current time: 2024-03-05 21:53:32 (running for 00:04:50.22)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      6 |         234.887  | 2.03534 |     0.2276 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00003:
      accuracy: 0.2487
      date: 2024-03-05_21-53-32
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 7
      loss: 1.9963909476280213
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 268.27615427970886
      time_this_iter_s: 33.38953161239624
      time_total_s: 268.27615427970886
      timestamp: 1709675612
      training_iteration: 7
      trial_id: '22016_00003'
  
    (func pid=5696) [7,  2000] loss: 0.974
    == Status ==
    Current time: 2024-03-05 21:53:37 (running for 00:04:55.25)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [5,  4000] loss: 0.630
    == Status ==
    Current time: 2024-03-05 21:53:42 (running for 00:05:00.27)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=3734) [8,  2000] loss: 2.030
    == Status ==
    Current time: 2024-03-05 21:53:47 (running for 00:05:05.28)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [5,  6000] loss: 0.419 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:53:52 (running for 00:05:10.29)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      6 |         229.312  | 1.26176 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5629
      date: 2024-03-05_21-53-54
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 7
      loss: 1.317746829789877
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 261.84475111961365
      time_this_iter_s: 32.532963514328
      time_total_s: 261.84475111961365
      timestamp: 1709675634
      training_iteration: 7
      trial_id: '22016_00007'
  
    (func pid=3734) [8,  4000] loss: 1.009
    (func pid=4712) [5,  8000] loss: 0.320
    == Status ==
    Current time: 2024-03-05 21:53:59 (running for 00:05:17.21)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      7 |         261.845  | 1.31775 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:54:04 (running for 00:05:22.22)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      7 |         268.276  | 1.99639 |     0.2487 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      7 |         261.845  | 1.31775 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00003:
      accuracy: 0.1959
      date: 2024-03-05_21-54-05
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 8
      loss: 2.097692689704895
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 301.4356882572174
      time_this_iter_s: 33.159533977508545
      time_total_s: 301.4356882572174
      timestamp: 1709675645
      training_iteration: 8
      trial_id: '22016_00003'
  
    (func pid=5696) [8,  2000] loss: 0.971
    (func pid=4712) [5, 10000] loss: 0.251
    == Status ==
    Current time: 2024-03-05 21:54:10 (running for 00:05:28.41)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.097692689704895 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      8 |         301.436  | 2.09769 |     0.1959 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      4 |         245.07   | 1.31569 |     0.5287 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      7 |         261.845  | 1.31775 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5398
      date: 2024-03-05_21-54-14
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 5
      loss: 1.293474568799138
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 297.0524377822876
      time_this_iter_s: 51.98228168487549
      time_total_s: 297.0524377822876
      timestamp: 1709675654
      training_iteration: 5
      trial_id: '22016_00005'
  
    (func pid=5696) [8,  4000] loss: 0.519
    (func pid=3734) [9,  2000] loss: 2.064
    == Status ==
    Current time: 2024-03-05 21:54:19 (running for 00:05:37.19)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.097692689704895 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      8 |         301.436  | 2.09769 |     0.1959 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      7 |         261.845  | 1.31775 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [6,  2000] loss: 1.212
    == Status ==
    Current time: 2024-03-05 21:54:24 (running for 00:05:42.20)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.097692689704895 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      8 |         301.436  | 2.09769 |     0.1959 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      7 |         261.845  | 1.31775 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5837
      date: 2024-03-05_21-54-26
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 8
      loss: 1.2837463493466377
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 294.356303691864
      time_this_iter_s: 32.511552572250366
      time_total_s: 294.356303691864
      timestamp: 1709675666
      training_iteration: 8
      trial_id: '22016_00007'
  
    (func pid=3734) [9,  4000] loss: 1.015
    == Status ==
    Current time: 2024-03-05 21:54:31 (running for 00:05:49.73)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      8 |         301.436  | 2.09769 |     0.1959 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:54:36 (running for 00:05:54.74)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      8 |         301.436  | 2.09769 |     0.1959 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=5696) [9,  2000] loss: 0.926 [repeated 2x across cluster]
    Result for train_cifar_22016_00003:
      accuracy: 0.2264
      date: 2024-03-05_21-54-38
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 9
      loss: 2.009858200931549
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 334.8672969341278
      time_this_iter_s: 33.4316086769104
      time_total_s: 334.8672969341278
      timestamp: 1709675678
      training_iteration: 9
      trial_id: '22016_00003'
  
    == Status ==
    Current time: 2024-03-05 21:54:43 (running for 00:06:01.85)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:54:48 (running for 00:06:06.86)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=5696) [9,  4000] loss: 0.498 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:54:53 (running for 00:06:11.87)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:54:58 (running for 00:06:16.88)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      8 |         294.356  | 1.28375 |     0.5837 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5686
      date: 2024-03-05_21-54-59
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 9
      loss: 1.3417569125115871
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 326.568852186203
      time_this_iter_s: 32.21254849433899
      time_total_s: 326.568852186203
      timestamp: 1709675699
      training_iteration: 9
      trial_id: '22016_00007'
  
    (func pid=4712) [6, 10000] loss: 0.245 [repeated 3x across cluster]
    == Status ==
    Current time: 2024-03-05 21:55:04 (running for 00:06:21.94)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      5 |         297.052  | 1.29347 |     0.5398 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      9 |         326.569  | 1.34176 |     0.5686 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5629
      date: 2024-03-05_21-55-06
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 6
      loss: 1.2215193254083394
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 349.1200838088989
      time_this_iter_s: 52.06764602661133
      time_total_s: 349.1200838088989
      timestamp: 1709675706
      training_iteration: 6
      trial_id: '22016_00005'
  
    (func pid=5696) [10,  2000] loss: 0.891 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:55:11 (running for 00:06:29.25)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00003 | RUNNING    | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |      9 |         334.867  | 2.00986 |     0.2264 |
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      9 |         326.569  | 1.34176 |     0.5686 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00003:
      accuracy: 0.245
      date: 2024-03-05_21-55-12
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 10
      loss: 2.033712712478638
      node_ip: 172.17.0.2
      pid: 3734
      should_checkpoint: true
      time_since_restore: 368.58850860595703
      time_this_iter_s: 33.721211671829224
      time_total_s: 368.58850860595703
      timestamp: 1709675712
      training_iteration: 10
      trial_id: '22016_00003'
  
    Trial train_cifar_22016_00003 completed.
    == Status ==
    Current time: 2024-03-05 21:55:17 (running for 00:06:35.58)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      9 |         326.569  | 1.34176 |     0.5686 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=5696) [10,  4000] loss: 0.490 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:55:22 (running for 00:06:40.59)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      9 |         326.569  | 1.34176 |     0.5686 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:55:27 (running for 00:06:45.60)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00007 | RUNNING    | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |      9 |         326.569  | 1.34176 |     0.5686 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00007:
      accuracy: 0.5765
      date: 2024-03-05_21-55-30
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 10
      loss: 1.3416220629751683
      node_ip: 172.17.0.2
      pid: 5696
      should_checkpoint: true
      time_since_restore: 358.43113946914673
      time_this_iter_s: 31.862287282943726
      time_total_s: 358.43113946914673
      timestamp: 1709675730
      training_iteration: 10
      trial_id: '22016_00007'
  
    Trial train_cifar_22016_00007 completed.
    (func pid=4712) [7,  6000] loss: 0.405 [repeated 2x across cluster]
    == Status ==
    Current time: 2024-03-05 21:55:35 (running for 00:06:53.80)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [7,  8000] loss: 0.298
    == Status ==
    Current time: 2024-03-05 21:55:40 (running for 00:06:58.81)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:55:45 (running for 00:07:03.82)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [7, 10000] loss: 0.234
    == Status ==
    Current time: 2024-03-05 21:55:50 (running for 00:07:08.83)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      6 |         349.12   | 1.22152 |     0.5629 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5722
      date: 2024-03-05_21-55-54
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 7
      loss: 1.2001091574043035
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 397.6290409564972
      time_this_iter_s: 48.50895714759827
      time_total_s: 397.6290409564972
      timestamp: 1709675754
      training_iteration: 7
      trial_id: '22016_00005'
  
    == Status ==
    Current time: 2024-03-05 21:55:59 (running for 00:07:17.76)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [8,  2000] loss: 1.171
    == Status ==
    Current time: 2024-03-05 21:56:04 (running for 00:07:22.77)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:56:09 (running for 00:07:27.78)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [8,  4000] loss: 0.580
    == Status ==
    Current time: 2024-03-05 21:56:14 (running for 00:07:32.79)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [8,  6000] loss: 0.390
    == Status ==
    Current time: 2024-03-05 21:56:19 (running for 00:07:37.80)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:56:24 (running for 00:07:42.80)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [8,  8000] loss: 0.290
    == Status ==
    Current time: 2024-03-05 21:56:29 (running for 00:07:47.81)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:56:34 (running for 00:07:52.82)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [8, 10000] loss: 0.234
    == Status ==
    Current time: 2024-03-05 21:56:39 (running for 00:07:57.83)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.6907195195257663 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      7 |         397.629  | 1.20011 |     0.5722 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5723
      date: 2024-03-05_21-56-42
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 8
      loss: 1.2069777980923653
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 444.93905377388
      time_this_iter_s: 47.31001281738281
      time_total_s: 444.93905377388
      timestamp: 1709675802
      training_iteration: 8
      trial_id: '22016_00005'
  
    == Status ==
    Current time: 2024-03-05 21:56:47 (running for 00:08:05.08)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [9,  2000] loss: 1.139
    == Status ==
    Current time: 2024-03-05 21:56:52 (running for 00:08:10.08)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:56:57 (running for 00:08:15.09)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [9,  4000] loss: 0.565
    == Status ==
    Current time: 2024-03-05 21:57:02 (running for 00:08:20.10)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [9,  6000] loss: 0.382
    == Status ==
    Current time: 2024-03-05 21:57:07 (running for 00:08:25.11)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:57:12 (running for 00:08:30.12)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [9,  8000] loss: 0.286
    == Status ==
    Current time: 2024-03-05 21:57:17 (running for 00:08:35.12)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:57:22 (running for 00:08:40.13)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [9, 10000] loss: 0.229
    == Status ==
    Current time: 2024-03-05 21:57:27 (running for 00:08:45.14)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      8 |         444.939  | 1.20698 |     0.5723 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5765
      date: 2024-03-05_21-57-29
      done: false
      hostname: aab91cc7f82b
      iterations_since_restore: 9
      loss: 1.1970967570990323
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 492.59371423721313
      time_this_iter_s: 47.65466046333313
      time_total_s: 492.59371423721313
      timestamp: 1709675849
      training_iteration: 9
      trial_id: '22016_00005'
  
    == Status ==
    Current time: 2024-03-05 21:57:34 (running for 00:08:52.73)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [10,  2000] loss: 1.132
    == Status ==
    Current time: 2024-03-05 21:57:39 (running for 00:08:57.74)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:57:44 (running for 00:09:02.74)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [10,  4000] loss: 0.559
    == Status ==
    Current time: 2024-03-05 21:57:49 (running for 00:09:07.75)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [10,  6000] loss: 0.373
    == Status ==
    Current time: 2024-03-05 21:57:54 (running for 00:09:12.76)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:57:59 (running for 00:09:17.77)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [10,  8000] loss: 0.280
    == Status ==
    Current time: 2024-03-05 21:58:04 (running for 00:09:22.78)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2024-03-05 21:58:09 (running for 00:09:27.79)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=4712) [10, 10000] loss: 0.226
    == Status ==
    Current time: 2024-03-05 21:58:14 (running for 00:09:32.79)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00005 | RUNNING    | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |      9 |         492.594  | 1.1971  |     0.5765 |
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_22016_00005:
      accuracy: 0.5753
      date: 2024-03-05_21-58-16
      done: true
      hostname: aab91cc7f82b
      iterations_since_restore: 10
      loss: 1.197506693315506
      node_ip: 172.17.0.2
      pid: 4712
      should_checkpoint: true
      time_since_restore: 539.4194295406342
      time_this_iter_s: 46.82571530342102
      time_total_s: 539.4194295406342
      timestamp: 1709675896
      training_iteration: 10
      trial_id: '22016_00005'
  
    Trial train_cifar_22016_00005 completed.
    == Status ==
    Current time: 2024-03-05 21:58:16 (running for 00:09:34.56)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2837463493466377 | Iter 4.000: -1.3156936649560929 | Iter 2.000: -1.7596446909189223 | Iter 1.000: -2.305631153249741
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-03-05_21-48-42
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_22016_00000 | TERMINATED | 172.17.0.2:2679 |            2 |   16 |    1 | 0.00213327  |      1 |         123.04   | 2.30551 |     0.0979 |
    | train_cifar_22016_00001 | TERMINATED | 172.17.0.2:2758 |            4 |    1 |    2 | 0.013416    |      1 |          67.6951 | 2.30575 |     0.1025 |
    | train_cifar_22016_00002 | TERMINATED | 172.17.0.2:3246 |            2 |  256 |   64 | 0.0113784   |      1 |         161.735  | 2.31053 |     0.0999 |
    | train_cifar_22016_00003 | TERMINATED | 172.17.0.2:3734 |            8 |   64 |  256 | 0.0274071   |     10 |         368.589  | 2.03371 |     0.245  |
    | train_cifar_22016_00004 | TERMINATED | 172.17.0.2:4223 |            4 |   16 |    2 | 0.056666    |      1 |          72.9327 | 2.3689  |     0.0963 |
    | train_cifar_22016_00005 | TERMINATED | 172.17.0.2:4712 |            4 |    8 |   64 | 0.000353097 |     10 |         539.419  | 1.19751 |     0.5753 |
    | train_cifar_22016_00006 | TERMINATED | 172.17.0.2:5204 |            8 |   16 |    4 | 0.000147684 |      1 |          44.4635 | 2.30807 |     0.0993 |
    | train_cifar_22016_00007 | TERMINATED | 172.17.0.2:5696 |            8 |  256 |  256 | 0.00477469  |     10 |         358.431  | 1.34162 |     0.5765 |
    | train_cifar_22016_00008 | TERMINATED | 172.17.0.2:2758 |            8 |  128 |  256 | 0.0306227   |      2 |          89.0128 | 2.07526 |     0.1914 |
    | train_cifar_22016_00009 | TERMINATED | 172.17.0.2:5204 |            2 |    2 |   16 | 0.0286986   |      1 |         117.739  | 2.3423  |     0.0997 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2024-03-05 21:58:16,645 INFO tune.py:945 -- Total run time: 574.64 seconds (574.55 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.197506693315506
    Best trial final validation accuracy: 0.5753
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5759




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

.. code-block:: sh

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 9 minutes  53.405 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

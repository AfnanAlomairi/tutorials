
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 688128/170498071 [00:00<00:24, 6874026.25it/s]
      4% 6651904/170498071 [00:00<00:04, 37820014.98it/s]
      9% 14614528/170498071 [00:00<00:02, 56840131.81it/s]
     13% 22806528/170498071 [00:00<00:02, 66579977.09it/s]
     18% 31162368/170498071 [00:00<00:01, 72390713.49it/s]
     23% 39649280/170498071 [00:00<00:01, 76555428.24it/s]
     28% 48136192/170498071 [00:00<00:01, 79134077.96it/s]
     33% 56852480/170498071 [00:00<00:01, 81507824.77it/s]
     39% 65667072/170498071 [00:00<00:01, 83525448.94it/s]
     44% 74448896/170498071 [00:01<00:01, 84841235.63it/s]
     49% 83623936/170498071 [00:01<00:01, 86705929.99it/s]
     54% 92864512/170498071 [00:01<00:00, 88335124.33it/s]
     60% 102137856/170498071 [00:01<00:00, 89647806.35it/s]
     65% 111542272/170498071 [00:01<00:00, 90921212.01it/s]
     71% 121110528/170498071 [00:01<00:00, 92346642.13it/s]
     77% 130744320/170498071 [00:01<00:00, 93446696.54it/s]
     83% 140673024/170498071 [00:01<00:00, 95112663.58it/s]
     88% 150863872/170498071 [00:01<00:00, 97135216.45it/s]
     95% 161316864/170498071 [00:01<00:00, 99331415.61it/s]
    100% 170498071/170498071 [00:01<00:00, 85526047.22it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-10-23 19:41:17,955 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-10-23 19:41:18,045 INFO worker.py:1625 -- Started a local Ray instance.
    2023-10-23 19:41:19,209 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-10-23 19:41:23 (running for 00:00:04.43)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2706) Files already downloaded and verified
    (func pid=2706) Files already downloaded and verified
    (func pid=2789) Files already downloaded and verified
    (func pid=2791) Files already downloaded and verified
    == Status ==
    Current time: 2023-10-23 19:41:29 (running for 00:00:10.03)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-23 19:41:34 (running for 00:00:15.05)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2706) [1,  2000] loss: 2.275
    (func pid=2797) Files already downloaded and verified [repeated 12x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-10-23 19:41:39 (running for 00:00:20.05)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2789) [1,  2000] loss: 2.313
    (func pid=2791) [1,  2000] loss: 2.284
    == Status ==
    Current time: 2023-10-23 19:41:44 (running for 00:00:25.06)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-23 19:41:49 (running for 00:00:30.07)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-23 19:41:54 (running for 00:00:35.08)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2789) [1,  4000] loss: 1.156 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-10-23 19:41:59 (running for 00:00:40.09)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2793) [1,  4000] loss: 1.028 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:04 (running for 00:00:45.10)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2789) [1,  6000] loss: 0.770 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:09 (running for 00:00:50.11)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_2331a_00006:
      accuracy: 0.0967
      date: 2023-10-23_19-42-12
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.3049501956939698
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 43.31187438964844
      time_this_iter_s: 43.31187438964844
      time_total_s: 43.31187438964844
      timestamp: 1698090132
      training_iteration: 1
      trial_id: 2331a_00006
  
    Result for train_cifar_2331a_00003:
      accuracy: 0.222
      date: 2023-10-23_19-42-14
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.0172617584228516
      node_ip: 172.17.0.2
      pid: 2793
      should_checkpoint: true
      time_since_restore: 45.65817308425903
      time_this_iter_s: 45.65817308425903
      time_total_s: 45.65817308425903
      timestamp: 1698090134
      training_iteration: 1
      trial_id: 2331a_00003
  
    Result for train_cifar_2331a_00007:
      accuracy: 0.4766
      date: 2023-10-23_19-42-16
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 1.4490428891181946
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 47.44996523857117
      time_this_iter_s: 47.44996523857117
      time_total_s: 47.44996523857117
      timestamp: 1698090136
      training_iteration: 1
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:42:16 (running for 00:00:57.07)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2789) [1,  8000] loss: 0.578 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:21 (running for 00:01:02.08)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2791) [1,  8000] loss: 0.547 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:26 (running for 00:01:07.10)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:42:31 (running for 00:01:12.11)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [1, 10000] loss: 0.338 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:36 (running for 00:01:17.12)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING  | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00001 | RUNNING  | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING  | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING  | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING  | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING  | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_2331a_00006 | RUNNING  | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING  | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2799) [2,  4000] loss: 1.112 [repeated 3x across cluster]
    Result for train_cifar_2331a_00001:
      accuracy: 0.1018
      date: 2023-10-23_19-42-41
      done: true
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.3078826136589052
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 72.53408575057983
      time_this_iter_s: 72.53408575057983
      time_total_s: 72.53408575057983
      timestamp: 1698090161
      training_iteration: 1
      trial_id: 2331a_00001
  
    Trial train_cifar_2331a_00001 completed.
    (func pid=2789) Files already downloaded and verified
    Result for train_cifar_2331a_00005:
      accuracy: 0.3724
      date: 2023-10-23_19-42-42
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 1.6817955298423768
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 72.853524684906
      time_this_iter_s: 72.853524684906
      time_total_s: 72.853524684906
      timestamp: 1698090162
      training_iteration: 1
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:42:42 (running for 00:01:22.90)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0172617584228516
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00004 | RUNNING    | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2789) Files already downloaded and verified
    Result for train_cifar_2331a_00004:
      accuracy: 0.1001
      date: 2023-10-23_19-42-42
      done: true
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.3430592007160187
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 73.87639570236206
      time_this_iter_s: 73.87639570236206
      time_total_s: 73.87639570236206
      timestamp: 1698090162
      training_iteration: 1
      trial_id: 2331a_00004
  
    Trial train_cifar_2331a_00004 completed.
    (func pid=2801) [2,  4000] loss: 0.670 [repeated 4x across cluster]
    (func pid=2795) Files already downloaded and verified [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:42:47 (running for 00:01:28.64)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:42:52 (running for 00:01:33.65)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      1 |          43.3119 | 2.30495 |     0.0967 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [1, 16000] loss: 0.244
    Result for train_cifar_2331a_00006:
      accuracy: 0.1775
      date: 2023-10-23_19-42-53
      done: false
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 2.125461794281006
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 84.52715563774109
      time_this_iter_s: 41.21528124809265
      time_total_s: 84.52715563774109
      timestamp: 1698090173
      training_iteration: 2
      trial_id: 2331a_00006
  
    (func pid=2797) [2,  2000] loss: 1.632
    == Status ==
    Current time: 2023-10-23 19:42:58 (running for 00:01:39.22)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.125461794281006 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      1 |          45.6582 | 2.01726 |     0.222  |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      1 |          47.45   | 1.44904 |     0.4766 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00003:
      accuracy: 0.2319
      date: 2023-10-23_19-42-59
      done: false
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 2.0458740071296693
      node_ip: 172.17.0.2
      pid: 2793
      should_checkpoint: true
      time_since_restore: 90.43224310874939
      time_this_iter_s: 44.774070024490356
      time_total_s: 90.43224310874939
      timestamp: 1698090179
      training_iteration: 2
      trial_id: 2331a_00003
  
    Result for train_cifar_2331a_00007:
      accuracy: 0.5243
      date: 2023-10-23_19-43-01
      done: false
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 1.3376753136396409
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 92.91456937789917
      time_this_iter_s: 45.464604139328
      time_total_s: 92.91456937789917
      timestamp: 1698090181
      training_iteration: 2
      trial_id: 2331a_00007
  
    (func pid=2706) [1, 18000] loss: 0.218 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-23 19:43:06 (running for 00:01:47.52)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:43:11 (running for 00:01:52.54)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2791) [1, 14000] loss: 0.317 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-23 19:43:16 (running for 00:01:57.55)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [2,  6000] loss: 0.520 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-23 19:43:21 (running for 00:02:02.56)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:43:26 (running for 00:02:07.57)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.1611059770584107
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00008:
      accuracy: 0.22
      date: 2023-10-23_19-43-28
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.0461429297447205
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 47.62791633605957
      time_this_iter_s: 47.62791633605957
      time_total_s: 47.62791633605957
      timestamp: 1698090208
      training_iteration: 1
      trial_id: 2331a_00008
  
    (func pid=2795) [1,  8000] loss: 0.584 [repeated 2x across cluster]
    Result for train_cifar_2331a_00000:
      accuracy: 0.2078
      date: 2023-10-23_19-43-32
      done: false
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 1.94732986856699
      node_ip: 172.17.0.2
      pid: 2706
      should_checkpoint: true
      time_since_restore: 129.23696732521057
      time_this_iter_s: 129.23696732521057
      time_total_s: 129.23696732521057
      timestamp: 1698090212
      training_iteration: 1
      trial_id: 2331a_00000
  
    == Status ==
    Current time: 2023-10-23 19:43:32 (running for 00:02:13.69)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      2 |          84.5272 | 2.12546 |     0.1775 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00006:
      accuracy: 0.2227
      date: 2023-10-23_19-43-35
      done: false
      hostname: ad5500790270
      iterations_since_restore: 3
      loss: 1.967590436935425
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 126.07005095481873
      time_this_iter_s: 41.54289531707764
      time_total_s: 126.07005095481873
      timestamp: 1698090215
      training_iteration: 3
      trial_id: 2331a_00006
  
    == Status ==
    Current time: 2023-10-23 19:43:40 (running for 00:02:20.76)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      2 |          90.4322 | 2.04587 |     0.2319 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      2 |          92.9146 | 1.33768 |     0.5243 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [1, 10000] loss: 0.467 [repeated 5x across cluster]
    Result for train_cifar_2331a_00003:
      accuracy: 0.2485
      date: 2023-10-23_19-43-44
      done: false
      hostname: ad5500790270
      iterations_since_restore: 3
      loss: 2.005305071735382
      node_ip: 172.17.0.2
      pid: 2793
      should_checkpoint: true
      time_since_restore: 135.55110001564026
      time_this_iter_s: 45.11885690689087
      time_total_s: 135.55110001564026
      timestamp: 1698090224
      training_iteration: 3
      trial_id: 2331a_00003
  
    (func pid=2791) [1, 18000] loss: 0.256 [repeated 3x across cluster]
    Result for train_cifar_2331a_00007:
      accuracy: 0.5744
      date: 2023-10-23_19-43-47
      done: false
      hostname: ad5500790270
      iterations_since_restore: 3
      loss: 1.218163480591774
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 138.46323823928833
      time_this_iter_s: 45.54866886138916
      time_total_s: 138.46323823928833
      timestamp: 1698090227
      training_iteration: 3
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:43:47 (running for 00:02:28.07)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [1, 12000] loss: 0.389 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:43:52 (running for 00:02:33.08)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      1 |          72.8535 | 1.6818  |     0.3724 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.4566
      date: 2023-10-23_19-43-53
      done: false
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 1.4856666068673134
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 143.764004945755
      time_this_iter_s: 70.910480260849
      time_total_s: 143.764004945755
      timestamp: 1698090233
      training_iteration: 2
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:43:58 (running for 00:02:38.82)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7657703069984914 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2793) [4,  2000] loss: 2.023 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:44:03 (running for 00:02:43.83)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7657703069984914 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [3,  2000] loss: 1.479 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-23 19:44:08 (running for 00:02:48.84)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7657703069984914 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:44:13 (running for 00:02:53.85)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7657703069984914 | Iter 1.000: -2.031702344083786
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      3 |         126.07   | 1.96759 |     0.2227 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          47.6279 | 2.04614 |     0.22   |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [1, 16000] loss: 0.292 [repeated 2x across cluster]
    Result for train_cifar_2331a_00006:
      accuracy: 0.2605
      date: 2023-10-23_19-44-16
      done: false
      hostname: ad5500790270
      iterations_since_restore: 4
      loss: 1.8746521109580994
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 167.62694668769836
      time_this_iter_s: 41.55689573287964
      time_total_s: 167.62694668769836
      timestamp: 1698090256
      training_iteration: 4
      trial_id: 2331a_00006
  
    Result for train_cifar_2331a_00008:
      accuracy: 0.2181
      date: 2023-10-23_19-44-17
      done: true
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 2.0710009474754334
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 96.21681642532349
      time_this_iter_s: 48.588900089263916
      time_total_s: 96.21681642532349
      timestamp: 1698090257
      training_iteration: 2
      trial_id: 2331a_00008
  
    Trial train_cifar_2331a_00008 completed.
    Result for train_cifar_2331a_00002:
      accuracy: 0.1206
      date: 2023-10-23_19-44-20
      done: true
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.3016244936704635
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 171.4353756904602
      time_this_iter_s: 171.4353756904602
      time_total_s: 171.4353756904602
      timestamp: 1698090260
      training_iteration: 1
      trial_id: 2331a_00002
  
    Trial train_cifar_2331a_00002 completed.
    == Status ==
    Current time: 2023-10-23 19:44:20 (running for 00:03:00.86)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00002 | RUNNING    | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [1, 18000] loss: 0.260 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-23 19:44:25 (running for 00:03:05.87)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:44:30 (running for 00:03:10.91)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00003 | RUNNING    | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      3 |         135.551  | 2.00531 |     0.2485 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      3 |         138.463  | 1.21816 |     0.5744 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [2, 10000] loss: 0.384
    Result for train_cifar_2331a_00003:
      accuracy: 0.2295
      date: 2023-10-23_19-44-33
      done: true
      hostname: ad5500790270
      iterations_since_restore: 4
      loss: 2.0184076524734498
      node_ip: 172.17.0.2
      pid: 2793
      should_checkpoint: true
      time_since_restore: 184.46173095703125
      time_this_iter_s: 48.91063094139099
      time_total_s: 184.46173095703125
      timestamp: 1698090273
      training_iteration: 4
      trial_id: 2331a_00003
  
    Trial train_cifar_2331a_00003 completed.
    (func pid=2797) [3,  6000] loss: 0.481
    Result for train_cifar_2331a_00007:
      accuracy: 0.5786
      date: 2023-10-23_19-44-35
      done: false
      hostname: ad5500790270
      iterations_since_restore: 4
      loss: 1.2373228597223758
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 186.8500154018402
      time_this_iter_s: 48.38677716255188
      time_total_s: 186.8500154018402
      timestamp: 1698090275
      training_iteration: 4
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:44:35 (running for 00:03:16.45)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2795) [1, 20000] loss: 0.233 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:44:40 (running for 00:03:21.47)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [3,  8000] loss: 0.353 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:44:45 (running for 00:03:26.48)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:44:50 (running for 00:03:31.49)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.0461429297447205
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      4 |         167.627  | 1.87465 |     0.2605 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00009 | RUNNING    | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [2, 14000] loss: 0.277 [repeated 3x across cluster]
    Result for train_cifar_2331a_00009:
      accuracy: 0.0954
      date: 2023-10-23_19-44-53
      done: true
      hostname: ad5500790270
      iterations_since_restore: 1
      loss: 2.394890830016136
      node_ip: 172.17.0.2
      pid: 2795
      should_checkpoint: true
      time_since_restore: 130.76549172401428
      time_this_iter_s: 130.76549172401428
      time_total_s: 130.76549172401428
      timestamp: 1698090293
      training_iteration: 1
      trial_id: 2331a_00009
  
    Trial train_cifar_2331a_00009 completed.
    Result for train_cifar_2331a_00006:
      accuracy: 0.3048
      date: 2023-10-23_19-44-57
      done: false
      hostname: ad5500790270
      iterations_since_restore: 5
      loss: 1.8078277767181397
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 208.0667428970337
      time_this_iter_s: 40.43979620933533
      time_total_s: 208.0667428970337
      timestamp: 1698090297
      training_iteration: 5
      trial_id: 2331a_00006
  
    == Status ==
    Current time: 2023-10-23 19:44:57 (running for 00:03:37.75)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [2, 16000] loss: 0.242 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:02 (running for 00:03:42.76)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      2 |         143.764  | 1.48567 |     0.4566 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.4756
      date: 2023-10-23_19-45-02
      done: false
      hostname: ad5500790270
      iterations_since_restore: 3
      loss: 1.440617700433731
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 213.01156997680664
      time_this_iter_s: 69.24756503105164
      time_total_s: 213.01156997680664
      timestamp: 1698090302
      training_iteration: 3
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:45:07 (running for 00:03:48.05)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2799) [6,  2000] loss: 1.762 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:12 (running for 00:03:53.07)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      4 |         186.85   | 1.23732 |     0.5786 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00007:
      accuracy: 0.5739
      date: 2023-10-23_19-45-12
      done: false
      hostname: ad5500790270
      iterations_since_restore: 5
      loss: 1.2320863264322282
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 223.83804988861084
      time_this_iter_s: 36.98803448677063
      time_total_s: 223.83804988861084
      timestamp: 1698090312
      training_iteration: 5
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:45:17 (running for 00:03:58.44)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [2, 20000] loss: 0.194 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:22 (running for 00:04:03.45)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [6,  2000] loss: 1.002 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:27 (running for 00:04:08.46)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -2.0458740071296693 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      1 |         129.237  | 1.94733 |     0.2078 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      5 |         208.067  | 1.80783 |     0.3048 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00006:
      accuracy: 0.3546
      date: 2023-10-23_19-45-29
      done: false
      hostname: ad5500790270
      iterations_since_restore: 6
      loss: 1.7110086538791656
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 240.7955241203308
      time_this_iter_s: 32.72878122329712
      time_total_s: 240.7955241203308
      timestamp: 1698090329
      training_iteration: 6
      trial_id: 2331a_00006
  
    Result for train_cifar_2331a_00000:
      accuracy: 0.22
      date: 2023-10-23_19-45-31
      done: false
      hostname: ad5500790270
      iterations_since_restore: 2
      loss: 1.8970504651069642
      node_ip: 172.17.0.2
      pid: 2706
      should_checkpoint: true
      time_since_restore: 247.7468385696411
      time_this_iter_s: 118.50987124443054
      time_total_s: 247.7468385696411
      timestamp: 1698090331
      training_iteration: 2
      trial_id: 2331a_00000
  
    (func pid=2797) [4,  6000] loss: 0.456
    == Status ==
    Current time: 2023-10-23 19:45:36 (running for 00:04:17.20)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      6 |         240.796  | 1.71101 |     0.3546 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [6,  4000] loss: 0.522
    == Status ==
    Current time: 2023-10-23 19:45:41 (running for 00:04:22.21)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      6 |         240.796  | 1.71101 |     0.3546 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:45:46 (running for 00:04:27.22)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      6 |         240.796  | 1.71101 |     0.3546 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      5 |         223.838  | 1.23209 |     0.5739 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00007:
      accuracy: 0.5751
      date: 2023-10-23_19-45-48
      done: false
      hostname: ad5500790270
      iterations_since_restore: 6
      loss: 1.3232824146151543
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 259.36054491996765
      time_this_iter_s: 35.52249503135681
      time_total_s: 259.36054491996765
      timestamp: 1698090348
      training_iteration: 6
      trial_id: 2331a_00007
  
    (func pid=2706) [3,  4000] loss: 0.962 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:53 (running for 00:04:33.97)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      6 |         240.796  | 1.71101 |     0.3546 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [3,  6000] loss: 0.643 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:45:58 (running for 00:04:38.98)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      3 |         213.012  | 1.44062 |     0.4756 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      6 |         240.796  | 1.71101 |     0.3546 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5145
      date: 2023-10-23_19-45-58
      done: false
      hostname: ad5500790270
      iterations_since_restore: 4
      loss: 1.316737450236082
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 269.4601833820343
      time_this_iter_s: 56.44861340522766
      time_total_s: 269.4601833820343
      timestamp: 1698090358
      training_iteration: 4
      trial_id: 2331a_00005
  
    Result for train_cifar_2331a_00006:
      accuracy: 0.3727
      date: 2023-10-23_19-46-02
      done: false
      hostname: ad5500790270
      iterations_since_restore: 7
      loss: 1.6489577362060548
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 273.263222694397
      time_this_iter_s: 32.46769857406616
      time_total_s: 273.263222694397
      timestamp: 1698090362
      training_iteration: 7
      trial_id: 2331a_00006
  
    (func pid=2706) [3,  8000] loss: 0.482 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:07 (running for 00:04:47.95)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:46:12 (running for 00:04:52.96)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [7,  4000] loss: 0.504 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:17 (running for 00:04:57.97)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [5,  4000] loss: 0.649 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:22 (running for 00:05:02.98)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      6 |         259.361  | 1.32328 |     0.5751 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00007:
      accuracy: 0.5565
      date: 2023-10-23_19-46-23
      done: false
      hostname: ad5500790270
      iterations_since_restore: 7
      loss: 1.3337490421891212
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 295.0666482448578
      time_this_iter_s: 35.70610332489014
      time_total_s: 295.0666482448578
      timestamp: 1698090383
      training_iteration: 7
      trial_id: 2331a_00007
  
    (func pid=2706) [3, 12000] loss: 0.326
    (func pid=2799) [8,  4000] loss: 0.797
    == Status ==
    Current time: 2023-10-23 19:46:28 (running for 00:05:09.67)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      7 |         295.067  | 1.33375 |     0.5565 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [3, 14000] loss: 0.275 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:33 (running for 00:05:14.69)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      7 |         273.263  | 1.64896 |     0.3727 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      7 |         295.067  | 1.33375 |     0.5565 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00006:
      accuracy: 0.3955
      date: 2023-10-23_19-46-34
      done: false
      hostname: ad5500790270
      iterations_since_restore: 8
      loss: 1.5987422656536103
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 305.98087763786316
      time_this_iter_s: 32.71765494346619
      time_total_s: 305.98087763786316
      timestamp: 1698090394
      training_iteration: 8
      trial_id: 2331a_00006
  
    == Status ==
    Current time: 2023-10-23 19:46:39 (running for 00:05:20.66)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5987422656536103 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      8 |         305.981  | 1.59874 |     0.3955 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      7 |         295.067  | 1.33375 |     0.5565 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [3, 16000] loss: 0.238 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:44 (running for 00:05:25.68)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5987422656536103 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      8 |         305.981  | 1.59874 |     0.3955 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      7 |         295.067  | 1.33375 |     0.5565 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [5, 10000] loss: 0.255 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:46:49 (running for 00:05:30.68)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.5987422656536103 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      4 |         269.46   | 1.31674 |     0.5145 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      8 |         305.981  | 1.59874 |     0.3955 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      7 |         295.067  | 1.33375 |     0.5565 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5267
      date: 2023-10-23_19-46-54
      done: false
      hostname: ad5500790270
      iterations_since_restore: 5
      loss: 1.3087096585333347
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 325.5909626483917
      time_this_iter_s: 56.13077926635742
      time_total_s: 325.5909626483917
      timestamp: 1698090414
      training_iteration: 5
      trial_id: 2331a_00005
  
    (func pid=2799) [9,  4000] loss: 0.775 [repeated 3x across cluster]
    Result for train_cifar_2331a_00007:
      accuracy: 0.5632
      date: 2023-10-23_19-46-59
      done: false
      hostname: ad5500790270
      iterations_since_restore: 8
      loss: 1.3753507368147373
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 330.46472358703613
      time_this_iter_s: 35.398075342178345
      time_total_s: 330.46472358703613
      timestamp: 1698090419
      training_iteration: 8
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:46:59 (running for 00:05:40.07)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      8 |         305.981  | 1.59874 |     0.3955 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:47:04 (running for 00:05:45.08)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      8 |         305.981  | 1.59874 |     0.3955 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [6,  2000] loss: 1.250 [repeated 2x across cluster]
    Result for train_cifar_2331a_00006:
      accuracy: 0.4245
      date: 2023-10-23_19-47-07
      done: false
      hostname: ad5500790270
      iterations_since_restore: 9
      loss: 1.5429495810508729
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 338.6282503604889
      time_this_iter_s: 32.64737272262573
      time_total_s: 338.6282503604889
      timestamp: 1698090427
      training_iteration: 9
      trial_id: 2331a_00006
  
    (func pid=2801) [9,  2000] loss: 0.894
    == Status ==
    Current time: 2023-10-23 19:47:12 (running for 00:05:53.32)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      2 |         247.747  | 1.89705 |     0.22   |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00000:
      accuracy: 0.2134
      date: 2023-10-23_19-47-13
      done: false
      hostname: ad5500790270
      iterations_since_restore: 3
      loss: 1.9468686811685563
      node_ip: 172.17.0.2
      pid: 2706
      should_checkpoint: true
      time_since_restore: 349.7848014831543
      time_this_iter_s: 102.03796291351318
      time_total_s: 349.7848014831543
      timestamp: 1698090433
      training_iteration: 3
      trial_id: 2331a_00000
  
    (func pid=2797) [6,  4000] loss: 0.620
    == Status ==
    Current time: 2023-10-23 19:47:18 (running for 00:05:59.23)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [4,  2000] loss: 1.897 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:47:23 (running for 00:06:04.24)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:47:28 (running for 00:06:09.25)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2799) [10,  4000] loss: 0.753 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:47:33 (running for 00:06:14.26)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      8 |         330.465  | 1.37535 |     0.5632 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00007:
      accuracy: 0.5562
      date: 2023-10-23_19-47-34
      done: false
      hostname: ad5500790270
      iterations_since_restore: 9
      loss: 1.3947714603543282
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 366.0615122318268
      time_this_iter_s: 35.59678864479065
      time_total_s: 366.0615122318268
      timestamp: 1698090454
      training_iteration: 9
      trial_id: 2331a_00007
  
    == Status ==
    Current time: 2023-10-23 19:47:39 (running for 00:06:20.67)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00006 | RUNNING    | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |      9 |         338.628  | 1.54295 |     0.4245 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00006:
      accuracy: 0.4317
      date: 2023-10-23_19-47-40
      done: true
      hostname: ad5500790270
      iterations_since_restore: 10
      loss: 1.5264785224437714
      node_ip: 172.17.0.2
      pid: 2799
      should_checkpoint: true
      time_since_restore: 371.1143493652344
      time_this_iter_s: 32.48609900474548
      time_total_s: 371.1143493652344
      timestamp: 1698090460
      training_iteration: 10
      trial_id: 2331a_00006
  
    Trial train_cifar_2331a_00006 completed.
    (func pid=2706) [4,  6000] loss: 0.633 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:47:45 (running for 00:06:25.81)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2801) [10,  2000] loss: 0.885 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:47:50 (running for 00:06:30.81)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      5 |         325.591  | 1.30871 |     0.5267 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5598
      date: 2023-10-23_19-47-50
      done: false
      hostname: ad5500790270
      iterations_since_restore: 6
      loss: 1.2397743984937668
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 380.9977276325226
      time_this_iter_s: 55.40676498413086
      time_total_s: 380.9977276325226
      timestamp: 1698090470
      training_iteration: 6
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:47:55 (running for 00:06:36.04)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [4, 10000] loss: 0.385 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:48:00 (running for 00:06:41.05)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [4, 12000] loss: 0.322 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-23 19:48:05 (running for 00:06:46.06)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00007 | RUNNING    | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |      9 |         366.062  | 1.39477 |     0.5562 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00007:
      accuracy: 0.5341
      date: 2023-10-23_19-48-07
      done: true
      hostname: ad5500790270
      iterations_since_restore: 10
      loss: 1.4382781549453736
      node_ip: 172.17.0.2
      pid: 2801
      should_checkpoint: true
      time_since_restore: 398.8978991508484
      time_this_iter_s: 32.836386919021606
      time_total_s: 398.8978991508484
      timestamp: 1698090487
      training_iteration: 10
      trial_id: 2331a_00007
  
    Trial train_cifar_2331a_00007 completed.
    (func pid=2706) [4, 14000] loss: 0.272 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:48:12 (running for 00:06:53.51)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:48:17 (running for 00:06:58.52)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [4, 16000] loss: 0.241 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:48:22 (running for 00:07:03.53)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2706) [4, 18000] loss: 0.216 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-23 19:48:27 (running for 00:07:08.54)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:48:32 (running for 00:07:13.54)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [7, 10000] loss: 0.242
    (func pid=2706) [4, 20000] loss: 0.197
    == Status ==
    Current time: 2023-10-23 19:48:37 (running for 00:07:18.55)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      6 |         380.998  | 1.23977 |     0.5598 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.554
      date: 2023-10-23_19-48-39
      done: false
      hostname: ad5500790270
      iterations_since_restore: 7
      loss: 1.2331687732815741
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 430.4291477203369
      time_this_iter_s: 49.43142008781433
      time_total_s: 430.4291477203369
      timestamp: 1698090519
      training_iteration: 7
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:48:44 (running for 00:07:25.47)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.5956947805970907 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | RUNNING    | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      3 |         349.785  | 1.94687 |     0.2134 |
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00000:
      accuracy: 0.1921
      date: 2023-10-23_19-48-46
      done: true
      hostname: ad5500790270
      iterations_since_restore: 4
      loss: 2.011009928369522
      node_ip: 172.17.0.2
      pid: 2706
      should_checkpoint: true
      time_since_restore: 443.031343460083
      time_this_iter_s: 93.24654197692871
      time_total_s: 443.031343460083
      timestamp: 1698090526
      training_iteration: 4
      trial_id: 2331a_00000
  
    Trial train_cifar_2331a_00000 completed.
    (func pid=2797) [8,  2000] loss: 1.172
    == Status ==
    Current time: 2023-10-23 19:48:51 (running for 00:07:32.49)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [8,  4000] loss: 0.596
    == Status ==
    Current time: 2023-10-23 19:48:56 (running for 00:07:37.49)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:49:01 (running for 00:07:42.50)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [8,  6000] loss: 0.395
    == Status ==
    Current time: 2023-10-23 19:49:06 (running for 00:07:47.51)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:49:11 (running for 00:07:52.52)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [8,  8000] loss: 0.291
    == Status ==
    Current time: 2023-10-23 19:49:16 (running for 00:07:57.52)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [8, 10000] loss: 0.238
    == Status ==
    Current time: 2023-10-23 19:49:21 (running for 00:08:02.53)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4870465012341738 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      7 |         430.429  | 1.23317 |     0.554  |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5725
      date: 2023-10-23_19-49-26
      done: false
      hostname: ad5500790270
      iterations_since_restore: 8
      loss: 1.1907246381729841
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 477.3799960613251
      time_this_iter_s: 46.95084834098816
      time_total_s: 477.3799960613251
      timestamp: 1698090566
      training_iteration: 8
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:49:31 (running for 00:08:12.42)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [9,  2000] loss: 1.144
    == Status ==
    Current time: 2023-10-23 19:49:36 (running for 00:08:17.43)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:49:41 (running for 00:08:22.44)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [9,  4000] loss: 0.572
    == Status ==
    Current time: 2023-10-23 19:49:46 (running for 00:08:27.45)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [9,  6000] loss: 0.388
    == Status ==
    Current time: 2023-10-23 19:49:51 (running for 00:08:32.46)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:49:56 (running for 00:08:37.46)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [9,  8000] loss: 0.291
    == Status ==
    Current time: 2023-10-23 19:50:01 (running for 00:08:42.47)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:50:06 (running for 00:08:47.48)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [9, 10000] loss: 0.232
    == Status ==
    Current time: 2023-10-23 19:50:11 (running for 00:08:52.49)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      8 |         477.38   | 1.19072 |     0.5725 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5389
      date: 2023-10-23_19-50-13
      done: false
      hostname: ad5500790270
      iterations_since_restore: 9
      loss: 1.2988030375212432
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 523.7437551021576
      time_this_iter_s: 46.36375904083252
      time_total_s: 523.7437551021576
      timestamp: 1698090613
      training_iteration: 9
      trial_id: 2331a_00005
  
    == Status ==
    Current time: 2023-10-23 19:50:18 (running for 00:08:58.79)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [10,  2000] loss: 1.129
    == Status ==
    Current time: 2023-10-23 19:50:23 (running for 00:09:03.80)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:50:28 (running for 00:09:08.81)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [10,  4000] loss: 0.586
    == Status ==
    Current time: 2023-10-23 19:50:33 (running for 00:09:13.81)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [10,  6000] loss: 0.381
    == Status ==
    Current time: 2023-10-23 19:50:38 (running for 00:09:18.82)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:50:43 (running for 00:09:23.83)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [10,  8000] loss: 0.284
    == Status ==
    Current time: 2023-10-23 19:50:48 (running for 00:09:28.84)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-23 19:50:53 (running for 00:09:33.84)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2797) [10, 10000] loss: 0.223
    == Status ==
    Current time: 2023-10-23 19:50:58 (running for 00:09:38.85)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00005 | RUNNING    | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |      9 |         523.744  | 1.2988  |     0.5389 |
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_2331a_00005:
      accuracy: 0.5757
      date: 2023-10-23_19-50-59
      done: true
      hostname: ad5500790270
      iterations_since_restore: 10
      loss: 1.1902698599040509
      node_ip: 172.17.0.2
      pid: 2797
      should_checkpoint: true
      time_since_restore: 570.3624165058136
      time_this_iter_s: 46.618661403656006
      time_total_s: 570.3624165058136
      timestamp: 1698090659
      training_iteration: 10
      trial_id: 2331a_00005
  
    Trial train_cifar_2331a_00005 completed.
    == Status ==
    Current time: 2023-10-23 19:50:59 (running for 00:09:40.41)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.3753507368147373 | Iter 4.000: -1.8746521109580994 | Iter 2.000: -1.9714622361183167 | Iter 1.000: -2.173883711707592
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-23_19-41-19
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_2331a_00000 | TERMINATED | 172.17.0.2:2706 |            2 |   16 |    1 | 0.00213327  |      4 |         443.031  | 2.01101 |     0.1921 |
    | train_cifar_2331a_00001 | TERMINATED | 172.17.0.2:2789 |            4 |    1 |    2 | 0.013416    |      1 |          72.5341 | 2.30788 |     0.1018 |
    | train_cifar_2331a_00002 | TERMINATED | 172.17.0.2:2791 |            2 |  256 |   64 | 0.0113784   |      1 |         171.435  | 2.30162 |     0.1206 |
    | train_cifar_2331a_00003 | TERMINATED | 172.17.0.2:2793 |            8 |   64 |  256 | 0.0274071   |      4 |         184.462  | 2.01841 |     0.2295 |
    | train_cifar_2331a_00004 | TERMINATED | 172.17.0.2:2795 |            4 |   16 |    2 | 0.056666    |      1 |          73.8764 | 2.34306 |     0.1001 |
    | train_cifar_2331a_00005 | TERMINATED | 172.17.0.2:2797 |            4 |    8 |   64 | 0.000353097 |     10 |         570.362  | 1.19027 |     0.5757 |
    | train_cifar_2331a_00006 | TERMINATED | 172.17.0.2:2799 |            8 |   16 |    4 | 0.000147684 |     10 |         371.114  | 1.52648 |     0.4317 |
    | train_cifar_2331a_00007 | TERMINATED | 172.17.0.2:2801 |            8 |  256 |  256 | 0.00477469  |     10 |         398.898  | 1.43828 |     0.5341 |
    | train_cifar_2331a_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          96.2168 | 2.071   |     0.2181 |
    | train_cifar_2331a_00009 | TERMINATED | 172.17.0.2:2795 |            2 |    2 |   16 | 0.0286986   |      1 |         130.765  | 2.39489 |     0.0954 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-10-23 19:50:59,704 INFO tune.py:945 -- Total run time: 580.49 seconds (580.40 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.1902698599040509
    Best trial final validation accuracy: 0.5757
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5809




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 9 minutes  57.084 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

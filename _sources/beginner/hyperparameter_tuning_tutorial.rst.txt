
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      1% 884736/170498071 [00:00<00:19, 8826807.70it/s]
      4% 6291456/170498071 [00:00<00:04, 35265986.98it/s]
      8% 13762560/170498071 [00:00<00:02, 53172441.63it/s]
     12% 21299200/170498071 [00:00<00:02, 61844510.21it/s]
     16% 27492352/170498071 [00:00<00:02, 55159842.70it/s]
     19% 33128448/170498071 [00:00<00:02, 53122128.08it/s]
     23% 38535168/170498071 [00:00<00:02, 51836944.87it/s]
     26% 43778048/170498071 [00:00<00:02, 48821441.56it/s]
     29% 48726016/170498071 [00:00<00:02, 48287298.10it/s]
     32% 53739520/170498071 [00:01<00:02, 48715951.69it/s]
     34% 58654720/170498071 [00:01<00:02, 46910258.17it/s]
     37% 63406080/170498071 [00:01<00:02, 46887280.24it/s]
     40% 68288512/170498071 [00:01<00:02, 47432820.04it/s]
     43% 73072640/170498071 [00:01<00:02, 45771091.81it/s]
     46% 78086144/170498071 [00:01<00:01, 46977980.47it/s]
     49% 82903040/170498071 [00:01<00:01, 47221252.38it/s]
     51% 87654400/170498071 [00:01<00:01, 46055435.45it/s]
     54% 92504064/170498071 [00:01<00:01, 46719152.07it/s]
     57% 97189888/170498071 [00:02<00:01, 46409210.75it/s]
     60% 101842944/170498071 [00:02<00:01, 45905499.71it/s]
     63% 107151360/170498071 [00:02<00:01, 47891906.96it/s]
     66% 111968256/170498071 [00:02<00:01, 46756621.26it/s]
     68% 116654080/170498071 [00:02<00:01, 46336168.06it/s]
     71% 121864192/170498071 [00:02<00:01, 48005461.10it/s]
     74% 126681088/170498071 [00:02<00:00, 46450545.86it/s]
     77% 131497984/170498071 [00:02<00:00, 46747418.23it/s]
     80% 136445952/170498071 [00:02<00:00, 47519822.75it/s]
     83% 141230080/170498071 [00:02<00:00, 46093129.20it/s]
     86% 146112512/170498071 [00:03<00:00, 46772921.19it/s]
     89% 150994944/170498071 [00:03<00:00, 47240210.47it/s]
     91% 155746304/170498071 [00:03<00:00, 45647155.05it/s]
     94% 160825344/170498071 [00:03<00:00, 47013451.37it/s]
     97% 165543936/170498071 [00:03<00:00, 46780010.35it/s]
    100% 170262528/170498071 [00:03<00:00, 45474996.77it/s]
    100% 170498071/170498071 [00:03<00:00, 47279897.42it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-10-02 18:08:29,201 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-10-02 18:08:29,249 INFO worker.py:1625 -- Started a local Ray instance.
    2023-10-02 18:08:30,005 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-10-02 18:08:32 (running for 00:00:02.71)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2728) Files already downloaded and verified
    (func pid=2728) Files already downloaded and verified
    == Status ==
    Current time: 2023-10-02 18:08:37 (running for 00:00:07.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2728) [1,  2000] loss: 2.322
    (func pid=2808) Files already downloaded and verified [repeated 14x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-10-02 18:08:42 (running for 00:00:12.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2806) [1,  2000] loss: 2.331 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-02 18:08:47 (running for 00:00:17.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-02 18:08:52 (running for 00:00:22.77)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2798) [1,  4000] loss: 1.112 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-02 18:08:57 (running for 00:00:27.79)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2808) [1,  4000] loss: 0.777 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-10-02 18:09:02 (running for 00:00:32.79)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_b1038_00000 | RUNNING  | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_b1038_00001 | RUNNING  | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_b1038_00002 | RUNNING  | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_b1038_00003 | RUNNING  | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_b1038_00004 | RUNNING  | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_b1038_00005 | RUNNING  | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_b1038_00006 | RUNNING  | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_b1038_00007 | RUNNING  | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_b1038_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_b1038_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_b1038_00003:
      accuracy: 0.2024
      date: 2023-10-02_18-09-05
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.1465593576431274
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 29.899922847747803
      time_this_iter_s: 29.899922847747803
      time_total_s: 29.899922847747803
      timestamp: 1696270145
      training_iteration: 1
      trial_id: b1038_00003
  
    Result for train_cifar_b1038_00006:
      accuracy: 0.1055
      date: 2023-10-02_18-09-06
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.3044766025543213
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 30.227038145065308
      time_this_iter_s: 30.227038145065308
      time_total_s: 30.227038145065308
      timestamp: 1696270146
      training_iteration: 1
      trial_id: b1038_00006
  
    Trial train_cifar_b1038_00006 completed.
    (func pid=2806) Files already downloaded and verified
    (func pid=2728) [1,  8000] loss: 0.576 [repeated 5x across cluster]
    (func pid=2806) Files already downloaded and verified
    Result for train_cifar_b1038_00007:
      accuracy: 0.4517
      date: 2023-10-02_18-09-09
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 1.498324126958847
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 33.68749809265137
      time_this_iter_s: 33.68749809265137
      time_total_s: 33.68749809265137
      timestamp: 1696270149
      training_iteration: 1
      trial_id: b1038_00007
  
    == Status ==
    Current time: 2023-10-02 18:09:09 (running for 00:00:39.50)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1465593576431274
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00001 | RUNNING    | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      1 |          29.8999 | 2.14656 |     0.2024 |
    | train_cifar_b1038_00004 | RUNNING    | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      1 |          33.6875 | 1.49832 |     0.4517 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_b1038_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-02 18:09:14 (running for 00:00:44.52)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1465593576431274
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00001 | RUNNING    | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      1 |          29.8999 | 2.14656 |     0.2024 |
    | train_cifar_b1038_00004 | RUNNING    | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      1 |          33.6875 | 1.49832 |     0.4517 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_b1038_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2800) [2,  2000] loss: 2.023 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-02 18:09:19 (running for 00:00:49.53)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1465593576431274
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00001 | RUNNING    | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      1 |          29.8999 | 2.14656 |     0.2024 |
    | train_cifar_b1038_00004 | RUNNING    | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      1 |          33.6875 | 1.49832 |     0.4517 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_b1038_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-02 18:09:24 (running for 00:00:54.53)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1465593576431274
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00001 | RUNNING    | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      1 |          29.8999 | 2.14656 |     0.2024 |
    | train_cifar_b1038_00004 | RUNNING    | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      1 |          33.6875 | 1.49832 |     0.4517 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_b1038_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.3178
      date: 2023-10-02_18-09-25
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 1.7658286809444428
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 49.52815914154053
      time_this_iter_s: 49.52815914154053
      time_total_s: 49.52815914154053
      timestamp: 1696270165
      training_iteration: 1
      trial_id: b1038_00005
  
    (func pid=2728) [1, 14000] loss: 0.329 [repeated 8x across cluster]
    Result for train_cifar_b1038_00001:
      accuracy: 0.1014
      date: 2023-10-02_18-09-26
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.310926878833771
      node_ip: 172.17.0.2
      pid: 2796
      should_checkpoint: true
      time_since_restore: 50.83632969856262
      time_this_iter_s: 50.83632969856262
      time_total_s: 50.83632969856262
      timestamp: 1696270166
      training_iteration: 1
      trial_id: b1038_00001
  
    Trial train_cifar_b1038_00001 completed.
    Result for train_cifar_b1038_00004:
      accuracy: 0.0975
      date: 2023-10-02_18-09-26
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.3140784039497375
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 51.04946970939636
      time_this_iter_s: 51.04946970939636
      time_total_s: 51.04946970939636
      timestamp: 1696270166
      training_iteration: 1
      trial_id: b1038_00004
  
    Trial train_cifar_b1038_00004 completed.
    (func pid=2796) Files already downloaded and verified
    (func pid=2796) Files already downloaded and verified
    == Status ==
    Current time: 2023-10-02 18:09:31 (running for 00:01:01.91)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.2255179800987244
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      1 |          29.8999 | 2.14656 |     0.2024 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      1 |          33.6875 | 1.49832 |     0.4517 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2728) [1, 16000] loss: 0.288 [repeated 5x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.2461
      date: 2023-10-02_18-09-34
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 2
      loss: 2.017415925216675
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 58.25583505630493
      time_this_iter_s: 28.35591220855713
      time_total_s: 58.25583505630493
      timestamp: 1696270174
      training_iteration: 2
      trial_id: b1038_00003
  
    Result for train_cifar_b1038_00008:
      accuracy: 0.2181
      date: 2023-10-02_18-09-36
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.084682375526428
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 30.554292917251587
      time_this_iter_s: 30.554292917251587
      time_total_s: 30.554292917251587
      timestamp: 1696270176
      training_iteration: 1
      trial_id: b1038_00008
  
    Result for train_cifar_b1038_00007:
      accuracy: 0.5334
      date: 2023-10-02_18-09-39
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 2
      loss: 1.32189930870533
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 64.09517288208008
      time_this_iter_s: 30.40767478942871
      time_total_s: 64.09517288208008
      timestamp: 1696270179
      training_iteration: 2
      trial_id: b1038_00007
  
    == Status ==
    Current time: 2023-10-02 18:09:39 (running for 00:01:09.91)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6696576169610025 | Iter 1.000: -2.1465593576431274
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      2 |          58.2558 | 2.01742 |     0.2461 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      2 |          64.0952 | 1.3219  |     0.5334 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      1 |          30.5543 | 2.08468 |     0.2181 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2728) [1, 18000] loss: 0.256 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-02 18:09:44 (running for 00:01:14.91)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6696576169610025 | Iter 1.000: -2.1465593576431274
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      2 |          58.2558 | 2.01742 |     0.2461 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      2 |          64.0952 | 1.3219  |     0.5334 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      1 |          30.5543 | 2.08468 |     0.2181 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2806) [2,  2000] loss: 2.060 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-02 18:09:49 (running for 00:01:19.93)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6696576169610025 | Iter 1.000: -2.1465593576431274
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      2 |          58.2558 | 2.01742 |     0.2461 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      2 |          64.0952 | 1.3219  |     0.5334 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      1 |          30.5543 | 2.08468 |     0.2181 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2800) [3,  4000] loss: 1.019 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-02 18:09:54 (running for 00:01:24.93)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6696576169610025 | Iter 1.000: -2.1465593576431274
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      2 |          58.2558 | 2.01742 |     0.2461 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      2 |          64.0952 | 1.3219  |     0.5334 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      1 |          30.5543 | 2.08468 |     0.2181 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-02 18:10:00 (running for 00:01:29.94)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6696576169610025 | Iter 1.000: -2.1465593576431274
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | RUNNING    | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      2 |          58.2558 | 2.01742 |     0.2461 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      2 |          64.0952 | 1.3219  |     0.5334 |
    | train_cifar_b1038_00008 | RUNNING    | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      1 |          30.5543 | 2.08468 |     0.2181 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00000:
      accuracy: 0.1009
      date: 2023-10-02_18-10-00
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.3043973481655122
      node_ip: 172.17.0.2
      pid: 2728
      should_checkpoint: true
      time_since_restore: 87.3891224861145
      time_this_iter_s: 87.3891224861145
      time_total_s: 87.3891224861145
      timestamp: 1696270200
      training_iteration: 1
      trial_id: b1038_00000
  
    Trial train_cifar_b1038_00000 completed.
    (func pid=2808) [3,  4000] loss: 0.624 [repeated 5x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.2365
      date: 2023-10-02_18-10-01
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 3
      loss: 2.0308959528923034
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 84.95221590995789
      time_this_iter_s: 26.696380853652954
      time_total_s: 84.95221590995789
      timestamp: 1696270201
      training_iteration: 3
      trial_id: b1038_00003
  
    Result for train_cifar_b1038_00008:
      accuracy: 0.2047
      date: 2023-10-02_18-10-04
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 2
      loss: 2.104394083404541
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 58.26336884498596
      time_this_iter_s: 27.709075927734375
      time_total_s: 58.26336884498596
      timestamp: 1696270204
      training_iteration: 2
      trial_id: b1038_00008
  
    Trial train_cifar_b1038_00008 completed.
    Result for train_cifar_b1038_00007:
      accuracy: 0.5406
      date: 2023-10-02_18-10-08
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 3
      loss: 1.2858485427856445
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 92.72226858139038
      time_this_iter_s: 28.627095699310303
      time_total_s: 92.72226858139038
      timestamp: 1696270208
      training_iteration: 3
      trial_id: b1038_00007
  
    == Status ==
    Current time: 2023-10-02 18:10:08 (running for 00:01:38.53)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.017415925216675 | Iter 1.000: -2.22547835290432
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00002 | RUNNING    | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      3 |          84.9522 | 2.0309  |     0.2365 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      1 |          49.5282 | 1.76583 |     0.3178 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      3 |          92.7223 | 1.28585 |     0.5406 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.4468
      date: 2023-10-02_18-10-08
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 2
      loss: 1.4924170568585395
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 93.00285720825195
      time_this_iter_s: 43.474698066711426
      time_total_s: 93.00285720825195
      timestamp: 1696270208
      training_iteration: 2
      trial_id: b1038_00005
  
    Result for train_cifar_b1038_00002:
      accuracy: 0.101
      date: 2023-10-02_18-10-09
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.32170434217453
      node_ip: 172.17.0.2
      pid: 2798
      should_checkpoint: true
      time_since_restore: 93.86214542388916
      time_this_iter_s: 93.86214542388916
      time_total_s: 93.86214542388916
      timestamp: 1696270209
      training_iteration: 1
      trial_id: b1038_00002
  
    Trial train_cifar_b1038_00002 completed.
    (func pid=2796) [1, 12000] loss: 0.390 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-02 18:10:14 (running for 00:01:44.67)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3043973481655122
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      3 |          84.9522 | 2.0309  |     0.2365 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      2 |          93.0029 | 1.49242 |     0.4468 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      3 |          92.7223 | 1.28585 |     0.5406 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [3,  2000] loss: 1.475 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:10:19 (running for 00:01:49.68)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3043973481655122
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      3 |          84.9522 | 2.0309  |     0.2365 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      2 |          93.0029 | 1.49242 |     0.4468 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      3 |          92.7223 | 1.28585 |     0.5406 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2796) [1, 16000] loss: 0.292 [repeated 4x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.2362
      date: 2023-10-02_18-10-23
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 4
      loss: 2.018368705749512
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 107.70691251754761
      time_this_iter_s: 22.75469660758972
      time_total_s: 107.70691251754761
      timestamp: 1696270223
      training_iteration: 4
      trial_id: b1038_00003
  
    (func pid=2796) [1, 18000] loss: 0.260 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-02 18:10:28 (running for 00:01:58.73)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -2.018368705749512 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3043973481655122
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      4 |         107.707  | 2.01837 |     0.2362 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      2 |          93.0029 | 1.49242 |     0.4468 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      3 |          92.7223 | 1.28585 |     0.5406 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2796) [1, 20000] loss: 0.233 [repeated 2x across cluster]
    Result for train_cifar_b1038_00007:
      accuracy: 0.5552
      date: 2023-10-02_18-10-32
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 4
      loss: 1.260321550667286
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 116.43392896652222
      time_this_iter_s: 23.711660385131836
      time_total_s: 116.43392896652222
      timestamp: 1696270232
      training_iteration: 4
      trial_id: b1038_00007
  
    == Status ==
    Current time: 2023-10-02 18:10:37 (running for 00:02:07.25)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3043973481655122
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      4 |         107.707  | 2.01837 |     0.2362 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      2 |          93.0029 | 1.49242 |     0.4468 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      4 |         116.434  | 1.26032 |     0.5552 |
    | train_cifar_b1038_00009 | RUNNING    | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [3, 10000] loss: 0.276 [repeated 3x across cluster]
    Result for train_cifar_b1038_00009:
      accuracy: 0.1035
      date: 2023-10-02_18-10-40
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 1
      loss: 2.317973042654991
      node_ip: 172.17.0.2
      pid: 2796
      should_checkpoint: true
      time_since_restore: 74.01363635063171
      time_this_iter_s: 74.01363635063171
      time_total_s: 74.01363635063171
      timestamp: 1696270240
      training_iteration: 1
      trial_id: b1038_00009
  
    Trial train_cifar_b1038_00009 completed.
    Result for train_cifar_b1038_00005:
      accuracy: 0.4902
      date: 2023-10-02_18-10-44
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 3
      loss: 1.3979048459351062
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 128.31556749343872
      time_this_iter_s: 35.31271028518677
      time_total_s: 128.31556749343872
      timestamp: 1696270244
      training_iteration: 3
      trial_id: b1038_00005
  
    == Status ==
    Current time: 2023-10-02 18:10:44 (running for 00:02:14.18)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      4 |         107.707  | 2.01837 |     0.2362 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      4 |         116.434  | 1.26032 |     0.5552 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00003:
      accuracy: 0.2427
      date: 2023-10-02_18-10-45
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 5
      loss: 2.0172132433891297
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 129.67820692062378
      time_this_iter_s: 21.971294403076172
      time_total_s: 129.67820692062378
      timestamp: 1696270245
      training_iteration: 5
      trial_id: b1038_00003
  
    (func pid=2808) [5,  4000] loss: 0.559 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-02 18:10:50 (running for 00:02:20.70)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      5 |         129.678  | 2.01721 |     0.2427 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      4 |         116.434  | 1.26032 |     0.5552 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [4,  4000] loss: 0.671 [repeated 3x across cluster]
    Result for train_cifar_b1038_00007:
      accuracy: 0.565
      date: 2023-10-02_18-10-55
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 5
      loss: 1.2660969140589238
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 139.77994060516357
      time_this_iter_s: 23.346011638641357
      time_total_s: 139.77994060516357
      timestamp: 1696270255
      training_iteration: 5
      trial_id: b1038_00007
  
    == Status ==
    Current time: 2023-10-02 18:11:00 (running for 00:02:30.59)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      5 |         129.678  | 2.01721 |     0.2427 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      5 |         139.78   | 1.2661  |     0.565  |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [4,  6000] loss: 0.443 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:05 (running for 00:02:35.60)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      5 |         129.678  | 2.01721 |     0.2427 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      5 |         139.78   | 1.2661  |     0.565  |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [4,  8000] loss: 0.327 [repeated 2x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.2354
      date: 2023-10-02_18-11-06
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 6
      loss: 1.9963496508598328
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 150.40989756584167
      time_this_iter_s: 20.731690645217896
      time_total_s: 150.40989756584167
      timestamp: 1696270266
      training_iteration: 6
      trial_id: b1038_00003
  
    == Status ==
    Current time: 2023-10-02 18:11:11 (running for 00:02:41.43)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      6 |         150.41   | 1.99635 |     0.2354 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      5 |         139.78   | 1.2661  |     0.565  |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [4, 10000] loss: 0.258 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:16 (running for 00:02:46.43)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.639345128208399 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      6 |         150.41   | 1.99635 |     0.2354 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      3 |         128.316  | 1.3979  |     0.4902 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      5 |         139.78   | 1.2661  |     0.565  |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5343
      date: 2023-10-02_18-11-16
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 4
      loss: 1.289273008799553
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 160.72776174545288
      time_this_iter_s: 32.41219425201416
      time_total_s: 160.72776174545288
      timestamp: 1696270276
      training_iteration: 4
      trial_id: b1038_00005
  
    Result for train_cifar_b1038_00007:
      accuracy: 0.5527
      date: 2023-10-02_18-11-18
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 6
      loss: 1.3037852122545242
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 162.22456574440002
      time_this_iter_s: 22.44462513923645
      time_total_s: 162.22456574440002
      timestamp: 1696270278
      training_iteration: 6
      trial_id: b1038_00007
  
    (func pid=2800) [7,  4000] loss: 1.062 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:23 (running for 00:02:53.04)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      6 |         150.41   | 1.99635 |     0.2354 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      4 |         160.728  | 1.28927 |     0.5343 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      6 |         162.225  | 1.30379 |     0.5527 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2808) [7,  2000] loss: 0.983 [repeated 2x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.1829
      date: 2023-10-02_18-11-27
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 7
      loss: 2.122456594276428
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 170.94932079315186
      time_this_iter_s: 20.53942322731018
      time_total_s: 170.94932079315186
      timestamp: 1696270287
      training_iteration: 7
      trial_id: b1038_00003
  
    == Status ==
    Current time: 2023-10-02 18:11:32 (running for 00:03:01.97)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      7 |         170.949  | 2.12246 |     0.1829 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      4 |         160.728  | 1.28927 |     0.5343 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      6 |         162.225  | 1.30379 |     0.5527 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [5,  6000] loss: 0.418 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:37 (running for 00:03:06.98)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      7 |         170.949  | 2.12246 |     0.1829 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      4 |         160.728  | 1.28927 |     0.5343 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      6 |         162.225  | 1.30379 |     0.5527 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [5,  8000] loss: 0.317 [repeated 3x across cluster]
    Result for train_cifar_b1038_00007:
      accuracy: 0.5563
      date: 2023-10-02_18-11-40
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 7
      loss: 1.3396614312171935
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 184.620436668396
      time_this_iter_s: 22.39587092399597
      time_total_s: 184.620436668396
      timestamp: 1696270300
      training_iteration: 7
      trial_id: b1038_00007
  
    (func pid=2804) [5, 10000] loss: 0.247 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:45 (running for 00:03:15.43)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      7 |         170.949  | 2.12246 |     0.1829 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      4 |         160.728  | 1.28927 |     0.5343 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      7 |         184.62   | 1.33966 |     0.5563 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00003:
      accuracy: 0.2125
      date: 2023-10-02_18-11-47
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 8
      loss: 2.079906907558441
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 191.02524852752686
      time_this_iter_s: 20.075927734375
      time_total_s: 191.02524852752686
      timestamp: 1696270307
      training_iteration: 8
      trial_id: b1038_00003
  
    Result for train_cifar_b1038_00005:
      accuracy: 0.5106
      date: 2023-10-02_18-11-49
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 5
      loss: 1.360655928978324
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 193.44245862960815
      time_this_iter_s: 32.71469688415527
      time_total_s: 193.44245862960815
      timestamp: 1696270309
      training_iteration: 5
      trial_id: b1038_00005
  
    (func pid=2800) [9,  2000] loss: 2.056 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:11:54 (running for 00:03:24.31)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.079906907558441 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      8 |         191.025  | 2.07991 |     0.2125 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      7 |         184.62   | 1.33966 |     0.5563 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-02 18:11:59 (running for 00:03:29.32)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.079906907558441 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      8 |         191.025  | 2.07991 |     0.2125 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      7 |         184.62   | 1.33966 |     0.5563 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [6,  4000] loss: 0.618 [repeated 3x across cluster]
    Result for train_cifar_b1038_00007:
      accuracy: 0.5423
      date: 2023-10-02_18-12-03
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 8
      loss: 1.4109529500365257
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 207.57308793067932
      time_this_iter_s: 22.952651262283325
      time_total_s: 207.57308793067932
      timestamp: 1696270323
      training_iteration: 8
      trial_id: b1038_00007
  
    (func pid=2804) [6,  6000] loss: 0.405 [repeated 2x across cluster]
    Result for train_cifar_b1038_00003:
      accuracy: 0.2358
      date: 2023-10-02_18-12-06
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 9
      loss: 2.0145837955474852
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 210.51332664489746
      time_this_iter_s: 19.488078117370605
      time_total_s: 210.51332664489746
      timestamp: 1696270326
      training_iteration: 9
      trial_id: b1038_00003
  
    == Status ==
    Current time: 2023-10-02 18:12:06 (running for 00:03:36.53)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      9 |         210.513  | 2.01458 |     0.2358 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      8 |         207.573  | 1.41095 |     0.5423 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2808) [9,  2000] loss: 0.940
    == Status ==
    Current time: 2023-10-02 18:12:11 (running for 00:03:41.54)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      9 |         210.513  | 2.01458 |     0.2358 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      8 |         207.573  | 1.41095 |     0.5423 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [6,  8000] loss: 0.307
    == Status ==
    Current time: 2023-10-02 18:12:16 (running for 00:03:46.54)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      9 |         210.513  | 2.01458 |     0.2358 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      8 |         207.573  | 1.41095 |     0.5423 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [6, 10000] loss: 0.242 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:12:21 (running for 00:03:51.55)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00003 | RUNNING    | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |      9 |         210.513  | 2.01458 |     0.2358 |
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      5 |         193.442  | 1.36066 |     0.5106 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      8 |         207.573  | 1.41095 |     0.5423 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5515
      date: 2023-10-02_18-12-22
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 6
      loss: 1.233707968762517
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 226.51780724525452
      time_this_iter_s: 33.07534861564636
      time_total_s: 226.51780724525452
      timestamp: 1696270342
      training_iteration: 6
      trial_id: b1038_00005
  
    Result for train_cifar_b1038_00003:
      accuracy: 0.2335
      date: 2023-10-02_18-12-25
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 10
      loss: 2.040827238368988
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 229.1926486492157
      time_this_iter_s: 18.679322004318237
      time_total_s: 229.1926486492157
      timestamp: 1696270345
      training_iteration: 10
      trial_id: b1038_00003
  
    Trial train_cifar_b1038_00003 completed.
    Result for train_cifar_b1038_00007:
      accuracy: 0.5403
      date: 2023-10-02_18-12-26
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 9
      loss: 1.508304876101017
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 230.63223600387573
      time_this_iter_s: 23.05914807319641
      time_total_s: 230.63223600387573
      timestamp: 1696270346
      training_iteration: 9
      trial_id: b1038_00007
  
    (func pid=2804) [7,  2000] loss: 1.166 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-02 18:12:31 (running for 00:04:01.44)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      6 |         226.518  | 1.23371 |     0.5515 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      9 |         230.632  | 1.5083  |     0.5403 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2808) [10,  2000] loss: 0.916 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:12:36 (running for 00:04:06.45)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      6 |         226.518  | 1.23371 |     0.5515 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      9 |         230.632  | 1.5083  |     0.5403 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2808) [10,  4000] loss: 0.499 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:12:41 (running for 00:04:11.46)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      6 |         226.518  | 1.23371 |     0.5515 |
    | train_cifar_b1038_00007 | RUNNING    | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |      9 |         230.632  | 1.5083  |     0.5403 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00007:
      accuracy: 0.5276
      date: 2023-10-02_18-12-45
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 10
      loss: 1.5321220136284828
      node_ip: 172.17.0.2
      pid: 2808
      should_checkpoint: true
      time_since_restore: 250.0877799987793
      time_this_iter_s: 19.455543994903564
      time_total_s: 250.0877799987793
      timestamp: 1696270365
      training_iteration: 10
      trial_id: b1038_00007
  
    Trial train_cifar_b1038_00007 completed.
    (func pid=2804) [7, 10000] loss: 0.232 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-02 18:12:50 (running for 00:04:20.91)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      6 |         226.518  | 1.23371 |     0.5515 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5671
      date: 2023-10-02_18-12-51
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 7
      loss: 1.206379076462984
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 255.5466468334198
      time_this_iter_s: 29.028839588165283
      time_total_s: 255.5466468334198
      timestamp: 1696270371
      training_iteration: 7
      trial_id: b1038_00005
  
    (func pid=2804) [8,  2000] loss: 1.146
    == Status ==
    Current time: 2023-10-02 18:12:56 (running for 00:04:26.41)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      7 |         255.547  | 1.20638 |     0.5671 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8,  4000] loss: 0.571
    == Status ==
    Current time: 2023-10-02 18:13:01 (running for 00:04:31.42)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      7 |         255.547  | 1.20638 |     0.5671 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8,  6000] loss: 0.382
    == Status ==
    Current time: 2023-10-02 18:13:06 (running for 00:04:36.43)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      7 |         255.547  | 1.20638 |     0.5671 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8,  8000] loss: 0.289
    == Status ==
    Current time: 2023-10-02 18:13:11 (running for 00:04:41.44)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      7 |         255.547  | 1.20638 |     0.5671 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8, 10000] loss: 0.230
    == Status ==
    Current time: 2023-10-02 18:13:16 (running for 00:04:46.44)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.7454299287974835 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      7 |         255.547  | 1.20638 |     0.5671 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5735
      date: 2023-10-02_18-13-18
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 8
      loss: 1.1945408323019744
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 282.6628248691559
      time_this_iter_s: 27.116178035736084
      time_total_s: 282.6628248691559
      timestamp: 1696270398
      training_iteration: 8
      trial_id: b1038_00005
  
    (func pid=2804) [9,  2000] loss: 1.121
    == Status ==
    Current time: 2023-10-02 18:13:23 (running for 00:04:53.53)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      8 |         282.663  | 1.19454 |     0.5735 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [9,  4000] loss: 0.564
    == Status ==
    Current time: 2023-10-02 18:13:28 (running for 00:04:58.54)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      8 |         282.663  | 1.19454 |     0.5735 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [9,  6000] loss: 0.378
    == Status ==
    Current time: 2023-10-02 18:13:33 (running for 00:05:03.55)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      8 |         282.663  | 1.19454 |     0.5735 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [9,  8000] loss: 0.280
    == Status ==
    Current time: 2023-10-02 18:13:38 (running for 00:05:08.55)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      8 |         282.663  | 1.19454 |     0.5735 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [9, 10000] loss: 0.225
    == Status ==
    Current time: 2023-10-02 18:13:43 (running for 00:05:13.56)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      8 |         282.663  | 1.19454 |     0.5735 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5855
      date: 2023-10-02_18-13-45
      done: false
      hostname: 5d85b14625f6
      iterations_since_restore: 9
      loss: 1.156560538521409
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 309.71180844306946
      time_this_iter_s: 27.048983573913574
      time_total_s: 309.71180844306946
      timestamp: 1696270425
      training_iteration: 9
      trial_id: b1038_00005
  
    (func pid=2804) [10,  2000] loss: 1.108
    == Status ==
    Current time: 2023-10-02 18:13:50 (running for 00:05:20.58)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      9 |         309.712  | 1.15656 |     0.5855 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [10,  4000] loss: 0.551
    == Status ==
    Current time: 2023-10-02 18:13:55 (running for 00:05:25.59)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      9 |         309.712  | 1.15656 |     0.5855 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [10,  6000] loss: 0.372
    == Status ==
    Current time: 2023-10-02 18:14:00 (running for 00:05:30.59)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      9 |         309.712  | 1.15656 |     0.5855 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [10,  8000] loss: 0.274
    == Status ==
    Current time: 2023-10-02 18:14:05 (running for 00:05:35.60)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      9 |         309.712  | 1.15656 |     0.5855 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [10, 10000] loss: 0.225
    == Status ==
    Current time: 2023-10-02 18:14:10 (running for 00:05:40.61)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00005 | RUNNING    | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |      9 |         309.712  | 1.15656 |     0.5855 |
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_b1038_00005:
      accuracy: 0.5934
      date: 2023-10-02_18-14-12
      done: true
      hostname: 5d85b14625f6
      iterations_since_restore: 10
      loss: 1.1471209490925074
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 336.9534707069397
      time_this_iter_s: 27.24166226387024
      time_total_s: 336.9534707069397
      timestamp: 1696270452
      training_iteration: 10
      trial_id: b1038_00005
  
    Trial train_cifar_b1038_00005 completed.
    == Status ==
    Current time: 2023-10-02 18:14:12 (running for 00:05:42.83)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.4109529500365257 | Iter 4.000: -1.289273008799553 | Iter 2.000: -1.7549164910376072 | Iter 1.000: -2.3044369753599168
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-02_18-08-30
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_b1038_00000 | TERMINATED | 172.17.0.2:2728 |            2 |   16 |    1 | 0.00213327  |      1 |          87.3891 | 2.3044  |     0.1009 |
    | train_cifar_b1038_00001 | TERMINATED | 172.17.0.2:2796 |            4 |    1 |    2 | 0.013416    |      1 |          50.8363 | 2.31093 |     0.1014 |
    | train_cifar_b1038_00002 | TERMINATED | 172.17.0.2:2798 |            2 |  256 |   64 | 0.0113784   |      1 |          93.8621 | 2.3217  |     0.101  |
    | train_cifar_b1038_00003 | TERMINATED | 172.17.0.2:2800 |            8 |   64 |  256 | 0.0274071   |     10 |         229.193  | 2.04083 |     0.2335 |
    | train_cifar_b1038_00004 | TERMINATED | 172.17.0.2:2802 |            4 |   16 |    2 | 0.056666    |      1 |          51.0495 | 2.31408 |     0.0975 |
    | train_cifar_b1038_00005 | TERMINATED | 172.17.0.2:2804 |            4 |    8 |   64 | 0.000353097 |     10 |         336.953  | 1.14712 |     0.5934 |
    | train_cifar_b1038_00006 | TERMINATED | 172.17.0.2:2806 |            8 |   16 |    4 | 0.000147684 |      1 |          30.227  | 2.30448 |     0.1055 |
    | train_cifar_b1038_00007 | TERMINATED | 172.17.0.2:2808 |            8 |  256 |  256 | 0.00477469  |     10 |         250.088  | 1.53212 |     0.5276 |
    | train_cifar_b1038_00008 | TERMINATED | 172.17.0.2:2806 |            8 |  128 |  256 | 0.0306227   |      2 |          58.2634 | 2.10439 |     0.2047 |
    | train_cifar_b1038_00009 | TERMINATED | 172.17.0.2:2796 |            2 |    2 |   16 | 0.0286986   |      1 |          74.0136 | 2.31797 |     0.1035 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-10-02 18:14:12,893 INFO tune.py:945 -- Total run time: 342.89 seconds (342.82 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.1471209490925074
    Best trial final validation accuracy: 0.5934
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5969




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  58.674 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 655360/170498071 [00:00<00:25, 6553371.88it/s]
      5% 8126464/170498071 [00:00<00:03, 46630201.25it/s]
     11% 19365888/170498071 [00:00<00:01, 76621098.55it/s]
     18% 30638080/170498071 [00:00<00:01, 90776903.67it/s]
     24% 41517056/170498071 [00:00<00:01, 97255100.17it/s]
     31% 52559872/170498071 [00:00<00:01, 101692065.01it/s]
     37% 63897600/170498071 [00:00<00:01, 105441588.21it/s]
     44% 74973184/170498071 [00:00<00:00, 107080716.94it/s]
     50% 85688320/170498071 [00:00<00:00, 99717258.33it/s] 
     56% 96043008/170498071 [00:01<00:00, 99843927.58it/s]
     62% 106233856/170498071 [00:01<00:00, 100438764.57it/s]
     68% 116424704/170498071 [00:01<00:00, 100780757.95it/s]
     75% 127303680/170498071 [00:01<00:00, 103098866.67it/s]
     81% 138149888/170498071 [00:01<00:00, 104606884.49it/s]
     87% 148635648/170498071 [00:01<00:00, 102989916.07it/s]
     94% 159481856/170498071 [00:01<00:00, 104590358.45it/s]
    100% 170295296/170498071 [00:01<00:00, 105579284.39it/s]
    100% 170498071/170498071 [00:01<00:00, 98142461.94it/s] 
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-12-14 19:06:06,123 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-12-14 19:06:06,157 INFO worker.py:1625 -- Started a local Ray instance.
    2023-12-14 19:06:06,940 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    (pid=2714) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
    (pid=2714)   _torch_pytree._register_pytree_node(
    == Status ==
    Current time: 2023-12-14 19:06:11 (running for 00:00:04.06)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2714) Files already downloaded and verified
    (func pid=2714) Files already downloaded and verified
    == Status ==
    Current time: 2023-12-14 19:06:16 (running for 00:00:09.13)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2782) Files already downloaded and verified [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    (func pid=2714) [1,  2000] loss: 2.245
    == Status ==
    Current time: 2023-12-14 19:06:21 (running for 00:00:14.14)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-12-14 19:06:26 (running for 00:00:19.15)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2791) Files already downloaded and verified [repeated 6x across cluster]
    (func pid=2779) [1,  2000] loss: 2.311
    (func pid=2781) [1,  2000] loss: 2.239
    == Status ==
    Current time: 2023-12-14 19:06:31 (running for 00:00:24.16)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2785) [1,  4000] loss: 1.167 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-12-14 19:06:36 (running for 00:00:29.16)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2791) [1,  4000] loss: 0.779 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-12-14 19:06:41 (running for 00:00:34.17)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-12-14 19:06:46 (running for 00:00:39.18)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_d5a96_00000 | RUNNING  | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_d5a96_00001 | RUNNING  | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_d5a96_00002 | RUNNING  | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_d5a96_00003 | RUNNING  | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_d5a96_00004 | RUNNING  | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_d5a96_00005 | RUNNING  | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_d5a96_00006 | RUNNING  | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_d5a96_00007 | RUNNING  | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_d5a96_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_d5a96_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.1684
      date: 2023-12-14_19-06-47
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.1398294564247133
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 32.32372999191284
      time_this_iter_s: 32.32372999191284
      time_total_s: 32.32372999191284
      timestamp: 1702580807
      training_iteration: 1
      trial_id: d5a96_00003
  
    Result for train_cifar_d5a96_00006:
      accuracy: 0.1312
      date: 2023-12-14_19-06-48
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.247952480220795
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 32.5991849899292
      time_this_iter_s: 32.5991849899292
      time_total_s: 32.5991849899292
      timestamp: 1702580808
      training_iteration: 1
      trial_id: d5a96_00006
  
    Trial train_cifar_d5a96_00006 completed.
    (func pid=2789) Files already downloaded and verified
    (func pid=2787) [1,  6000] loss: 0.682 [repeated 5x across cluster]
    (func pid=2789) Files already downloaded and verified
    Result for train_cifar_d5a96_00007:
      accuracy: 0.482
      date: 2023-12-14_19-06-51
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 1.4472523307561875
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 35.43115973472595
      time_this_iter_s: 35.43115973472595
      time_total_s: 35.43115973472595
      timestamp: 1702580811
      training_iteration: 1
      trial_id: d5a96_00007
  
    == Status ==
    Current time: 2023-12-14 19:06:51 (running for 00:00:44.24)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1398294564247133
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00001 | RUNNING    | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      1 |          32.3237 | 2.13983 |     0.1684 |
    | train_cifar_d5a96_00004 | RUNNING    | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_d5a96_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:06:56 (running for 00:00:49.25)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1398294564247133
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00001 | RUNNING    | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      1 |          32.3237 | 2.13983 |     0.1684 |
    | train_cifar_d5a96_00004 | RUNNING    | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_d5a96_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2782) [2,  2000] loss: 2.130 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:01 (running for 00:00:54.26)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1398294564247133
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00001 | RUNNING    | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      1 |          32.3237 | 2.13983 |     0.1684 |
    | train_cifar_d5a96_00004 | RUNNING    | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_d5a96_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:07:06 (running for 00:00:59.27)
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1398294564247133
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00001 | RUNNING    | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      1 |          32.3237 | 2.13983 |     0.1684 |
    | train_cifar_d5a96_00004 | RUNNING    | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_d5a96_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2782) [2,  4000] loss: 1.076 [repeated 8x across cluster]
    Result for train_cifar_d5a96_00004:
      accuracy: 0.0986
      date: 2023-12-14_19-07-09
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.3130693758010863
      node_ip: 172.17.0.2
      pid: 2785
      should_checkpoint: true
      time_since_restore: 53.68202471733093
      time_this_iter_s: 53.68202471733093
      time_total_s: 53.68202471733093
      timestamp: 1702580829
      training_iteration: 1
      trial_id: d5a96_00004
  
    Trial train_cifar_d5a96_00004 completed.
    (func pid=2785) Files already downloaded and verified
    Result for train_cifar_d5a96_00001:
      accuracy: 0.1009
      date: 2023-12-14_19-07-09
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.3049571054458617
      node_ip: 172.17.0.2
      pid: 2779
      should_checkpoint: true
      time_since_restore: 54.4379346370697
      time_this_iter_s: 54.4379346370697
      time_total_s: 54.4379346370697
      timestamp: 1702580829
      training_iteration: 1
      trial_id: d5a96_00001
  
    Trial train_cifar_d5a96_00001 completed.
    Result for train_cifar_d5a96_00005:
      accuracy: 0.3587
      date: 2023-12-14_19-07-10
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 1.7464240653514862
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 54.662433385849
      time_this_iter_s: 54.662433385849
      time_total_s: 54.662433385849
      timestamp: 1702580830
      training_iteration: 1
      trial_id: d5a96_00005
  
    (func pid=2785) Files already downloaded and verified
    (func pid=2791) [2,  4000] loss: 0.679 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:15 (running for 00:01:08.32)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.193890968322754
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      1 |          32.3237 | 2.13983 |     0.1684 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.0979
      date: 2023-12-14_19-07-18
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 2
      loss: 2.308165188217163
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 62.64239287376404
      time_this_iter_s: 30.318662881851196
      time_total_s: 62.64239287376404
      timestamp: 1702580838
      training_iteration: 2
      trial_id: d5a96_00003
  
    Result for train_cifar_d5a96_00008:
      accuracy: 0.2474
      date: 2023-12-14_19-07-21
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.0561342250823973
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 33.13684296607971
      time_this_iter_s: 33.13684296607971
      time_total_s: 33.13684296607971
      timestamp: 1702580841
      training_iteration: 1
      trial_id: d5a96_00008
  
    == Status ==
    Current time: 2023-12-14 19:07:21 (running for 00:01:14.33)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.308165188217163 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      2 |          62.6424 | 2.30817 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      1 |          35.4312 | 1.44725 |     0.482  |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          33.1368 | 2.05613 |     0.2474 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5005
      date: 2023-12-14_19-07-24
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 2
      loss: 1.406810056734085
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 68.51804661750793
      time_this_iter_s: 33.08688688278198
      time_total_s: 68.51804661750793
      timestamp: 1702580844
      training_iteration: 2
      trial_id: d5a96_00007
  
    (func pid=2714) [1, 18000] loss: 0.213 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:29 (running for 00:01:22.33)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.857487622475624 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      2 |          62.6424 | 2.30817 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      2 |          68.518  | 1.40681 |     0.5005 |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          33.1368 | 2.05613 |     0.2474 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2789) [2,  2000] loss: 2.098 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:34 (running for 00:01:27.34)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.857487622475624 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      2 |          62.6424 | 2.30817 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      2 |          68.518  | 1.40681 |     0.5005 |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          33.1368 | 2.05613 |     0.2474 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2782) [3,  4000] loss: 1.155 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:39 (running for 00:01:32.34)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.857487622475624 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      2 |          62.6424 | 2.30817 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      2 |          68.518  | 1.40681 |     0.5005 |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          33.1368 | 2.05613 |     0.2474 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2781) [1, 20000] loss: 0.232 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:07:44 (running for 00:01:37.35)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.857487622475624 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      2 |          62.6424 | 2.30817 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      2 |          68.518  | 1.40681 |     0.5005 |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      1 |          33.1368 | 2.05613 |     0.2474 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00000:
      accuracy: 0.1857
      date: 2023-12-14_19-07-44
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 1.931199220252037
      node_ip: 172.17.0.2
      pid: 2714
      should_checkpoint: true
      time_since_restore: 93.8702802658081
      time_this_iter_s: 93.8702802658081
      time_total_s: 93.8702802658081
      timestamp: 1702580864
      training_iteration: 1
      trial_id: d5a96_00000
  
    Result for train_cifar_d5a96_00003:
      accuracy: 0.0992
      date: 2023-12-14_19-07-47
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 3
      loss: 2.3054366594314577
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 91.74336457252502
      time_this_iter_s: 29.100971698760986
      time_total_s: 91.74336457252502
      timestamp: 1702580867
      training_iteration: 3
      trial_id: d5a96_00003
  
    (func pid=2785) [1, 10000] loss: 0.468 [repeated 3x across cluster]
    Result for train_cifar_d5a96_00008:
      accuracy: 0.1465
      date: 2023-12-14_19-07-51
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 2
      loss: 2.2301367038726805
      node_ip: 172.17.0.2
      pid: 2789
      should_checkpoint: true
      time_since_restore: 63.21752166748047
      time_this_iter_s: 30.080678701400757
      time_total_s: 63.21752166748047
      timestamp: 1702580871
      training_iteration: 2
      trial_id: d5a96_00008
  
    Trial train_cifar_d5a96_00008 completed.
    == Status ==
    Current time: 2023-12-14 19:07:51 (running for 00:01:44.41)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.2301367038726805 | Iter 1.000: -2.0979818407535555
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00002 | RUNNING    | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      3 |          91.7434 | 2.30544 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      1 |          54.6624 | 1.74642 |     0.3587 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      2 |          68.518  | 1.40681 |     0.5005 |
    | train_cifar_d5a96_00008 | RUNNING    | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.552
      date: 2023-12-14_19-07-56
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 3
      loss: 1.2922333163261415
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 100.53624749183655
      time_this_iter_s: 32.01820087432861
      time_total_s: 100.53624749183655
      timestamp: 1702580876
      training_iteration: 3
      trial_id: d5a96_00007
  
    Result for train_cifar_d5a96_00002:
      accuracy: 0.0996
      date: 2023-12-14_19-07-56
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.313875011396408
      node_ip: 172.17.0.2
      pid: 2781
      should_checkpoint: true
      time_since_restore: 100.65871095657349
      time_this_iter_s: 100.65871095657349
      time_total_s: 100.65871095657349
      timestamp: 1702580876
      training_iteration: 1
      trial_id: d5a96_00002
  
    Trial train_cifar_d5a96_00002 completed.
    (func pid=2785) [1, 12000] loss: 0.389 [repeated 3x across cluster]
    Result for train_cifar_d5a96_00005:
      accuracy: 0.453
      date: 2023-12-14_19-07-59
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 2
      loss: 1.4961724370360374
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 103.51655602455139
      time_this_iter_s: 48.85412263870239
      time_total_s: 103.51655602455139
      timestamp: 1702580879
      training_iteration: 2
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:07:59 (running for 00:01:52.16)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      3 |          91.7434 | 2.30544 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      3 |         100.536  | 1.29223 |     0.552  |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2785) [1, 14000] loss: 0.333 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:04 (running for 00:01:57.18)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      3 |          91.7434 | 2.30544 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      3 |         100.536  | 1.29223 |     0.552  |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:08:09 (running for 00:02:02.19)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      3 |          91.7434 | 2.30544 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      3 |         100.536  | 1.29223 |     0.552  |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2785) [1, 16000] loss: 0.292 [repeated 5x across cluster]
    Result for train_cifar_d5a96_00003:
      accuracy: 0.0969
      date: 2023-12-14_19-08-13
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 4
      loss: 2.3089038446426393
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 118.49326777458191
      time_this_iter_s: 26.749903202056885
      time_total_s: 118.49326777458191
      timestamp: 1702580893
      training_iteration: 4
      trial_id: d5a96_00003
  
    (func pid=2791) [4,  4000] loss: 0.584 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:18 (running for 00:02:12.00)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -2.3089038446426393 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      4 |         118.493  | 2.3089  |     0.0969 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      3 |         100.536  | 1.29223 |     0.552  |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [3,  6000] loss: 0.473 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:24 (running for 00:02:17.00)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -2.3089038446426393 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      4 |         118.493  | 2.3089  |     0.0969 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      3 |         100.536  | 1.29223 |     0.552  |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5655
      date: 2023-12-14_19-08-24
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 4
      loss: 1.2441536710143088
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 128.88352060317993
      time_this_iter_s: 28.347273111343384
      time_total_s: 128.88352060317993
      timestamp: 1702580904
      training_iteration: 4
      trial_id: d5a96_00007
  
    (func pid=2787) [3,  8000] loss: 0.355 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:29 (running for 00:02:22.69)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.1398294564247133
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      4 |         118.493  | 2.3089  |     0.0969 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      4 |         128.884  | 1.24415 |     0.5655 |
    | train_cifar_d5a96_00009 | RUNNING    | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00009:
      accuracy: 0.0941
      date: 2023-12-14_19-08-33
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 1
      loss: 2.3252178466796876
      node_ip: 172.17.0.2
      pid: 2785
      should_checkpoint: true
      time_since_restore: 84.05428647994995
      time_this_iter_s: 84.05428647994995
      time_total_s: 84.05428647994995
      timestamp: 1702580913
      training_iteration: 1
      trial_id: d5a96_00009
  
    Trial train_cifar_d5a96_00009 completed.
    (func pid=2791) [5,  2000] loss: 1.086 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:38 (running for 00:02:31.58)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.193890968322754
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      4 |         118.493  | 2.3089  |     0.0969 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      2 |         103.517  | 1.49617 |     0.453  |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      4 |         128.884  | 1.24415 |     0.5655 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.0992
      date: 2023-12-14_19-08-39
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 5
      loss: 2.3104869178771974
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 143.78552174568176
      time_this_iter_s: 25.292253971099854
      time_total_s: 143.78552174568176
      timestamp: 1702580919
      training_iteration: 5
      trial_id: d5a96_00003
  
    Result for train_cifar_d5a96_00005:
      accuracy: 0.4949
      date: 2023-12-14_19-08-41
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 3
      loss: 1.3771073498815298
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 145.5730004310608
      time_this_iter_s: 42.0564444065094
      time_total_s: 145.5730004310608
      timestamp: 1702580921
      training_iteration: 3
      trial_id: d5a96_00005
  
    (func pid=2791) [5,  4000] loss: 0.559 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:46 (running for 00:02:39.23)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.193890968322754
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      5 |         143.786  | 2.31049 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      4 |         128.884  | 1.24415 |     0.5655 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2714) [2, 20000] loss: 0.192 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:51 (running for 00:02:44.24)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.193890968322754
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      5 |         143.786  | 2.31049 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      4 |         128.884  | 1.24415 |     0.5655 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5774
      date: 2023-12-14_19-08-52
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 5
      loss: 1.2481239364743233
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 156.48989701271057
      time_this_iter_s: 27.60637640953064
      time_total_s: 156.48989701271057
      timestamp: 1702580932
      training_iteration: 5
      trial_id: d5a96_00007
  
    (func pid=2782) [6,  4000] loss: 1.155 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:08:57 (running for 00:02:50.29)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.863154570454359 | Iter 1.000: -2.193890968322754
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | RUNNING    | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      1 |          93.8703 | 1.9312  |     0.1857 |
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      5 |         143.786  | 2.31049 |     0.0992 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      5 |         156.49   | 1.24812 |     0.5774 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00000:
      accuracy: 0.2076
      date: 2023-12-14_19-08-59
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 2
      loss: 1.929408298754692
      node_ip: 172.17.0.2
      pid: 2714
      should_checkpoint: true
      time_since_restore: 168.88889503479004
      time_this_iter_s: 75.01861476898193
      time_total_s: 168.88889503479004
      timestamp: 1702580939
      training_iteration: 2
      trial_id: d5a96_00000
  
    Trial train_cifar_d5a96_00000 completed.
    (func pid=2791) [6,  2000] loss: 1.031
    (func pid=2787) [4,  6000] loss: 0.442
    Result for train_cifar_d5a96_00003:
      accuracy: 0.0979
      date: 2023-12-14_19-09-03
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 6
      loss: 2.3079767147064207
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 167.8968334197998
      time_this_iter_s: 24.111311674118042
      time_total_s: 167.8968334197998
      timestamp: 1702580943
      training_iteration: 6
      trial_id: d5a96_00003
  
    == Status ==
    Current time: 2023-12-14 19:09:03 (running for 00:02:56.40)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      6 |         167.897  | 2.30798 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      5 |         156.49   | 1.24812 |     0.5774 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:09:08 (running for 00:03:01.41)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      6 |         167.897  | 2.30798 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      5 |         156.49   | 1.24812 |     0.5774 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

    (func pid=2787) [4,  8000] loss: 0.326

    (func pid=2791) [6,  4000] loss: 0.535
    == Status ==
    Current time: 2023-12-14 19:09:13 (running for 00:03:06.42)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.776528757828474 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      6 |         167.897  | 2.30798 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      3 |         145.573  | 1.37711 |     0.4949 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      5 |         156.49   | 1.24812 |     0.5774 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5846
      date: 2023-12-14_19-09-17
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 6
      loss: 1.2599709447324277
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 181.978679895401
      time_this_iter_s: 25.48878288269043
      time_total_s: 181.978679895401
      timestamp: 1702580957
      training_iteration: 6
      trial_id: d5a96_00007
  
    (func pid=2782) [7,  4000] loss: 1.155 [repeated 3x across cluster]
    Result for train_cifar_d5a96_00005:
      accuracy: 0.5235
      date: 2023-12-14_19-09-19
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 4
      loss: 1.3212311032176018
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 184.02457904815674
      time_this_iter_s: 38.45157861709595
      time_total_s: 184.02457904815674
      timestamp: 1702580959
      training_iteration: 4
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:09:19 (running for 00:03:12.67)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      6 |         167.897  | 2.30798 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      6 |         181.979  | 1.25997 |     0.5846 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:09:24 (running for 00:03:17.68)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      6 |         167.897  | 2.30798 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      6 |         181.979  | 1.25997 |     0.5846 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.1021
      date: 2023-12-14_19-09-25
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 7
      loss: 2.309220392036438
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 190.26875853538513
      time_this_iter_s: 22.371925115585327
      time_total_s: 190.26875853538513
      timestamp: 1702580965
      training_iteration: 7
      trial_id: d5a96_00003
  
    (func pid=2787) [5,  2000] loss: 1.249
    (func pid=2791) [7,  2000] loss: 0.982
    == Status ==
    Current time: 2023-12-14 19:09:30 (running for 00:03:23.77)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      7 |         190.269  | 2.30922 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      6 |         181.979  | 1.25997 |     0.5846 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [5,  4000] loss: 0.640
    (func pid=2782) [8,  2000] loss: 2.310
    == Status ==
    Current time: 2023-12-14 19:09:35 (running for 00:03:28.77)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      7 |         190.269  | 2.30922 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      6 |         181.979  | 1.25997 |     0.5846 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [5,  6000] loss: 0.420 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:09:40 (running for 00:03:33.78)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      7 |         190.269  | 2.30922 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      6 |         181.979  | 1.25997 |     0.5846 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5716
      date: 2023-12-14_19-09-42
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 7
      loss: 1.3360796859443187
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 206.74960589408875
      time_this_iter_s: 24.770925998687744
      time_total_s: 206.74960589408875
      timestamp: 1702580982
      training_iteration: 7
      trial_id: d5a96_00007
  
    (func pid=2787) [5,  8000] loss: 0.311 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:09:47 (running for 00:03:40.55)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      7 |         190.269  | 2.30922 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      7 |         206.75   | 1.33608 |     0.5716 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.1021
      date: 2023-12-14_19-09-47
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 8
      loss: 2.3138444232940674
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 212.4504747390747
      time_this_iter_s: 22.181716203689575
      time_total_s: 212.4504747390747
      timestamp: 1702580987
      training_iteration: 8
      trial_id: d5a96_00003
  
    (func pid=2787) [5, 10000] loss: 0.252
    (func pid=2791) [8,  2000] loss: 0.950
    == Status ==
    Current time: 2023-12-14 19:09:52 (running for 00:03:45.95)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.3138444232940674 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      8 |         212.45   | 2.31384 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      4 |         184.025  | 1.32123 |     0.5235 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      7 |         206.75   | 1.33608 |     0.5716 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00005:
      accuracy: 0.5479
      date: 2023-12-14_19-09-56
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 5
      loss: 1.2510445901066065
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 220.85690569877625
      time_this_iter_s: 36.83232665061951
      time_total_s: 220.85690569877625
      timestamp: 1702580996
      training_iteration: 5
      trial_id: d5a96_00005
  
    (func pid=2791) [8,  4000] loss: 0.505 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:10:01 (running for 00:03:54.51)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.3138444232940674 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      8 |         212.45   | 2.31384 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      7 |         206.75   | 1.33608 |     0.5716 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:10:06 (running for 00:03:59.52)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -2.3138444232940674 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      8 |         212.45   | 2.31384 |     0.1021 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      7 |         206.75   | 1.33608 |     0.5716 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5821
      date: 2023-12-14_19-10-07
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 8
      loss: 1.3201933920025826
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 232.0770606994629
      time_this_iter_s: 25.327454805374146
      time_total_s: 232.0770606994629
      timestamp: 1702581007
      training_iteration: 8
      trial_id: d5a96_00007
  
    (func pid=2787) [6,  4000] loss: 0.618 [repeated 3x across cluster]
    Result for train_cifar_d5a96_00003:
      accuracy: 0.0979
      date: 2023-12-14_19-10-10
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 9
      loss: 2.3076448236465454
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 234.94189643859863
      time_this_iter_s: 22.491421699523926
      time_total_s: 234.94189643859863
      timestamp: 1702581010
      training_iteration: 9
      trial_id: d5a96_00003
  
    == Status ==
    Current time: 2023-12-14 19:10:15 (running for 00:04:08.44)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      9 |         234.942  | 2.30764 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      8 |         232.077  | 1.32019 |     0.5821 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [6,  6000] loss: 0.402
    (func pid=2791) [9,  2000] loss: 0.927
    == Status ==
    Current time: 2023-12-14 19:10:20 (running for 00:04:13.45)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      9 |         234.942  | 2.30764 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      8 |         232.077  | 1.32019 |     0.5821 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [6,  8000] loss: 0.305 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:10:25 (running for 00:04:18.46)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      9 |         234.942  | 2.30764 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      8 |         232.077  | 1.32019 |     0.5821 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [6, 10000] loss: 0.240 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-12-14 19:10:30 (running for 00:04:23.47)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00003 | RUNNING    | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |      9 |         234.942  | 2.30764 |     0.0979 |
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      5 |         220.857  | 1.25104 |     0.5479 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      8 |         232.077  | 1.32019 |     0.5821 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00003:
      accuracy: 0.0979
      date: 2023-12-14_19-10-31
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 10
      loss: 2.3103190145492554
      node_ip: 172.17.0.2
      pid: 2782
      should_checkpoint: true
      time_since_restore: 256.2805926799774
      time_this_iter_s: 21.338696241378784
      time_total_s: 256.2805926799774
      timestamp: 1702581031
      training_iteration: 10
      trial_id: d5a96_00003
  
    Trial train_cifar_d5a96_00003 completed.
    Result for train_cifar_d5a96_00007:
      accuracy: 0.5691
      date: 2023-12-14_19-10-32
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 9
      loss: 1.3518806369185448
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 256.6421844959259
      time_this_iter_s: 24.565123796463013
      time_total_s: 256.6421844959259
      timestamp: 1702581032
      training_iteration: 9
      trial_id: d5a96_00007
  
    Result for train_cifar_d5a96_00005:
      accuracy: 0.5592
      date: 2023-12-14_19-10-34
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 6
      loss: 1.2310811492860316
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 258.5319519042969
      time_this_iter_s: 37.67504620552063
      time_total_s: 258.5319519042969
      timestamp: 1702581034
      training_iteration: 6
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:10:39 (running for 00:04:32.19)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      9 |         256.642  | 1.35188 |     0.5691 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [7,  2000] loss: 1.164
    (func pid=2791) [10,  2000] loss: 0.909
    == Status ==
    Current time: 2023-12-14 19:10:44 (running for 00:04:37.19)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      9 |         256.642  | 1.35188 |     0.5691 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2791) [10,  4000] loss: 0.500 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:10:49 (running for 00:04:42.20)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      9 |         256.642  | 1.35188 |     0.5691 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-12-14 19:10:54 (running for 00:04:47.21)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00007 | RUNNING    | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |      9 |         256.642  | 1.35188 |     0.5691 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00007:
      accuracy: 0.5611
      date: 2023-12-14_19-10-54
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 10
      loss: 1.47524132168293
      node_ip: 172.17.0.2
      pid: 2791
      should_checkpoint: true
      time_since_restore: 278.9080674648285
      time_this_iter_s: 22.265882968902588
      time_total_s: 278.9080674648285
      timestamp: 1702581054
      training_iteration: 10
      trial_id: d5a96_00007
  
    Trial train_cifar_d5a96_00007 completed.
    (func pid=2787) [7,  8000] loss: 0.298 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-12-14 19:10:59 (running for 00:04:52.72)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [7, 10000] loss: 0.236
    == Status ==
    Current time: 2023-12-14 19:11:04 (running for 00:04:57.72)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      6 |         258.532  | 1.23108 |     0.5592 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00005:
      accuracy: 0.5641
      date: 2023-12-14_19-11-05
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 7
      loss: 1.2019260732412338
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 290.2517499923706
      time_this_iter_s: 31.71979808807373
      time_total_s: 290.2517499923706
      timestamp: 1702581065
      training_iteration: 7
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:11:10 (running for 00:05:03.90)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [8,  2000] loss: 1.136
    == Status ==
    Current time: 2023-12-14 19:11:15 (running for 00:05:08.91)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [8,  4000] loss: 0.590
    == Status ==
    Current time: 2023-12-14 19:11:20 (running for 00:05:13.92)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [8,  6000] loss: 0.386
    == Status ==
    Current time: 2023-12-14 19:11:25 (running for 00:05:18.92)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [8,  8000] loss: 0.287
    == Status ==
    Current time: 2023-12-14 19:11:30 (running for 00:05:23.93)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [8, 10000] loss: 0.226
    == Status ==
    Current time: 2023-12-14 19:11:35 (running for 00:05:28.94)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.817018907648325 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      7 |         290.252  | 1.20193 |     0.5641 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00005:
      accuracy: 0.5698
      date: 2023-12-14_19-11-36
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 8
      loss: 1.2112148784071206
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 320.88399028778076
      time_this_iter_s: 30.632240295410156
      time_total_s: 320.88399028778076
      timestamp: 1702581096
      training_iteration: 8
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:11:41 (running for 00:05:34.54)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [9,  2000] loss: 1.116
    == Status ==
    Current time: 2023-12-14 19:11:46 (running for 00:05:39.54)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [9,  4000] loss: 0.564
    == Status ==
    Current time: 2023-12-14 19:11:51 (running for 00:05:44.55)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [9,  6000] loss: 0.381
    == Status ==
    Current time: 2023-12-14 19:11:56 (running for 00:05:49.56)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [9,  8000] loss: 0.279
    == Status ==
    Current time: 2023-12-14 19:12:01 (running for 00:05:54.57)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [9, 10000] loss: 0.225
    == Status ==
    Current time: 2023-12-14 19:12:06 (running for 00:05:59.57)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      8 |         320.884  | 1.21121 |     0.5698 |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00005:
      accuracy: 0.57
      date: 2023-12-14_19-12-07
      done: false
      hostname: 8682f841ae71
      iterations_since_restore: 9
      loss: 1.196170206156373
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 352.022198677063
      time_this_iter_s: 31.138208389282227
      time_total_s: 352.022198677063
      timestamp: 1702581127
      training_iteration: 9
      trial_id: d5a96_00005
  
    == Status ==
    Current time: 2023-12-14 19:12:12 (running for 00:06:05.68)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [10,  2000] loss: 1.104
    == Status ==
    Current time: 2023-12-14 19:12:17 (running for 00:06:10.68)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [10,  4000] loss: 0.559
    == Status ==
    Current time: 2023-12-14 19:12:22 (running for 00:06:15.69)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [10,  6000] loss: 0.375
    == Status ==
    Current time: 2023-12-14 19:12:27 (running for 00:06:20.69)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [10,  8000] loss: 0.274
    == Status ==
    Current time: 2023-12-14 19:12:32 (running for 00:06:25.70)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2787) [10, 10000] loss: 0.224
    == Status ==
    Current time: 2023-12-14 19:12:37 (running for 00:06:30.71)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00005 | RUNNING    | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |      9 |         352.022  | 1.19617 |     0.57   |
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_d5a96_00005:
      accuracy: 0.5896
      date: 2023-12-14_19-12-39
      done: true
      hostname: 8682f841ae71
      iterations_since_restore: 10
      loss: 1.1635507949173451
      node_ip: 172.17.0.2
      pid: 2787
      should_checkpoint: true
      time_since_restore: 383.5518910884857
      time_this_iter_s: 31.52969241142273
      time_total_s: 383.5518910884857
      timestamp: 1702581159
      training_iteration: 10
      trial_id: d5a96_00005
  
    Trial train_cifar_d5a96_00005 completed.
    == Status ==
    Current time: 2023-12-14 19:12:39 (running for 00:06:32.20)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.3201933920025826 | Iter 4.000: -1.3212311032176018 | Iter 2.000: -1.929408298754692 | Iter 1.000: -2.193890968322754
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A10G)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-12-14_19-06-06
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_d5a96_00000 | TERMINATED | 172.17.0.2:2714 |            2 |   16 |    1 | 0.00213327  |      2 |         168.889  | 1.92941 |     0.2076 |
    | train_cifar_d5a96_00001 | TERMINATED | 172.17.0.2:2779 |            4 |    1 |    2 | 0.013416    |      1 |          54.4379 | 2.30496 |     0.1009 |
    | train_cifar_d5a96_00002 | TERMINATED | 172.17.0.2:2781 |            2 |  256 |   64 | 0.0113784   |      1 |         100.659  | 2.31388 |     0.0996 |
    | train_cifar_d5a96_00003 | TERMINATED | 172.17.0.2:2782 |            8 |   64 |  256 | 0.0274071   |     10 |         256.281  | 2.31032 |     0.0979 |
    | train_cifar_d5a96_00004 | TERMINATED | 172.17.0.2:2785 |            4 |   16 |    2 | 0.056666    |      1 |          53.682  | 2.31307 |     0.0986 |
    | train_cifar_d5a96_00005 | TERMINATED | 172.17.0.2:2787 |            4 |    8 |   64 | 0.000353097 |     10 |         383.552  | 1.16355 |     0.5896 |
    | train_cifar_d5a96_00006 | TERMINATED | 172.17.0.2:2789 |            8 |   16 |    4 | 0.000147684 |      1 |          32.5992 | 2.24795 |     0.1312 |
    | train_cifar_d5a96_00007 | TERMINATED | 172.17.0.2:2791 |            8 |  256 |  256 | 0.00477469  |     10 |         278.908  | 1.47524 |     0.5611 |
    | train_cifar_d5a96_00008 | TERMINATED | 172.17.0.2:2789 |            8 |  128 |  256 | 0.0306227   |      2 |          63.2175 | 2.23014 |     0.1465 |
    | train_cifar_d5a96_00009 | TERMINATED | 172.17.0.2:2785 |            2 |    2 |   16 | 0.0286986   |      1 |          84.0543 | 2.32522 |     0.0941 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-12-14 19:12:39,207 INFO tune.py:945 -- Total run time: 392.27 seconds (392.20 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.1635507949173451
    Best trial final validation accuracy: 0.5896
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5959




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 6 minutes  44.745 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 458752/170498071 [00:00<00:37, 4578496.85it/s]
      4% 6488064/170498071 [00:00<00:04, 37039826.91it/s]
      8% 14352384/170498071 [00:00<00:02, 55462901.96it/s]
     13% 22478848/170498071 [00:00<00:02, 65329519.98it/s]
     18% 30441472/170498071 [00:00<00:01, 70400128.16it/s]
     22% 38076416/170498071 [00:00<00:01, 72311396.84it/s]
     27% 45318144/170498071 [00:00<00:01, 70190092.24it/s]
     31% 52363264/170498071 [00:00<00:01, 66008489.78it/s]
     35% 59015168/170498071 [00:00<00:01, 65547316.14it/s]
     39% 67108864/170498071 [00:01<00:01, 69928554.24it/s]
     44% 75235328/170498071 [00:01<00:01, 73211895.72it/s]
     49% 83329024/170498071 [00:01<00:01, 75433701.38it/s]
     54% 91586560/170498071 [00:01<00:01, 77486504.29it/s]
     59% 99909632/170498071 [00:01<00:00, 79191938.07it/s]
     63% 108232704/170498071 [00:01<00:00, 80326755.62it/s]
     68% 116686848/170498071 [00:01<00:00, 81467205.48it/s]
     73% 125206528/170498071 [00:01<00:00, 82536524.08it/s]
     78% 133758976/170498071 [00:01<00:00, 83416291.33it/s]
     83% 142344192/170498071 [00:01<00:00, 84119320.94it/s]
     89% 151158784/170498071 [00:02<00:00, 85307012.36it/s]
     94% 160104448/170498071 [00:02<00:00, 86390118.45it/s]
     99% 169082880/170498071 [00:02<00:00, 87385880.97it/s]
    100% 170498071/170498071 [00:02<00:00, 75478045.37it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-10-05 19:25:56,272 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-10-05 19:25:56,521 INFO worker.py:1625 -- Started a local Ray instance.
    2023-10-05 19:25:57,688 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-10-05 19:26:02 (running for 00:00:04.35)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2707) Files already downloaded and verified
    (func pid=2707) Files already downloaded and verified
    == Status ==
    Current time: 2023-10-05 19:26:07 (running for 00:00:09.68)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2802) Files already downloaded and verified [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-10-05 19:26:12 (running for 00:00:14.69)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2707) [1,  2000] loss: 2.321
    (func pid=2804) Files already downloaded and verified [repeated 9x across cluster]
    == Status ==
    Current time: 2023-10-05 19:26:17 (running for 00:00:19.70)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2794) [1,  2000] loss: 2.267
    (func pid=2802) [1,  2000] loss: 2.304
    == Status ==
    Current time: 2023-10-05 19:26:22 (running for 00:00:24.71)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-05 19:26:27 (running for 00:00:29.72)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    == Status ==
    Current time: 2023-10-05 19:26:32 (running for 00:00:34.73)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2802) [1,  4000] loss: 1.144 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-10-05 19:26:37 (running for 00:00:39.74)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2806) [1,  4000] loss: 0.780 [repeated 7x across cluster]
    == Status ==
    Current time: 2023-10-05 19:26:42 (running for 00:00:44.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2800) [1,  6000] loss: 0.779 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-05 19:26:47 (running for 00:00:49.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_027d8_00006:
      accuracy: 0.1437
      date: 2023-10-05_19-26-49
      done: false
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.266955425834656
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 42.3643274307251
      time_this_iter_s: 42.3643274307251
      time_total_s: 42.3643274307251
      timestamp: 1696534009
      training_iteration: 1
      trial_id: 027d8_00006
  
    Result for train_cifar_027d8_00003:
      accuracy: 0.235
      date: 2023-10-05_19-26-50
      done: false
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 1.9893562960624696
      node_ip: 172.17.0.2
      pid: 2798
      should_checkpoint: true
      time_since_restore: 43.25250601768494
      time_this_iter_s: 43.25250601768494
      time_total_s: 43.25250601768494
      timestamp: 1696534010
      training_iteration: 1
      trial_id: 027d8_00003
  
    Result for train_cifar_027d8_00007:
      accuracy: 0.4552
      date: 2023-10-05_19-26-52
      done: false
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 1.5313636626958846
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 45.768681049346924
      time_this_iter_s: 45.768681049346924
      time_total_s: 45.768681049346924
      timestamp: 1696534012
      training_iteration: 1
      trial_id: 027d8_00007
  
    == Status ==
    Current time: 2023-10-05 19:26:52 (running for 00:00:55.21)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9893562960624696
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2794) [1,  8000] loss: 0.577 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-05 19:26:57 (running for 00:01:00.22)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9893562960624696
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:27:03 (running for 00:01:05.24)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9893562960624696
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [2,  2000] loss: 2.247 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-05 19:27:08 (running for 00:01:10.25)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9893562960624696
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:27:13 (running for 00:01:15.26)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9893562960624696
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING  | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00001 | RUNNING  | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING  | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING  | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING  | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
    | train_cifar_027d8_00005 | RUNNING  | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
    | train_cifar_027d8_00006 | RUNNING  | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING  | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.347
      date: 2023-10-05_19-27-17
      done: false
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 1.7539124301671982
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 70.2458884716034
      time_this_iter_s: 70.2458884716034
      time_total_s: 70.2458884716034
      timestamp: 1696534037
      training_iteration: 1
      trial_id: 027d8_00005
  
    Result for train_cifar_027d8_00001:
      accuracy: 0.0981
      date: 2023-10-05_19-27-17
      done: true
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.3083494417190553
      node_ip: 172.17.0.2
      pid: 2794
      should_checkpoint: true
      time_since_restore: 70.30523300170898
      time_this_iter_s: 70.30523300170898
      time_total_s: 70.30523300170898
      timestamp: 1696534037
      training_iteration: 1
      trial_id: 027d8_00001
  
    Trial train_cifar_027d8_00001 completed.
    (func pid=2804) [2,  4000] loss: 1.107 [repeated 8x across cluster]
    (func pid=2794) Files already downloaded and verified
    Result for train_cifar_027d8_00004:
      accuracy: 0.1022
      date: 2023-10-05_19-27-18
      done: true
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.344879946756363
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 71.55432844161987
      time_this_iter_s: 71.55432844161987
      time_total_s: 71.55432844161987
      timestamp: 1696534038
      training_iteration: 1
      trial_id: 027d8_00004
  
    Trial train_cifar_027d8_00004 completed.
    == Status ==
    Current time: 2023-10-05 19:27:18 (running for 00:01:20.83)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 PENDING, 8 RUNNING, 1 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00004 | RUNNING    | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | PENDING    |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2794) Files already downloaded and verified
    (func pid=2806) [2,  4000] loss: 0.665 [repeated 4x across cluster]
    (func pid=2800) Files already downloaded and verified [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:27:23 (running for 00:01:25.87)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:27:28 (running for 00:01:30.88)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      1 |          43.2525 | 1.98936 |     0.235  |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      1 |          42.3643 | 2.26696 |     0.1437 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      1 |          45.7687 | 1.53136 |     0.4552 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2707) [1, 16000] loss: 0.288
    (func pid=2802) [2,  2000] loss: 1.702
    Result for train_cifar_027d8_00006:
      accuracy: 0.1845
      date: 2023-10-05_19-27-30
      done: false
      hostname: 344139faed32
      iterations_since_restore: 2
      loss: 2.1781167145729063
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 82.76680827140808
      time_this_iter_s: 40.40248084068298
      time_total_s: 82.76680827140808
      timestamp: 1696534050
      training_iteration: 2
      trial_id: 027d8_00006
  
    Result for train_cifar_027d8_00003:
      accuracy: 0.2179
      date: 2023-10-05_19-27-33
      done: false
      hostname: 344139faed32
      iterations_since_restore: 2
      loss: 2.0787693601608277
      node_ip: 172.17.0.2
      pid: 2798
      should_checkpoint: true
      time_since_restore: 85.94992876052856
      time_this_iter_s: 42.69742274284363
      time_total_s: 85.94992876052856
      timestamp: 1696534053
      training_iteration: 2
      trial_id: 027d8_00003
  
    (func pid=2794) [1,  2000] loss: 2.102 [repeated 2x across cluster]
    Result for train_cifar_027d8_00007:
      accuracy: 0.5077
      date: 2023-10-05_19-27-36
      done: false
      hostname: 344139faed32
      iterations_since_restore: 2
      loss: 1.4223324749469757
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 89.39618825912476
      time_this_iter_s: 43.62750720977783
      time_total_s: 89.39618825912476
      timestamp: 1696534056
      training_iteration: 2
      trial_id: 027d8_00007
  
    == Status ==
    Current time: 2023-10-05 19:27:36 (running for 00:01:38.83)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2707) [1, 18000] loss: 0.256 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:27:41 (running for 00:01:43.84)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:27:46 (running for 00:01:48.85)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2798) [3,  2000] loss: 2.091 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-05 19:27:51 (running for 00:01:53.86)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2800) [1,  6000] loss: 0.778 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-05 19:27:56 (running for 00:01:58.88)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:28:01 (running for 00:02:03.89)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.1281558609485627
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2798) [3,  4000] loss: 1.043 [repeated 2x across cluster]
    Result for train_cifar_027d8_00008:
      accuracy: 0.2149
      date: 2023-10-05_19-28-03
      done: false
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.112707799720764
      node_ip: 172.17.0.2
      pid: 2794
      should_checkpoint: true
      time_since_restore: 46.2958664894104
      time_this_iter_s: 46.2958664894104
      time_total_s: 46.2958664894104
      timestamp: 1696534083
      training_iteration: 1
      trial_id: 027d8_00008
  
    Result for train_cifar_027d8_00000:
      accuracy: 0.0969
      date: 2023-10-05_19-28-07
      done: true
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.3058509619235994
      node_ip: 172.17.0.2
      pid: 2707
      should_checkpoint: true
      time_since_restore: 125.44566321372986
      time_this_iter_s: 125.44566321372986
      time_total_s: 125.44566321372986
      timestamp: 1696534087
      training_iteration: 1
      trial_id: 027d8_00000
  
    Trial train_cifar_027d8_00000 completed.
    == Status ==
    Current time: 2023-10-05 19:28:07 (running for 00:02:09.82)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.18983161277771
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | RUNNING    | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      2 |          82.7668 | 2.17812 |     0.1845 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00006:
      accuracy: 0.2306
      date: 2023-10-05_19-28-10
      done: false
      hostname: 344139faed32
      iterations_since_restore: 3
      loss: 2.073096878051758
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 122.80525660514832
      time_this_iter_s: 40.038448333740234
      time_total_s: 122.80525660514832
      timestamp: 1696534090
      training_iteration: 3
      trial_id: 027d8_00006
  
    (func pid=2800) [1, 10000] loss: 0.467 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-10-05 19:28:15 (running for 00:02:17.50)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      2 |          85.9499 | 2.07877 |     0.2179 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      1 |          70.2459 | 1.75391 |     0.347  |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      2 |          89.3962 | 1.42233 |     0.5077 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00003:
      accuracy: 0.1001
      date: 2023-10-05_19-28-15
      done: false
      hostname: 344139faed32
      iterations_since_restore: 3
      loss: 2.308484087562561
      node_ip: 172.17.0.2
      pid: 2798
      should_checkpoint: true
      time_since_restore: 128.89882612228394
      time_this_iter_s: 42.94889736175537
      time_total_s: 128.89882612228394
      timestamp: 1696534095
      training_iteration: 3
      trial_id: 027d8_00003
  
    Result for train_cifar_027d8_00007:
      accuracy: 0.4917
      date: 2023-10-05_19-28-19
      done: false
      hostname: 344139faed32
      iterations_since_restore: 3
      loss: 1.5046547170877456
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 132.3216438293457
      time_this_iter_s: 42.92545557022095
      time_total_s: 132.3216438293457
      timestamp: 1696534099
      training_iteration: 3
      trial_id: 027d8_00007
  
    (func pid=2794) [2,  2000] loss: 2.140 [repeated 2x across cluster]
    Result for train_cifar_027d8_00005:
      accuracy: 0.4449
      date: 2023-10-05_19-28-24
      done: false
      hostname: 344139faed32
      iterations_since_restore: 2
      loss: 1.5279954950332642
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 137.1639106273651
      time_this_iter_s: 66.91802215576172
      time_total_s: 137.1639106273651
      timestamp: 1696534104
      training_iteration: 2
      trial_id: 027d8_00005
  
    == Status ==
    Current time: 2023-10-05 19:28:24 (running for 00:02:26.54)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8033824275970458 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:28:29 (running for 00:02:31.56)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8033824275970458 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2798) [4,  2000] loss: 2.446 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-10-05 19:28:34 (running for 00:02:36.57)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8033824275970458 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [4,  4000] loss: 0.985 [repeated 6x across cluster]
    == Status ==
    Current time: 2023-10-05 19:28:39 (running for 00:02:41.59)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8033824275970458 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:28:44 (running for 00:02:46.60)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8033824275970458 | Iter 1.000: -2.18983161277771
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      3 |         122.805  | 2.0731  |     0.2306 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00008 | RUNNING    | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      1 |          46.2959 | 2.11271 |     0.2149 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2800) [1, 16000] loss: 0.292
    (func pid=2798) [4,  4000] loss: 1.155
    Result for train_cifar_027d8_00006:
      accuracy: 0.2748
      date: 2023-10-05_19-28-48
      done: false
      hostname: 344139faed32
      iterations_since_restore: 4
      loss: 1.915447696018219
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 161.21017837524414
      time_this_iter_s: 38.404921770095825
      time_total_s: 161.21017837524414
      timestamp: 1696534128
      training_iteration: 4
      trial_id: 027d8_00006
  
    Result for train_cifar_027d8_00008:
      accuracy: 0.1743
      date: 2023-10-05_19-28-48
      done: true
      hostname: 344139faed32
      iterations_since_restore: 2
      loss: 2.1151750494003294
      node_ip: 172.17.0.2
      pid: 2794
      should_checkpoint: true
      time_since_restore: 91.24184465408325
      time_this_iter_s: 44.94597816467285
      time_total_s: 91.24184465408325
      timestamp: 1696534128
      training_iteration: 2
      trial_id: 027d8_00008
  
    Trial train_cifar_027d8_00008 completed.
    Result for train_cifar_027d8_00002:
      accuracy: 0.1424
      date: 2023-10-05_19-28-51
      done: true
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.202449523830414
      node_ip: 172.17.0.2
      pid: 2796
      should_checkpoint: true
      time_since_restore: 164.5819206237793
      time_this_iter_s: 164.5819206237793
      time_total_s: 164.5819206237793
      timestamp: 1696534131
      training_iteration: 1
      trial_id: 027d8_00002
  
    Trial train_cifar_027d8_00002 completed.
    == Status ==
    Current time: 2023-10-05 19:28:51 (running for 00:02:53.81)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.202449523830414
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00002 | RUNNING    | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      4 |         161.21   | 1.91545 |     0.2748 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2800) [1, 18000] loss: 0.259 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-10-05 19:28:56 (running for 00:02:58.84)
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.202449523830414
    Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00003 | RUNNING    | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      3 |         128.899  | 2.30848 |     0.1001 |
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      4 |         161.21   | 1.91545 |     0.2748 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      3 |         132.322  | 1.50465 |     0.4917 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00003:
      accuracy: 0.0995
      date: 2023-10-05_19-28-57
      done: true
      hostname: 344139faed32
      iterations_since_restore: 4
      loss: 2.3094982933044435
      node_ip: 172.17.0.2
      pid: 2798
      should_checkpoint: true
      time_since_restore: 170.30065035820007
      time_this_iter_s: 41.40182423591614
      time_total_s: 170.30065035820007
      timestamp: 1696534137
      training_iteration: 4
      trial_id: 027d8_00003
  
    Trial train_cifar_027d8_00003 completed.
    Result for train_cifar_027d8_00007:
      accuracy: 0.5662
      date: 2023-10-05_19-28-59
      done: false
      hostname: 344139faed32
      iterations_since_restore: 4
      loss: 1.2522986597776413
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 172.27478218078613
      time_this_iter_s: 39.95313835144043
      time_total_s: 172.27478218078613
      timestamp: 1696534139
      training_iteration: 4
      trial_id: 027d8_00007
  
    (func pid=2804) [5,  2000] loss: 1.908 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:29:04 (running for 00:03:06.70)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.202449523830414
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      4 |         161.21   | 1.91545 |     0.2748 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      4 |         172.275  | 1.2523  |     0.5662 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [3,  8000] loss: 0.351 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:29:09 (running for 00:03:11.72)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.202449523830414
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      4 |         161.21   | 1.91545 |     0.2748 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      4 |         172.275  | 1.2523  |     0.5662 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2806) [5,  2000] loss: 1.038
    (func pid=2804) [5,  4000] loss: 0.934
    == Status ==
    Current time: 2023-10-05 19:29:14 (running for 00:03:16.72)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.202449523830414
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      4 |         161.21   | 1.91545 |     0.2748 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      4 |         172.275  | 1.2523  |     0.5662 |
    | train_cifar_027d8_00009 | RUNNING    | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00009:
      accuracy: 0.0984
      date: 2023-10-05_19-29-17
      done: true
      hostname: 344139faed32
      iterations_since_restore: 1
      loss: 2.3261309956550598
      node_ip: 172.17.0.2
      pid: 2800
      should_checkpoint: true
      time_since_restore: 118.89718389511108
      time_this_iter_s: 118.89718389511108
      time_total_s: 118.89718389511108
      timestamp: 1696534157
      training_iteration: 1
      trial_id: 027d8_00009
  
    Trial train_cifar_027d8_00009 completed.
    Result for train_cifar_027d8_00006:
      accuracy: 0.3076
      date: 2023-10-05_19-29-21
      done: false
      hostname: 344139faed32
      iterations_since_restore: 5
      loss: 1.81654455909729
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 194.19259595870972
      time_this_iter_s: 32.982417583465576
      time_total_s: 194.19259595870972
      timestamp: 1696534161
      training_iteration: 5
      trial_id: 027d8_00006
  
    == Status ==
    Current time: 2023-10-05 19:29:21 (running for 00:03:23.89)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      2 |         137.164  | 1.528   |     0.4449 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      5 |         194.193  | 1.81654 |     0.3076 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      4 |         172.275  | 1.2523  |     0.5662 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.4978
      date: 2023-10-05_19-29-22
      done: false
      hostname: 344139faed32
      iterations_since_restore: 3
      loss: 1.3766852389752864
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 195.68448185920715
      time_this_iter_s: 58.52057123184204
      time_total_s: 195.68448185920715
      timestamp: 1696534162
      training_iteration: 3
      trial_id: 027d8_00005
  
    (func pid=2806) [5,  4000] loss: 0.542 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:29:27 (running for 00:03:30.06)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      5 |         194.193  | 1.81654 |     0.3076 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      4 |         172.275  | 1.2523  |     0.5662 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [4,  2000] loss: 1.344
    (func pid=2804) [6,  2000] loss: 1.819
    Result for train_cifar_027d8_00007:
      accuracy: 0.5702
      date: 2023-10-05_19-29-32
      done: false
      hostname: 344139faed32
      iterations_since_restore: 5
      loss: 1.2486362325668334
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 205.3531150817871
      time_this_iter_s: 33.07833290100098
      time_total_s: 205.3531150817871
      timestamp: 1696534172
      training_iteration: 5
      trial_id: 027d8_00007
  
    == Status ==
    Current time: 2023-10-05 19:29:37 (running for 00:03:39.79)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      5 |         194.193  | 1.81654 |     0.3076 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      5 |         205.353  | 1.24864 |     0.5702 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [4,  4000] loss: 0.660
    (func pid=2804) [6,  4000] loss: 0.897
    == Status ==
    Current time: 2023-10-05 19:29:42 (running for 00:03:44.80)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      5 |         194.193  | 1.81654 |     0.3076 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      5 |         205.353  | 1.24864 |     0.5702 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:29:47 (running for 00:03:49.81)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      5 |         194.193  | 1.81654 |     0.3076 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      5 |         205.353  | 1.24864 |     0.5702 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [4,  6000] loss: 0.438 [repeated 2x across cluster]
    Result for train_cifar_027d8_00006:
      accuracy: 0.3265
      date: 2023-10-05_19-29-51
      done: false
      hostname: 344139faed32
      iterations_since_restore: 6
      loss: 1.7532815039634704
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 223.8207187652588
      time_this_iter_s: 29.628122806549072
      time_total_s: 223.8207187652588
      timestamp: 1696534191
      training_iteration: 6
      trial_id: 027d8_00006
  
    (func pid=2806) [6,  4000] loss: 0.525
    == Status ==
    Current time: 2023-10-05 19:29:56 (running for 00:03:58.52)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      6 |         223.821  | 1.75328 |     0.3265 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      5 |         205.353  | 1.24864 |     0.5702 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [4,  8000] loss: 0.323
    == Status ==
    Current time: 2023-10-05 19:30:01 (running for 00:04:03.53)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      6 |         223.821  | 1.75328 |     0.3265 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      5 |         205.353  | 1.24864 |     0.5702 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00007:
      accuracy: 0.5696
      date: 2023-10-05_19-30-03
      done: false
      hostname: 344139faed32
      iterations_since_restore: 6
      loss: 1.2925931854844093
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 236.48700594902039
      time_this_iter_s: 31.133890867233276
      time_total_s: 236.48700594902039
      timestamp: 1696534203
      training_iteration: 6
      trial_id: 027d8_00007
  
    (func pid=2802) [4, 10000] loss: 0.257 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:30:08 (running for 00:04:10.92)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.915447696018219 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      3 |         195.684  | 1.37669 |     0.4978 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      6 |         223.821  | 1.75328 |     0.3265 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      6 |         236.487  | 1.29259 |     0.5696 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [7,  4000] loss: 0.866
    Result for train_cifar_027d8_00005:
      accuracy: 0.53
      date: 2023-10-05_19-30-12
      done: false
      hostname: 344139faed32
      iterations_since_restore: 4
      loss: 1.293916858625412
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 245.26260423660278
      time_this_iter_s: 49.57812237739563
      time_total_s: 245.26260423660278
      timestamp: 1696534212
      training_iteration: 4
      trial_id: 027d8_00005
  
    (func pid=2806) [7,  2000] loss: 0.941
    == Status ==
    Current time: 2023-10-05 19:30:17 (running for 00:04:19.64)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      6 |         223.821  | 1.75328 |     0.3265 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      6 |         236.487  | 1.29259 |     0.5696 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00006:
      accuracy: 0.3492
      date: 2023-10-05_19-30-20
      done: false
      hostname: 344139faed32
      iterations_since_restore: 7
      loss: 1.6994000571250916
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 253.49043321609497
      time_this_iter_s: 29.66971445083618
      time_total_s: 253.49043321609497
      timestamp: 1696534220
      training_iteration: 7
      trial_id: 027d8_00006
  
    (func pid=2802) [5,  2000] loss: 1.255
    (func pid=2806) [7,  4000] loss: 0.508
    == Status ==
    Current time: 2023-10-05 19:30:25 (running for 00:04:28.19)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      7 |         253.49   | 1.6994  |     0.3492 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      6 |         236.487  | 1.29259 |     0.5696 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:30:30 (running for 00:04:33.20)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      7 |         253.49   | 1.6994  |     0.3492 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      6 |         236.487  | 1.29259 |     0.5696 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8,  2000] loss: 1.688 [repeated 2x across cluster]
    Result for train_cifar_027d8_00007:
      accuracy: 0.5695
      date: 2023-10-05_19-30-35
      done: false
      hostname: 344139faed32
      iterations_since_restore: 7
      loss: 1.3231843158841132
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 267.875417470932
      time_this_iter_s: 31.38841152191162
      time_total_s: 267.875417470932
      timestamp: 1696534235
      training_iteration: 7
      trial_id: 027d8_00007
  
    (func pid=2802) [5,  6000] loss: 0.410
    == Status ==
    Current time: 2023-10-05 19:30:40 (running for 00:04:42.30)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      7 |         253.49   | 1.6994  |     0.3492 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      7 |         267.875  | 1.32318 |     0.5695 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2804) [8,  4000] loss: 0.835
    == Status ==
    Current time: 2023-10-05 19:30:45 (running for 00:04:47.31)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      7 |         253.49   | 1.6994  |     0.3492 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      7 |         267.875  | 1.32318 |     0.5695 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [5,  8000] loss: 0.310 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:30:50 (running for 00:04:52.32)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      7 |         253.49   | 1.6994  |     0.3492 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      7 |         267.875  | 1.32318 |     0.5695 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00006:
      accuracy: 0.37
      date: 2023-10-05_19-30-50
      done: false
      hostname: 344139faed32
      iterations_since_restore: 8
      loss: 1.6353540323257447
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 282.78397846221924
      time_this_iter_s: 29.293545246124268
      time_total_s: 282.78397846221924
      timestamp: 1696534250
      training_iteration: 8
      trial_id: 027d8_00006
  
    (func pid=2802) [5, 10000] loss: 0.247
    == Status ==
    Current time: 2023-10-05 19:30:55 (running for 00:04:57.48)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6353540323257447 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      8 |         282.784  | 1.63535 |     0.37   |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      7 |         267.875  | 1.32318 |     0.5695 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2806) [8,  4000] loss: 0.492
    == Status ==
    Current time: 2023-10-05 19:31:00 (running for 00:05:02.49)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.6353540323257447 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      4 |         245.263  | 1.29392 |     0.53   |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      8 |         282.784  | 1.63535 |     0.37   |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      7 |         267.875  | 1.32318 |     0.5695 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.5459
      date: 2023-10-05_19-31-01
      done: false
      hostname: 344139faed32
      iterations_since_restore: 5
      loss: 1.259981678032875
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 294.75923204421997
      time_this_iter_s: 49.49662780761719
      time_total_s: 294.75923204421997
      timestamp: 1696534261
      training_iteration: 5
      trial_id: 027d8_00005
  
    Result for train_cifar_027d8_00007:
      accuracy: 0.5629
      date: 2023-10-05_19-31-06
      done: false
      hostname: 344139faed32
      iterations_since_restore: 8
      loss: 1.3450099944114684
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 299.3240165710449
      time_this_iter_s: 31.448599100112915
      time_total_s: 299.3240165710449
      timestamp: 1696534266
      training_iteration: 8
      trial_id: 027d8_00007
  
    == Status ==
    Current time: 2023-10-05 19:31:06 (running for 00:05:08.76)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      8 |         282.784  | 1.63535 |     0.37   |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [6,  2000] loss: 1.198 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:31:11 (running for 00:05:13.76)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      8 |         282.784  | 1.63535 |     0.37   |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:31:16 (running for 00:05:18.78)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      8 |         282.784  | 1.63535 |     0.37   |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2806) [9,  2000] loss: 0.906 [repeated 2x across cluster]
    Result for train_cifar_027d8_00006:
      accuracy: 0.3966
      date: 2023-10-05_19-31-19
      done: false
      hostname: 344139faed32
      iterations_since_restore: 9
      loss: 1.585573999118805
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 312.40010237693787
      time_this_iter_s: 29.616123914718628
      time_total_s: 312.40010237693787
      timestamp: 1696534279
      training_iteration: 9
      trial_id: 027d8_00006
  
    == Status ==
    Current time: 2023-10-05 19:31:24 (running for 00:05:27.09)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      9 |         312.4    | 1.58557 |     0.3966 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [6,  6000] loss: 0.398 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:31:29 (running for 00:05:32.10)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      9 |         312.4    | 1.58557 |     0.3966 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:31:34 (running for 00:05:37.11)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      9 |         312.4    | 1.58557 |     0.3966 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      8 |         299.324  | 1.34501 |     0.5629 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [6,  8000] loss: 0.298 [repeated 3x across cluster]
    Result for train_cifar_027d8_00007:
      accuracy: 0.5513
      date: 2023-10-05_19-31-37
      done: false
      hostname: 344139faed32
      iterations_since_restore: 9
      loss: 1.4266060800135136
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 330.4533302783966
      time_this_iter_s: 31.129313707351685
      time_total_s: 330.4533302783966
      timestamp: 1696534297
      training_iteration: 9
      trial_id: 027d8_00007
  
    == Status ==
    Current time: 2023-10-05 19:31:42 (running for 00:05:44.88)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      9 |         312.4    | 1.58557 |     0.3966 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      9 |         330.453  | 1.42661 |     0.5513 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [6, 10000] loss: 0.234 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:31:47 (running for 00:05:49.89)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      5 |         294.759  | 1.25998 |     0.5459 |
    | train_cifar_027d8_00006 | RUNNING    | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |      9 |         312.4    | 1.58557 |     0.3966 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      9 |         330.453  | 1.42661 |     0.5513 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00006:
      accuracy: 0.4209
      date: 2023-10-05_19-31-49
      done: true
      hostname: 344139faed32
      iterations_since_restore: 10
      loss: 1.5243597846984864
      node_ip: 172.17.0.2
      pid: 2804
      should_checkpoint: true
      time_since_restore: 342.085577249527
      time_this_iter_s: 29.68547487258911
      time_total_s: 342.085577249527
      timestamp: 1696534309
      training_iteration: 10
      trial_id: 027d8_00006
  
    Trial train_cifar_027d8_00006 completed.
    Result for train_cifar_027d8_00005:
      accuracy: 0.5682
      date: 2023-10-05_19-31-51
      done: false
      hostname: 344139faed32
      iterations_since_restore: 6
      loss: 1.2216057551324369
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 343.9302179813385
      time_this_iter_s: 49.17098593711853
      time_total_s: 343.9302179813385
      timestamp: 1696534311
      training_iteration: 6
      trial_id: 027d8_00005
  
    == Status ==
    Current time: 2023-10-05 19:31:56 (running for 00:05:58.32)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      9 |         330.453  | 1.42661 |     0.5513 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2806) [10,  4000] loss: 0.468 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-10-05 19:32:01 (running for 00:06:03.32)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      9 |         330.453  | 1.42661 |     0.5513 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:32:06 (running for 00:06:08.33)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00007 | RUNNING    | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |      9 |         330.453  | 1.42661 |     0.5513 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [7,  4000] loss: 0.571 [repeated 2x across cluster]
    Result for train_cifar_027d8_00007:
      accuracy: 0.5723
      date: 2023-10-05_19-32-08
      done: true
      hostname: 344139faed32
      iterations_since_restore: 10
      loss: 1.3843137427806855
      node_ip: 172.17.0.2
      pid: 2806
      should_checkpoint: true
      time_since_restore: 361.0826771259308
      time_this_iter_s: 30.62934684753418
      time_total_s: 361.0826771259308
      timestamp: 1696534328
      training_iteration: 10
      trial_id: 027d8_00007
  
    Trial train_cifar_027d8_00007 completed.
    == Status ==
    Current time: 2023-10-05 19:32:13 (running for 00:06:15.52)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [7,  6000] loss: 0.384
    == Status ==
    Current time: 2023-10-05 19:32:18 (running for 00:06:20.53)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [7,  8000] loss: 0.291
    == Status ==
    Current time: 2023-10-05 19:32:23 (running for 00:06:25.53)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:32:28 (running for 00:06:30.54)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [7, 10000] loss: 0.231
    == Status ==
    Current time: 2023-10-05 19:32:33 (running for 00:06:35.55)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      6 |         343.93   | 1.22161 |     0.5682 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.5676
      date: 2023-10-05_19-32-36
      done: false
      hostname: 344139faed32
      iterations_since_restore: 7
      loss: 1.212571862474084
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 389.26810908317566
      time_this_iter_s: 45.33789110183716
      time_total_s: 389.26810908317566
      timestamp: 1696534356
      training_iteration: 7
      trial_id: 027d8_00005
  
    == Status ==
    Current time: 2023-10-05 19:32:41 (running for 00:06:43.65)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [8,  2000] loss: 1.124
    == Status ==
    Current time: 2023-10-05 19:32:46 (running for 00:06:48.66)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:32:51 (running for 00:06:53.67)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [8,  4000] loss: 0.565
    == Status ==
    Current time: 2023-10-05 19:32:56 (running for 00:06:58.67)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [8,  6000] loss: 0.374
    == Status ==
    Current time: 2023-10-05 19:33:01 (running for 00:07:03.68)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:33:06 (running for 00:07:08.69)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [8,  8000] loss: 0.284
    == Status ==
    Current time: 2023-10-05 19:33:11 (running for 00:07:13.70)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [8, 10000] loss: 0.223
    == Status ==
    Current time: 2023-10-05 19:33:16 (running for 00:07:18.71)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4901820133686066 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      7 |         389.268  | 1.21257 |     0.5676 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.5755
      date: 2023-10-05_19-33-21
      done: false
      hostname: 344139faed32
      iterations_since_restore: 8
      loss: 1.190472411969304
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 434.06748723983765
      time_this_iter_s: 44.79937815666199
      time_total_s: 434.06748723983765
      timestamp: 1696534401
      training_iteration: 8
      trial_id: 027d8_00005
  
    == Status ==
    Current time: 2023-10-05 19:33:26 (running for 00:07:28.45)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [9,  2000] loss: 1.119
    == Status ==
    Current time: 2023-10-05 19:33:31 (running for 00:07:33.46)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:33:36 (running for 00:07:38.47)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [9,  4000] loss: 0.538
    == Status ==
    Current time: 2023-10-05 19:33:41 (running for 00:07:43.47)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [9,  6000] loss: 0.365
    == Status ==
    Current time: 2023-10-05 19:33:46 (running for 00:07:48.48)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:33:51 (running for 00:07:53.49)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [9,  8000] loss: 0.276
    == Status ==
    Current time: 2023-10-05 19:33:56 (running for 00:07:58.50)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [9, 10000] loss: 0.225
    == Status ==
    Current time: 2023-10-05 19:34:01 (running for 00:08:03.50)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:34:06 (running for 00:08:08.51)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      8 |         434.067  | 1.19047 |     0.5755 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.5763
      date: 2023-10-05_19-34-06
      done: false
      hostname: 344139faed32
      iterations_since_restore: 9
      loss: 1.1784906668871642
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 479.22748374938965
      time_this_iter_s: 45.159996509552
      time_total_s: 479.22748374938965
      timestamp: 1696534446
      training_iteration: 9
      trial_id: 027d8_00005
  
    == Status ==
    Current time: 2023-10-05 19:34:11 (running for 00:08:13.61)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [10,  2000] loss: 1.065
    == Status ==
    Current time: 2023-10-05 19:34:16 (running for 00:08:18.62)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:34:21 (running for 00:08:23.63)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [10,  4000] loss: 0.544
    == Status ==
    Current time: 2023-10-05 19:34:26 (running for 00:08:28.64)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [10,  6000] loss: 0.362
    == Status ==
    Current time: 2023-10-05 19:34:31 (running for 00:08:33.65)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-10-05 19:34:36 (running for 00:08:38.65)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [10,  8000] loss: 0.275
    == Status ==
    Current time: 2023-10-05 19:34:41 (running for 00:08:43.66)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2802) [10, 10000] loss: 0.220
    == Status ==
    Current time: 2023-10-05 19:34:46 (running for 00:08:48.67)
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00005 | RUNNING    | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |      9 |         479.227  | 1.17849 |     0.5763 |
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_027d8_00005:
      accuracy: 0.5886
      date: 2023-10-05_19-34-51
      done: true
      hostname: 344139faed32
      iterations_since_restore: 10
      loss: 1.1624956280395389
      node_ip: 172.17.0.2
      pid: 2802
      should_checkpoint: true
      time_since_restore: 524.0497026443481
      time_this_iter_s: 44.822218894958496
      time_total_s: 524.0497026443481
      timestamp: 1696534491
      training_iteration: 10
      trial_id: 027d8_00005
  
    Trial train_cifar_027d8_00005 completed.
    == Status ==
    Current time: 2023-10-05 19:34:51 (running for 00:08:53.43)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.3450099944114684 | Iter 4.000: -1.6046822773218155 | Iter 2.000: -2.0787693601608277 | Iter 1.000: -2.2347024748325346
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-10-05_19-25-57
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_027d8_00000 | TERMINATED | 172.17.0.2:2707 |            2 |   16 |    1 | 0.00213327  |      1 |         125.446  | 2.30585 |     0.0969 |
    | train_cifar_027d8_00001 | TERMINATED | 172.17.0.2:2794 |            4 |    1 |    2 | 0.013416    |      1 |          70.3052 | 2.30835 |     0.0981 |
    | train_cifar_027d8_00002 | TERMINATED | 172.17.0.2:2796 |            2 |  256 |   64 | 0.0113784   |      1 |         164.582  | 2.20245 |     0.1424 |
    | train_cifar_027d8_00003 | TERMINATED | 172.17.0.2:2798 |            8 |   64 |  256 | 0.0274071   |      4 |         170.301  | 2.3095  |     0.0995 |
    | train_cifar_027d8_00004 | TERMINATED | 172.17.0.2:2800 |            4 |   16 |    2 | 0.056666    |      1 |          71.5543 | 2.34488 |     0.1022 |
    | train_cifar_027d8_00005 | TERMINATED | 172.17.0.2:2802 |            4 |    8 |   64 | 0.000353097 |     10 |         524.05   | 1.1625  |     0.5886 |
    | train_cifar_027d8_00006 | TERMINATED | 172.17.0.2:2804 |            8 |   16 |    4 | 0.000147684 |     10 |         342.086  | 1.52436 |     0.4209 |
    | train_cifar_027d8_00007 | TERMINATED | 172.17.0.2:2806 |            8 |  256 |  256 | 0.00477469  |     10 |         361.083  | 1.38431 |     0.5723 |
    | train_cifar_027d8_00008 | TERMINATED | 172.17.0.2:2794 |            8 |  128 |  256 | 0.0306227   |      2 |          91.2418 | 2.11518 |     0.1743 |
    | train_cifar_027d8_00009 | TERMINATED | 172.17.0.2:2800 |            2 |    2 |   16 | 0.0286986   |      1 |         118.897  | 2.32613 |     0.0984 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-10-05 19:34:51,210 INFO tune.py:945 -- Total run time: 533.52 seconds (533.43 seconds for the tuning loop).
    Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
    Best trial final validation loss: 1.1624956280395389
    Best trial final validation accuracy: 0.5886
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5925




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 9 minutes  10.830 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

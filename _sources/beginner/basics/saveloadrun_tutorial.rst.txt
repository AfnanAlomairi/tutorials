
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/basics/saveloadrun_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_basics_saveloadrun_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_basics_saveloadrun_tutorial.py:


`Learn the Basics <intro.html>`_ ||
`Quickstart <quickstart_tutorial.html>`_ ||
`Tensors <tensorqs_tutorial.html>`_ ||
`Datasets & DataLoaders <data_tutorial.html>`_ ||
`Transforms <transforms_tutorial.html>`_ ||
`Build Model <buildmodel_tutorial.html>`_ ||
`Autograd <autogradqs_tutorial.html>`_ ||
`Optimization <optimization_tutorial.html>`_ ||
**Save & Load Model**

Save and Load the Model
============================

In this section we will look at how to persist model state with saving, loading and running model predictions.

.. GENERATED FROM PYTHON SOURCE LINES 17-22

.. code-block:: default


    import torch
    import torchvision.models as models









.. GENERATED FROM PYTHON SOURCE LINES 23-28

Saving and Loading Model Weights
--------------------------------
PyTorch models store the learned parameters in an internal
state dictionary, called ``state_dict``. These can be persisted via the ``torch.save``
method:

.. GENERATED FROM PYTHON SOURCE LINES 28-32

.. code-block:: default


    model = models.vgg16(pretrained=True)
    torch.save(model.state_dict(), 'model_weights.pth')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning:

    The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.

    /opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning:

    Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.

    Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to /var/lib/jenkins/.cache/torch/hub/checkpoints/vgg16-397923af.pth

      0%|          | 0.00/528M [00:00<?, ?B/s]
      0%|          | 8.00k/528M [00:00<3:23:29, 45.3kB/s]
      0%|          | 1.89M/528M [00:00<01:03, 8.74MB/s]  
      1%|1         | 7.06M/528M [00:00<00:20, 26.3MB/s]
      2%|2         | 10.7M/528M [00:00<00:18, 30.1MB/s]
      3%|2         | 13.9M/528M [00:00<00:20, 26.9MB/s]
      4%|3         | 18.9M/528M [00:00<00:15, 34.3MB/s]
      4%|4         | 22.4M/528M [00:00<00:21, 24.7MB/s]
      5%|4         | 25.3M/528M [00:01<00:24, 21.4MB/s]
      6%|5         | 30.2M/528M [00:01<00:18, 27.7MB/s]
      6%|6         | 33.4M/528M [00:01<00:18, 28.0MB/s]
      7%|6         | 36.5M/528M [00:01<00:21, 23.8MB/s]
      7%|7         | 39.1M/528M [00:01<00:21, 23.5MB/s]
      8%|7         | 41.6M/528M [00:01<00:22, 23.1MB/s]
      9%|8         | 45.4M/528M [00:01<00:20, 24.6MB/s]
     10%|9         | 50.5M/528M [00:02<00:19, 25.2MB/s]
     11%|#         | 55.5M/528M [00:02<00:16, 30.8MB/s]
     11%|#1        | 58.6M/528M [00:02<00:17, 28.8MB/s]
     12%|#1        | 62.6M/528M [00:02<00:15, 31.6MB/s]
     13%|#2        | 67.1M/528M [00:02<00:13, 35.4MB/s]
     13%|#3        | 70.7M/528M [00:03<00:26, 18.1MB/s]
     14%|#3        | 73.4M/528M [00:03<00:33, 14.2MB/s]
     14%|#4        | 75.9M/528M [00:03<00:29, 15.9MB/s]
     15%|#4        | 78.2M/528M [00:03<00:31, 14.8MB/s]
     15%|#5        | 80.3M/528M [00:03<00:29, 15.9MB/s]
     16%|#5        | 82.7M/528M [00:03<00:26, 17.6MB/s]
     16%|#6        | 84.8M/528M [00:04<00:25, 18.5MB/s]
     16%|#6        | 86.8M/528M [00:04<00:41, 11.2MB/s]
     17%|#6        | 88.8M/528M [00:04<00:36, 12.7MB/s]
     17%|#7        | 91.6M/528M [00:04<00:28, 15.9MB/s]
     18%|#7        | 93.7M/528M [00:04<00:27, 16.3MB/s]
     18%|#8        | 95.8M/528M [00:04<00:25, 17.5MB/s]
     19%|#8        | 98.6M/528M [00:04<00:22, 20.0MB/s]
     19%|#9        | 102M/528M [00:05<00:19, 23.5MB/s] 
     20%|##        | 106M/528M [00:05<00:15, 28.2MB/s]
     21%|##        | 109M/528M [00:05<00:23, 19.0MB/s]
     21%|##1       | 113M/528M [00:05<00:19, 22.2MB/s]
     22%|##2       | 118M/528M [00:05<00:14, 29.3MB/s]
     23%|##3       | 124M/528M [00:05<00:11, 36.7MB/s]
     24%|##4       | 129M/528M [00:05<00:10, 38.5MB/s]
     26%|##5       | 135M/528M [00:06<00:08, 46.2MB/s]
     27%|##6       | 140M/528M [00:06<00:09, 41.7MB/s]
     27%|##7       | 144M/528M [00:06<00:09, 41.2MB/s]
     28%|##8       | 148M/528M [00:06<00:15, 25.7MB/s]
     29%|##8       | 152M/528M [00:06<00:14, 26.9MB/s]
     29%|##9       | 155M/528M [00:06<00:13, 28.2MB/s]
     30%|###       | 159M/528M [00:06<00:12, 30.5MB/s]
     31%|###       | 163M/528M [00:07<00:12, 30.9MB/s]
     32%|###1      | 166M/528M [00:07<00:12, 29.2MB/s]
     33%|###2      | 173M/528M [00:07<00:09, 39.7MB/s]
     34%|###3      | 177M/528M [00:07<00:15, 23.9MB/s]
     34%|###4      | 181M/528M [00:07<00:14, 25.1MB/s]
     35%|###4      | 184M/528M [00:07<00:14, 25.4MB/s]
     35%|###5      | 187M/528M [00:08<00:13, 27.3MB/s]
     36%|###6      | 193M/528M [00:08<00:10, 34.0MB/s]
     37%|###7      | 196M/528M [00:08<00:11, 29.6MB/s]
     38%|###7      | 200M/528M [00:08<00:10, 32.0MB/s]
     39%|###8      | 204M/528M [00:08<00:09, 34.2MB/s]
     39%|###9      | 208M/528M [00:08<00:09, 34.1MB/s]
     40%|####      | 212M/528M [00:08<00:14, 23.7MB/s]
     41%|####      | 214M/528M [00:09<00:15, 20.8MB/s]
     41%|####1     | 218M/528M [00:09<00:13, 24.6MB/s]
     42%|####1     | 221M/528M [00:09<00:12, 26.0MB/s]
     42%|####2     | 224M/528M [00:09<00:13, 23.8MB/s]
     43%|####2     | 227M/528M [00:09<00:16, 19.1MB/s]
     44%|####3     | 230M/528M [00:09<00:13, 22.6MB/s]
     45%|####4     | 236M/528M [00:09<00:10, 29.7MB/s]
     46%|####5     | 241M/528M [00:10<00:08, 35.7MB/s]
     46%|####6     | 245M/528M [00:10<00:08, 33.3MB/s]
     47%|####7     | 249M/528M [00:10<00:08, 33.4MB/s]
     48%|####7     | 252M/528M [00:10<00:11, 24.8MB/s]
     49%|####8     | 256M/528M [00:10<00:10, 27.8MB/s]
     49%|####9     | 259M/528M [00:10<00:10, 27.6MB/s]
     50%|#####     | 265M/528M [00:10<00:07, 36.3MB/s]
     51%|#####1    | 269M/528M [00:10<00:07, 35.0MB/s]
     52%|#####2    | 275M/528M [00:11<00:06, 42.3MB/s]
     53%|#####3    | 280M/528M [00:11<00:11, 22.2MB/s]
     54%|#####4    | 286M/528M [00:11<00:09, 27.3MB/s]
     55%|#####4    | 290M/528M [00:11<00:08, 29.5MB/s]
     56%|#####5    | 293M/528M [00:11<00:08, 29.1MB/s]
     56%|#####6    | 297M/528M [00:12<00:08, 28.4MB/s]
     57%|#####7    | 303M/528M [00:12<00:06, 37.1MB/s]
     58%|#####8    | 307M/528M [00:12<00:08, 27.4MB/s]
     59%|#####8    | 311M/528M [00:12<00:08, 27.4MB/s]
     60%|#####9    | 315M/528M [00:12<00:07, 30.8MB/s]
     60%|######    | 318M/528M [00:12<00:06, 32.0MB/s]
     61%|######    | 322M/528M [00:12<00:06, 32.1MB/s]
     62%|######1   | 325M/528M [00:13<00:09, 22.6MB/s]
     62%|######2   | 329M/528M [00:13<00:08, 24.0MB/s]
     63%|######2   | 332M/528M [00:13<00:09, 21.8MB/s]
     63%|######3   | 335M/528M [00:13<00:08, 23.3MB/s]
     64%|######3   | 337M/528M [00:14<00:15, 12.9MB/s]
     64%|######4   | 339M/528M [00:14<00:15, 13.0MB/s]
     65%|######4   | 341M/528M [00:14<00:13, 14.2MB/s]
     65%|######5   | 343M/528M [00:14<00:12, 15.7MB/s]
     65%|######5   | 345M/528M [00:14<00:11, 16.5MB/s]
     66%|######5   | 348M/528M [00:14<00:09, 20.2MB/s]
     67%|######6   | 353M/528M [00:14<00:07, 23.2MB/s]
     67%|######7   | 356M/528M [00:14<00:08, 21.1MB/s]
     68%|######8   | 360M/528M [00:15<00:06, 25.4MB/s]
     69%|######8   | 362M/528M [00:15<00:07, 24.0MB/s]
     69%|######9   | 365M/528M [00:15<00:07, 22.0MB/s]
     70%|######9   | 369M/528M [00:15<00:06, 26.2MB/s]
     70%|#######   | 371M/528M [00:15<00:07, 20.6MB/s]
     71%|#######   | 373M/528M [00:15<00:07, 20.8MB/s]
     71%|#######1  | 376M/528M [00:15<00:07, 21.9MB/s]
     72%|#######1  | 379M/528M [00:15<00:06, 24.3MB/s]
     73%|#######2  | 384M/528M [00:16<00:05, 29.4MB/s]
     74%|#######3  | 390M/528M [00:16<00:03, 39.3MB/s]
     75%|#######5  | 397M/528M [00:16<00:02, 47.8MB/s]
     76%|#######6  | 402M/528M [00:16<00:03, 43.1MB/s]
     77%|#######6  | 406M/528M [00:16<00:02, 43.5MB/s]
     78%|#######7  | 411M/528M [00:16<00:02, 46.1MB/s]
     79%|#######8  | 416M/528M [00:16<00:02, 45.3MB/s]
     80%|#######9  | 420M/528M [00:16<00:02, 39.1MB/s]
     80%|########  | 424M/528M [00:17<00:04, 24.9MB/s]
     81%|########  | 427M/528M [00:17<00:04, 24.8MB/s]
     81%|########1 | 430M/528M [00:17<00:04, 25.2MB/s]
     82%|########2 | 433M/528M [00:17<00:03, 25.8MB/s]
     83%|########2 | 436M/528M [00:17<00:04, 21.4MB/s]
     83%|########2 | 438M/528M [00:17<00:04, 22.0MB/s]
     84%|########3 | 441M/528M [00:17<00:03, 24.4MB/s]
     84%|########4 | 444M/528M [00:18<00:03, 24.8MB/s]
     85%|########4 | 448M/528M [00:18<00:02, 29.9MB/s]
     86%|########5 | 452M/528M [00:18<00:02, 32.6MB/s]
     87%|########6 | 457M/528M [00:18<00:01, 39.2MB/s]
     88%|########7 | 464M/528M [00:18<00:01, 48.3MB/s]
     89%|########8 | 469M/528M [00:18<00:01, 36.5MB/s]
     90%|########9 | 473M/528M [00:18<00:01, 36.4MB/s]
     90%|######### | 477M/528M [00:19<00:01, 29.3MB/s]
     91%|######### | 480M/528M [00:19<00:01, 31.2MB/s]
     92%|#########1| 485M/528M [00:19<00:01, 34.1MB/s]
     93%|#########2| 488M/528M [00:19<00:01, 26.9MB/s]
     93%|#########3| 492M/528M [00:19<00:01, 29.1MB/s]
     94%|#########4| 498M/528M [00:19<00:00, 37.2MB/s]
     95%|#########5| 503M/528M [00:19<00:00, 39.1MB/s]
     96%|#########6| 507M/528M [00:19<00:00, 37.2MB/s]
     97%|#########7| 513M/528M [00:20<00:00, 42.7MB/s]
     98%|#########7| 517M/528M [00:20<00:00, 22.2MB/s]
     99%|#########8| 521M/528M [00:20<00:00, 22.5MB/s]
    100%|#########9| 525M/528M [00:20<00:00, 27.6MB/s]
    100%|##########| 528M/528M [00:20<00:00, 26.6MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 33-35

To load model weights, you need to create an instance of the same model first, and then load the parameters
using ``load_state_dict()`` method.

.. GENERATED FROM PYTHON SOURCE LINES 35-40

.. code-block:: default


    model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights
    model.load_state_dict(torch.load('model_weights.pth'))
    model.eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    VGG(
      (features): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace=True)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace=True)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace=True)
        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (18): ReLU(inplace=True)
        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace=True)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace=True)
        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (25): ReLU(inplace=True)
        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (27): ReLU(inplace=True)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace=True)
        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
      (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=4096, bias=True)
        (4): ReLU(inplace=True)
        (5): Dropout(p=0.5, inplace=False)
        (6): Linear(in_features=4096, out_features=1000, bias=True)
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 41-42

.. note:: be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.

.. GENERATED FROM PYTHON SOURCE LINES 44-49

Saving and Loading Models with Shapes
-------------------------------------
When loading model weights, we needed to instantiate the model class first, because the class
defines the structure of a network. We might want to save the structure of this class together with
the model, in which case we can pass ``model`` (and not ``model.state_dict()``) to the saving function:

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: default


    torch.save(model, 'model.pth')








.. GENERATED FROM PYTHON SOURCE LINES 53-54

We can then load the model like this:

.. GENERATED FROM PYTHON SOURCE LINES 54-57

.. code-block:: default


    model = torch.load('model.pth')








.. GENERATED FROM PYTHON SOURCE LINES 58-59

.. note:: This approach uses Python `pickle <https://docs.python.org/3/library/pickle.html>`_ module when serializing the model, thus it relies on the actual class definition to be available when loading the model.

.. GENERATED FROM PYTHON SOURCE LINES 61-64

Related Tutorials
-----------------
`Saving and Loading a General Checkpoint in PyTorch <https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html>`_


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  26.563 seconds)


.. _sphx_glr_download_beginner_basics_saveloadrun_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: saveloadrun_tutorial.py <saveloadrun_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: saveloadrun_tutorial.ipynb <saveloadrun_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

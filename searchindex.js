Search.setIndex({"docnames": ["advanced/ONNXLive", "advanced/coding_ddpg", "advanced/cpp_autograd", "advanced/cpp_cuda_graphs", "advanced/cpp_export", "advanced/cpp_extension", "advanced/cpp_frontend", "advanced/ddp_pipeline", "advanced/dispatcher", "advanced/dynamic_quantization_tutorial", "advanced/extend_dispatcher", "advanced/generic_join", "advanced/neural_style_tutorial", "advanced/numpy_extensions_tutorial", "advanced/rpc_ddp_tutorial", "advanced/sg_execution_times", "advanced/sharding", "advanced/static_quantization_tutorial", "advanced/super_resolution_with_onnxruntime", "advanced/torch-script-parallelism", "advanced/torch_script_custom_classes", "advanced/torch_script_custom_ops", "beginner/Intro_to_TorchScript_tutorial", "beginner/audio_data_augmentation_tutorial", "beginner/audio_datasets_tutorial", "beginner/audio_feature_augmentation_tutorial", "beginner/audio_feature_extractions_tutorial", "beginner/audio_io_tutorial", "beginner/audio_resampling_tutorial", "beginner/basics/autogradqs_tutorial", "beginner/basics/buildmodel_tutorial", "beginner/basics/data_tutorial", "beginner/basics/index", "beginner/basics/intro", "beginner/basics/optimization_tutorial", "beginner/basics/quickstart_tutorial", "beginner/basics/saveloadrun_tutorial", "beginner/basics/sg_execution_times", "beginner/basics/tensorqs_tutorial", "beginner/basics/transforms_tutorial", "beginner/bettertransformer_tutorial", "beginner/blitz/autograd_tutorial", "beginner/blitz/cifar10_tutorial", "beginner/blitz/data_parallel_tutorial", "beginner/blitz/index", "beginner/blitz/neural_networks_tutorial", "beginner/blitz/sg_execution_times", "beginner/blitz/tensor_tutorial", "beginner/chatbot_tutorial", "beginner/colab", "beginner/data_loading_tutorial", "beginner/dcgan_faces_tutorial", "beginner/ddp_series_fault_tolerance", "beginner/ddp_series_intro", "beginner/ddp_series_multigpu", "beginner/ddp_series_theory", "beginner/deep_learning_60min_blitz", "beginner/deep_learning_nlp_tutorial", "beginner/deeplabv3_on_android", "beginner/deeplabv3_on_ios", "beginner/deploy_seq2seq_hybrid_frontend_tutorial", "beginner/dist_overview", "beginner/examples_autograd/index", "beginner/examples_autograd/polynomial_autograd", "beginner/examples_autograd/polynomial_custom_function", "beginner/examples_nn/dynamic_net", "beginner/examples_nn/index", "beginner/examples_nn/polynomial_module", "beginner/examples_nn/polynomial_nn", "beginner/examples_nn/polynomial_optim", "beginner/examples_nn/sg_execution_times", "beginner/examples_tensor/index", "beginner/examples_tensor/polynomial_numpy", "beginner/examples_tensor/polynomial_tensor", "beginner/examples_tensor/sg_execution_times", "beginner/fgsm_tutorial", "beginner/finetuning_torchvision_models_tutorial", "beginner/flava_finetuning_tutorial", "beginner/former_torchies/autograd_tutorial_old", "beginner/former_torchies/index", "beginner/former_torchies/nnft_tutorial", "beginner/former_torchies/parallelism_tutorial", "beginner/former_torchies/sg_execution_times", "beginner/former_torchies/tensor_tutorial_old", "beginner/former_torchies_tutorial", "beginner/hybrid_frontend/index", "beginner/hybrid_frontend/learning_hybrid_frontend_through_example_tutorial", "beginner/hybrid_frontend/sg_execution_times", "beginner/hybrid_frontend_tutorial", "beginner/hyperparameter_tuning_tutorial", "beginner/introyt", "beginner/introyt/autogradyt_tutorial", "beginner/introyt/captumyt", "beginner/introyt/index", "beginner/introyt/introyt1_tutorial", "beginner/introyt/modelsyt_tutorial", "beginner/introyt/sg_execution_times", "beginner/introyt/tensorboardyt_tutorial", "beginner/introyt/tensors_deeper_tutorial", "beginner/introyt/trainingyt", "beginner/nlp/advanced_tutorial", "beginner/nlp/deep_learning_tutorial", "beginner/nlp/index", "beginner/nlp/pytorch_tutorial", "beginner/nlp/sequence_models_tutorial", "beginner/nlp/sg_execution_times", "beginner/nlp/word_embeddings_tutorial", "beginner/nn_tutorial", "beginner/profiler", "beginner/ptcheat", "beginner/pytorch_with_examples", "beginner/saving_loading_models", "beginner/sg_execution_times", "beginner/t5_tutorial", "beginner/template_tutorial", "beginner/text_sentiment_ngrams_tutorial", "beginner/torchtext_custom_dataset_tutorial", "beginner/transfer_learning_tutorial", "beginner/transformer_tutorial", "beginner/translation_transformer", "beginner/vt_tutorial", "distributed/home", "index", "intermediate/FSDP_adavnced_tutorial", "intermediate/FSDP_tutorial", "intermediate/autograd_saved_tensors_hooks_tutorial", "intermediate/ax_multiobjective_nas_tutorial", "intermediate/char_rnn_classification_tutorial", "intermediate/char_rnn_generation_tutorial", "intermediate/custom_function_conv_bn_tutorial", "intermediate/custom_function_double_backward_tutorial", "intermediate/ddp_series_minGPT", "intermediate/ddp_series_multinode", "intermediate/ddp_tutorial", "intermediate/dist_pipeline_parallel_tutorial", "intermediate/dist_tuto", "intermediate/dynamic_quantization_bert_tutorial", "intermediate/ensembling", "intermediate/flask_rest_api_tutorial", "intermediate/forced_alignment_with_torchaudio_tutorial", "intermediate/forward_ad_usage", "intermediate/fx_conv_bn_fuser", "intermediate/fx_profiling_tutorial", "intermediate/inductor_debug_cpu", "intermediate/jacobians_hessians", "intermediate/mario_rl_tutorial", "intermediate/memory_format_tutorial", "intermediate/mnist_train_nas", "intermediate/model_parallel_tutorial", "intermediate/neural_tangent_kernels", "intermediate/nvfuser_intro_tutorial", "intermediate/parametrizations", "intermediate/per_sample_grads", "intermediate/pipeline_tutorial", "intermediate/process_group_cpp_extension_tutorial", "intermediate/pruning_tutorial", "intermediate/quantized_transfer_learning_tutorial", "intermediate/realtime_rpi", "intermediate/reinforcement_ppo", "intermediate/reinforcement_q_learning", "intermediate/rpc_async_execution", "intermediate/rpc_param_server_tutorial", "intermediate/rpc_tutorial", "intermediate/scaled_dot_product_attention_tutorial", "intermediate/seq2seq_translation_tutorial", "intermediate/sg_execution_times", "intermediate/spatial_transformer_tutorial", "intermediate/speech_recognition_pipeline_tutorial", "intermediate/tensorboard_profiler_tutorial", "intermediate/tensorboard_tutorial", "intermediate/text_to_speech_with_torchaudio", "intermediate/torch_compile_tutorial", "intermediate/torchrec_tutorial", "intermediate/torchserve_with_ipex", "intermediate/torchserve_with_ipex_2", "intermediate/torchvision_tutorial", "prototype/backend_config_tutorial", "prototype/distributed_rpc_profiling", "prototype/fx_graph_mode_ptq_dynamic", "prototype/fx_graph_mode_ptq_static", "prototype/fx_graph_mode_quant_guide", "prototype/graph_mode_dynamic_bert_tutorial", "prototype/ios_coreml_workflow", "prototype/ios_gpu_workflow", "prototype/maskedtensor_adagrad", "prototype/maskedtensor_advanced_semantics", "prototype/maskedtensor_overview", "prototype/maskedtensor_sparsity", "prototype/nestedtensor", "prototype/nnapi_mobilenetv2", "prototype/numeric_suite_tutorial", "prototype/prototype_index", "prototype/pt2e_quant_ptq_static", "prototype/pt2e_quantizer", "prototype/sg_execution_times", "prototype/skip_param_init", "prototype/torchscript_freezing", "prototype/tracing_based_selective_build", "prototype/vmap_recipe", "prototype/vulkan_workflow", "recipes/amx", "recipes/android_native_app_with_custom_op", "recipes/bundled_inputs", "recipes/cuda_rpc", "recipes/deployment_with_flask", "recipes/distributed_optim_torchscript", "recipes/distributed_rpc_profiling", "recipes/fuse", "recipes/intel_extension_for_pytorch", "recipes/intel_neural_compressor_for_pytorch", "recipes/mobile_interpreter", "recipes/mobile_perf", "recipes/model_preparation_android", "recipes/model_preparation_ios", "recipes/profile_with_itt", "recipes/ptmobile_recipes_summary", "recipes/quantization", "recipes/recipes/Captum_Recipe", "recipes/recipes/amp_recipe", "recipes/recipes/benchmark", "recipes/recipes/changing_default_device", "recipes/recipes/defining_a_neural_network", "recipes/recipes/dynamic_quantization", "recipes/recipes/index", "recipes/recipes/loading_data_recipe", "recipes/recipes/profiler_recipe", "recipes/recipes/reasoning_about_shapes", "recipes/recipes/save_load_across_devices", "recipes/recipes/saving_and_loading_a_general_checkpoint", "recipes/recipes/saving_and_loading_models_for_inference", "recipes/recipes/saving_multiple_models_in_one_file", "recipes/recipes/sg_execution_times", "recipes/recipes/tensorboard_with_pytorch", "recipes/recipes/timer_quick_start", "recipes/recipes/tuning_guide", "recipes/recipes/warmstarting_model_using_parameters_from_a_different_model", "recipes/recipes/what_is_state_dict", "recipes/recipes/zeroing_out_gradients", "recipes/recipes_index", "recipes/script_optimized", "recipes/torchscript_inference", "recipes/zero_redundancy_optimizer", "src/pytorch-sphinx-theme/docs/changelog", "src/pytorch-sphinx-theme/docs/configuring", "src/pytorch-sphinx-theme/docs/demo/api", "src/pytorch-sphinx-theme/docs/demo/demo", "src/pytorch-sphinx-theme/docs/demo/lists_tables", "src/pytorch-sphinx-theme/docs/demo/long", "src/pytorch-sphinx-theme/docs/demo/structure", "src/pytorch-sphinx-theme/docs/index", "src/pytorch-sphinx-theme/docs/installing"], "filenames": ["advanced/ONNXLive.rst", "advanced/coding_ddpg.rst", "advanced/cpp_autograd.rst", "advanced/cpp_cuda_graphs.rst", "advanced/cpp_export.rst", "advanced/cpp_extension.rst", "advanced/cpp_frontend.rst", "advanced/ddp_pipeline.rst", "advanced/dispatcher.rst", "advanced/dynamic_quantization_tutorial.rst", "advanced/extend_dispatcher.rst", "advanced/generic_join.rst", "advanced/neural_style_tutorial.rst", "advanced/numpy_extensions_tutorial.rst", "advanced/rpc_ddp_tutorial.rst", "advanced/sg_execution_times.rst", "advanced/sharding.rst", "advanced/static_quantization_tutorial.rst", "advanced/super_resolution_with_onnxruntime.rst", "advanced/torch-script-parallelism.rst", "advanced/torch_script_custom_classes.rst", "advanced/torch_script_custom_ops.rst", "beginner/Intro_to_TorchScript_tutorial.rst", "beginner/audio_data_augmentation_tutorial.rst", "beginner/audio_datasets_tutorial.rst", "beginner/audio_feature_augmentation_tutorial.rst", "beginner/audio_feature_extractions_tutorial.rst", "beginner/audio_io_tutorial.rst", "beginner/audio_resampling_tutorial.rst", "beginner/basics/autogradqs_tutorial.rst", "beginner/basics/buildmodel_tutorial.rst", "beginner/basics/data_tutorial.rst", "beginner/basics/index.rst", "beginner/basics/intro.rst", "beginner/basics/optimization_tutorial.rst", "beginner/basics/quickstart_tutorial.rst", "beginner/basics/saveloadrun_tutorial.rst", "beginner/basics/sg_execution_times.rst", "beginner/basics/tensorqs_tutorial.rst", "beginner/basics/transforms_tutorial.rst", "beginner/bettertransformer_tutorial.rst", "beginner/blitz/autograd_tutorial.rst", "beginner/blitz/cifar10_tutorial.rst", "beginner/blitz/data_parallel_tutorial.rst", "beginner/blitz/index.rst", "beginner/blitz/neural_networks_tutorial.rst", "beginner/blitz/sg_execution_times.rst", "beginner/blitz/tensor_tutorial.rst", "beginner/chatbot_tutorial.rst", "beginner/colab.rst", "beginner/data_loading_tutorial.rst", "beginner/dcgan_faces_tutorial.rst", "beginner/ddp_series_fault_tolerance.rst", "beginner/ddp_series_intro.rst", "beginner/ddp_series_multigpu.rst", "beginner/ddp_series_theory.rst", "beginner/deep_learning_60min_blitz.rst", "beginner/deep_learning_nlp_tutorial.rst", "beginner/deeplabv3_on_android.rst", "beginner/deeplabv3_on_ios.rst", "beginner/deploy_seq2seq_hybrid_frontend_tutorial.rst", "beginner/dist_overview.rst", "beginner/examples_autograd/index.rst", "beginner/examples_autograd/polynomial_autograd.rst", "beginner/examples_autograd/polynomial_custom_function.rst", "beginner/examples_nn/dynamic_net.rst", "beginner/examples_nn/index.rst", "beginner/examples_nn/polynomial_module.rst", "beginner/examples_nn/polynomial_nn.rst", "beginner/examples_nn/polynomial_optim.rst", "beginner/examples_nn/sg_execution_times.rst", "beginner/examples_tensor/index.rst", "beginner/examples_tensor/polynomial_numpy.rst", "beginner/examples_tensor/polynomial_tensor.rst", "beginner/examples_tensor/sg_execution_times.rst", "beginner/fgsm_tutorial.rst", "beginner/finetuning_torchvision_models_tutorial.rst", "beginner/flava_finetuning_tutorial.rst", "beginner/former_torchies/autograd_tutorial_old.rst", "beginner/former_torchies/index.rst", "beginner/former_torchies/nnft_tutorial.rst", "beginner/former_torchies/parallelism_tutorial.rst", "beginner/former_torchies/sg_execution_times.rst", "beginner/former_torchies/tensor_tutorial_old.rst", "beginner/former_torchies_tutorial.rst", "beginner/hybrid_frontend/index.rst", "beginner/hybrid_frontend/learning_hybrid_frontend_through_example_tutorial.rst", "beginner/hybrid_frontend/sg_execution_times.rst", "beginner/hybrid_frontend_tutorial.rst", "beginner/hyperparameter_tuning_tutorial.rst", "beginner/introyt.rst", "beginner/introyt/autogradyt_tutorial.rst", "beginner/introyt/captumyt.rst", "beginner/introyt/index.rst", "beginner/introyt/introyt1_tutorial.rst", "beginner/introyt/modelsyt_tutorial.rst", "beginner/introyt/sg_execution_times.rst", "beginner/introyt/tensorboardyt_tutorial.rst", "beginner/introyt/tensors_deeper_tutorial.rst", "beginner/introyt/trainingyt.rst", "beginner/nlp/advanced_tutorial.rst", "beginner/nlp/deep_learning_tutorial.rst", "beginner/nlp/index.rst", "beginner/nlp/pytorch_tutorial.rst", "beginner/nlp/sequence_models_tutorial.rst", "beginner/nlp/sg_execution_times.rst", "beginner/nlp/word_embeddings_tutorial.rst", "beginner/nn_tutorial.rst", "beginner/profiler.rst", "beginner/ptcheat.rst", "beginner/pytorch_with_examples.rst", "beginner/saving_loading_models.rst", "beginner/sg_execution_times.rst", "beginner/t5_tutorial.rst", "beginner/template_tutorial.rst", "beginner/text_sentiment_ngrams_tutorial.rst", "beginner/torchtext_custom_dataset_tutorial.rst", "beginner/transfer_learning_tutorial.rst", "beginner/transformer_tutorial.rst", "beginner/translation_transformer.rst", "beginner/vt_tutorial.rst", "distributed/home.rst", "index.rst", "intermediate/FSDP_adavnced_tutorial.rst", "intermediate/FSDP_tutorial.rst", "intermediate/autograd_saved_tensors_hooks_tutorial.rst", "intermediate/ax_multiobjective_nas_tutorial.rst", "intermediate/char_rnn_classification_tutorial.rst", "intermediate/char_rnn_generation_tutorial.rst", "intermediate/custom_function_conv_bn_tutorial.rst", "intermediate/custom_function_double_backward_tutorial.rst", "intermediate/ddp_series_minGPT.rst", "intermediate/ddp_series_multinode.rst", "intermediate/ddp_tutorial.rst", "intermediate/dist_pipeline_parallel_tutorial.rst", "intermediate/dist_tuto.rst", "intermediate/dynamic_quantization_bert_tutorial.rst", "intermediate/ensembling.rst", "intermediate/flask_rest_api_tutorial.rst", "intermediate/forced_alignment_with_torchaudio_tutorial.rst", "intermediate/forward_ad_usage.rst", "intermediate/fx_conv_bn_fuser.rst", "intermediate/fx_profiling_tutorial.rst", "intermediate/inductor_debug_cpu.rst", "intermediate/jacobians_hessians.rst", "intermediate/mario_rl_tutorial.rst", "intermediate/memory_format_tutorial.rst", "intermediate/mnist_train_nas.rst", "intermediate/model_parallel_tutorial.rst", "intermediate/neural_tangent_kernels.rst", "intermediate/nvfuser_intro_tutorial.rst", "intermediate/parametrizations.rst", "intermediate/per_sample_grads.rst", "intermediate/pipeline_tutorial.rst", "intermediate/process_group_cpp_extension_tutorial.rst", "intermediate/pruning_tutorial.rst", "intermediate/quantized_transfer_learning_tutorial.rst", "intermediate/realtime_rpi.rst", "intermediate/reinforcement_ppo.rst", "intermediate/reinforcement_q_learning.rst", "intermediate/rpc_async_execution.rst", "intermediate/rpc_param_server_tutorial.rst", "intermediate/rpc_tutorial.rst", "intermediate/scaled_dot_product_attention_tutorial.rst", "intermediate/seq2seq_translation_tutorial.rst", "intermediate/sg_execution_times.rst", "intermediate/spatial_transformer_tutorial.rst", "intermediate/speech_recognition_pipeline_tutorial.rst", "intermediate/tensorboard_profiler_tutorial.rst", "intermediate/tensorboard_tutorial.rst", "intermediate/text_to_speech_with_torchaudio.rst", "intermediate/torch_compile_tutorial.rst", "intermediate/torchrec_tutorial.rst", "intermediate/torchserve_with_ipex.rst", "intermediate/torchserve_with_ipex_2.rst", "intermediate/torchvision_tutorial.rst", "prototype/backend_config_tutorial.rst", "prototype/distributed_rpc_profiling.rst", "prototype/fx_graph_mode_ptq_dynamic.rst", "prototype/fx_graph_mode_ptq_static.rst", "prototype/fx_graph_mode_quant_guide.rst", "prototype/graph_mode_dynamic_bert_tutorial.rst", "prototype/ios_coreml_workflow.rst", "prototype/ios_gpu_workflow.rst", "prototype/maskedtensor_adagrad.rst", "prototype/maskedtensor_advanced_semantics.rst", "prototype/maskedtensor_overview.rst", "prototype/maskedtensor_sparsity.rst", "prototype/nestedtensor.rst", "prototype/nnapi_mobilenetv2.rst", "prototype/numeric_suite_tutorial.rst", "prototype/prototype_index.rst", "prototype/pt2e_quant_ptq_static.rst", "prototype/pt2e_quantizer.rst", "prototype/sg_execution_times.rst", "prototype/skip_param_init.rst", "prototype/torchscript_freezing.rst", "prototype/tracing_based_selective_build.rst", "prototype/vmap_recipe.rst", "prototype/vulkan_workflow.rst", "recipes/amx.rst", "recipes/android_native_app_with_custom_op.rst", "recipes/bundled_inputs.rst", "recipes/cuda_rpc.rst", "recipes/deployment_with_flask.rst", "recipes/distributed_optim_torchscript.rst", "recipes/distributed_rpc_profiling.rst", "recipes/fuse.rst", "recipes/intel_extension_for_pytorch.rst", "recipes/intel_neural_compressor_for_pytorch.rst", "recipes/mobile_interpreter.rst", "recipes/mobile_perf.rst", "recipes/model_preparation_android.rst", "recipes/model_preparation_ios.rst", "recipes/profile_with_itt.rst", "recipes/ptmobile_recipes_summary.rst", "recipes/quantization.rst", "recipes/recipes/Captum_Recipe.rst", "recipes/recipes/amp_recipe.rst", "recipes/recipes/benchmark.rst", "recipes/recipes/changing_default_device.rst", "recipes/recipes/defining_a_neural_network.rst", "recipes/recipes/dynamic_quantization.rst", "recipes/recipes/index.rst", "recipes/recipes/loading_data_recipe.rst", "recipes/recipes/profiler_recipe.rst", "recipes/recipes/reasoning_about_shapes.rst", "recipes/recipes/save_load_across_devices.rst", "recipes/recipes/saving_and_loading_a_general_checkpoint.rst", "recipes/recipes/saving_and_loading_models_for_inference.rst", "recipes/recipes/saving_multiple_models_in_one_file.rst", "recipes/recipes/sg_execution_times.rst", "recipes/recipes/tensorboard_with_pytorch.rst", "recipes/recipes/timer_quick_start.rst", "recipes/recipes/tuning_guide.rst", "recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.rst", "recipes/recipes/what_is_state_dict.rst", "recipes/recipes/zeroing_out_gradients.rst", "recipes/recipes_index.rst", "recipes/script_optimized.rst", "recipes/torchscript_inference.rst", "recipes/zero_redundancy_optimizer.rst", "src/pytorch-sphinx-theme/docs/changelog.rst", "src/pytorch-sphinx-theme/docs/configuring.rst", "src/pytorch-sphinx-theme/docs/demo/api.rst", "src/pytorch-sphinx-theme/docs/demo/demo.rst", "src/pytorch-sphinx-theme/docs/demo/lists_tables.rst", "src/pytorch-sphinx-theme/docs/demo/long.rst", "src/pytorch-sphinx-theme/docs/demo/structure.rst", "src/pytorch-sphinx-theme/docs/index.rst", "src/pytorch-sphinx-theme/docs/installing.rst"], "titles": ["ONNX Live Tutorial", "TorchRL objectives: Coding a DDPG loss", "Autograd in C++ Frontend", "Using CUDA Graphs in PyTorch C++ API", "Loading a TorchScript Model in C++", "Custom C++ and CUDA Extensions", "Using the PyTorch C++ Frontend", "Training Transformer models using Distributed Data Parallel and Pipeline Parallelism", "Registering a Dispatched Operator in C++", "(beta) Dynamic Quantization on an LSTM Word Language Model", "Extending dispatcher for a new backend in C++", "Distributed Training with Uneven Inputs Using the Join Context Manager", "Neural Transfer Using PyTorch", "Creating Extensions Using NumPy and SciPy", "Combining Distributed DataParallel with Distributed RPC Framework", "Computation times", "Exploring TorchRec sharding", "(beta) Static Quantization with Eager Mode in PyTorch", "(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime", "Dynamic Parallelism in TorchScript", "Extending TorchScript with Custom C++ Classes", "Extending TorchScript with Custom C++ Operators", "Introduction to TorchScript", "Audio Data Augmentation", "Audio Datasets", "Audio Feature Augmentation", "Audio Feature Extractions", "Audio I/O", "Audio Resampling", "Automatic Differentiation with <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.autograd</span></code>", "Build the Neural Network", "Datasets &amp; DataLoaders", "Learn the Basics", "Learn the Basics", "Optimizing Model Parameters", "Quickstart", "Save and Load the Model", "Computation times", "Tensors", "Transforms", "Fast Transformer Inference with Better Transformer", "A Gentle Introduction to <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.autograd</span></code>", "Training a Classifier", "Optional: Data Parallelism", "Deep Learning with PyTorch: A 60 Minute Blitz", "Neural Networks", "Computation times", "Tensors", "Chatbot Tutorial", "Running Tutorials in Google Colab", "Writing Custom Datasets, DataLoaders and Transforms", "DCGAN Tutorial", "Fault-tolerant Distributed Training with <code class=\"docutils literal notranslate\"><span class=\"pre\">torchrun</span></code>", "Distributed Data Parallel in PyTorch - Video Tutorials", "Multi GPU training with DDP", "What is Distributed Data Parallel (DDP)", "Deep Learning with PyTorch: A 60 Minute Blitz", "Deep Learning for NLP with Pytorch", "Image Segmentation DeepLabV3 on Android", "Image Segmentation DeepLabV3 on iOS", "Deploying a Seq2Seq Model with TorchScript", "PyTorch Distributed Overview", "&lt;no title&gt;", "PyTorch: Tensors and autograd", "PyTorch: Defining New autograd Functions", "PyTorch: Control Flow + Weight Sharing", "&lt;no title&gt;", "PyTorch: Custom nn Modules", "PyTorch: nn", "PyTorch: optim", "Computation times", "&lt;no title&gt;", "Warm-up: numpy", "PyTorch: Tensors", "Computation times", "Adversarial Example Generation", "Finetuning Torchvision Models", "TorchMultimodal Tutorial: Finetuning FLAVA", "Autograd", "&lt;no title&gt;", "nn package", "Multi-GPU Examples", "Computation times", "Tensors", "PyTorch for Former Torch Users", "&lt;no title&gt;", "Learning Hybrid Frontend Syntax Through Example", "Computation times", "Hybrid Frontend Tutorials", "Hyperparameter tuning with Ray Tune", "Introduction to PyTorch - YouTube Series", "The Fundamentals of Autograd", "Model Understanding with Captum", "Introduction to PyTorch on YouTube", "Introduction to PyTorch", "Building Models with PyTorch", "Computation times", "PyTorch TensorBoard Support", "Introduction to PyTorch Tensors", "Training with PyTorch", "Advanced: Making Dynamic Decisions and the Bi-LSTM CRF", "Deep Learning with PyTorch", "Deep Learning for NLP with Pytorch", "Introduction to PyTorch", "Sequence Models and Long Short-Term Memory Networks", "Computation times", "Word Embeddings: Encoding Lexical Semantics", "What is <cite>torch.nn</cite> <em>really</em>?", "Profiling your PyTorch Module", "PyTorch Cheat Sheet", "Learning PyTorch with Examples", "Saving and Loading Models", "Computation times", "T5-Base Model for Summarization, Sentiment Classification, and Translation", "Template Tutorial", "Text classification with the torchtext library", "Preprocess custom text dataset using Torchtext", "Transfer Learning for Computer Vision Tutorial", "Language Modeling with <code class=\"docutils literal notranslate\"><span class=\"pre\">nn.Transformer</span></code> and torchtext", "Language Translation with <code class=\"docutils literal notranslate\"><span class=\"pre\">nn.Transformer</span></code> and torchtext", "Optimizing Vision Transformer Model for Deployment", "Distributed and Parallel Training Tutorials", "Welcome to PyTorch Tutorials", "Advanced Model Training with Fully Sharded Data Parallel (FSDP)", "Getting Started with Fully Sharded Data Parallel(FSDP)", "Hooks for autograd saved tensors", "Multi-Objective NAS with Ax", "NLP From Scratch: Classifying Names with a Character-Level RNN", "NLP From Scratch: Generating Names with a Character-Level RNN", "Fusing Convolution and Batch Norm using Custom Function", "Double Backward with Custom Functions", "Training \u201creal-world\u201d models with DDP", "Multinode Training", "Getting Started with Distributed Data Parallel", "Distributed Pipeline Parallelism Using RPC", "Writing Distributed Applications with PyTorch", "(beta) Dynamic Quantization on BERT", "Model ensembling", "Deploying PyTorch in Python via a REST API with Flask", "Forced Alignment with Wav2Vec2", "Forward-mode Automatic Differentiation (Beta)", "(beta) Building a Convolution/Batch Norm fuser in FX", "(beta) Building a Simple CPU Performance Profiler with FX", "Inductor CPU backend debugging and profiling", "Jacobians, Hessians, hvp, vhp, and more: composing function transforms", "Train a Mario-playing RL Agent", "(beta) Channels Last Memory Format in PyTorch", "&lt;no title&gt;", "Single-Machine Model Parallel Best Practices", "Neural Tangent Kernels", "Getting Started - Accelerate Your Scripts with nvFuser", "Parametrizations Tutorial", "Per-sample-gradients", "Training Transformer models using Pipeline Parallelism", "Customize Process Group Backends Using Cpp Extensions", "Pruning Tutorial", "(beta) Quantized Transfer Learning for Computer Vision Tutorial", "Real Time Inference on Raspberry Pi 4 (30 fps!)", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Reinforcement Learning (DQN) Tutorial", "Implementing Batch RPC Processing Using Asynchronous Executions", "Implementing a Parameter Server Using Distributed RPC Framework", "Getting Started with Distributed RPC Framework", "(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)", "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention", "Computation times", "Spatial Transformer Networks Tutorial", "Speech Recognition with Wav2Vec2", "PyTorch Profiler With TensorBoard", "Visualizing Models, Data, and Training with TensorBoard", "Text-to-speech with Tacotron2", "torch.compile Tutorial", "Introduction to TorchRec", "Grokking PyTorch Intel CPU performance from first principles", "Grokking PyTorch Intel CPU performance from first principles (Part 2)", "TorchVision Object Detection Finetuning Tutorial", "(prototype) PyTorch BackendConfig Tutorial", "Profiling PyTorch RPC-Based Workloads", "(prototype) FX Graph Mode Post Training Dynamic Quantization", "(prototype) FX Graph Mode Post Training Static Quantization", "(prototype) FX Graph Mode Quantization User Guide", "(prototype) Graph Mode Dynamic Quantization on BERT", "(Prototype) Convert Mobilenetv2 to Core ML", "(Prototype) Use iOS GPU in PyTorch", "(Prototype) Efficiently writing \u201csparse\u201d semantics for Adagrad with MaskedTensor", "(Prototype) MaskedTensor Advanced Semantics", "(Prototype) MaskedTensor Overview", "(Prototype) MaskedTensor Sparsity", "NestedTensors", "(Beta) Convert MobileNetV2 to NNAPI", "PyTorch Numeric Suite Tutorial", "PyTorch Prototype Recipes", "(prototype) PyTorch 2.0 Export Post Training Static Quantization", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2.0 Export Quantization", "Computation times", "Skipping Module Parameter Initialization", "Model Freezing in TorchScript", "(prototype) Tracing-based Selective Build Mobile Interpreter in Android and iOS", "torch.vmap", "PyTorch Vulkan Backend User Workflow", "Leverage Intel\u00ae Advanced Matrix Extensions", "Making Native Android Application that uses PyTorch prebuilt libraries", "(beta) Bundling inputs to PyTorch Models", "Direct Device-to-Device Communication with TensorPipe CUDA RPC", "Deploying with Flask", "Distributed Optimizer with TorchScript support", "Profiling PyTorch RPC-Based Workloads", "Fuse Modules Recipe", "Intel\u00ae Extension for PyTorch*", "Ease-of-use quantization for PyTorch with Intel\u00ae Neural Compressor", "(beta) Efficient mobile interpreter in Android and iOS", "Pytorch Mobile Performance Recipes", "Model Preparation for Android Recipe", "Model Preparation for iOS Recipe", "Profiling PyTorch workloads with The Instrumentation and Tracing Technology (ITT) API", "Summary of PyTorch Mobile Recipes", "Quantization Recipe", "Model Interpretability using Captum", "Automatic Mixed Precision", "SyntaxError", "Changing default device", "Defining a Neural Network in PyTorch", "Dynamic Quantization", "PyTorch Recipes", "Loading data in PyTorch", "PyTorch Profiler", "Reasoning about Shapes in PyTorch", "Saving and loading models across devices in PyTorch", "Saving and loading a general checkpoint in PyTorch", "Saving and loading models for inference in PyTorch", "Saving and loading multiple models in one file using PyTorch", "Computation times", "How to use TensorBoard with PyTorch", "Timer quick start", "Performance Tuning Guide", "Warmstarting model using parameters from a different model in PyTorch", "What is a state_dict in PyTorch", "Zeroing out gradients in PyTorch", "PyTorch Recipes", "Script and Optimize for Mobile Recipe", "TorchScript for Deployment", "Shard Optimizer States with ZeroRedundancyOptimizer", "Changelog", "Configuration", "<span class=\"section-number\">5. </span><code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">test_py_module</span></code>", "<span class=\"section-number\">3. </span>Paragraph Level Markup", "<span class=\"section-number\">4. </span>Lists &amp; Tables", "<span class=\"section-number\">1. </span>Long Sticky Nav", "<span class=\"section-number\">1. </span>Structural Elements", "&lt;no title&gt;", "Installation"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 75, 76, 77, 78, 80, 81, 83, 84, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 247, 248], "show": [0, 1, 5, 10, 11, 16, 17, 20, 40, 42, 50, 51, 58, 59, 61, 75, 86, 89, 91, 92, 94, 95, 98, 99, 107, 108, 113, 115, 116, 117, 119, 120, 122, 124, 126, 127, 128, 129, 130, 133, 134, 138, 143, 146, 148, 154, 156, 157, 159, 160, 162, 168, 169, 171, 173, 174, 176, 179, 181, 182, 183, 184, 189, 190, 192, 197, 201, 203, 205, 208, 210, 211, 213, 214, 216, 218, 219, 222, 225, 232, 233, 234, 241, 243, 245], "you": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 28, 29, 30, 31, 33, 34, 36, 38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 67, 68, 75, 77, 78, 80, 84, 86, 88, 89, 90, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 175, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230, 232, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 246, 247], "neural": [0, 2, 5, 13, 15, 18, 29, 32, 33, 35, 41, 44, 46, 48, 50, 56, 57, 60, 68, 75, 80, 81, 84, 91, 92, 94, 95, 99, 100, 101, 103, 104, 106, 110, 116, 117, 118, 120, 122, 126, 127, 128, 129, 148, 155, 158, 159, 161, 164, 165, 166, 169, 174, 182, 189, 191, 200, 208, 214, 222, 223, 224, 231, 234, 238], "ha": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 35, 40, 41, 42, 45, 48, 49, 58, 59, 60, 61, 63, 68, 75, 76, 77, 78, 80, 83, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 101, 103, 104, 106, 107, 108, 110, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 139, 141, 143, 144, 146, 149, 150, 151, 153, 155, 156, 157, 158, 159, 162, 163, 164, 167, 169, 170, 172, 173, 174, 175, 177, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 192, 193, 195, 196, 201, 203, 204, 205, 206, 208, 209, 211, 216, 217, 219, 220, 222, 225, 233, 234, 239, 240, 241, 245, 246], "been": [0, 1, 3, 4, 6, 7, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 40, 49, 58, 59, 69, 75, 76, 83, 86, 89, 91, 92, 94, 98, 103, 107, 113, 120, 124, 128, 129, 130, 131, 135, 139, 141, 143, 144, 149, 150, 151, 153, 155, 157, 158, 159, 163, 167, 169, 170, 173, 174, 177, 179, 182, 184, 187, 188, 193, 205, 206, 208, 209, 214, 219, 232, 246], "export": [0, 4, 8, 15, 19, 21, 45, 60, 86, 91, 109, 122, 132, 133, 136, 143, 163, 171, 191, 197, 200, 201, 202, 210, 218, 225, 234, 238], "from": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 19, 21, 22, 29, 31, 34, 35, 38, 40, 42, 45, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 63, 64, 67, 68, 69, 72, 73, 75, 77, 78, 80, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 168, 169, 171, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 197, 198, 199, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 221, 222, 223, 224, 225, 228, 230, 231, 233, 234, 236, 238, 239, 240, 241, 243, 244, 245, 246], "appl": [0, 173, 182, 183], "format": [0, 1, 5, 12, 17, 18, 21, 22, 39, 58, 59, 60, 107, 109, 120, 122, 123, 124, 135, 136, 142, 143, 156, 157, 160, 162, 165, 168, 169, 173, 175, 179, 181, 182, 183, 184, 186, 187, 189, 192, 193, 200, 205, 208, 209, 212, 213, 216, 217, 219, 238, 240, 245, 246], "us": [0, 1, 4, 8, 9, 10, 14, 15, 16, 17, 19, 29, 30, 31, 34, 35, 36, 38, 39, 40, 42, 43, 45, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 84, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 109, 110, 112, 114, 115, 117, 118, 121, 122, 123, 125, 126, 127, 128, 130, 132, 135, 136, 138, 141, 142, 143, 144, 145, 146, 148, 149, 151, 155, 156, 157, 158, 159, 164, 165, 166, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 200, 204, 205, 207, 208, 212, 213, 215, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 231, 233, 236, 237, 238, 243, 244, 245, 246], "allow": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 17, 20, 21, 22, 29, 30, 31, 41, 48, 49, 50, 51, 52, 60, 61, 81, 86, 89, 91, 92, 95, 98, 101, 103, 104, 106, 107, 110, 113, 118, 120, 123, 126, 128, 130, 135, 136, 138, 141, 145, 146, 149, 151, 153, 154, 155, 156, 158, 159, 160, 162, 163, 164, 166, 171, 172, 173, 174, 175, 181, 184, 185, 190, 192, 193, 199, 201, 203, 205, 216, 218, 219, 222, 225, 232, 233, 243], "easili": [0, 1, 5, 12, 17, 30, 43, 60, 61, 75, 92, 98, 99, 107, 108, 110, 111, 118, 119, 120, 123, 126, 133, 135, 141, 142, 143, 149, 155, 158, 159, 162, 171, 173, 174, 175, 179, 195, 209, 219, 228, 230, 236], "deep": [0, 1, 6, 12, 13, 22, 33, 45, 48, 51, 60, 69, 72, 73, 81, 90, 94, 95, 98, 103, 105, 106, 110, 117, 120, 121, 122, 127, 128, 129, 136, 143, 144, 145, 151, 155, 156, 159, 164, 172, 174, 200, 207, 209, 214, 221, 233, 234, 243], "learn": [0, 1, 4, 6, 7, 9, 13, 18, 19, 22, 29, 30, 31, 34, 35, 36, 38, 39, 41, 43, 45, 48, 50, 51, 52, 53, 54, 55, 60, 61, 69, 72, 73, 75, 81, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 98, 99, 103, 105, 106, 107, 111, 112, 113, 114, 115, 116, 118, 122, 123, 124, 126, 127, 128, 131, 132, 133, 135, 143, 144, 151, 152, 153, 155, 157, 161, 164, 165, 166, 169, 172, 174, 175, 184, 185, 186, 187, 191, 192, 193, 196, 197, 200, 201, 203, 204, 205, 209, 211, 214, 217, 227, 228, 230, 234, 238, 240, 241], "devic": [0, 1, 3, 6, 8, 10, 11, 14, 16, 17, 18, 21, 22, 35, 38, 40, 41, 42, 43, 47, 48, 51, 52, 54, 55, 58, 59, 60, 61, 64, 73, 75, 81, 89, 91, 98, 101, 107, 109, 110, 117, 122, 124, 126, 132, 133, 134, 135, 136, 143, 146, 148, 155, 156, 157, 158, 159, 161, 162, 168, 172, 175, 176, 178, 179, 181, 182, 183, 189, 192, 195, 201, 207, 208, 211, 216, 219, 223, 225, 226, 231, 235, 237, 238, 239, 241], "case": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 13, 14, 18, 20, 21, 22, 29, 36, 41, 48, 50, 60, 61, 68, 75, 77, 86, 91, 92, 97, 98, 100, 101, 103, 104, 106, 107, 110, 111, 121, 122, 123, 124, 125, 126, 127, 129, 130, 134, 135, 137, 138, 140, 143, 144, 146, 148, 149, 151, 152, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 171, 173, 174, 175, 176, 181, 184, 186, 187, 188, 189, 192, 193, 195, 198, 199, 201, 205, 208, 211, 217, 218, 219, 222, 225, 226, 227, 233, 237, 239], "stream": [0, 3, 98, 100, 134, 148, 157, 201, 208], "camera": [0, 157], "open": [0, 5, 33, 35, 49, 58, 59, 60, 90, 92, 94, 97, 99, 106, 116, 117, 122, 123, 135, 136, 137, 138, 142, 152, 164, 168, 175, 181, 183, 197, 199, 201, 204, 208, 209, 210, 211, 212, 213, 214], "network": [0, 2, 3, 5, 8, 12, 13, 17, 18, 19, 22, 29, 32, 33, 34, 35, 36, 41, 44, 46, 48, 50, 56, 57, 60, 68, 69, 75, 80, 81, 84, 91, 92, 94, 95, 99, 100, 102, 103, 105, 106, 107, 110, 116, 117, 118, 120, 122, 125, 126, 129, 132, 133, 148, 149, 151, 155, 156, 161, 165, 169, 174, 189, 191, 200, 208, 209, 214, 222, 223, 224, 226, 231, 234, 238, 239], "exchang": [0, 48, 123, 135, 164, 168], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 61, 65, 67, 69, 75, 77, 78, 80, 83, 86, 88, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 107, 108, 109, 110, 111, 113, 116, 117, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 229, 230, 233, 234, 236, 238, 239, 240, 243, 245, 246], "repres": [0, 1, 5, 7, 10, 12, 13, 16, 18, 19, 22, 30, 41, 48, 50, 51, 60, 63, 75, 77, 86, 91, 92, 94, 95, 99, 106, 108, 109, 110, 115, 116, 118, 123, 124, 126, 127, 138, 140, 141, 142, 145, 146, 153, 158, 159, 162, 164, 173, 175, 179, 184, 188, 192, 197, 204, 219, 221, 224, 233, 245], "With": [0, 4, 8, 10, 14, 16, 17, 19, 38, 40, 47, 51, 58, 59, 61, 75, 86, 91, 92, 97, 103, 130, 135, 136, 143, 148, 149, 160, 161, 162, 163, 164, 165, 173, 174, 189, 192, 193, 197, 200, 203, 205, 212, 213, 214, 216, 217, 222, 234, 240, 241, 243, 245], "ai": [0, 57, 77, 92, 101, 107, 124, 126, 136, 145, 164, 172, 200, 208, 217], "develop": [0, 1, 3, 5, 8, 10, 12, 21, 58, 59, 60, 86, 92, 103, 107, 113, 115, 135, 138, 146, 154, 162, 176, 182, 183, 184, 187, 192, 193, 197, 201, 208, 209, 210, 215, 222, 223, 245, 246], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 68, 73, 75, 78, 80, 81, 83, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 17, 18, 19, 20, 22, 31, 33, 34, 35, 38, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 54, 55, 61, 67, 75, 77, 78, 80, 81, 86, 92, 94, 95, 97, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 116, 117, 118, 119, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 135, 138, 140, 141, 142, 145, 148, 149, 151, 153, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 169, 171, 173, 174, 175, 176, 179, 180, 181, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 204, 205, 208, 209, 211, 214, 217, 227, 228, 230, 233, 234, 240, 241, 243, 246], "move": [0, 1, 4, 5, 12, 21, 23, 24, 25, 26, 27, 28, 30, 35, 38, 41, 45, 47, 76, 91, 101, 107, 109, 123, 124, 132, 133, 134, 139, 148, 151, 154, 156, 159, 161, 162, 167, 168, 170, 174, 175, 180, 183, 185, 199, 202, 203, 211, 219, 222, 233, 234, 239], "between": [0, 1, 5, 6, 8, 11, 12, 14, 17, 19, 20, 21, 30, 38, 45, 47, 48, 58, 59, 60, 65, 73, 75, 86, 89, 91, 94, 95, 98, 100, 101, 104, 106, 107, 110, 118, 122, 124, 126, 135, 136, 142, 146, 148, 149, 155, 159, 161, 162, 163, 164, 169, 171, 173, 174, 175, 178, 181, 184, 185, 187, 190, 191, 193, 207, 218, 219, 220, 222, 225, 234, 241, 245, 246], "state": [0, 1, 5, 8, 10, 11, 20, 35, 36, 42, 48, 51, 52, 54, 60, 61, 80, 81, 89, 92, 94, 95, 99, 100, 104, 107, 110, 111, 120, 123, 124, 127, 128, 129, 131, 133, 136, 137, 140, 145, 152, 155, 158, 159, 160, 161, 162, 164, 168, 181, 187, 190, 205, 217, 218, 222, 236, 238], "art": [0, 5, 42, 51, 81, 92, 94, 95, 120, 136, 155, 181, 217], "tool": [0, 3, 6, 8, 19, 22, 50, 60, 89, 91, 92, 95, 99, 100, 110, 124, 133, 135, 143, 160, 163, 169, 174, 179, 190, 201, 202, 204, 211, 214, 225], "choos": [0, 1, 8, 10, 12, 48, 51, 54, 59, 65, 89, 92, 101, 110, 111, 128, 133, 135, 145, 151, 157, 158, 159, 164, 168, 174, 175, 181, 192, 203, 214, 215, 218, 225, 227], "combin": [0, 5, 10, 19, 34, 61, 77, 89, 91, 94, 95, 100, 103, 106, 107, 115, 121, 122, 125, 127, 128, 129, 137, 149, 155, 156, 159, 162, 164, 180, 188, 192, 209, 219, 222, 224], "best": [0, 5, 6, 7, 8, 21, 41, 51, 58, 61, 75, 89, 108, 111, 115, 117, 120, 122, 131, 134, 135, 136, 137, 143, 152, 153, 156, 157, 159, 160, 162, 165, 166, 189, 208, 209, 211, 224, 225, 233, 234, 237, 245], "them": [0, 1, 2, 3, 5, 6, 8, 10, 11, 12, 16, 17, 21, 22, 29, 31, 34, 41, 42, 45, 47, 48, 50, 52, 54, 57, 59, 60, 61, 68, 77, 89, 91, 92, 94, 95, 97, 98, 99, 103, 104, 106, 107, 110, 111, 115, 116, 119, 122, 123, 126, 127, 128, 129, 130, 134, 135, 137, 138, 142, 143, 144, 148, 149, 151, 152, 155, 157, 159, 160, 161, 162, 173, 174, 175, 186, 188, 189, 190, 193, 195, 201, 202, 204, 207, 208, 209, 213, 218, 219, 222, 228, 230, 233, 234, 239, 243], "support": [0, 4, 6, 11, 14, 16, 17, 20, 21, 29, 35, 40, 45, 50, 55, 60, 61, 75, 80, 83, 86, 90, 91, 92, 93, 94, 95, 98, 99, 108, 113, 122, 123, 124, 126, 130, 132, 133, 135, 136, 140, 143, 146, 151, 154, 155, 157, 158, 160, 161, 162, 168, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 197, 199, 200, 201, 203, 208, 209, 211, 216, 217, 219, 225, 232, 234, 238, 239, 243, 244], "commun": [0, 11, 16, 54, 61, 109, 113, 122, 123, 124, 126, 131, 132, 133, 154, 158, 160, 161, 162, 168, 173, 191, 234, 238], "partner": [0, 113], "about": [0, 1, 4, 5, 6, 7, 8, 9, 10, 18, 19, 20, 21, 33, 34, 35, 38, 40, 41, 48, 51, 52, 53, 54, 56, 57, 72, 73, 75, 80, 89, 91, 94, 95, 97, 98, 101, 103, 104, 106, 107, 108, 110, 111, 113, 117, 118, 120, 121, 123, 126, 127, 128, 130, 132, 133, 135, 137, 138, 141, 142, 143, 144, 152, 153, 156, 157, 158, 159, 160, 162, 163, 164, 166, 168, 171, 173, 180, 181, 182, 183, 185, 186, 187, 189, 191, 192, 193, 196, 197, 201, 202, 205, 210, 211, 216, 222, 223, 231, 233, 236, 238, 243], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 34, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 67, 68, 69, 75, 77, 78, 80, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 221, 222, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 246, 247], "go": [0, 4, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 38, 47, 50, 58, 59, 60, 80, 91, 92, 94, 98, 99, 100, 103, 104, 107, 117, 120, 122, 123, 125, 127, 132, 135, 137, 141, 142, 144, 156, 157, 159, 161, 164, 169, 174, 175, 176, 182, 183, 184, 193, 197, 204, 211, 216, 219, 222, 232, 233, 240], "walk": [0, 5, 6, 10, 14, 20, 21, 22, 41, 53, 57, 58, 59, 60, 61, 91, 107, 114, 121, 122, 125, 143, 145, 161, 173, 176, 182, 183, 197, 210, 218, 232], "through": [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 17, 19, 20, 21, 22, 29, 30, 34, 35, 41, 45, 48, 51, 53, 54, 57, 58, 59, 60, 61, 77, 80, 85, 87, 89, 91, 94, 95, 97, 99, 101, 103, 104, 107, 109, 110, 114, 115, 118, 119, 120, 121, 122, 123, 125, 127, 129, 130, 135, 137, 141, 142, 143, 144, 145, 146, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 168, 169, 171, 172, 173, 174, 179, 180, 182, 183, 184, 186, 190, 192, 193, 197, 198, 201, 202, 203, 208, 209, 210, 216, 218, 219, 224, 225, 232, 237, 245], "4": [0, 1, 2, 3, 5, 6, 7, 12, 14, 19, 21, 33, 43, 47, 50, 52, 53, 54, 63, 64, 65, 75, 77, 83, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 106, 107, 110, 113, 115, 116, 117, 118, 120, 122, 123, 124, 129, 131, 132, 135, 143, 145, 146, 148, 153, 155, 156, 159, 160, 161, 162, 173, 175, 178, 187, 192, 197, 200, 201, 210, 232, 239, 243, 245, 246, 249], "main": [0, 1, 3, 4, 5, 6, 7, 11, 14, 17, 20, 21, 34, 51, 52, 54, 58, 59, 61, 89, 110, 113, 120, 123, 124, 127, 131, 134, 135, 136, 143, 156, 159, 160, 161, 162, 166, 173, 174, 175, 182, 192, 193, 198, 199, 201, 207, 208, 209, 210, 211, 214, 234, 240, 241, 243, 245, 247], "step": [0, 3, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 19, 21, 29, 33, 34, 41, 42, 45, 48, 51, 60, 61, 75, 86, 91, 94, 99, 100, 101, 107, 109, 115, 117, 120, 121, 122, 123, 124, 127, 128, 129, 131, 133, 135, 136, 141, 143, 145, 149, 151, 156, 159, 160, 161, 162, 163, 164, 169, 171, 173, 174, 175, 176, 178, 179, 181, 183, 189, 190, 192, 193, 195, 197, 199, 201, 202, 205, 208, 209, 210, 211, 214, 216, 218, 232, 234, 239, 241], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 58, 59, 60, 63, 64, 65, 68, 69, 75, 77, 78, 80, 81, 86, 89, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 210, 211, 212, 213, 214, 216, 217, 219, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 235, 236, 237, 239, 240, 241, 243, 245], "work": [0, 1, 2, 4, 5, 6, 9, 12, 16, 18, 19, 20, 21, 22, 33, 34, 40, 41, 48, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61, 75, 80, 86, 89, 91, 92, 94, 95, 98, 99, 100, 106, 107, 113, 115, 116, 120, 122, 125, 127, 128, 129, 130, 131, 133, 134, 135, 137, 138, 140, 141, 142, 144, 148, 151, 152, 153, 154, 155, 157, 158, 160, 162, 163, 164, 168, 173, 175, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 192, 193, 195, 196, 198, 199, 200, 201, 204, 208, 211, 212, 213, 218, 219, 222, 225, 233, 234, 239, 245, 246], "virtualenv": 0, "order": [0, 4, 6, 11, 12, 18, 20, 29, 30, 31, 42, 43, 48, 49, 54, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 89, 91, 92, 94, 98, 107, 108, 110, 113, 118, 119, 122, 124, 125, 126, 128, 130, 133, 134, 135, 141, 142, 143, 144, 146, 154, 155, 161, 164, 166, 171, 172, 175, 176, 179, 183, 186, 188, 189, 193, 198, 204, 205, 210, 227, 233, 239], "avoid": [0, 5, 14, 42, 58, 59, 89, 97, 123, 124, 129, 133, 134, 135, 146, 149, 153, 158, 160, 174, 184, 185, 188, 191, 195, 211, 218, 219, 222, 225], "conflict": [0, 14, 143], "your": [0, 2, 6, 8, 9, 11, 12, 16, 17, 20, 21, 22, 29, 30, 33, 35, 40, 41, 42, 43, 45, 48, 49, 50, 52, 53, 54, 58, 59, 61, 67, 75, 77, 80, 89, 90, 91, 92, 95, 98, 99, 101, 103, 104, 106, 109, 110, 111, 112, 113, 114, 122, 123, 124, 125, 129, 130, 131, 132, 133, 135, 136, 138, 140, 142, 144, 145, 146, 148, 151, 154, 155, 156, 157, 158, 161, 162, 163, 166, 168, 169, 171, 173, 174, 181, 182, 183, 188, 189, 191, 192, 193, 195, 197, 198, 199, 202, 205, 207, 210, 212, 213, 217, 218, 219, 222, 224, 225, 227, 228, 229, 230, 232, 233, 235, 236, 237, 238, 243, 245, 246, 250], "local": [0, 5, 6, 8, 9, 14, 16, 17, 20, 21, 33, 48, 49, 90, 91, 100, 111, 114, 123, 126, 133, 134, 135, 136, 155, 156, 160, 161, 162, 164, 166, 174, 181, 201, 203, 205, 207, 210, 211, 218, 221, 228, 230, 234, 239, 241, 243], "packag": [0, 2, 5, 6, 16, 20, 21, 42, 45, 50, 56, 61, 68, 69, 77, 78, 79, 81, 82, 84, 89, 99, 101, 107, 109, 110, 115, 116, 117, 120, 121, 122, 123, 124, 133, 135, 136, 142, 154, 156, 157, 159, 162, 174, 181, 182, 201, 204, 208, 211, 217, 221, 224, 225, 233, 237, 238, 240], "also": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 35, 38, 40, 41, 45, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 68, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 116, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 148, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 168, 171, 173, 174, 175, 176, 178, 179, 180, 183, 184, 185, 186, 187, 190, 192, 193, 195, 196, 198, 199, 200, 201, 204, 205, 208, 209, 210, 211, 216, 218, 219, 220, 222, 224, 225, 227, 228, 230, 232, 233, 234, 236, 237, 239, 240, 241, 243, 245, 246], "python": [0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 16, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 52, 54, 55, 56, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 158, 159, 161, 163, 164, 165, 166, 168, 171, 172, 174, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 196, 197, 198, 201, 204, 205, 208, 209, 210, 211, 214, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 240, 245, 246], "3": [0, 2, 3, 5, 6, 7, 14, 16, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 40, 41, 47, 51, 63, 64, 68, 69, 72, 75, 76, 77, 83, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 123, 124, 127, 129, 130, 135, 138, 139, 141, 143, 145, 146, 148, 149, 150, 152, 155, 156, 157, 158, 160, 161, 162, 163, 167, 170, 171, 172, 174, 175, 180, 182, 183, 188, 189, 192, 195, 197, 198, 199, 200, 201, 204, 208, 209, 210, 214, 215, 217, 218, 240, 245, 246, 249], "6": [0, 3, 6, 7, 11, 17, 21, 33, 47, 48, 58, 59, 61, 72, 86, 91, 92, 94, 95, 98, 103, 106, 108, 110, 111, 116, 117, 118, 129, 130, 134, 135, 136, 143, 146, 153, 154, 155, 157, 160, 162, 173, 174, 175, 181, 192, 201, 204, 207, 209, 212, 213, 215, 216, 218, 229, 234, 239, 240, 249], "other": [0, 1, 5, 6, 7, 8, 10, 11, 17, 19, 20, 21, 22, 29, 30, 33, 38, 42, 45, 47, 48, 51, 52, 54, 55, 56, 58, 59, 60, 61, 68, 69, 75, 77, 81, 83, 89, 91, 92, 94, 98, 101, 103, 104, 106, 107, 110, 111, 113, 114, 116, 124, 127, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 142, 143, 144, 145, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 164, 169, 171, 173, 174, 175, 176, 179, 180, 181, 184, 185, 186, 187, 188, 189, 192, 193, 195, 197, 202, 207, 211, 216, 218, 219, 221, 222, 224, 225, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 240, 241, 244, 245], "version": [0, 1, 3, 4, 5, 6, 8, 10, 12, 18, 20, 21, 22, 40, 83, 92, 94, 95, 98, 99, 107, 115, 116, 120, 123, 124, 125, 127, 135, 136, 137, 138, 140, 144, 146, 151, 154, 155, 156, 157, 158, 166, 168, 169, 172, 175, 180, 181, 182, 183, 184, 188, 192, 197, 199, 201, 207, 208, 209, 210, 211, 216, 218, 219, 222, 232, 233, 240, 243, 246], "should": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 14, 16, 17, 18, 19, 20, 21, 29, 40, 41, 42, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 69, 75, 80, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 110, 117, 118, 120, 122, 123, 125, 126, 127, 130, 133, 135, 137, 138, 142, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 169, 171, 172, 173, 174, 175, 179, 182, 183, 184, 185, 186, 192, 193, 198, 199, 201, 204, 207, 210, 211, 214, 218, 219, 225, 232, 233, 234, 237, 238, 239, 240, 243, 245, 248], "well": [0, 1, 3, 4, 5, 6, 8, 10, 11, 17, 18, 20, 21, 31, 38, 40, 42, 47, 48, 52, 60, 86, 89, 92, 94, 101, 103, 107, 109, 111, 113, 117, 123, 125, 126, 127, 129, 130, 135, 136, 140, 141, 151, 156, 157, 160, 161, 162, 163, 164, 168, 169, 171, 174, 175, 179, 181, 182, 183, 184, 185, 186, 188, 190, 192, 195, 208, 210, 211, 214, 219, 222, 233, 234, 236, 245], "python3": [0, 5, 16, 20, 21, 182, 233], "m": [0, 4, 5, 6, 7, 8, 10, 17, 20, 21, 29, 41, 48, 91, 95, 103, 107, 109, 113, 116, 117, 118, 119, 123, 124, 134, 136, 141, 143, 144, 148, 153, 154, 156, 160, 162, 180, 181, 192, 195, 201, 214, 234, 246], "venv": 0, "sourc": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 18, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 54, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 120, 123, 125, 126, 127, 128, 129, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 158, 159, 160, 162, 163, 164, 166, 168, 171, 174, 175, 178, 182, 184, 185, 186, 187, 188, 189, 190, 191, 196, 197, 198, 199, 207, 208, 209, 210, 211, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "bin": [0, 4, 6, 20, 21, 94, 135, 189, 197, 201, 207, 208, 211, 214], "activ": [0, 5, 6, 9, 10, 12, 17, 30, 51, 91, 92, 94, 101, 107, 123, 131, 135, 136, 144, 155, 157, 168, 174, 176, 179, 181, 182, 190, 193, 198, 200, 201, 208, 209, 214, 216, 217, 222, 225, 234, 240, 245], "need": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 29, 30, 31, 34, 35, 36, 38, 39, 41, 42, 43, 45, 48, 49, 50, 52, 53, 54, 58, 59, 60, 61, 63, 64, 67, 77, 78, 81, 89, 92, 94, 97, 98, 99, 101, 103, 104, 106, 107, 110, 111, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 171, 172, 174, 175, 176, 179, 181, 182, 183, 184, 188, 189, 190, 192, 193, 195, 197, 199, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 240, 245], "instal": [0, 5, 6, 7, 8, 18, 21, 33, 49, 50, 52, 54, 56, 58, 89, 90, 97, 98, 107, 115, 116, 118, 119, 120, 123, 124, 127, 128, 131, 132, 135, 138, 140, 142, 145, 153, 154, 158, 159, 160, 164, 168, 171, 175, 181, 182, 183, 189, 197, 199, 201, 204, 210, 211, 212, 213, 214, 215, 217, 219, 221, 224, 225, 227, 228, 229, 230, 233, 235, 236, 237, 240, 249], "pip": [0, 18, 49, 77, 92, 97, 115, 118, 119, 120, 136, 138, 145, 156, 157, 159, 168, 171, 175, 189, 199, 209, 211, 217, 219, 221, 224, 225, 227, 228, 229, 230, 232, 235, 236, 237], "torchvis": [0, 4, 10, 12, 17, 31, 33, 35, 39, 41, 42, 49, 56, 58, 59, 77, 89, 90, 92, 94, 97, 99, 109, 117, 120, 122, 123, 124, 134, 136, 138, 141, 142, 148, 156, 157, 160, 161, 168, 169, 171, 173, 174, 179, 182, 183, 189, 192, 193, 197, 199, 204, 208, 209, 211, 212, 213, 215, 216, 224, 225, 232, 234, 237, 240], "xcode": [0, 59, 183, 197, 210, 211, 213, 215], "want": [0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 20, 21, 29, 30, 31, 34, 36, 41, 42, 45, 48, 50, 51, 57, 58, 59, 60, 63, 64, 67, 75, 78, 80, 81, 86, 89, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 107, 110, 111, 125, 126, 127, 135, 136, 137, 140, 142, 144, 146, 149, 151, 155, 156, 157, 158, 161, 163, 164, 166, 171, 172, 175, 178, 179, 180, 184, 186, 190, 191, 192, 193, 198, 201, 209, 210, 211, 214, 216, 218, 219, 222, 227, 228, 233, 235], "iphon": [0, 182, 211], "linux": [0, 5, 6, 16, 18, 20, 21, 133, 135, 157, 173, 174, 189, 199, 201, 208], "howev": [0, 1, 5, 6, 8, 10, 12, 18, 20, 21, 22, 29, 43, 45, 48, 50, 51, 60, 61, 75, 78, 86, 89, 100, 110, 113, 117, 118, 125, 129, 130, 134, 135, 137, 138, 142, 146, 148, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 169, 171, 173, 176, 180, 185, 186, 188, 197, 198, 200, 210, 211, 219, 222, 233, 243, 244], "itself": [0, 5, 7, 11, 21, 29, 30, 41, 60, 61, 86, 95, 98, 103, 104, 107, 111, 113, 125, 127, 130, 135, 141, 145, 153, 158, 161, 162, 164, 190, 204, 205, 218, 225, 229], "mac": [0, 18, 136, 199, 213], "For": [0, 1, 2, 4, 5, 6, 7, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 34, 35, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 63, 64, 68, 75, 77, 80, 81, 83, 89, 92, 95, 97, 98, 99, 100, 101, 104, 106, 107, 110, 111, 113, 114, 115, 116, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 148, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 171, 172, 173, 174, 175, 176, 178, 179, 181, 183, 184, 185, 186, 187, 188, 190, 192, 193, 195, 199, 200, 201, 202, 204, 205, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246], "publish": [0, 201], "http": [0, 4, 6, 7, 16, 17, 22, 23, 24, 25, 26, 27, 32, 43, 44, 48, 58, 59, 60, 76, 77, 79, 80, 85, 93, 97, 102, 113, 115, 117, 118, 119, 123, 124, 127, 128, 129, 136, 138, 139, 140, 141, 142, 146, 152, 153, 154, 156, 157, 159, 164, 167, 168, 169, 170, 171, 175, 176, 178, 179, 182, 183, 185, 187, 189, 196, 197, 198, 199, 201, 204, 207, 209, 210, 217, 218, 219, 222, 223, 225, 232, 243, 245], "github": [0, 2, 3, 4, 6, 7, 10, 11, 14, 17, 20, 21, 48, 52, 53, 54, 60, 61, 80, 115, 118, 119, 122, 123, 124, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 145, 146, 152, 153, 154, 160, 161, 162, 168, 175, 176, 179, 183, 197, 198, 199, 200, 201, 204, 207, 208, 209, 210, 217, 225, 243], "com": [0, 7, 10, 16, 17, 22, 48, 60, 77, 80, 115, 118, 119, 124, 127, 128, 129, 140, 141, 142, 146, 152, 153, 154, 159, 164, 175, 176, 178, 179, 189, 197, 198, 199, 201, 204, 207, 210, 217, 219, 225], "exampl": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 57, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 77, 78, 79, 82, 83, 85, 87, 89, 94, 95, 97, 98, 99, 100, 103, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 192, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 249], "tree": [0, 6, 10, 20, 48, 60, 80, 100, 106, 113, 129, 197, 210, 243], "master": [0, 4, 14, 17, 48, 60, 80, 124, 129, 134, 135, 141, 142, 146, 161, 162, 175, 176, 179, 183, 189, 191, 197, 199, 203, 208, 210], "fast_neural_styl": 0, "If": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 19, 20, 21, 29, 33, 38, 41, 42, 43, 45, 47, 48, 49, 51, 52, 54, 57, 58, 60, 61, 63, 75, 77, 78, 80, 89, 91, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 110, 111, 113, 114, 117, 118, 119, 123, 124, 125, 128, 129, 133, 135, 137, 138, 140, 141, 143, 144, 146, 148, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 168, 171, 172, 173, 175, 176, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 192, 195, 198, 199, 200, 201, 202, 204, 205, 207, 208, 209, 210, 211, 213, 214, 217, 218, 220, 222, 224, 225, 228, 230, 232, 233, 234, 235, 237, 239, 243, 245], "would": [0, 3, 4, 5, 6, 7, 8, 14, 16, 17, 18, 19, 20, 21, 22, 29, 41, 48, 52, 54, 60, 61, 75, 78, 89, 91, 94, 95, 98, 103, 106, 107, 111, 113, 116, 117, 118, 124, 125, 126, 127, 128, 129, 130, 133, 134, 136, 138, 141, 142, 143, 144, 146, 148, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 164, 171, 173, 174, 175, 179, 181, 186, 187, 191, 198, 200, 202, 205, 211, 213, 214, 228, 230, 234], "like": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 18, 19, 20, 21, 22, 30, 31, 34, 35, 36, 38, 41, 42, 43, 45, 47, 48, 50, 51, 52, 58, 59, 60, 61, 68, 77, 80, 81, 83, 86, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 116, 117, 122, 124, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 164, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 191, 192, 193, 198, 199, 200, 201, 202, 204, 205, 207, 208, 209, 210, 213, 214, 217, 218, 219, 220, 221, 222, 225, 233, 234, 240, 244, 245], "differ": [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 29, 34, 38, 45, 47, 48, 50, 51, 58, 59, 60, 61, 73, 75, 83, 84, 86, 89, 92, 94, 95, 98, 99, 100, 101, 106, 107, 115, 116, 118, 120, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 142, 143, 144, 146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 171, 173, 174, 176, 179, 183, 184, 185, 186, 187, 188, 190, 192, 193, 195, 197, 199, 201, 205, 207, 211, 216, 219, 222, 223, 225, 227, 231, 232, 233, 234, 238, 239, 241, 243], "feel": [0, 6, 10, 17, 34, 41, 48, 111, 123, 141, 142, 143, 145, 146, 168, 182], "free": [0, 6, 10, 17, 20, 21, 22, 34, 41, 48, 60, 75, 86, 111, 123, 126, 135, 141, 142, 145, 146, 158, 160, 164, 168, 172, 182, 205, 222, 233], "skip": [0, 1, 4, 5, 10, 17, 21, 40, 41, 100, 111, 116, 130, 140, 145, 158, 160, 162, 168, 179, 191, 203, 219, 225, 237], "These": [0, 1, 5, 7, 8, 11, 12, 17, 18, 19, 22, 36, 41, 48, 51, 54, 89, 95, 104, 106, 107, 108, 113, 117, 119, 135, 145, 153, 156, 158, 159, 161, 164, 173, 174, 179, 192, 193, 219, 224, 233, 243, 245], "meant": [0, 6, 11, 86, 91, 95, 123, 186, 234, 240], "appli": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 21, 22, 29, 30, 39, 50, 51, 58, 59, 60, 61, 68, 81, 86, 91, 94, 95, 98, 101, 110, 113, 116, 118, 120, 122, 124, 129, 130, 133, 134, 135, 137, 138, 141, 144, 145, 146, 149, 151, 152, 153, 155, 158, 160, 161, 162, 164, 166, 173, 174, 178, 181, 184, 185, 188, 195, 198, 200, 201, 204, 205, 207, 208, 211, 216, 217, 234, 238, 239], "still": [0, 1, 5, 6, 8, 10, 11, 12, 16, 17, 21, 40, 45, 51, 61, 75, 81, 83, 89, 91, 98, 103, 107, 108, 111, 113, 120, 123, 127, 128, 133, 135, 140, 141, 142, 146, 148, 162, 171, 173, 176, 178, 179, 182, 183, 184, 186, 190, 192, 193, 197, 201, 202, 210, 211, 216, 233, 234, 241], "imag": [0, 1, 17, 21, 30, 31, 33, 39, 41, 45, 48, 50, 51, 56, 60, 75, 77, 89, 92, 94, 95, 98, 99, 107, 122, 137, 145, 146, 148, 152, 159, 166, 169, 175, 179, 188, 192, 197, 199, 200, 201, 210, 211, 212, 213, 217, 221, 227, 228, 229, 230, 232, 235, 236, 238, 240], "realli": [0, 5, 8, 21, 22, 40, 42, 91, 95, 98, 100, 101, 106, 110, 112, 113, 122, 125, 156, 169, 184, 186, 198, 219, 229], "optim": [0, 3, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 19, 21, 22, 29, 30, 31, 32, 33, 36, 38, 39, 41, 45, 48, 52, 54, 58, 59, 60, 61, 65, 66, 67, 70, 81, 86, 89, 91, 94, 97, 100, 111, 112, 115, 117, 118, 119, 122, 123, 124, 127, 129, 131, 133, 134, 135, 137, 141, 142, 143, 145, 146, 148, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 168, 169, 171, 172, 173, 175, 179, 181, 183, 184, 188, 189, 190, 191, 196, 197, 199, 200, 207, 208, 209, 210, 215, 216, 218, 219, 227, 235, 238, 240], "fast": [0, 1, 5, 6, 16, 19, 48, 91, 107, 122, 124, 133, 149, 158, 163, 188, 191, 211, 222, 233], "enough": [0, 5, 6, 19, 21, 48, 94, 103, 107, 110, 125, 129, 157, 218], "video": [0, 18, 34, 41, 42, 52, 54, 55, 77, 81, 90, 91, 92, 94, 95, 97, 98, 99, 114, 121, 122, 131, 132, 172, 234], "reduc": [0, 3, 6, 9, 11, 17, 31, 34, 41, 55, 58, 59, 61, 94, 95, 108, 120, 123, 124, 126, 129, 131, 133, 135, 136, 144, 145, 146, 155, 157, 158, 160, 162, 168, 171, 173, 174, 181, 189, 196, 197, 207, 210, 211, 215, 216, 218, 219, 222, 238, 241], "resolut": [0, 18, 95], "low": [0, 1, 4, 5, 6, 22, 48, 51, 68, 95, 101, 110, 113, 122, 127, 168, 174, 208, 209, 233], "thei": [0, 1, 3, 4, 5, 6, 8, 10, 12, 14, 17, 18, 19, 21, 22, 30, 31, 38, 42, 47, 48, 51, 54, 57, 58, 59, 60, 75, 83, 86, 91, 94, 95, 98, 99, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 123, 125, 126, 127, 128, 130, 133, 134, 135, 143, 144, 146, 151, 158, 159, 160, 162, 164, 173, 174, 175, 176, 179, 181, 184, 185, 186, 187, 188, 190, 192, 193, 195, 196, 200, 201, 208, 212, 213, 219, 222, 225, 232, 233, 234, 236, 237, 239, 243, 245], "let": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 30, 34, 41, 42, 43, 45, 48, 50, 51, 58, 59, 60, 68, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 116, 117, 119, 120, 126, 130, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 151, 152, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 182, 183, 184, 185, 188, 201, 210, 211, 217, 219, 221, 224, 225, 229, 232, 233, 234, 237, 240, 243, 245], "s": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 56, 58, 59, 68, 75, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 108, 109, 110, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 175, 176, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 197, 198, 200, 201, 202, 203, 204, 205, 210, 211, 212, 213, 216, 217, 218, 219, 221, 222, 224, 225, 227, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 245, 246], "git": [0, 175, 204, 207, 225, 249], "clone": [0, 11, 20, 21, 53, 98, 109, 127, 130, 131, 135, 143, 146, 201, 202, 204, 207, 225], "cd": [0, 4, 6, 20, 21, 178, 183, 189, 199, 201, 207, 213, 214, 225], "yourself": [0, 4, 5, 6, 8, 21, 33, 40, 60, 94, 103, 122, 145, 180], "repositori": [0, 6, 10, 53, 58, 59, 114, 120, 123, 135, 154, 162, 163, 164, 197, 199, 201, 204, 210, 243, 250], "just": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 17, 19, 20, 21, 22, 29, 40, 42, 43, 45, 48, 49, 50, 51, 52, 55, 57, 60, 72, 73, 78, 80, 86, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 111, 113, 117, 123, 124, 126, 127, 128, 133, 136, 138, 143, 144, 148, 149, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 169, 173, 175, 179, 183, 186, 189, 192, 197, 201, 204, 205, 208, 216, 219, 220, 221, 228, 229, 233, 234, 237, 245, 247], "inform": [0, 1, 2, 4, 5, 7, 8, 10, 18, 20, 21, 22, 29, 43, 48, 52, 75, 80, 89, 91, 95, 97, 98, 103, 104, 106, 111, 113, 118, 119, 120, 125, 126, 127, 128, 133, 135, 136, 140, 141, 142, 145, 153, 156, 157, 158, 159, 161, 163, 164, 168, 169, 172, 173, 174, 175, 176, 179, 180, 182, 187, 189, 192, 195, 198, 199, 200, 204, 211, 214, 216, 218, 219, 228, 230, 233, 234, 236, 237, 239, 240, 245], "how": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 31, 34, 35, 36, 40, 41, 42, 43, 45, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 75, 77, 80, 86, 88, 89, 91, 92, 94, 95, 98, 99, 101, 103, 104, 106, 107, 108, 111, 113, 115, 116, 117, 119, 120, 121, 122, 125, 126, 127, 128, 130, 131, 134, 135, 136, 137, 138, 140, 141, 142, 143, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 196, 197, 200, 201, 202, 204, 207, 209, 211, 212, 213, 216, 217, 218, 219, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 237, 238, 239, 245, 247, 249], "do": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 29, 30, 36, 40, 45, 48, 49, 50, 51, 53, 58, 59, 60, 61, 63, 64, 69, 78, 83, 86, 89, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 110, 111, 114, 116, 119, 122, 124, 125, 126, 127, 132, 133, 134, 135, 137, 138, 141, 142, 143, 144, 145, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 162, 164, 169, 173, 174, 175, 178, 179, 181, 183, 185, 186, 187, 189, 190, 191, 192, 195, 196, 198, 201, 204, 205, 207, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 225, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 240, 244, 246], "now": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 18, 19, 20, 21, 22, 34, 35, 40, 41, 42, 43, 45, 48, 49, 50, 51, 54, 58, 59, 60, 75, 78, 80, 83, 86, 89, 91, 92, 97, 98, 101, 103, 106, 107, 110, 116, 117, 119, 120, 123, 124, 125, 126, 127, 129, 130, 133, 134, 135, 136, 138, 141, 142, 143, 144, 145, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 162, 166, 168, 169, 171, 172, 173, 175, 176, 178, 179, 181, 182, 183, 184, 185, 188, 189, 192, 193, 195, 198, 201, 204, 205, 211, 212, 220, 221, 222, 224, 229, 232, 233, 236, 240, 245], "ll": [0, 1, 4, 5, 6, 8, 9, 10, 17, 18, 20, 21, 30, 31, 33, 38, 47, 48, 49, 60, 89, 91, 92, 94, 95, 97, 98, 99, 100, 107, 127, 128, 135, 137, 138, 140, 144, 149, 152, 157, 158, 159, 161, 164, 169, 173, 178, 179, 180, 181, 182, 183, 184, 186, 190, 192, 204, 211, 219], "pre": [0, 17, 31, 100, 122, 123, 124, 135, 136, 156, 157, 175, 181, 182, 183, 205, 210, 211], "script": [0, 1, 5, 6, 7, 9, 10, 12, 13, 17, 18, 19, 20, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 54, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 111, 113, 114, 115, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 158, 159, 161, 163, 164, 166, 168, 171, 173, 174, 175, 178, 179, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 196, 197, 198, 199, 201, 202, 204, 205, 207, 208, 210, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 240], "provid": [0, 1, 4, 5, 6, 8, 10, 11, 14, 16, 17, 18, 19, 20, 21, 22, 30, 31, 42, 48, 50, 51, 55, 58, 59, 60, 61, 75, 86, 89, 91, 92, 94, 98, 99, 100, 101, 107, 110, 111, 113, 115, 116, 119, 121, 122, 123, 125, 126, 131, 132, 133, 134, 135, 136, 141, 142, 143, 144, 145, 146, 155, 157, 158, 160, 161, 163, 168, 171, 175, 181, 182, 186, 187, 188, 189, 190, 191, 192, 195, 198, 200, 201, 202, 204, 205, 207, 208, 209, 211, 214, 215, 217, 218, 219, 221, 222, 225, 232, 233, 234, 245], "download_saved_model": 0, "py": [0, 1, 5, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 131, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 158, 159, 161, 163, 164, 165, 166, 168, 171, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 194, 196, 197, 198, 199, 204, 209, 211, 214, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 243, 245, 250], "put": [0, 2, 5, 6, 8, 12, 14, 30, 40, 43, 48, 50, 59, 77, 86, 94, 95, 98, 113, 122, 123, 124, 134, 135, 148, 151, 158, 159, 161, 162, 182, 193, 201, 224, 245], "saved_model": [0, 99], "folder": [0, 4, 6, 17, 21, 49, 51, 92, 94, 123, 136, 169, 175, 178, 179, 181, 183, 192, 197, 199, 201, 204, 207, 212, 213], "There": [0, 4, 6, 8, 10, 20, 21, 22, 29, 45, 75, 78, 81, 86, 91, 92, 94, 95, 98, 99, 100, 101, 104, 106, 107, 113, 117, 121, 128, 132, 137, 142, 144, 146, 148, 149, 152, 156, 157, 158, 161, 162, 164, 175, 176, 178, 186, 188, 189, 192, 193, 204, 216, 219, 221, 222, 227, 229, 233, 234, 237, 239, 246], "file": [0, 2, 5, 6, 8, 10, 15, 17, 18, 19, 20, 21, 37, 46, 49, 50, 51, 54, 58, 59, 60, 70, 74, 77, 82, 87, 89, 91, 92, 96, 103, 105, 107, 108, 109, 112, 114, 116, 119, 120, 123, 125, 127, 128, 133, 135, 136, 138, 143, 154, 157, 165, 168, 175, 179, 181, 183, 187, 188, 192, 194, 197, 199, 200, 202, 207, 208, 209, 210, 211, 212, 213, 218, 219, 223, 225, 228, 229, 231, 232, 233, 235, 238, 240, 243, 244, 246, 250], "candi": 0, "pth": [0, 5, 17, 21, 111, 117, 178, 179, 192, 208, 209, 229, 239], "mosaic": 0, "rain_princess": 0, "udni": 0, "directori": [0, 1, 4, 5, 6, 12, 20, 21, 31, 48, 50, 51, 77, 89, 97, 111, 114, 117, 126, 127, 128, 136, 143, 156, 164, 168, 181, 183, 189, 197, 201, 209, 211, 214, 224, 229, 232], "have": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 34, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 68, 69, 75, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 130, 131, 132, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 195, 198, 199, 200, 201, 202, 204, 205, 208, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 224, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245], "The": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 34, 35, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 67, 68, 69, 73, 75, 77, 78, 80, 81, 83, 86, 90, 92, 93, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 166, 168, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 216, 218, 219, 221, 222, 224, 225, 229, 232, 233, 234, 237, 239, 240, 241, 243, 246], "definit": [0, 5, 6, 8, 10, 18, 20, 22, 36, 45, 58, 59, 60, 68, 75, 86, 101, 110, 122, 142, 151, 159, 163, 178, 185, 201, 202, 207, 209, 216, 233, 234, 239, 245], "previous": [0, 4, 5, 8, 18, 29, 60, 86, 103, 107, 115, 119, 140, 141, 155, 158, 159, 160, 184, 192, 198, 211, 230, 238], "few": [0, 5, 6, 8, 9, 10, 17, 19, 20, 21, 45, 50, 55, 57, 60, 81, 86, 91, 92, 94, 98, 101, 103, 104, 106, 111, 113, 115, 116, 121, 123, 125, 127, 128, 133, 135, 148, 151, 157, 158, 161, 164, 174, 176, 185, 186, 187, 188, 192, 201, 202, 205, 208, 209, 218, 233, 234, 235], "line": [0, 4, 5, 6, 8, 12, 19, 20, 21, 48, 49, 50, 55, 58, 59, 60, 61, 91, 94, 97, 98, 99, 101, 107, 108, 115, 116, 126, 127, 128, 135, 142, 143, 148, 157, 161, 162, 164, 168, 169, 171, 174, 183, 184, 186, 201, 208, 209, 210, 212, 213, 224, 232, 234, 239, 240, 246], "In": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 35, 36, 38, 40, 41, 43, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 64, 68, 75, 77, 78, 80, 81, 83, 84, 86, 88, 89, 90, 92, 94, 95, 97, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 192, 193, 195, 196, 197, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 211, 212, 214, 217, 218, 219, 221, 222, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 240, 241, 245, 246, 248], "instead": [0, 4, 5, 6, 8, 10, 17, 18, 20, 21, 22, 29, 42, 43, 48, 50, 51, 52, 58, 59, 60, 61, 64, 91, 94, 98, 100, 101, 106, 107, 108, 110, 113, 116, 117, 123, 124, 125, 126, 127, 128, 130, 131, 134, 135, 141, 142, 144, 145, 146, 148, 149, 154, 155, 156, 157, 160, 161, 162, 164, 166, 169, 171, 173, 174, 176, 184, 186, 187, 188, 198, 202, 205, 211, 226, 239, 241], "actual": [0, 1, 3, 5, 6, 8, 11, 13, 17, 19, 20, 21, 22, 29, 36, 48, 50, 51, 58, 59, 60, 75, 86, 94, 100, 103, 106, 111, 119, 122, 125, 126, 127, 129, 133, 135, 138, 141, 142, 158, 164, 168, 169, 171, 172, 174, 179, 184, 186, 192, 193, 197, 198, 211, 212, 213, 219, 222, 239], "net": [0, 3, 6, 17, 42, 43, 45, 48, 51, 75, 81, 84, 86, 89, 94, 97, 98, 109, 124, 135, 149, 157, 161, 168, 169, 202, 209, 221, 229, 245, 246], "call": [0, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 29, 30, 31, 34, 36, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 52, 54, 58, 59, 60, 61, 67, 75, 77, 78, 80, 83, 86, 91, 92, 94, 95, 97, 98, 101, 103, 106, 107, 108, 110, 111, 113, 116, 119, 121, 122, 124, 125, 126, 128, 133, 134, 135, 136, 138, 140, 141, 142, 143, 145, 146, 148, 149, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 171, 172, 173, 174, 179, 180, 181, 182, 183, 188, 189, 190, 197, 198, 199, 200, 201, 204, 205, 207, 211, 212, 213, 216, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 234, 237, 239, 245], "torch": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 34, 35, 36, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56, 58, 59, 60, 64, 67, 73, 78, 80, 81, 86, 89, 91, 92, 94, 97, 98, 99, 101, 104, 106, 108, 109, 110, 112, 115, 116, 117, 120, 122, 123, 124, 127, 128, 130, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160, 161, 162, 164, 165, 168, 169, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 191, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 216, 220, 221, 222, 224, 225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "_export": [0, 192], "which": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 47, 48, 50, 51, 55, 58, 59, 60, 61, 63, 64, 67, 68, 69, 75, 77, 78, 80, 81, 86, 89, 90, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 192, 193, 195, 197, 200, 201, 203, 205, 209, 210, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 229, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246], "api": [0, 2, 5, 8, 10, 11, 16, 18, 19, 20, 21, 22, 30, 31, 33, 35, 38, 39, 47, 55, 60, 61, 92, 108, 113, 122, 124, 125, 126, 127, 133, 134, 135, 136, 142, 143, 144, 152, 156, 160, 161, 162, 165, 168, 172, 174, 176, 178, 179, 180, 182, 183, 189, 190, 191, 192, 196, 197, 198, 201, 203, 204, 205, 208, 209, 210, 211, 216, 217, 219, 220, 222, 224, 225, 233, 238, 239, 240, 244], "directli": [0, 4, 5, 6, 8, 11, 12, 18, 20, 21, 22, 30, 38, 40, 47, 51, 61, 86, 89, 91, 92, 98, 113, 119, 130, 131, 136, 144, 157, 158, 162, 164, 179, 181, 186, 187, 195, 199, 202, 203, 205, 209, 210, 216], "don": [0, 5, 6, 8, 10, 19, 40, 41, 42, 51, 52, 78, 89, 95, 98, 100, 101, 104, 107, 111, 113, 117, 125, 127, 130, 136, 142, 144, 145, 156, 158, 159, 162, 163, 179, 180, 181, 182, 183, 184, 185, 186, 205, 210, 214, 218, 243, 245, 246], "t": [0, 2, 4, 5, 6, 7, 8, 10, 11, 13, 17, 19, 20, 21, 22, 29, 33, 34, 38, 40, 41, 42, 45, 47, 49, 51, 52, 58, 59, 72, 75, 78, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 109, 110, 111, 113, 115, 116, 117, 118, 123, 124, 125, 127, 130, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 152, 153, 155, 156, 157, 158, 159, 160, 162, 163, 164, 169, 171, 173, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 190, 192, 198, 199, 201, 202, 205, 210, 214, 216, 218, 219, 221, 227, 228, 229, 230, 233, 234, 235, 236, 237, 239, 243, 245, 246], "even": [0, 4, 5, 6, 8, 10, 14, 19, 21, 22, 41, 42, 50, 75, 78, 91, 94, 95, 98, 106, 107, 111, 113, 123, 124, 130, 133, 138, 141, 142, 144, 151, 158, 160, 163, 173, 184, 186, 187, 190, 196, 204, 216, 219, 234, 235], "becaus": [0, 1, 2, 4, 5, 6, 8, 12, 14, 17, 18, 19, 20, 21, 29, 31, 36, 38, 40, 41, 42, 45, 47, 48, 50, 51, 54, 55, 58, 59, 60, 61, 75, 80, 81, 86, 89, 91, 92, 94, 95, 98, 100, 101, 103, 107, 111, 116, 117, 118, 120, 125, 127, 129, 130, 133, 134, 136, 140, 144, 145, 146, 148, 149, 152, 155, 156, 160, 162, 164, 166, 168, 171, 173, 175, 178, 180, 181, 183, 184, 186, 188, 189, 190, 196, 198, 201, 204, 216, 219, 222, 229, 234, 236, 237, 239], "alreadi": [0, 1, 2, 4, 5, 6, 10, 11, 20, 21, 81, 91, 94, 98, 100, 107, 113, 126, 133, 138, 146, 148, 156, 157, 158, 163, 169, 173, 174, 186, 189, 193, 203, 205, 208, 211, 216, 219, 221, 224, 227, 228, 229, 230, 234, 235, 236, 237, 241], "exist": [0, 2, 4, 6, 8, 10, 11, 20, 21, 22, 45, 51, 52, 67, 78, 83, 86, 98, 103, 110, 122, 135, 136, 141, 155, 157, 162, 163, 164, 166, 168, 171, 181, 183, 184, 185, 187, 192, 193, 201, 202, 203, 205, 213, 218, 219, 224, 234], "neural_styl": 0, "take": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 17, 18, 19, 21, 22, 30, 31, 38, 41, 42, 45, 47, 48, 49, 50, 51, 58, 59, 60, 61, 68, 75, 77, 80, 86, 91, 92, 94, 95, 97, 98, 99, 101, 103, 104, 106, 107, 109, 110, 111, 113, 116, 117, 119, 125, 126, 127, 128, 130, 133, 134, 135, 136, 138, 142, 144, 145, 148, 156, 157, 158, 159, 160, 161, 162, 164, 168, 169, 171, 172, 173, 174, 175, 179, 184, 187, 188, 190, 192, 193, 198, 201, 202, 204, 205, 208, 209, 210, 211, 216, 219, 220, 221, 222, 224, 225, 229, 233, 234, 235, 236, 237, 239, 240, 243, 245], "look": [0, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 31, 36, 38, 41, 42, 45, 47, 48, 49, 50, 51, 75, 80, 81, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 111, 113, 116, 117, 119, 124, 125, 126, 130, 135, 137, 146, 148, 149, 155, 157, 158, 161, 162, 164, 168, 169, 172, 174, 175, 178, 179, 182, 184, 187, 188, 192, 204, 208, 211, 219, 221, 224, 225, 229, 232, 233, 235, 236, 237], "essenti": [0, 6, 10, 29, 48, 100, 101, 103, 122, 135, 159, 195, 202, 209, 222, 239], "trace": [0, 5, 8, 10, 18, 19, 29, 41, 60, 80, 91, 97, 108, 109, 111, 136, 141, 143, 149, 163, 168, 182, 189, 191, 196, 202, 208, 211, 212, 213, 234, 238], "so": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 29, 40, 42, 45, 48, 50, 51, 52, 57, 58, 59, 60, 65, 68, 75, 77, 78, 80, 83, 86, 89, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 135, 136, 138, 141, 143, 144, 145, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 168, 171, 173, 174, 175, 176, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 192, 193, 195, 197, 199, 201, 202, 205, 208, 210, 211, 212, 213, 214, 215, 216, 218, 219, 222, 233, 234, 237, 238, 239, 241, 244, 245, 246], "intern": [0, 5, 8, 10, 11, 20, 35, 36, 48, 55, 60, 68, 78, 95, 110, 113, 122, 124, 126, 135, 168, 173, 183, 184, 191, 196, 200, 201, 233, 245], "dummi": [0, 1, 8, 18, 80, 86, 94, 99, 109, 133, 137, 144, 152, 154, 173, 181, 209, 239, 240], "data": [0, 2, 3, 5, 11, 12, 14, 15, 16, 18, 19, 20, 21, 29, 30, 33, 34, 38, 39, 41, 44, 45, 46, 47, 50, 57, 58, 59, 72, 73, 75, 77, 80, 81, 86, 91, 92, 94, 97, 99, 100, 101, 103, 104, 106, 110, 111, 116, 120, 121, 122, 125, 126, 131, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 152, 157, 159, 160, 161, 162, 171, 173, 174, 175, 179, 180, 181, 183, 185, 187, 188, 191, 192, 193, 198, 199, 200, 201, 204, 205, 207, 208, 209, 211, 214, 217, 218, 219, 222, 223, 226, 231, 232, 238, 239, 241, 245, 249], "gener": [0, 1, 4, 5, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 52, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 112, 114, 116, 117, 119, 120, 122, 125, 127, 129, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 155, 156, 158, 159, 160, 162, 163, 164, 165, 166, 168, 169, 171, 173, 174, 175, 178, 183, 184, 185, 186, 187, 188, 190, 196, 197, 198, 200, 201, 202, 204, 208, 209, 210, 211, 213, 214, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 243, 245, 246, 249], "graph": [0, 1, 5, 10, 18, 21, 22, 45, 48, 57, 63, 65, 68, 72, 73, 78, 80, 86, 88, 91, 100, 109, 110, 125, 127, 130, 141, 142, 143, 144, 146, 161, 162, 168, 169, 173, 176, 191, 192, 193, 194, 199, 200, 205, 207, 208, 209, 221, 232, 239, 240], "input": [0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14, 18, 19, 20, 21, 22, 29, 30, 33, 34, 38, 40, 41, 42, 43, 45, 47, 48, 55, 61, 63, 64, 65, 67, 68, 69, 72, 73, 77, 78, 80, 81, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 115, 117, 119, 121, 123, 124, 126, 128, 129, 131, 133, 134, 136, 137, 138, 140, 141, 143, 144, 145, 146, 149, 152, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 173, 175, 176, 178, 179, 180, 181, 182, 183, 187, 188, 189, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 208, 209, 211, 217, 218, 221, 222, 225, 226, 227, 237, 240, 246], "simpli": [0, 1, 3, 4, 5, 6, 8, 9, 13, 17, 19, 21, 41, 42, 48, 52, 58, 59, 60, 80, 86, 94, 103, 106, 110, 111, 113, 126, 128, 130, 134, 135, 143, 144, 148, 154, 155, 158, 159, 160, 161, 164, 166, 169, 171, 173, 174, 176, 182, 183, 185, 195, 198, 207, 208, 211, 212, 213, 216, 219, 222, 227, 228, 230, 233, 235, 236, 237, 239], "blank": [0, 245], "pixel": [0, 1, 18, 30, 39, 42, 75, 95, 98, 146, 166, 197], "size": [0, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 21, 29, 30, 34, 35, 39, 41, 42, 43, 45, 47, 48, 50, 51, 54, 58, 59, 60, 77, 83, 89, 92, 94, 95, 98, 99, 103, 104, 106, 107, 109, 111, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 135, 137, 138, 143, 144, 145, 146, 148, 149, 152, 153, 154, 156, 157, 158, 159, 160, 161, 164, 168, 171, 172, 174, 175, 178, 179, 180, 183, 184, 187, 188, 189, 191, 197, 201, 202, 204, 205, 207, 208, 210, 211, 215, 216, 218, 219, 226, 233, 234, 238, 239, 241, 243], "import": [0, 3, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 29, 40, 41, 45, 47, 48, 49, 50, 51, 52, 58, 59, 60, 72, 75, 77, 78, 84, 86, 91, 92, 94, 95, 97, 98, 101, 103, 104, 107, 110, 111, 113, 114, 116, 117, 123, 124, 129, 130, 133, 134, 135, 138, 140, 141, 142, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 195, 197, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 219, 222, 232, 233, 239, 241, 243, 245], "To": [0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 18, 21, 29, 30, 34, 35, 36, 39, 40, 45, 48, 49, 50, 56, 58, 59, 60, 61, 65, 73, 81, 86, 89, 92, 97, 99, 100, 101, 103, 104, 106, 107, 110, 111, 114, 115, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 135, 136, 138, 140, 143, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 168, 169, 172, 173, 174, 175, 179, 181, 182, 183, 184, 186, 187, 191, 192, 193, 195, 197, 199, 201, 202, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 243], "get": [0, 1, 2, 5, 6, 7, 8, 11, 14, 17, 18, 19, 20, 21, 31, 33, 35, 41, 42, 43, 48, 49, 50, 51, 54, 55, 57, 60, 61, 75, 80, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 107, 108, 110, 111, 116, 117, 118, 121, 122, 123, 126, 127, 128, 134, 135, 136, 137, 138, 141, 142, 144, 148, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 164, 168, 169, 172, 173, 174, 175, 179, 181, 184, 189, 190, 192, 193, 197, 199, 200, 201, 202, 203, 205, 207, 210, 211, 214, 216, 219, 222, 225, 234, 237, 240, 241], "good": [0, 1, 2, 4, 5, 6, 18, 19, 42, 49, 51, 59, 94, 97, 98, 106, 113, 124, 126, 135, 143, 149, 157, 158, 159, 163, 169, 173, 174, 175, 190, 214, 216, 219, 234, 245], "perform": [0, 1, 3, 4, 6, 8, 10, 11, 12, 14, 17, 18, 19, 21, 22, 29, 30, 34, 35, 39, 40, 41, 42, 43, 48, 55, 60, 61, 64, 72, 75, 86, 89, 91, 94, 95, 98, 99, 100, 101, 106, 107, 111, 113, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 135, 136, 138, 140, 141, 144, 145, 148, 149, 154, 156, 158, 159, 160, 162, 165, 166, 169, 175, 179, 181, 184, 185, 188, 189, 190, 195, 200, 203, 204, 205, 207, 208, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 231, 233, 237, 238, 239, 240], "250x540": 0, "larger": [0, 3, 8, 12, 75, 91, 107, 111, 120, 123, 124, 126, 131, 141, 148, 156, 159, 162, 164, 168, 188, 196, 204, 219, 243], "care": [0, 1, 5, 19, 61, 75, 89, 91, 113, 119, 130, 135, 148, 158, 162, 184, 192, 219, 220, 222, 233], "less": [0, 3, 5, 6, 8, 17, 55, 60, 95, 100, 107, 113, 116, 117, 120, 123, 126, 140, 158, 159, 160, 168, 169, 171, 173, 192, 219, 222], "fp": [0, 48, 122, 149], "qualiti": [0, 113, 118, 145, 164, 224], "imagemagick": 0, "creat": [0, 1, 2, 4, 5, 6, 7, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 33, 36, 38, 39, 40, 41, 42, 45, 47, 49, 50, 51, 57, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 83, 86, 91, 92, 94, 95, 97, 99, 100, 104, 106, 109, 110, 114, 116, 117, 118, 119, 120, 122, 123, 130, 133, 134, 135, 136, 138, 140, 141, 145, 146, 148, 151, 152, 153, 154, 156, 157, 158, 159, 161, 162, 164, 168, 169, 171, 172, 175, 178, 179, 181, 182, 183, 184, 187, 188, 189, 190, 192, 193, 195, 197, 199, 201, 202, 204, 210, 211, 213, 214, 218, 219, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 235, 236, 237, 238, 239, 240, 241, 245], "xc": 0, "white": [0, 12, 75, 95, 107, 113, 169, 245], "png24": 0, "jpg": [0, 12, 31, 50, 51, 58, 59, 92, 117, 138, 197, 204], "eval": [0, 12, 17, 18, 36, 40, 48, 58, 59, 60, 107, 111, 117, 123, 124, 129, 136, 138, 141, 156, 161, 164, 173, 174, 175, 178, 180, 181, 182, 189, 197, 199, 201, 204, 208, 209, 210, 211, 216, 228, 229, 230, 240], "content": [0, 2, 5, 21, 22, 49, 55, 61, 97, 98, 99, 111, 125, 133, 135, 157, 158, 162, 164, 171, 173, 174, 183, 201, 204, 210, 219, 233, 249], "output": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 29, 30, 34, 38, 40, 41, 42, 43, 45, 47, 48, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 80, 86, 89, 91, 92, 94, 95, 98, 99, 101, 103, 104, 106, 107, 108, 110, 111, 114, 116, 117, 118, 119, 120, 123, 124, 125, 127, 128, 133, 134, 135, 136, 137, 138, 140, 141, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 162, 164, 166, 169, 171, 174, 175, 176, 179, 181, 182, 189, 190, 192, 193, 197, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 216, 217, 219, 221, 222, 224, 225, 226, 232, 234, 239, 240, 241, 243, 245, 246], "out": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 18, 19, 20, 21, 22, 29, 33, 34, 38, 39, 41, 42, 43, 47, 48, 50, 51, 57, 58, 59, 60, 61, 75, 77, 78, 80, 86, 89, 91, 92, 94, 95, 98, 100, 104, 107, 108, 113, 117, 122, 124, 125, 126, 127, 130, 131, 134, 135, 137, 138, 142, 143, 144, 148, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 168, 169, 173, 174, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 198, 199, 200, 201, 204, 208, 209, 210, 217, 223, 224, 225, 231, 234, 238, 239, 245], "cuda": [0, 1, 4, 6, 8, 10, 11, 12, 16, 17, 21, 30, 40, 41, 42, 43, 47, 48, 52, 53, 54, 64, 73, 75, 89, 91, 98, 101, 107, 108, 109, 110, 111, 117, 122, 123, 124, 129, 131, 132, 133, 134, 135, 146, 148, 151, 154, 156, 159, 160, 161, 162, 163, 168, 171, 172, 175, 188, 218, 219, 220, 225, 227, 234, 238, 241], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 54, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 86, 87, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 244, 245], "export_onnx": 0, "end": [0, 4, 5, 6, 7, 8, 17, 20, 21, 22, 29, 41, 48, 51, 53, 58, 59, 60, 77, 86, 91, 92, 94, 95, 98, 104, 107, 110, 113, 116, 118, 122, 123, 126, 127, 128, 129, 134, 135, 136, 143, 145, 153, 156, 157, 159, 160, 162, 164, 166, 168, 169, 172, 173, 180, 181, 184, 193, 201, 204, 208, 209, 210, 216, 218, 219, 222, 225, 234, 241, 245], "up": [0, 1, 3, 4, 5, 6, 7, 8, 10, 16, 17, 19, 20, 29, 31, 34, 40, 48, 51, 54, 61, 71, 74, 78, 86, 90, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 113, 120, 122, 123, 124, 127, 128, 131, 132, 133, 135, 137, 142, 143, 149, 152, 153, 156, 157, 158, 159, 160, 161, 164, 168, 169, 171, 172, 173, 174, 179, 181, 182, 192, 193, 196, 197, 200, 203, 204, 205, 208, 211, 212, 213, 219, 225, 228, 234, 237, 238, 241, 245], "correspond": [0, 1, 2, 3, 5, 6, 8, 10, 12, 30, 31, 35, 41, 48, 54, 60, 77, 91, 92, 95, 97, 101, 104, 108, 111, 116, 119, 125, 126, 133, 143, 153, 155, 158, 161, 164, 166, 168, 169, 171, 172, 175, 181, 182, 187, 193, 202, 209, 217, 225, 230, 234, 238], "come": [0, 1, 5, 6, 10, 17, 18, 20, 21, 39, 50, 51, 60, 75, 86, 89, 91, 95, 98, 100, 111, 124, 126, 135, 143, 151, 154, 158, 163, 171, 172, 179, 181, 209, 219, 224, 241, 244], "abov": [0, 1, 3, 4, 5, 6, 8, 10, 11, 14, 17, 18, 20, 21, 41, 42, 48, 50, 51, 58, 59, 61, 65, 67, 68, 75, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 109, 110, 113, 116, 118, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 138, 140, 143, 144, 145, 146, 148, 149, 151, 152, 155, 156, 158, 160, 161, 162, 163, 168, 171, 172, 173, 174, 175, 176, 182, 183, 184, 185, 186, 187, 190, 192, 193, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 222, 225, 232, 239, 244, 245], "ad": [0, 2, 5, 6, 10, 16, 20, 21, 22, 29, 48, 49, 52, 58, 59, 60, 75, 86, 91, 94, 95, 97, 98, 99, 101, 103, 109, 111, 113, 115, 123, 124, 128, 133, 138, 140, 144, 149, 154, 159, 164, 174, 175, 182, 183, 202, 204, 208, 209, 211, 212, 213, 222, 233, 236, 239], "our": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 38, 39, 41, 42, 43, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 61, 64, 65, 67, 68, 69, 77, 80, 81, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 108, 110, 116, 117, 119, 122, 123, 124, 126, 127, 128, 130, 131, 132, 136, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 158, 159, 160, 161, 163, 164, 166, 169, 171, 173, 175, 176, 179, 182, 183, 184, 185, 186, 187, 189, 190, 192, 196, 198, 201, 202, 204, 205, 210, 211, 217, 219, 222, 233, 238, 241], "path": [0, 4, 5, 6, 16, 17, 20, 21, 31, 40, 48, 49, 51, 52, 59, 60, 75, 91, 94, 98, 99, 100, 107, 111, 116, 117, 123, 124, 136, 138, 141, 143, 154, 156, 171, 173, 175, 179, 181, 183, 184, 188, 189, 190, 192, 193, 197, 199, 200, 201, 204, 210, 211, 212, 213, 214, 216, 219, 227, 229, 230, 233, 234, 235, 240], "unfortun": [0, 8, 21, 22, 110, 135], "won": [0, 3, 5, 10, 41, 107, 110, 115, 124, 130, 140, 149, 152, 158, 216, 218, 239], "mark": [0, 29, 48, 58, 59, 77, 146, 159, 160, 173, 174, 179, 180, 186, 214, 243], "while": [0, 1, 2, 3, 4, 5, 6, 9, 11, 12, 13, 17, 19, 21, 31, 34, 48, 51, 54, 60, 91, 92, 98, 108, 113, 116, 118, 120, 121, 123, 125, 126, 131, 133, 135, 136, 138, 143, 144, 146, 148, 155, 156, 157, 158, 161, 162, 163, 164, 166, 171, 173, 174, 176, 179, 181, 184, 185, 186, 187, 188, 192, 193, 201, 211, 216, 218, 219, 225, 234], "onli": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 18, 20, 21, 29, 40, 41, 42, 43, 45, 48, 52, 54, 55, 60, 61, 75, 80, 83, 89, 90, 91, 94, 95, 98, 100, 101, 106, 107, 108, 111, 113, 114, 116, 117, 118, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 161, 162, 164, 168, 169, 171, 173, 174, 175, 176, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 197, 198, 199, 201, 203, 205, 207, 210, 211, 212, 213, 214, 216, 218, 219, 225, 229, 234, 235, 236, 239, 241, 245], "when": [0, 1, 5, 6, 8, 10, 11, 12, 16, 18, 19, 20, 21, 22, 29, 31, 34, 36, 38, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 75, 77, 80, 81, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 103, 106, 107, 108, 109, 110, 111, 115, 119, 120, 122, 123, 124, 125, 126, 128, 129, 132, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 148, 149, 151, 154, 155, 156, 158, 159, 160, 162, 163, 164, 168, 171, 172, 173, 174, 175, 179, 180, 183, 184, 187, 188, 190, 192, 193, 195, 196, 199, 200, 201, 202, 203, 204, 214, 215, 218, 219, 221, 222, 224, 225, 226, 227, 228, 229, 230, 233, 234, 235, 237, 238, 241, 243, 245, 247], "applic": [0, 2, 3, 11, 12, 21, 31, 48, 58, 59, 60, 61, 77, 92, 95, 117, 121, 122, 124, 125, 126, 129, 133, 136, 138, 142, 148, 155, 156, 160, 162, 173, 186, 189, 199, 203, 209, 210, 211, 214, 234, 238], "netron": 0, "see": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 21, 22, 30, 34, 35, 38, 40, 42, 43, 45, 47, 48, 49, 50, 51, 54, 57, 58, 59, 60, 75, 77, 80, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 116, 118, 120, 123, 124, 126, 127, 128, 129, 130, 133, 135, 136, 137, 138, 140, 141, 142, 143, 145, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 181, 182, 183, 184, 186, 187, 189, 191, 192, 193, 195, 196, 198, 199, 200, 201, 204, 205, 207, 210, 212, 213, 214, 216, 217, 218, 219, 222, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 240, 245], "name": [0, 2, 4, 5, 6, 8, 10, 12, 13, 16, 17, 19, 20, 21, 29, 49, 50, 51, 59, 81, 91, 100, 106, 107, 108, 109, 111, 122, 123, 126, 133, 134, 136, 138, 141, 143, 151, 154, 155, 158, 159, 160, 161, 163, 164, 165, 168, 171, 172, 179, 181, 182, 190, 192, 196, 197, 199, 201, 202, 204, 208, 209, 210, 216, 219, 225, 232, 233, 235, 240, 245, 246], "186": 0, "numer": [0, 17, 18, 38, 48, 72, 73, 98, 100, 110, 113, 126, 179, 181, 191, 192, 194, 218, 234, 239, 246], "id": [0, 33, 90, 113, 133, 136, 138, 160, 161, 162, 172, 175, 243, 244, 248], "assign": [0, 6, 20, 39, 43, 45, 52, 92, 95, 98, 100, 101, 104, 106, 118, 135, 151, 158, 173, 214, 234, 244], "small": [0, 1, 3, 5, 6, 9, 16, 18, 19, 21, 22, 40, 41, 42, 45, 56, 57, 75, 80, 81, 83, 91, 94, 95, 97, 98, 101, 104, 110, 116, 117, 123, 124, 126, 128, 129, 142, 148, 151, 156, 157, 158, 159, 162, 164, 166, 171, 175, 184, 202, 218, 219, 221, 234], "onnx_to_coreml": 0, "touch": [0, 2, 4, 6, 20, 21, 200], "command": [0, 4, 5, 6, 21, 49, 77, 92, 97, 99, 114, 120, 122, 127, 132, 133, 134, 136, 138, 154, 158, 160, 161, 162, 164, 168, 169, 173, 175, 183, 201, 204, 207, 208, 210, 211, 225, 232, 234, 240, 245, 246], "edit": [0, 3, 6, 9, 11, 12, 14, 17, 18, 47, 49, 61, 113, 124, 133, 134, 135, 136, 142, 143, 154, 156, 157, 160, 161, 162, 179, 213, 243], "favorit": [0, 33, 40, 59, 90, 135, 142], "editor": [0, 213], "add": [0, 2, 4, 6, 8, 10, 12, 17, 19, 20, 21, 34, 42, 45, 47, 49, 58, 59, 60, 61, 75, 80, 83, 86, 89, 95, 98, 99, 101, 104, 113, 114, 116, 119, 122, 123, 124, 127, 128, 129, 135, 138, 141, 142, 143, 144, 152, 153, 154, 157, 158, 160, 161, 162, 164, 173, 174, 179, 182, 183, 184, 186, 193, 197, 199, 201, 205, 207, 210, 215, 219, 221, 225, 238, 239, 243, 245, 250], "follow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 38, 40, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 75, 77, 84, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 138, 141, 142, 143, 144, 145, 146, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 192, 193, 195, 197, 198, 199, 201, 202, 204, 205, 207, 208, 210, 211, 212, 213, 214, 215, 216, 218, 221, 224, 225, 226, 232, 239, 240, 243, 245, 246, 250], "code": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 29, 30, 31, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 173, 174, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 192, 196, 198, 200, 203, 205, 207, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 246], "sy": [0, 3, 16, 17, 52, 54, 133, 136, 154, 179, 181, 189, 192], "onnx_pb": 0, "onnx_coreml": 0, "model_in": 0, "argv": [0, 4, 20, 21, 52, 54, 208, 240], "1": [0, 1, 2, 3, 5, 6, 7, 8, 11, 12, 14, 16, 18, 19, 20, 21, 29, 30, 33, 39, 40, 41, 47, 48, 51, 52, 54, 60, 61, 64, 68, 75, 83, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 120, 123, 124, 127, 128, 129, 130, 131, 132, 133, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 155, 157, 158, 159, 160, 161, 162, 171, 172, 174, 180, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 209, 210, 214, 215, 218, 226, 232, 234, 240, 241, 242, 243, 245, 246, 249], "model_out": 0, "2": [0, 1, 2, 3, 5, 6, 7, 11, 12, 14, 16, 19, 21, 30, 33, 40, 41, 47, 48, 50, 51, 52, 54, 60, 61, 63, 64, 68, 69, 72, 75, 89, 91, 92, 94, 98, 100, 101, 103, 106, 109, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 135, 137, 138, 143, 144, 146, 148, 152, 153, 155, 157, 158, 159, 160, 161, 162, 163, 171, 172, 180, 184, 188, 191, 195, 197, 198, 199, 200, 201, 202, 203, 205, 208, 209, 210, 218, 220, 234, 240, 241, 243, 245, 246, 249], "model_fil": [0, 17, 179, 192, 197], "rb": [0, 138, 211], "model_proto": 0, "modelproto": [0, 18], "parsefromstr": 0, "read": [0, 1, 2, 5, 6, 9, 17, 20, 21, 35, 45, 48, 50, 75, 94, 103, 104, 107, 111, 113, 116, 117, 121, 123, 125, 126, 127, 128, 135, 136, 138, 141, 143, 148, 157, 158, 161, 164, 166, 169, 171, 181, 182, 183, 190, 197, 201, 210, 211, 215, 218, 219, 224, 243, 245], "coreml_model": 0, "image_input_nam": 0, "image_output_nam": 0, "save": [0, 2, 4, 6, 7, 11, 12, 17, 18, 21, 29, 30, 31, 32, 33, 34, 38, 39, 42, 47, 48, 51, 58, 59, 75, 89, 97, 99, 112, 115, 117, 118, 122, 124, 126, 127, 129, 136, 138, 143, 144, 153, 155, 156, 159, 160, 161, 162, 164, 165, 168, 179, 181, 182, 183, 189, 190, 197, 199, 201, 207, 208, 209, 210, 211, 212, 213, 216, 221, 222, 223, 225, 231, 232, 233, 234, 236, 237, 238, 239, 240], "mlmodel": [0, 182], "i": [0, 5, 6, 7, 8, 11, 16, 17, 20, 21, 29, 30, 35, 40, 41, 48, 50, 51, 57, 58, 59, 61, 75, 77, 78, 86, 89, 91, 95, 100, 101, 103, 104, 106, 107, 111, 113, 117, 118, 123, 127, 128, 132, 134, 135, 137, 141, 146, 151, 152, 153, 155, 160, 161, 162, 164, 169, 172, 173, 174, 175, 186, 187, 188, 195, 196, 201, 202, 203, 205, 209, 214, 219, 221, 222, 236, 237, 245, 246], "e": [0, 4, 5, 6, 7, 8, 10, 11, 16, 20, 21, 22, 29, 30, 35, 40, 41, 42, 48, 50, 51, 57, 58, 60, 61, 75, 77, 78, 81, 86, 89, 91, 94, 95, 98, 106, 107, 109, 111, 117, 118, 122, 124, 126, 127, 128, 130, 132, 133, 134, 135, 137, 141, 146, 151, 152, 153, 154, 155, 160, 162, 164, 168, 172, 173, 176, 179, 181, 186, 187, 188, 191, 193, 195, 198, 199, 201, 203, 205, 208, 219, 221, 225, 233, 234, 236, 237, 240], "one": [0, 1, 4, 5, 6, 7, 8, 9, 11, 12, 16, 17, 19, 20, 21, 22, 29, 31, 33, 38, 39, 43, 45, 47, 48, 50, 51, 54, 55, 57, 60, 61, 75, 78, 83, 86, 89, 91, 92, 94, 95, 98, 99, 100, 103, 104, 106, 107, 110, 111, 113, 114, 116, 117, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 148, 151, 152, 153, 155, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 172, 174, 175, 176, 180, 184, 185, 186, 188, 189, 190, 193, 198, 201, 204, 205, 212, 216, 219, 221, 222, 223, 224, 225, 229, 231, 234, 235, 237, 238, 239, 241, 245], "re": [0, 1, 4, 5, 6, 7, 9, 10, 14, 17, 19, 20, 21, 33, 35, 38, 42, 47, 48, 49, 60, 92, 94, 95, 97, 98, 99, 100, 107, 110, 117, 125, 127, 128, 137, 138, 140, 144, 149, 152, 153, 157, 158, 159, 160, 161, 164, 172, 173, 179, 182, 184, 189, 192, 195, 198, 201, 204, 211, 218, 219, 222, 233, 234, 245], "current": [0, 1, 5, 6, 8, 10, 11, 12, 17, 20, 21, 48, 51, 60, 92, 113, 117, 123, 124, 125, 126, 127, 128, 135, 140, 141, 145, 146, 148, 152, 155, 156, 158, 159, 160, 161, 162, 163, 164, 168, 176, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 192, 205, 207, 212, 216, 224, 225, 232, 234, 243], "readm": [0, 120, 176], "md": [0, 120, 176], "contain": [0, 1, 2, 4, 6, 8, 10, 12, 18, 19, 20, 21, 22, 30, 31, 35, 39, 40, 45, 48, 49, 54, 58, 60, 67, 68, 69, 77, 78, 80, 86, 91, 92, 95, 98, 99, 103, 104, 107, 110, 111, 116, 117, 122, 123, 124, 125, 126, 127, 131, 133, 134, 138, 141, 148, 151, 155, 156, 158, 159, 160, 162, 164, 166, 169, 172, 175, 176, 179, 182, 187, 190, 193, 195, 199, 201, 203, 204, 209, 210, 211, 214, 218, 221, 224, 228, 229, 233, 234, 236, 245, 246], "abl": [0, 1, 3, 4, 5, 6, 21, 29, 30, 48, 57, 60, 86, 94, 100, 106, 107, 111, 117, 126, 129, 130, 131, 132, 135, 137, 138, 143, 145, 146, 152, 156, 158, 161, 169, 171, 179, 181, 183, 186, 192, 193, 200, 201, 211, 221, 222, 237], "phone": [0, 183, 211], "onnxliv": 0, "xcodeproj": [0, 211], "project": [0, 4, 5, 6, 21, 51, 58, 59, 60, 91, 97, 111, 116, 138, 154, 159, 164, 169, 182, 183, 197, 201, 208, 209, 210, 211, 212, 213, 214, 215, 229, 238, 240, 241, 244, 249], "recommend": [0, 4, 6, 8, 10, 16, 17, 18, 21, 61, 92, 97, 107, 115, 116, 120, 122, 128, 133, 136, 156, 157, 164, 168, 171, 172, 173, 174, 175, 178, 179, 181, 186, 191, 200, 208, 214, 215, 216, 225, 229, 232, 233, 234, 240, 245], "9": [0, 3, 5, 6, 16, 17, 21, 31, 41, 48, 89, 91, 94, 103, 106, 107, 108, 111, 115, 117, 143, 151, 156, 157, 159, 160, 169, 173, 174, 175, 197, 199, 201, 208, 209, 210, 219, 221, 225, 229, 249], "x": [0, 2, 5, 6, 7, 12, 16, 17, 18, 19, 20, 21, 22, 29, 38, 41, 45, 47, 48, 51, 63, 64, 67, 68, 69, 72, 73, 75, 78, 80, 83, 86, 91, 94, 95, 98, 100, 101, 103, 107, 109, 110, 111, 113, 115, 116, 117, 118, 124, 125, 127, 128, 130, 133, 134, 135, 138, 141, 144, 148, 151, 153, 154, 156, 157, 158, 159, 160, 161, 162, 169, 171, 172, 173, 174, 175, 176, 180, 192, 198, 201, 202, 203, 204, 207, 208, 209, 211, 214, 216, 219, 229, 233, 239, 246], "might": [0, 1, 5, 8, 10, 14, 22, 29, 36, 42, 49, 50, 51, 52, 60, 81, 91, 94, 98, 100, 104, 106, 108, 130, 131, 132, 133, 135, 141, 142, 144, 148, 151, 156, 162, 163, 164, 168, 175, 179, 181, 183, 184, 197, 199, 211, 219, 220, 225, 239, 243], "issu": [0, 2, 4, 5, 6, 8, 9, 17, 18, 20, 21, 50, 58, 113, 119, 123, 132, 136, 137, 141, 142, 143, 146, 152, 157, 168, 181, 182, 183, 184, 186, 188, 190, 197, 198, 200, 204, 210, 214, 218, 220], "older": [0, 55, 108, 110, 137, 152, 159, 172], "some": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 20, 21, 22, 29, 30, 31, 34, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 57, 58, 59, 60, 61, 63, 68, 75, 78, 80, 83, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 116, 118, 122, 123, 124, 126, 128, 129, 130, 131, 133, 134, 135, 137, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 155, 156, 158, 159, 161, 162, 164, 166, 168, 169, 171, 173, 174, 175, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 192, 193, 195, 196, 198, 202, 204, 205, 208, 209, 211, 218, 219, 221, 222, 224, 225, 226, 233, 234, 235, 239, 244, 245], "replac": [0, 3, 6, 17, 41, 54, 56, 58, 59, 80, 92, 101, 107, 108, 117, 124, 135, 136, 138, 140, 141, 155, 156, 162, 164, 174, 175, 186, 189, 207, 208, 210, 219, 222, 239], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 75, 78, 80, 83, 86, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 111, 113, 114, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 171, 173, 174, 175, 176, 178, 181, 182, 183, 184, 185, 187, 188, 191, 192, 195, 197, 198, 199, 201, 203, 204, 208, 209, 211, 214, 216, 217, 219, 221, 222, 224, 227, 228, 229, 230, 232, 233, 235, 236, 237, 238, 240, 241, 245, 246], "set": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 29, 34, 36, 40, 41, 42, 45, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 63, 64, 68, 75, 78, 81, 88, 91, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 109, 110, 111, 113, 115, 116, 117, 118, 119, 122, 123, 124, 127, 128, 131, 132, 133, 135, 138, 143, 145, 148, 151, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 171, 174, 175, 178, 182, 183, 184, 186, 188, 189, 197, 199, 200, 201, 204, 208, 209, 211, 212, 213, 214, 216, 219, 220, 224, 227, 228, 229, 230, 233, 235, 237, 243, 247, 250], "tap": 0, "screen": [0, 58, 59, 145, 159, 214, 243], "switch": [0, 5, 8, 17, 97, 98, 111, 138, 189, 199, 218, 220, 237], "hope": [0, 5, 22, 48, 145, 164, 171, 246], "gave": [0, 106, 204], "framework": [0, 6, 7, 10, 22, 33, 51, 57, 60, 61, 91, 101, 110, 121, 122, 134, 148, 153, 160, 163, 173, 174, 180, 183, 200, 203, 205, 209, 210], "experi": [0, 6, 10, 100, 123, 135, 136, 145, 148, 154, 156, 158, 159, 163, 164, 166, 171, 172, 173, 174, 175, 181, 184, 191, 198, 203, 216, 218, 227, 232, 233, 235], "test": [0, 3, 8, 17, 18, 20, 21, 31, 34, 35, 40, 48, 57, 58, 59, 60, 86, 92, 94, 99, 101, 113, 114, 120, 122, 123, 124, 135, 137, 138, 140, 143, 146, 157, 161, 164, 166, 169, 171, 178, 179, 180, 191, 192, 197, 198, 204, 208, 209, 210, 211, 219, 222, 224, 240, 245, 246], "own": [0, 5, 6, 7, 8, 10, 11, 14, 16, 21, 22, 30, 31, 48, 51, 58, 59, 64, 75, 89, 91, 92, 94, 107, 108, 110, 113, 122, 123, 124, 128, 129, 133, 138, 143, 148, 151, 155, 157, 158, 161, 162, 164, 171, 173, 175, 176, 189, 190, 192, 193, 202, 205, 219, 228, 245], "pleas": [0, 2, 4, 5, 6, 7, 9, 10, 17, 18, 20, 21, 42, 43, 45, 50, 61, 77, 89, 113, 115, 118, 119, 123, 124, 133, 136, 137, 140, 141, 142, 143, 146, 148, 152, 153, 154, 156, 160, 161, 162, 168, 172, 173, 175, 176, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 197, 198, 202, 208, 209, 210, 214, 218, 220, 222, 234, 239, 245], "know": [0, 5, 6, 8, 11, 16, 17, 20, 21, 29, 41, 48, 72, 73, 75, 94, 95, 98, 101, 103, 106, 107, 110, 113, 125, 127, 128, 130, 135, 137, 143, 145, 146, 148, 149, 152, 158, 159, 160, 164, 169, 173, 174, 175, 176, 179, 185, 190, 209, 219, 243, 245], "hit": [0, 5, 9, 17, 61, 75, 113, 168], "ani": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 20, 21, 29, 39, 41, 43, 45, 48, 50, 52, 54, 57, 60, 78, 91, 94, 95, 98, 100, 103, 106, 107, 109, 111, 113, 115, 118, 121, 124, 125, 127, 130, 131, 135, 136, 137, 140, 141, 142, 145, 146, 148, 151, 152, 153, 157, 158, 159, 161, 162, 166, 168, 173, 174, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 195, 197, 200, 201, 202, 205, 207, 210, 213, 214, 216, 218, 221, 226, 227, 230, 233, 237, 239, 243, 245], "give": [0, 1, 2, 5, 6, 11, 21, 22, 34, 43, 45, 48, 49, 51, 58, 59, 60, 61, 75, 77, 81, 91, 92, 94, 95, 101, 103, 104, 106, 107, 111, 119, 128, 131, 137, 141, 142, 143, 144, 145, 152, 157, 161, 164, 168, 171, 173, 174, 179, 185, 188, 205, 211, 219, 222, 229, 240, 243, 245], "feedback": [0, 6, 9, 17, 123, 136, 141, 142, 145, 146, 173, 174, 181, 182, 183, 190, 191, 197, 210], "d": [0, 2, 5, 6, 7, 8, 17, 20, 35, 51, 61, 63, 64, 72, 78, 91, 92, 94, 95, 98, 101, 106, 107, 110, 113, 118, 123, 126, 128, 129, 133, 135, 136, 144, 145, 153, 168, 172, 181, 187, 198, 201, 208, 245, 246], "hear": [0, 141, 142], "think": [0, 6, 20, 21, 42, 51, 68, 80, 92, 94, 100, 101, 103, 104, 106, 110, 113, 142, 144, 158, 161, 187, 198, 222, 245], "click": [1, 7, 9, 12, 13, 18, 19, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 169, 171, 178, 183, 184, 185, 186, 187, 188, 190, 196, 197, 198, 201, 213, 214, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "here": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 156, 158, 159, 161, 162, 163, 164, 166, 168, 169, 171, 172, 173, 175, 176, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 192, 193, 196, 197, 198, 201, 202, 205, 207, 208, 209, 210, 211, 213, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 243, 245, 246], "download": [1, 4, 6, 7, 9, 12, 13, 17, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 58, 59, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 161, 163, 164, 166, 168, 169, 171, 175, 179, 182, 183, 184, 185, 186, 187, 188, 190, 192, 196, 197, 198, 199, 201, 208, 209, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 249], "full": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 20, 22, 29, 30, 31, 33, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 131, 134, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 166, 168, 171, 175, 178, 179, 184, 185, 186, 187, 188, 189, 190, 196, 197, 198, 201, 202, 210, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 240], "author": [1, 5, 7, 9, 11, 12, 13, 14, 17, 33, 40, 43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 75, 84, 86, 88, 90, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 116, 117, 123, 124, 126, 127, 128, 131, 132, 133, 134, 135, 136, 138, 141, 142, 143, 145, 146, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 171, 173, 174, 176, 178, 179, 180, 181, 182, 183, 192, 193, 197, 198, 199, 201, 202, 210, 218, 234, 246], "vincent": [1, 158], "moen": [1, 158], "separ": [1, 5, 6, 7, 8, 18, 20, 21, 22, 31, 48, 51, 86, 91, 97, 98, 99, 107, 108, 137, 143, 145, 151, 153, 156, 161, 164, 175, 176, 178, 179, 184, 192, 193, 205, 219, 234], "rl": [1, 61, 122, 158, 159, 160, 165], "algorithm": [1, 5, 6, 10, 11, 12, 29, 34, 39, 48, 51, 55, 57, 69, 89, 92, 94, 99, 100, 101, 103, 107, 110, 119, 123, 126, 129, 135, 145, 154, 158, 161, 166, 205, 217, 221, 228, 234], "variou": [1, 8, 38, 45, 47, 48, 49, 60, 86, 94, 97, 104, 107, 108, 111, 116, 126, 142, 144, 155, 158, 161, 162, 186, 188, 200, 222, 229, 233, 237], "piec": [1, 5, 8, 59, 86, 94, 107, 157, 158, 162, 172, 174, 175, 176, 183, 204], "assembl": [1, 8, 48, 94, 134], "collect": [1, 4, 6, 11, 16, 17, 19, 34, 40, 41, 43, 48, 54, 61, 81, 94, 98, 99, 101, 106, 122, 123, 124, 133, 134, 142, 148, 154, 159, 162, 172, 174, 214, 228, 230, 233, 234, 238], "final": [1, 6, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 39, 40, 41, 45, 48, 51, 58, 60, 75, 77, 86, 89, 91, 94, 95, 98, 99, 104, 107, 108, 111, 113, 117, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 134, 135, 138, 142, 143, 144, 145, 149, 152, 155, 156, 158, 159, 160, 161, 162, 164, 168, 169, 171, 172, 173, 174, 176, 181, 182, 183, 184, 187, 192, 193, 196, 197, 201, 204, 205, 209, 227], "function": [1, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 18, 19, 20, 21, 22, 31, 35, 36, 38, 39, 40, 41, 47, 48, 50, 52, 54, 59, 60, 61, 62, 65, 67, 68, 69, 77, 78, 81, 83, 91, 92, 94, 97, 98, 103, 106, 108, 111, 113, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 128, 134, 135, 137, 141, 142, 143, 145, 148, 151, 154, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 171, 173, 174, 175, 176, 178, 181, 182, 184, 185, 186, 187, 189, 190, 193, 195, 198, 199, 201, 204, 205, 208, 209, 211, 214, 218, 220, 221, 222, 227, 229, 233, 235, 239, 240, 241], "trainabl": [1, 6, 68, 101, 156], "paramet": [1, 4, 5, 7, 10, 11, 12, 14, 17, 18, 20, 22, 29, 31, 32, 33, 36, 38, 39, 41, 42, 45, 47, 48, 50, 51, 61, 67, 68, 75, 86, 89, 91, 94, 99, 101, 103, 106, 107, 108, 109, 110, 117, 119, 121, 122, 123, 124, 126, 127, 131, 133, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 148, 149, 151, 152, 153, 156, 159, 162, 163, 166, 168, 169, 173, 174, 175, 179, 184, 188, 191, 192, 196, 203, 205, 208, 209, 214, 216, 218, 222, 223, 224, 225, 226, 227, 228, 229, 231, 236, 237, 238, 239, 241, 249], "tutori": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 35, 41, 42, 43, 44, 50, 52, 54, 55, 57, 58, 59, 60, 61, 75, 76, 79, 81, 84, 85, 89, 92, 93, 95, 97, 99, 100, 102, 103, 107, 110, 111, 112, 113, 115, 116, 118, 119, 120, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 152, 153, 154, 157, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 172, 174, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 210, 211, 216, 217, 218, 222, 223, 225, 232, 233, 234, 238, 239, 240, 241], "guid": [1, 58, 59, 61, 86, 122, 135, 146, 157, 168, 173, 191, 204, 214, 217, 219, 223, 231, 238, 244], "ground": [1, 42, 75, 175], "aim": [1, 6, 57, 61, 77, 159, 162, 187, 209], "focus": [1, 3, 18, 92, 148, 154, 164, 209], "rel": [1, 5, 6, 7, 92, 99, 117, 118, 120, 125, 136, 144, 148, 149, 153, 162, 164, 173, 192, 209, 222, 227, 238], "straightforward": [1, 5, 6, 14, 48, 60, 91, 94, 98, 100, 143, 188, 222, 227, 238], "determinist": [1, 11, 159, 233, 234], "gradient": [1, 6, 7, 10, 11, 13, 14, 22, 34, 40, 41, 42, 45, 48, 51, 55, 61, 63, 64, 65, 68, 72, 73, 80, 91, 94, 95, 98, 99, 100, 101, 103, 107, 109, 110, 115, 117, 118, 122, 123, 124, 125, 127, 130, 131, 133, 135, 140, 144, 145, 148, 153, 155, 156, 158, 159, 160, 161, 162, 165, 169, 184, 198, 205, 217, 223, 231, 238, 241], "simpl": [1, 3, 4, 5, 6, 8, 12, 14, 17, 19, 20, 21, 22, 45, 48, 50, 53, 55, 61, 67, 75, 81, 86, 89, 92, 94, 95, 98, 99, 107, 110, 111, 116, 121, 122, 124, 125, 126, 130, 135, 137, 143, 144, 149, 152, 155, 158, 160, 161, 162, 163, 165, 166, 168, 171, 179, 181, 198, 200, 204, 208, 209, 216, 219, 222, 224, 232, 233, 236, 238, 239, 241, 245, 246], "continu": [1, 5, 18, 19, 48, 52, 60, 86, 89, 94, 98, 104, 107, 113, 122, 128, 131, 135, 141, 142, 156, 158, 162, 164, 168, 173, 182, 183, 184, 186, 187, 197, 210, 219, 221, 222, 224, 225, 229, 234, 235, 236, 237, 239, 245], "control": [1, 4, 8, 10, 19, 21, 22, 29, 31, 34, 41, 60, 61, 66, 70, 86, 91, 109, 113, 114, 123, 125, 126, 134, 135, 140, 151, 158, 159, 160, 171, 180, 192, 201, 214, 219, 239], "It": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 39, 40, 41, 42, 43, 45, 48, 50, 51, 57, 60, 61, 75, 76, 77, 78, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 106, 107, 111, 113, 115, 117, 118, 123, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 137, 139, 140, 142, 143, 144, 145, 148, 149, 151, 152, 153, 155, 156, 159, 160, 162, 164, 166, 167, 168, 170, 174, 175, 176, 188, 193, 195, 197, 198, 201, 203, 204, 205, 210, 211, 212, 213, 216, 219, 220, 224, 227, 228, 232, 234, 237, 240, 243, 245], "consist": [1, 3, 6, 7, 20, 22, 29, 30, 31, 34, 41, 77, 101, 107, 118, 119, 131, 141, 142, 145, 149, 153, 158, 163, 164, 168, 174, 176, 186, 187, 193, 201, 219, 225, 234, 245], "parametr": [1, 2, 122, 158, 165], "action": [1, 17, 58, 59, 95, 99, 103, 107, 113, 123, 124, 145, 155, 158, 159, 160, 161, 162, 168, 179, 192, 197, 201, 225, 233, 238, 245], "pair": [1, 6, 45, 48, 51, 92, 116, 118, 119, 128, 129, 136, 152, 158, 159, 164, 168, 175, 176, 189, 214, 233, 245], "maxim": [1, 51, 75, 101, 126, 145, 159, 171, 173, 189, 234], "given": [1, 6, 8, 10, 12, 18, 19, 20, 21, 22, 29, 31, 34, 38, 39, 41, 47, 48, 51, 57, 60, 61, 75, 78, 86, 92, 95, 99, 103, 106, 107, 111, 118, 123, 127, 128, 133, 135, 137, 140, 141, 144, 145, 146, 152, 155, 158, 159, 161, 162, 164, 171, 174, 175, 187, 190, 193, 205, 219, 226, 227, 234, 241], "certain": [1, 4, 5, 6, 10, 11, 48, 54, 60, 92, 103, 113, 121, 123, 125, 129, 140, 144, 146, 158, 163, 183, 184, 187, 188, 189, 217, 221], "what": [1, 2, 3, 5, 8, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 41, 43, 44, 52, 53, 54, 58, 59, 61, 75, 80, 88, 89, 92, 94, 95, 98, 99, 100, 101, 103, 104, 106, 112, 114, 122, 125, 126, 128, 131, 132, 135, 141, 145, 155, 158, 159, 160, 163, 169, 175, 182, 186, 190, 192, 193, 210, 218, 219, 220, 221, 223, 224, 231, 233, 238, 239, 245], "write": [1, 4, 8, 10, 19, 20, 21, 42, 48, 57, 58, 59, 60, 61, 64, 77, 97, 100, 101, 103, 107, 110, 112, 116, 117, 122, 125, 126, 130, 131, 133, 136, 138, 140, 141, 143, 146, 148, 149, 151, 154, 158, 161, 162, 164, 171, 181, 183, 187, 191, 192, 194, 198, 199, 201, 211, 212, 213, 218, 219, 220, 221, 226, 245], "custom": [1, 4, 6, 8, 11, 48, 51, 64, 66, 70, 81, 92, 107, 108, 112, 122, 126, 145, 158, 161, 165, 171, 174, 176, 180, 183, 192, 193, 195, 197, 208, 209, 214, 218, 223, 234, 238], "its": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 29, 30, 34, 39, 41, 45, 48, 50, 51, 52, 54, 60, 61, 68, 77, 83, 91, 92, 94, 95, 98, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 123, 124, 125, 126, 127, 128, 135, 136, 137, 138, 140, 142, 143, 145, 146, 148, 151, 155, 158, 159, 160, 161, 162, 164, 168, 169, 171, 172, 173, 183, 186, 187, 188, 192, 193, 195, 197, 199, 200, 201, 202, 207, 208, 210, 214, 216, 218, 219, 221, 225, 227, 228, 229, 230, 234, 235, 236, 237, 241, 245], "includ": [1, 2, 3, 4, 5, 6, 8, 20, 21, 22, 34, 35, 38, 40, 47, 48, 52, 54, 58, 59, 60, 61, 69, 75, 77, 86, 89, 91, 92, 94, 95, 98, 99, 100, 107, 108, 113, 115, 118, 126, 127, 128, 130, 131, 133, 135, 143, 145, 146, 154, 155, 158, 161, 164, 168, 169, 171, 172, 173, 174, 175, 179, 183, 184, 186, 189, 197, 199, 201, 203, 205, 208, 209, 210, 212, 213, 214, 216, 217, 218, 219, 221, 222, 224, 225, 234, 240, 243, 245], "design": [1, 5, 6, 22, 51, 55, 61, 75, 86, 92, 106, 107, 128, 133, 158, 159, 160, 162, 169, 174, 176, 184, 185, 186, 190, 192, 193, 198, 200, 219, 221, 222, 234], "effici": [1, 5, 7, 10, 12, 18, 21, 22, 29, 40, 48, 50, 75, 98, 103, 106, 115, 120, 122, 123, 124, 126, 127, 135, 138, 144, 149, 153, 155, 158, 162, 163, 168, 172, 174, 182, 187, 188, 189, 194, 197, 219, 224], "store": [1, 4, 5, 6, 14, 17, 20, 21, 29, 30, 31, 35, 36, 38, 41, 47, 50, 52, 60, 68, 89, 91, 97, 98, 100, 101, 103, 106, 107, 110, 125, 126, 128, 135, 143, 145, 146, 151, 154, 155, 158, 159, 160, 161, 162, 164, 179, 187, 192, 197, 205, 222, 225, 233, 234, 239], "trajectori": [1, 61, 158], "transit": [1, 60, 86, 88, 100, 159], "assum": [1, 2, 4, 6, 8, 10, 17, 19, 20, 33, 41, 42, 50, 53, 57, 60, 75, 90, 91, 94, 100, 104, 107, 116, 125, 127, 128, 135, 138, 151, 155, 158, 161, 164, 172, 175, 186, 187, 188, 211, 225, 233], "complet": [1, 4, 5, 6, 19, 22, 33, 78, 80, 86, 89, 91, 94, 100, 101, 103, 113, 117, 120, 122, 123, 126, 130, 135, 138, 155, 156, 157, 158, 159, 161, 164, 171, 174, 175, 186, 187, 213, 216, 217, 222, 234, 239, 240], "ppo": [1, 122, 165], "compon": [1, 5, 6, 8, 10, 18, 22, 51, 61, 86, 95, 103, 111, 113, 115, 118, 120, 122, 126, 141, 145, 158, 162, 166, 168, 171, 174, 188, 200, 240], "depend": [1, 5, 6, 7, 8, 11, 19, 20, 21, 40, 45, 49, 51, 60, 75, 86, 91, 92, 97, 98, 100, 104, 107, 109, 118, 119, 120, 122, 126, 129, 130, 135, 136, 140, 141, 142, 144, 145, 148, 153, 154, 157, 158, 161, 171, 175, 178, 179, 180, 183, 186, 191, 192, 197, 199, 200, 201, 204, 210, 212, 213, 219, 220, 222, 224, 226, 234, 239, 240], "tensordict": [1, 158], "nn": [1, 2, 4, 5, 6, 7, 9, 11, 12, 13, 14, 16, 17, 19, 20, 22, 34, 35, 40, 41, 42, 43, 45, 48, 54, 60, 66, 69, 70, 79, 81, 82, 89, 91, 94, 99, 101, 106, 108, 109, 112, 115, 117, 122, 123, 124, 125, 127, 128, 129, 133, 134, 136, 140, 141, 148, 149, 151, 152, 153, 156, 158, 159, 160, 161, 162, 163, 169, 171, 174, 176, 178, 179, 180, 181, 185, 189, 190, 192, 195, 202, 203, 207, 208, 209, 211, 214, 216, 218, 221, 222, 225, 226, 228, 229, 230, 234, 235, 236, 238, 239, 240, 241], "tensordictmodul": [1, 158], "although": [1, 12, 14, 41, 48, 60, 61, 100, 101, 106, 107, 115, 120, 125, 145, 148, 151, 156, 161, 173, 179, 188, 196, 234, 245], "suffici": [1, 6, 48, 51, 100, 117, 131, 133], "transpar": [1, 12, 40, 92, 101, 161, 199, 208], "understood": [1, 4, 113], "without": [1, 4, 5, 6, 8, 9, 10, 18, 21, 29, 40, 48, 52, 54, 60, 80, 95, 98, 100, 111, 113, 116, 122, 124, 125, 128, 135, 136, 140, 142, 144, 145, 146, 154, 155, 156, 157, 158, 159, 160, 163, 168, 173, 174, 184, 186, 187, 189, 193, 201, 202, 208, 215, 216, 218, 222, 226, 234, 238, 239, 241, 243, 245], "understand": [1, 2, 4, 6, 21, 41, 42, 51, 56, 58, 59, 86, 90, 91, 93, 94, 95, 97, 98, 99, 100, 103, 107, 117, 122, 125, 126, 127, 128, 130, 135, 136, 140, 143, 148, 156, 164, 173, 185, 190, 193, 201, 214, 217, 224, 232, 236], "class": [1, 2, 4, 5, 6, 8, 10, 13, 17, 19, 21, 22, 29, 31, 33, 35, 36, 40, 42, 45, 48, 51, 52, 57, 58, 59, 65, 67, 75, 77, 78, 80, 86, 91, 92, 94, 95, 97, 98, 99, 101, 106, 107, 109, 110, 111, 115, 117, 120, 122, 123, 124, 126, 127, 130, 131, 133, 134, 135, 136, 138, 141, 142, 143, 145, 146, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 169, 174, 175, 176, 179, 180, 184, 185, 186, 189, 190, 192, 193, 195, 201, 202, 203, 204, 205, 207, 209, 211, 214, 217, 219, 221, 224, 229, 233, 237, 239, 244, 245, 246], "sota": [1, 77, 113, 120], "implement": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 18, 30, 31, 33, 40, 41, 43, 45, 48, 50, 54, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 78, 81, 86, 91, 94, 99, 106, 107, 110, 115, 118, 121, 122, 125, 127, 130, 133, 134, 135, 137, 138, 140, 143, 144, 145, 146, 148, 149, 152, 153, 155, 158, 159, 162, 165, 168, 175, 176, 185, 187, 188, 189, 191, 192, 193, 197, 199, 200, 201, 205, 208, 209, 210, 212, 219, 234, 244], "rather": [1, 13, 21, 22, 48, 51, 69, 75, 86, 95, 98, 106, 107, 111, 122, 128, 129, 143, 148, 151, 152, 158, 183, 184, 200, 211, 219, 222, 229, 234], "high": [1, 2, 5, 6, 17, 21, 22, 40, 42, 48, 51, 52, 54, 56, 60, 86, 95, 101, 106, 108, 111, 122, 123, 124, 126, 129, 135, 138, 148, 165, 168, 169, 173, 174, 187, 190, 191, 192, 203, 205, 222, 224, 233, 234, 239, 240, 241, 243], "level": [1, 2, 5, 6, 17, 18, 21, 22, 42, 48, 52, 54, 56, 57, 68, 81, 95, 110, 115, 122, 123, 124, 131, 133, 135, 136, 140, 141, 143, 146, 148, 163, 164, 165, 168, 173, 174, 179, 181, 190, 191, 192, 202, 203, 205, 209, 211, 215, 222, 241, 249], "illustr": [1, 17, 30, 42, 45, 55, 116, 117, 125, 126, 137, 159, 169, 175, 186, 187, 190, 214, 217, 225, 234], "librari": [1, 3, 4, 5, 6, 8, 12, 16, 18, 20, 21, 22, 31, 35, 40, 42, 49, 50, 56, 61, 77, 89, 92, 107, 112, 113, 119, 122, 126, 129, 130, 136, 138, 142, 154, 157, 158, 162, 168, 174, 188, 189, 197, 199, 200, 208, 210, 211, 214, 215, 216, 238], "featur": [1, 4, 6, 10, 11, 12, 17, 20, 21, 31, 35, 39, 48, 49, 50, 51, 58, 59, 60, 61, 86, 91, 94, 95, 98, 100, 106, 107, 110, 113, 122, 124, 125, 136, 143, 144, 145, 148, 154, 157, 158, 162, 163, 169, 171, 172, 173, 174, 175, 181, 182, 183, 187, 188, 191, 197, 198, 199, 200, 201, 203, 205, 214, 217, 221, 222, 224, 233, 234, 237, 238, 239], "context": [1, 2, 5, 8, 14, 41, 48, 60, 61, 75, 91, 95, 106, 107, 108, 121, 134, 140, 151, 158, 161, 162, 163, 164, 168, 174, 199, 201, 203, 218, 220, 225, 226, 234], "avail": [1, 2, 3, 5, 6, 10, 12, 16, 17, 19, 20, 21, 29, 30, 31, 34, 35, 36, 38, 40, 41, 42, 47, 49, 50, 51, 52, 58, 59, 75, 83, 89, 92, 94, 95, 98, 99, 103, 107, 113, 115, 120, 123, 124, 125, 135, 138, 140, 145, 146, 155, 156, 157, 158, 159, 162, 163, 164, 168, 172, 173, 174, 175, 178, 179, 182, 183, 191, 192, 198, 203, 204, 208, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 224, 227, 228, 229, 230, 234, 235, 236, 237, 240, 243], "seri": [1, 6, 21, 51, 52, 53, 54, 55, 93, 95, 98, 99, 121, 122, 127, 128, 131, 132, 138, 142, 155, 158, 186], "reusabl": [1, 6, 22], "swappabl": 1, "signatur": [1, 5, 8, 10, 21, 135, 151, 161, 239], "characterist": [1, 41, 142, 144, 145, 157, 163, 188], "copi": [1, 5, 6, 12, 16, 20, 21, 33, 38, 42, 43, 49, 54, 58, 75, 90, 91, 99, 108, 109, 111, 114, 117, 122, 124, 125, 127, 129, 133, 135, 136, 141, 142, 145, 148, 151, 156, 161, 175, 178, 179, 180, 183, 189, 192, 197, 199, 201, 203, 204, 207, 227, 234, 246], "loss_modul": 1, "whatev": [1, 8, 20, 21, 94, 98, 99, 101, 103, 107, 111, 190, 214, 227], "convent": [1, 51, 60, 107, 111, 205, 219, 228, 229], "receiv": [1, 4, 6, 14, 54, 89, 98, 103, 110, 135, 158, 160, 161, 162, 171, 218, 221, 234], "necessari": [1, 4, 5, 6, 8, 10, 12, 16, 17, 21, 42, 51, 52, 54, 60, 86, 89, 98, 99, 100, 107, 111, 113, 123, 124, 129, 133, 138, 145, 148, 153, 160, 161, 162, 168, 174, 176, 179, 181, 186, 188, 190, 192, 218, 234], "return": [1, 2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 19, 21, 22, 30, 31, 35, 38, 43, 45, 48, 50, 51, 59, 60, 75, 83, 91, 92, 98, 99, 101, 103, 104, 107, 108, 109, 111, 113, 116, 117, 119, 123, 124, 127, 128, 130, 133, 134, 135, 136, 138, 140, 141, 143, 145, 146, 149, 151, 154, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 171, 173, 174, 175, 176, 179, 180, 181, 182, 184, 186, 189, 190, 192, 193, 198, 199, 201, 202, 203, 204, 207, 208, 209, 210, 211, 214, 217, 219, 221, 222, 224, 225, 227, 229, 233, 239, 240], "replay_buff": 1, "sampl": [1, 6, 8, 30, 31, 34, 35, 38, 42, 45, 47, 48, 50, 51, 54, 60, 61, 77, 80, 81, 89, 94, 95, 97, 98, 109, 115, 117, 119, 122, 124, 127, 129, 135, 136, 138, 144, 145, 151, 156, 158, 159, 160, 162, 165, 175, 179, 181, 188, 189, 192, 198, 202, 213, 217, 224, 225, 233, 234, 245], "loss_dict": 1, "instanc": [1, 4, 5, 6, 7, 11, 12, 19, 20, 21, 22, 30, 36, 43, 52, 53, 54, 58, 59, 60, 80, 89, 94, 95, 98, 99, 100, 101, 104, 106, 107, 110, 123, 124, 125, 126, 131, 132, 133, 134, 143, 145, 153, 156, 158, 160, 161, 162, 171, 179, 180, 192, 193, 195, 208, 214, 218, 222, 225, 227, 232, 233, 234, 239, 240, 241], "written": [1, 4, 5, 6, 8, 10, 20, 21, 22, 57, 86, 97, 107, 130, 142, 149, 151, 152, 156, 163, 184, 204, 208, 232], "under": [1, 4, 5, 8, 16, 17, 21, 29, 45, 48, 51, 53, 55, 97, 101, 108, 110, 113, 125, 135, 136, 138, 144, 145, 151, 155, 162, 168, 169, 174, 175, 176, 182, 183, 185, 187, 188, 197, 203, 205, 209, 210, 213, 214, 218, 245], "loss_": 1, "smth": 1, "where": [1, 3, 4, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 20, 21, 29, 31, 45, 48, 50, 60, 61, 64, 68, 77, 80, 81, 86, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 109, 110, 113, 122, 123, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 138, 143, 146, 148, 149, 151, 152, 157, 158, 159, 160, 161, 162, 163, 164, 169, 171, 172, 174, 175, 176, 179, 182, 184, 187, 189, 190, 193, 197, 201, 204, 205, 214, 216, 218, 219, 221, 224, 227, 228, 232, 233, 237, 238, 246], "string": [1, 8, 20, 21, 48, 58, 59, 60, 98, 115, 116, 119, 126, 127, 128, 138, 155, 158, 164, 179, 201, 202, 214, 219, 233, 243], "describ": [1, 4, 5, 6, 8, 10, 14, 17, 18, 19, 20, 21, 38, 47, 48, 51, 58, 59, 61, 75, 94, 114, 121, 135, 149, 158, 159, 162, 173, 191, 192, 195, 219, 222, 239], "addit": [1, 2, 5, 7, 8, 11, 17, 49, 60, 75, 77, 92, 98, 104, 107, 108, 113, 123, 125, 133, 135, 136, 137, 138, 141, 143, 146, 148, 155, 160, 161, 164, 169, 171, 173, 181, 184, 185, 186, 187, 199, 201, 205, 207, 208, 219, 224, 225, 228, 234], "kei": [1, 6, 8, 11, 48, 57, 58, 106, 108, 111, 114, 115, 120, 123, 126, 136, 138, 145, 157, 158, 159, 160, 163, 164, 168, 169, 172, 174, 181, 189, 190, 202, 208, 222, 232, 235, 245], "mai": [1, 4, 5, 6, 8, 10, 11, 12, 19, 20, 21, 22, 34, 40, 48, 49, 51, 58, 59, 60, 68, 75, 86, 91, 92, 94, 95, 98, 101, 110, 111, 113, 116, 124, 125, 126, 129, 130, 136, 137, 138, 140, 143, 144, 149, 151, 157, 158, 161, 164, 168, 171, 173, 174, 176, 178, 179, 181, 183, 186, 188, 192, 193, 195, 200, 201, 207, 216, 219, 222, 225, 227, 228, 230, 234, 237, 239, 245, 246], "metric": [1, 89, 97, 98, 108, 123, 136, 168, 174, 175, 209, 214, 219, 225, 232], "log": [1, 16, 34, 48, 49, 51, 52, 58, 97, 100, 101, 104, 106, 107, 118, 124, 126, 132, 136, 157, 158, 160, 162, 168, 169, 174, 181, 190, 201, 209], "dure": [1, 3, 7, 8, 12, 16, 17, 22, 29, 30, 34, 35, 48, 51, 60, 61, 63, 64, 78, 86, 91, 94, 95, 98, 99, 101, 106, 107, 110, 111, 113, 118, 119, 122, 123, 125, 128, 129, 130, 131, 133, 141, 142, 143, 148, 149, 151, 153, 156, 157, 158, 159, 160, 162, 168, 171, 173, 174, 175, 181, 191, 195, 199, 205, 208, 211, 212, 213, 214, 216, 222, 225, 229, 232, 239], "reason": [1, 5, 6, 8, 21, 22, 29, 51, 80, 91, 94, 101, 104, 107, 111, 117, 125, 129, 135, 143, 148, 156, 158, 163, 164, 186, 211, 219, 223, 229, 231, 238, 239], "independ": [1, 7, 21, 48, 60, 81, 106, 107, 109, 118, 144, 145, 149, 153, 161, 184], "user": [1, 3, 5, 16, 17, 20, 22, 39, 42, 48, 49, 60, 78, 81, 86, 92, 103, 109, 113, 114, 115, 123, 128, 133, 136, 138, 141, 143, 146, 160, 162, 163, 164, 168, 172, 173, 174, 175, 176, 179, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 197, 200, 203, 205, 208, 209, 214, 216, 225, 245, 246], "sum": [1, 2, 4, 5, 7, 11, 16, 17, 19, 30, 41, 48, 51, 60, 72, 91, 92, 100, 101, 103, 110, 117, 118, 123, 124, 127, 128, 130, 135, 144, 153, 156, 159, 160, 161, 162, 168, 171, 172, 179, 185, 192, 203, 209, 219, 237, 239, 241], "done": [1, 4, 5, 6, 8, 10, 14, 17, 18, 19, 20, 21, 22, 48, 53, 58, 59, 86, 95, 98, 100, 101, 107, 113, 115, 123, 124, 125, 128, 129, 135, 137, 142, 143, 145, 146, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 169, 175, 181, 189, 195, 201, 205, 208, 211, 222, 234, 240], "via": [1, 3, 5, 6, 7, 14, 16, 18, 20, 21, 36, 53, 54, 58, 59, 75, 86, 122, 123, 124, 126, 135, 144, 151, 153, 157, 158, 163, 165, 169, 171, 173, 174, 175, 183, 203, 204, 205, 208, 209, 214, 232, 238, 243, 249], "loss_val": 1, "item": [1, 2, 6, 10, 11, 38, 48, 68, 103, 110, 111, 114, 117, 123, 124, 127, 128, 135, 136, 138, 156, 157, 158, 159, 160, 161, 162, 169, 175, 176, 202, 204, 207, 209, 218, 224, 228, 230, 234, 244, 246], "startswith": 1, "parent": [1, 115, 141, 180, 181], "As": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 41, 48, 49, 51, 58, 59, 60, 61, 75, 86, 89, 92, 94, 95, 98, 99, 107, 110, 111, 116, 119, 123, 124, 125, 126, 127, 133, 135, 136, 140, 141, 142, 143, 144, 145, 148, 151, 153, 155, 156, 158, 159, 160, 161, 162, 163, 172, 173, 174, 176, 179, 181, 182, 183, 187, 188, 190, 192, 197, 200, 201, 203, 209, 210, 214, 219, 222, 234, 240, 241], "mani": [1, 2, 4, 5, 6, 10, 16, 21, 22, 29, 30, 34, 35, 48, 50, 51, 57, 60, 61, 65, 69, 75, 91, 92, 94, 95, 98, 101, 103, 107, 110, 113, 118, 123, 126, 127, 129, 135, 136, 137, 144, 146, 148, 149, 152, 156, 158, 160, 161, 164, 173, 174, 186, 189, 197, 198, 208, 209, 217, 218, 219, 221, 234, 239, 243, 245, 246], "expect": [1, 4, 5, 6, 10, 11, 18, 20, 21, 43, 45, 48, 50, 58, 59, 60, 61, 75, 86, 89, 91, 92, 94, 95, 98, 99, 103, 104, 106, 107, 111, 113, 117, 120, 126, 129, 133, 134, 144, 145, 151, 155, 157, 158, 159, 160, 161, 163, 173, 175, 176, 179, 182, 183, 189, 190, 192, 193, 197, 198, 204, 208, 211, 214, 217, 218, 219, 222, 225, 228, 230, 234, 241], "similar": [1, 3, 5, 8, 10, 11, 17, 20, 21, 38, 47, 48, 58, 59, 61, 92, 94, 95, 98, 100, 106, 107, 110, 116, 130, 134, 135, 138, 148, 151, 158, 160, 161, 162, 163, 164, 168, 169, 173, 175, 176, 179, 181, 184, 185, 186, 187, 188, 204, 207, 218, 219, 222, 233, 234, 241], "structur": [1, 4, 5, 6, 8, 9, 16, 17, 18, 19, 20, 21, 30, 35, 36, 38, 47, 48, 51, 52, 60, 61, 86, 91, 94, 95, 99, 100, 104, 109, 111, 131, 137, 142, 145, 146, 148, 151, 152, 155, 158, 162, 169, 171, 175, 187, 189, 192, 198, 201, 222, 229, 232, 243, 245, 249], "make": [1, 4, 5, 6, 8, 10, 12, 16, 17, 20, 21, 30, 34, 35, 39, 41, 42, 43, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 68, 75, 89, 91, 94, 95, 97, 98, 101, 102, 103, 105, 106, 107, 111, 113, 114, 115, 117, 119, 122, 123, 124, 126, 127, 128, 129, 133, 135, 136, 138, 141, 142, 143, 144, 145, 148, 151, 154, 155, 156, 158, 159, 160, 161, 162, 164, 169, 171, 173, 175, 179, 181, 183, 184, 185, 186, 187, 189, 190, 192, 193, 198, 203, 204, 205, 207, 208, 211, 215, 216, 217, 218, 219, 222, 226, 227, 232, 233, 234, 238, 239, 240, 245, 247], "possibl": [1, 2, 4, 5, 6, 8, 10, 20, 21, 51, 60, 61, 77, 91, 92, 95, 98, 100, 103, 120, 125, 129, 130, 137, 140, 142, 144, 145, 148, 156, 157, 158, 160, 161, 164, 171, 175, 179, 181, 182, 188, 192, 195, 197, 200, 205, 208, 209, 211, 218, 222, 234, 239, 245], "across": [1, 5, 7, 8, 11, 14, 16, 18, 38, 48, 51, 53, 54, 55, 61, 92, 98, 115, 121, 123, 124, 131, 132, 133, 134, 135, 137, 145, 148, 153, 155, 161, 162, 172, 173, 217, 223, 231, 232, 234, 235, 237, 238, 241, 243], "modal": [1, 60, 217], "complex": [1, 6, 21, 22, 30, 31, 49, 61, 67, 68, 91, 92, 95, 110, 111, 121, 124, 133, 149, 151, 160, 162, 169, 196, 202, 222, 226, 235], "multipl": [1, 5, 8, 10, 11, 14, 16, 17, 18, 21, 38, 43, 47, 48, 52, 53, 54, 55, 61, 65, 80, 81, 84, 89, 91, 92, 95, 98, 99, 103, 107, 109, 110, 118, 121, 124, 125, 126, 127, 128, 133, 134, 135, 137, 138, 143, 145, 148, 153, 157, 158, 160, 161, 162, 164, 168, 169, 172, 173, 174, 179, 188, 200, 204, 218, 219, 223, 225, 228, 229, 231, 233, 234, 235, 238, 245, 246], "entri": [1, 4, 11, 21, 52, 77, 103, 106, 108, 109, 111, 115, 131, 143, 155, 158, 160, 168, 186, 187, 188, 190, 203, 224, 236], "word": [1, 6, 7, 10, 11, 15, 40, 42, 48, 60, 75, 81, 92, 95, 100, 102, 104, 105, 111, 115, 116, 118, 119, 122, 127, 128, 135, 136, 151, 153, 155, 162, 164, 173, 178, 185, 187, 188, 190, 222, 224, 245], "oblivi": [1, 158], "type": [1, 4, 5, 6, 8, 10, 16, 17, 18, 19, 20, 21, 38, 40, 47, 48, 60, 75, 83, 86, 90, 92, 94, 97, 99, 103, 107, 113, 121, 123, 124, 126, 134, 136, 137, 138, 141, 143, 152, 154, 155, 158, 160, 161, 162, 168, 171, 172, 174, 176, 181, 182, 184, 189, 192, 193, 195, 197, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 214, 216, 217, 232, 234, 235, 245], "being": [1, 3, 4, 5, 6, 10, 12, 18, 19, 21, 40, 45, 48, 51, 58, 59, 60, 78, 92, 99, 100, 101, 103, 107, 109, 113, 117, 118, 123, 126, 129, 135, 141, 151, 155, 158, 159, 161, 174, 175, 181, 183, 185, 186, 188, 190, 195, 208, 219, 224, 234], "run": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 29, 30, 31, 34, 35, 36, 38, 39, 40, 41, 42, 45, 47, 50, 51, 55, 56, 61, 63, 64, 65, 67, 68, 69, 72, 73, 77, 78, 80, 81, 83, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 122, 123, 124, 125, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 169, 171, 172, 173, 174, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 205, 207, 208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 233, 234, 235, 236, 237, 238, 239, 245], "elementari": [1, 2], "those": [1, 4, 5, 6, 10, 11, 29, 40, 41, 61, 81, 89, 91, 98, 100, 106, 107, 113, 115, 116, 125, 127, 135, 137, 142, 154, 155, 162, 164, 169, 174, 179, 183, 185, 195, 197, 198, 199, 200, 209, 211, 214, 218, 219, 233, 245], "keep": [1, 6, 10, 11, 21, 29, 38, 41, 48, 51, 61, 75, 86, 94, 95, 98, 101, 103, 104, 107, 110, 111, 116, 120, 122, 123, 124, 125, 127, 128, 132, 133, 138, 141, 143, 149, 156, 162, 164, 174, 178, 179, 192, 201, 207, 219, 234, 241], "didact": [1, 135], "displai": [1, 2, 5, 6, 12, 31, 42, 58, 77, 92, 97, 99, 108, 117, 129, 138, 156, 159, 164, 168, 203, 218, 219, 232, 243], "each": [1, 2, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 19, 21, 22, 29, 30, 31, 33, 34, 35, 38, 41, 42, 43, 47, 48, 50, 51, 52, 54, 55, 58, 59, 60, 61, 65, 75, 77, 78, 81, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 108, 110, 111, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 140, 141, 142, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 172, 173, 174, 175, 181, 184, 187, 188, 190, 192, 193, 201, 202, 203, 205, 208, 209, 214, 217, 218, 219, 221, 222, 224, 225, 226, 230, 232, 233, 234, 236, 237, 239, 241, 243, 245], "popul": [1, 20, 29, 41, 48, 58, 59, 89, 98, 123, 145, 158, 160, 205, 233], "later": [1, 3, 4, 5, 6, 11, 21, 29, 38, 45, 48, 60, 75, 89, 92, 95, 103, 104, 107, 111, 113, 118, 124, 127, 128, 130, 134, 135, 137, 140, 141, 142, 143, 144, 145, 149, 152, 158, 159, 162, 163, 164, 169, 179, 184, 192, 211, 214, 216, 218, 219, 220, 229, 234], "stage": [1, 7, 14, 95, 107, 153, 183, 199, 203], "start": [1, 4, 5, 6, 9, 11, 14, 16, 17, 21, 22, 29, 33, 41, 42, 48, 49, 51, 52, 53, 54, 57, 59, 60, 61, 75, 89, 90, 91, 92, 95, 98, 99, 103, 107, 113, 116, 121, 122, 123, 125, 126, 127, 128, 129, 134, 135, 136, 138, 143, 144, 145, 148, 151, 153, 156, 157, 159, 160, 161, 164, 168, 169, 171, 173, 174, 175, 179, 181, 182, 186, 190, 192, 193, 201, 203, 204, 205, 211, 214, 219, 222, 223, 225, 231, 232, 234, 237, 238, 241, 246], "solv": [1, 6, 48, 50, 106, 117, 119, 148, 151, 156, 158, 160, 162, 173, 186, 219, 234], "task": [1, 6, 7, 13, 19, 34, 35, 48, 58, 59, 60, 77, 99, 100, 106, 108, 113, 116, 117, 118, 119, 120, 121, 122, 124, 136, 151, 153, 156, 158, 159, 164, 166, 181, 197, 201, 219, 225, 233, 234], "strategi": [1, 5, 16, 51, 113, 122, 128, 135, 143, 144, 148, 152, 160, 161, 200, 205, 209], "predict": [1, 9, 17, 18, 30, 33, 34, 35, 36, 41, 42, 48, 51, 60, 63, 64, 67, 68, 69, 72, 73, 91, 92, 94, 95, 99, 100, 104, 106, 107, 110, 113, 116, 118, 119, 122, 126, 127, 128, 136, 137, 144, 145, 148, 159, 164, 169, 175, 178, 179, 192, 204, 217, 221, 238, 240], "henc": [1, 38, 41, 47, 61, 80, 83, 113, 124, 125, 133, 134, 146, 148, 149, 154, 158, 160, 162, 173, 208, 216, 219], "two": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 19, 21, 22, 29, 31, 34, 35, 38, 39, 40, 41, 47, 48, 49, 51, 56, 58, 59, 60, 75, 77, 86, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 110, 117, 118, 120, 123, 124, 126, 127, 129, 130, 132, 133, 134, 135, 138, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 162, 164, 172, 173, 174, 175, 176, 180, 185, 187, 188, 190, 192, 193, 195, 196, 200, 203, 205, 209, 212, 213, 214, 219, 221, 222, 225, 229, 230, 233, 234, 235, 238, 239, 240, 241, 245, 246, 250], "constructor": [1, 6, 10, 11, 12, 19, 20, 21, 22, 60, 67, 69, 80, 86, 95, 99, 110, 116, 123, 124, 133, 134, 154, 155, 158, 160, 162, 187, 195, 218, 219, 239], "both": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 31, 40, 48, 50, 51, 58, 59, 61, 75, 86, 92, 98, 99, 106, 107, 108, 110, 113, 116, 119, 123, 126, 127, 129, 132, 133, 134, 135, 140, 141, 143, 144, 146, 148, 149, 155, 156, 158, 160, 161, 162, 163, 164, 172, 173, 174, 175, 176, 179, 181, 184, 187, 189, 190, 192, 193, 202, 203, 208, 209, 211, 214, 216, 217, 218, 219, 229, 233, 240, 243, 245], "compat": [1, 4, 5, 6, 8, 11, 49, 60, 97, 98, 103, 146, 179, 182, 195, 197, 205, 210, 240], "comput": [1, 3, 5, 6, 8, 11, 12, 13, 14, 17, 18, 19, 21, 22, 34, 38, 42, 45, 47, 48, 50, 51, 52, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 72, 73, 75, 77, 78, 80, 81, 86, 91, 92, 94, 95, 98, 99, 100, 101, 107, 109, 110, 115, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 136, 138, 140, 141, 143, 145, 148, 151, 152, 155, 157, 158, 159, 161, 163, 164, 168, 171, 173, 174, 175, 179, 182, 183, 188, 189, 190, 191, 192, 195, 198, 199, 200, 201, 205, 211, 216, 218, 219, 221, 222, 226, 233, 240, 245], "fit": [1, 6, 10, 11, 18, 61, 89, 106, 110, 118, 123, 124, 133, 148, 162, 218, 245], "crucial": [1, 2, 12, 21, 103, 158, 211], "convert_to_funct": 1, "extract": [1, 5, 18, 48, 51, 58, 59, 75, 97, 116, 117, 122, 127, 128, 136, 140, 143, 152, 156, 158, 164, 171, 175, 188, 201, 203, 204, 205, 221], "convert": [1, 5, 9, 10, 12, 17, 18, 20, 21, 30, 31, 38, 39, 42, 48, 50, 51, 54, 77, 94, 95, 98, 107, 109, 111, 113, 115, 116, 119, 120, 122, 127, 128, 136, 138, 156, 157, 158, 159, 160, 161, 169, 174, 175, 178, 180, 181, 183, 184, 185, 187, 188, 191, 193, 202, 204, 205, 207, 208, 211, 212, 213, 215, 216, 217, 222, 224, 227, 234, 238, 239], "strictli": [1, 98, 158], "speak": [1, 8, 41, 98, 125, 135, 148, 234], "perfectli": 1, "encourag": [1, 6, 17, 95, 138, 159, 164], "usag": [1, 3, 4, 11, 13, 19, 21, 60, 91, 108, 116, 122, 124, 125, 135, 143, 144, 158, 160, 162, 163, 168, 174, 181, 183, 188, 189, 190, 200, 208, 214, 218, 232, 234, 238, 240, 245], "doe": [1, 2, 5, 6, 8, 13, 17, 20, 21, 22, 29, 39, 41, 45, 60, 61, 72, 73, 75, 81, 83, 86, 91, 92, 94, 95, 97, 98, 99, 101, 103, 106, 107, 110, 111, 113, 117, 118, 123, 124, 130, 133, 134, 135, 138, 141, 144, 145, 146, 148, 151, 157, 158, 159, 161, 162, 163, 164, 168, 169, 171, 173, 175, 179, 180, 185, 186, 187, 192, 195, 198, 201, 205, 211, 213, 214, 216, 218, 219, 222, 227, 229, 233, 234, 245], "often": [1, 4, 5, 6, 10, 38, 48, 75, 89, 91, 92, 94, 98, 101, 103, 106, 107, 110, 111, 113, 125, 126, 128, 145, 151, 174, 188, 196, 205, 218, 233, 234, 245], "same": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 29, 30, 36, 38, 41, 42, 48, 50, 51, 52, 54, 58, 59, 60, 65, 73, 75, 80, 83, 86, 89, 91, 98, 99, 101, 103, 104, 106, 107, 108, 110, 111, 118, 119, 120, 123, 124, 125, 127, 129, 132, 133, 135, 136, 137, 138, 140, 143, 144, 145, 146, 148, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 173, 174, 176, 178, 179, 181, 184, 185, 186, 187, 188, 189, 193, 201, 204, 207, 210, 211, 216, 218, 219, 222, 225, 229, 234, 237, 239, 240, 241, 243, 245], "usual": [1, 5, 6, 8, 17, 21, 41, 57, 58, 59, 60, 61, 92, 94, 95, 97, 98, 101, 104, 106, 107, 113, 117, 125, 128, 129, 130, 133, 135, 143, 146, 155, 156, 158, 190, 198, 218, 225, 234, 243], "former": [1, 5, 61, 81, 127, 128, 164], "lag": [1, 158], "absolut": [1, 6, 7, 10, 101, 118, 153, 155, 159, 201, 233], "dilut": 1, "averag": [1, 3, 17, 48, 51, 61, 89, 92, 94, 99, 107, 113, 115, 124, 127, 128, 135, 136, 152, 159, 162, 164, 168, 173, 174, 175, 179, 192, 219, 234], "associ": [1, 5, 6, 8, 10, 30, 31, 49, 92, 130, 140, 141, 155, 163, 185, 195, 221, 234], "One": [1, 2, 4, 5, 6, 7, 10, 11, 19, 21, 48, 50, 60, 61, 75, 81, 91, 95, 98, 100, 101, 103, 123, 125, 128, 133, 135, 136, 137, 141, 148, 151, 166, 169, 171, 174, 175, 186, 190, 193, 198, 209, 211, 219, 226, 233, 234, 245, 246], "advantag": [1, 3, 6, 21, 48, 60, 86, 98, 100, 107, 121, 123, 125, 135, 151, 158, 171, 174, 179, 181, 187, 202, 208, 210, 214, 222, 234], "match": [1, 4, 5, 10, 17, 18, 20, 58, 59, 60, 61, 68, 77, 78, 94, 98, 107, 110, 111, 113, 134, 136, 137, 141, 143, 146, 148, 152, 158, 161, 171, 179, 181, 185, 187, 190, 192, 193, 208, 218, 221, 226, 235], "exactli": [1, 5, 7, 8, 10, 12, 22, 29, 41, 50, 51, 60, 80, 83, 94, 103, 106, 107, 110, 143, 151, 153, 181], "configur": [1, 4, 5, 6, 16, 17, 18, 20, 21, 40, 48, 49, 60, 61, 92, 99, 113, 123, 131, 133, 141, 143, 148, 156, 158, 161, 168, 173, 180, 201, 203, 208, 209, 213, 249], "pessimist": [1, 158], "bound": [1, 21, 48, 111, 126, 143, 158, 159, 168, 173, 175, 218, 219, 225, 229, 234], "pai": [1, 10, 43, 48, 60, 115], "attent": [1, 7, 10, 40, 43, 48, 95, 115, 118, 119, 120, 122, 127, 153, 165, 166, 181, 188, 239], "create_target_param": 1, "keyword": [1, 5, 155, 158], "argument": [1, 2, 4, 5, 6, 8, 19, 20, 21, 29, 35, 38, 41, 42, 47, 50, 54, 60, 69, 78, 91, 92, 95, 97, 98, 101, 104, 106, 108, 110, 111, 115, 123, 124, 127, 128, 132, 133, 135, 137, 143, 144, 152, 154, 155, 158, 160, 161, 162, 163, 168, 171, 176, 183, 186, 189, 198, 199, 201, 202, 203, 210, 211, 218, 219, 225, 227, 232, 234, 235, 245, 246], "below": [1, 2, 4, 6, 10, 11, 12, 14, 16, 17, 18, 21, 31, 38, 41, 43, 47, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 81, 86, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 113, 114, 116, 118, 119, 120, 126, 129, 131, 132, 133, 134, 135, 136, 140, 143, 146, 148, 154, 156, 158, 159, 160, 161, 162, 163, 168, 169, 171, 172, 173, 174, 175, 181, 183, 185, 186, 187, 190, 195, 196, 197, 203, 204, 205, 207, 209, 210, 211, 213, 214, 216, 218, 219, 222, 225, 234, 239, 241, 245], "tell": [1, 16, 21, 40, 69, 89, 91, 94, 95, 99, 106, 107, 110, 126, 127, 137, 140, 159, 160, 162, 164, 172, 182, 183, 202, 219, 225, 245], "fals": [1, 2, 6, 10, 11, 17, 18, 21, 40, 41, 54, 59, 63, 64, 91, 103, 109, 110, 111, 115, 117, 123, 124, 129, 134, 136, 140, 143, 146, 151, 156, 157, 159, 160, 161, 169, 173, 174, 175, 176, 179, 181, 185, 186, 188, 189, 192, 193, 199, 201, 207, 208, 209, 211, 216, 218, 234, 235, 239, 241, 243, 244, 245, 246], "target_actor_network_param": 1, "attribut": [1, 6, 11, 20, 22, 29, 41, 45, 52, 60, 78, 81, 86, 95, 106, 107, 116, 125, 134, 140, 146, 151, 155, 173, 179, 181, 188, 189, 191, 196, 200, 218, 237, 238, 245], "access": [1, 5, 6, 7, 10, 17, 21, 30, 31, 49, 60, 68, 75, 80, 81, 89, 91, 94, 95, 98, 99, 104, 107, 110, 111, 118, 119, 120, 122, 123, 125, 131, 135, 141, 151, 153, 157, 159, 161, 174, 181, 182, 184, 185, 187, 189, 201, 202, 207, 228, 230, 233, 237, 239, 243], "detach": [1, 2, 6, 11, 29, 91, 98, 103, 136, 149, 152, 181], "q": [1, 7, 41, 48, 60, 118, 122, 145, 153], "base": [1, 5, 6, 7, 9, 10, 11, 14, 16, 21, 22, 31, 40, 42, 48, 56, 58, 59, 60, 75, 77, 78, 80, 86, 89, 91, 92, 95, 99, 101, 108, 111, 112, 115, 116, 118, 120, 121, 122, 123, 124, 126, 127, 136, 145, 153, 154, 155, 159, 161, 164, 169, 174, 175, 178, 179, 181, 186, 190, 191, 192, 193, 203, 211, 213, 218, 222, 228, 233, 234, 238, 245], "empir": [1, 149, 158], "bootstrap": 1, "td": 1, "varianc": [1, 6, 17, 97, 158], "bia": [1, 2, 5, 6, 17, 41, 45, 68, 101, 107, 110, 111, 124, 129, 134, 141, 144, 155, 158, 162, 176, 181, 193, 207, 211], "mean": [1, 2, 5, 6, 7, 10, 12, 17, 21, 22, 34, 40, 45, 48, 50, 51, 58, 59, 60, 68, 75, 83, 86, 91, 94, 95, 98, 100, 101, 103, 106, 108, 110, 111, 115, 116, 117, 118, 123, 126, 127, 129, 135, 136, 138, 146, 148, 151, 153, 156, 157, 158, 159, 161, 162, 164, 168, 169, 175, 179, 181, 182, 184, 186, 188, 192, 193, 197, 198, 199, 200, 216, 219, 222, 225, 229, 233, 234, 239], "obtain": [1, 9, 29, 34, 48, 60, 68, 89, 107, 110, 126, 129, 135, 136, 141, 144, 152, 158, 159, 161, 175, 225], "reward": [1, 4, 145, 158, 159, 160, 162], "noth": [1, 21, 40, 75, 94, 107, 113, 130, 148, 162, 176, 240], "els": [1, 4, 5, 8, 11, 16, 17, 21, 22, 40, 45, 48, 58, 59, 89, 91, 106, 109, 117, 123, 134, 135, 136, 141, 154, 156, 159, 160, 161, 162, 169, 171, 175, 179, 181, 192, 201, 202, 203, 205, 207, 210, 218, 239, 240, 241, 245, 246], "mont": 1, "carlo": 1, "whole": [1, 3, 22, 42, 45, 60, 95, 107, 111, 113, 135, 155, 156, 158, 164, 179, 180, 181, 185, 193, 198, 201, 222], "sequenc": [1, 5, 6, 12, 19, 21, 38, 47, 48, 60, 67, 68, 95, 100, 102, 105, 106, 110, 111, 113, 115, 116, 119, 122, 127, 136, 151, 158, 163, 165, 172, 179, 181, 188, 190, 198, 207, 211, 218, 222, 225, 230, 234, 239, 245], "upcom": 1, "intermedi": [1, 22, 76, 91, 95, 98, 111, 122, 131, 134, 140, 143, 144, 145, 148, 165, 219, 226, 240], "lambda": [1, 5, 20, 107, 157, 159, 160, 198, 218, 219, 245], "compromis": 1, "easi": [1, 2, 5, 6, 9, 21, 31, 42, 43, 50, 58, 59, 60, 61, 68, 83, 91, 92, 98, 101, 123, 126, 135, 141, 144, 149, 151, 158, 168, 173, 180, 190, 198, 202, 208, 219, 233], "valueestim": 1, "enum": 1, "pointer": [1, 5, 6, 20, 21, 161], "defin": [1, 2, 5, 12, 14, 16, 18, 19, 21, 22, 29, 34, 35, 36, 39, 41, 43, 51, 58, 59, 62, 65, 67, 68, 69, 75, 80, 81, 86, 89, 91, 95, 97, 99, 100, 101, 106, 107, 111, 113, 116, 119, 122, 123, 124, 125, 127, 131, 135, 137, 138, 141, 142, 145, 149, 152, 159, 160, 161, 163, 166, 168, 169, 171, 180, 182, 184, 190, 193, 201, 202, 205, 208, 209, 216, 222, 223, 224, 225, 231, 238, 241, 243], "default": [1, 3, 5, 6, 8, 9, 10, 11, 17, 18, 19, 29, 34, 38, 41, 43, 48, 50, 51, 54, 60, 63, 64, 77, 78, 80, 94, 95, 97, 98, 101, 103, 110, 115, 116, 117, 119, 120, 122, 123, 124, 134, 135, 137, 140, 141, 143, 146, 148, 154, 156, 157, 160, 161, 162, 168, 169, 171, 174, 175, 176, 178, 179, 183, 187, 189, 190, 192, 195, 199, 200, 201, 204, 205, 208, 211, 214, 216, 219, 222, 223, 224, 225, 231, 232, 234, 237, 239, 241, 243, 244, 245], "simplest": [1, 6, 21, 29, 45, 91, 98, 101, 158, 164, 204, 234], "chang": [1, 2, 5, 6, 10, 11, 12, 17, 19, 20, 21, 29, 38, 41, 47, 49, 50, 51, 52, 54, 57, 58, 59, 61, 78, 80, 81, 83, 86, 89, 90, 91, 92, 94, 99, 100, 103, 104, 111, 116, 122, 124, 126, 131, 132, 135, 136, 138, 140, 143, 144, 145, 148, 151, 154, 155, 156, 158, 160, 168, 171, 174, 178, 179, 182, 183, 186, 188, 192, 197, 199, 200, 201, 203, 205, 208, 209, 210, 218, 219, 222, 223, 227, 231, 232, 234, 235, 239, 243], "instruct": [1, 6, 7, 17, 21, 33, 40, 90, 92, 97, 99, 113, 115, 116, 118, 119, 127, 128, 136, 140, 153, 155, 156, 158, 160, 162, 164, 173, 174, 179, 189, 192, 199, 200, 201, 204, 208, 214, 217, 222, 234, 238, 240], "queri": [1, 20, 48, 60, 94, 98, 111, 119, 161, 163, 175, 181, 192, 228, 230], "make_value_estim": 1, "central": [1, 8, 75, 91, 98, 99, 104, 106, 131, 237], "quit": [1, 6, 21, 48, 60, 75, 125, 135, 138, 148, 158, 162, 184, 201, 219, 233], "weight": [1, 2, 3, 4, 5, 6, 9, 12, 13, 17, 18, 29, 30, 41, 42, 48, 57, 60, 63, 64, 66, 68, 69, 70, 72, 73, 75, 80, 91, 94, 95, 98, 99, 101, 104, 107, 109, 111, 117, 122, 124, 129, 131, 134, 136, 137, 138, 141, 143, 144, 146, 151, 152, 155, 156, 158, 159, 162, 164, 168, 174, 175, 176, 178, 179, 180, 181, 183, 188, 193, 195, 198, 205, 209, 211, 216, 221, 222, 236, 237, 240, 245], "must": [1, 2, 4, 5, 6, 8, 10, 11, 12, 20, 21, 30, 31, 40, 48, 51, 60, 61, 75, 86, 91, 92, 98, 100, 106, 111, 113, 123, 133, 135, 137, 140, 156, 158, 161, 168, 171, 176, 184, 185, 187, 188, 189, 193, 195, 198, 203, 215, 224, 226, 227, 228, 229, 230, 245, 246], "sure": [1, 4, 5, 6, 8, 10, 11, 17, 20, 36, 50, 56, 58, 59, 60, 89, 94, 97, 100, 106, 111, 113, 115, 119, 124, 133, 135, 136, 138, 142, 148, 156, 158, 160, 181, 183, 185, 187, 189, 198, 203, 204, 208, 217, 218, 227, 232, 234], "otherwis": [1, 8, 10, 17, 21, 30, 54, 86, 98, 107, 111, 113, 124, 125, 130, 133, 143, 144, 146, 158, 159, 161, 198, 199, 203, 233], "mix": [1, 8, 60, 61, 108, 113, 146, 179, 208, 209, 223, 231, 238, 239], "hold_out_param": 1, "reli": [1, 3, 6, 8, 21, 36, 48, 91, 106, 118, 125, 145, 155, 158, 186, 197, 200, 203, 234], "miss": [1, 50, 111, 113, 133, 168, 171, 174, 185, 197, 210, 218, 233, 235, 245], "glue": [1, 136, 162], "cost": [1, 5, 48, 101, 108, 123, 124, 125, 149, 168, 189, 211, 220, 234], "deliv": [1, 40, 174, 200, 208], "most": [1, 2, 4, 5, 11, 20, 21, 22, 29, 33, 40, 41, 48, 50, 51, 58, 59, 60, 75, 77, 89, 91, 92, 94, 95, 98, 101, 103, 104, 107, 108, 110, 111, 117, 121, 124, 125, 126, 128, 129, 130, 135, 136, 141, 142, 143, 145, 146, 156, 157, 158, 160, 161, 162, 163, 164, 168, 171, 172, 173, 174, 175, 179, 186, 187, 189, 190, 192, 201, 204, 208, 209, 211, 217, 225, 229, 233, 234], "first": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 33, 36, 39, 40, 42, 43, 48, 49, 50, 51, 52, 58, 59, 60, 61, 68, 69, 75, 78, 80, 81, 83, 86, 89, 90, 91, 94, 95, 98, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 116, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 148, 149, 152, 154, 155, 156, 158, 159, 160, 161, 162, 164, 168, 171, 172, 175, 176, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 192, 196, 198, 201, 203, 204, 205, 207, 209, 210, 211, 213, 218, 219, 221, 222, 225, 227, 228, 229, 230, 234, 245, 246], "taken": [1, 6, 8, 17, 20, 22, 60, 95, 113, 120, 138, 158, 159, 181, 222, 226, 245], "condit": [1, 48, 54, 98, 104, 113, 124, 135, 136, 151, 171, 195, 205, 245], "remaind": [1, 94, 134, 140], "cheetah": 1, "goal": [1, 6, 42, 48, 51, 58, 61, 75, 86, 125, 126, 135, 142, 158, 160, 162, 173, 184, 209], "half": [1, 7, 8, 98, 117, 118, 153, 173, 174, 218, 241, 245], "dm_control": 1, "gym": [1, 122, 145, 158, 159, 160, 162], "env": [1, 16, 132, 135, 158, 159, 160, 162, 182, 189, 199, 201, 219, 233], "gymenv": [1, 158], "halfcheetah": 1, "v4": 1, "dmcontrolenv": 1, "By": [1, 8, 17, 22, 29, 38, 41, 60, 63, 64, 78, 89, 91, 98, 103, 106, 107, 110, 113, 123, 126, 135, 137, 140, 142, 143, 155, 159, 168, 173, 174, 185, 187, 188, 189, 199, 204, 214, 221, 225, 234, 239, 243], "disabl": [1, 11, 40, 123, 124, 145, 149, 157, 161, 163, 168, 184, 185, 186, 187, 197, 199, 218, 239, 243, 244], "render": [1, 6, 58, 92, 97, 145, 158, 243], "easier": [1, 16, 21, 49, 50, 58, 100, 107, 124, 126, 143, 160, 164, 169, 173, 184, 187, 189, 193, 198, 205, 219, 233], "than": [1, 3, 5, 6, 8, 10, 11, 12, 13, 17, 21, 22, 38, 42, 47, 48, 49, 51, 52, 60, 67, 69, 75, 86, 91, 94, 95, 98, 100, 101, 103, 106, 107, 110, 111, 113, 116, 117, 122, 123, 124, 126, 128, 129, 132, 133, 135, 137, 143, 144, 145, 148, 149, 151, 152, 157, 158, 159, 160, 168, 169, 174, 175, 179, 183, 184, 188, 189, 190, 192, 196, 197, 199, 200, 202, 211, 216, 219, 222, 228, 234, 235, 238, 244, 245], "focu": [1, 6, 7, 10, 16, 57, 58, 59, 92, 101, 123, 125, 136, 138, 153, 158, 160, 162, 164, 174, 185, 209, 222], "pass": [1, 2, 3, 4, 6, 8, 10, 12, 13, 14, 17, 20, 21, 22, 29, 30, 31, 34, 35, 36, 41, 42, 48, 50, 51, 52, 55, 60, 61, 63, 64, 65, 72, 73, 77, 78, 86, 89, 91, 92, 94, 95, 98, 99, 101, 103, 104, 107, 110, 111, 113, 115, 116, 118, 119, 122, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 137, 140, 142, 145, 146, 149, 151, 152, 153, 155, 158, 159, 160, 161, 162, 164, 168, 171, 176, 180, 181, 182, 184, 187, 189, 190, 193, 195, 203, 204, 205, 210, 218, 219, 224, 225, 226, 227, 229, 234, 237, 239, 241], "from_pixel": 1, "true": [1, 2, 4, 5, 6, 10, 11, 12, 17, 20, 21, 29, 31, 34, 40, 41, 45, 48, 50, 54, 58, 59, 63, 64, 78, 89, 91, 94, 98, 103, 108, 109, 110, 113, 116, 117, 123, 124, 126, 129, 130, 133, 134, 135, 136, 138, 140, 143, 146, 151, 156, 157, 159, 160, 161, 162, 168, 169, 171, 173, 174, 175, 176, 179, 181, 182, 183, 185, 186, 187, 189, 192, 193, 197, 198, 199, 201, 203, 204, 207, 208, 209, 210, 211, 212, 213, 216, 222, 224, 225, 237, 239, 240, 241, 243, 246], "pixels_onli": 1, "make_env": 1, "helper": [1, 5, 8, 9, 14, 21, 45, 50, 54, 59, 92, 97, 99, 100, 109, 119, 123, 124, 126, 127, 128, 134, 135, 159, 160, 161, 162, 164, 166, 169, 175, 201, 225], "either": [1, 2, 4, 5, 6, 8, 17, 21, 40, 42, 48, 60, 73, 89, 99, 107, 111, 113, 117, 123, 133, 136, 146, 155, 159, 160, 161, 168, 171, 179, 181, 187, 192, 196, 202, 204, 205, 208, 209, 212, 213, 214, 218, 225, 229, 234, 240, 243, 245], "backend": [1, 5, 6, 11, 16, 22, 30, 52, 54, 61, 117, 121, 122, 126, 132, 133, 136, 146, 157, 158, 165, 168, 171, 172, 174, 182, 183, 189, 191, 193, 200, 203, 211, 216, 218, 239, 244], "consid": [1, 6, 10, 11, 21, 29, 48, 60, 61, 68, 75, 110, 116, 124, 130, 133, 135, 146, 149, 151, 154, 156, 160, 164, 168, 171, 175, 184, 185, 186, 198, 211, 225, 226, 239], "dm": 1, "modifi": [1, 3, 6, 10, 11, 17, 35, 39, 41, 42, 51, 58, 59, 75, 80, 100, 119, 120, 135, 138, 141, 142, 143, 154, 156, 158, 160, 164, 176, 183, 190, 196, 204, 211, 234, 246], "represent": [1, 4, 10, 21, 22, 41, 51, 60, 86, 92, 95, 97, 101, 104, 106, 109, 111, 122, 126, 136, 141, 142, 145, 164, 168, 169, 172, 175, 191, 192, 196, 202, 205, 219, 222, 233, 240], "friendli": [1, 4, 21, 174, 205, 218], "append": [1, 8, 14, 16, 17, 19, 48, 60, 98, 108, 111, 123, 134, 135, 136, 155, 158, 159, 160, 161, 162, 164, 169, 175, 179, 181, 192, 205, 230], "special": [1, 10, 16, 20, 21, 38, 47, 60, 94, 95, 101, 103, 106, 107, 113, 115, 116, 119, 125, 146, 154, 155, 168, 179, 188, 195, 239], "torchr": 1, "transformedenv": [1, 158], "common": [1, 4, 6, 8, 10, 17, 34, 35, 42, 48, 50, 60, 61, 94, 98, 101, 103, 106, 111, 117, 122, 133, 134, 136, 142, 145, 151, 155, 156, 157, 158, 172, 175, 180, 182, 186, 188, 205, 209, 219, 220, 224, 228, 229, 233, 234, 235, 238, 245], "rescal": [1, 50, 175], "heurist": [1, 193], "multipli": [1, 5, 12, 17, 47, 48, 60, 91, 92, 94, 98, 107, 141, 164, 173, 174, 222, 233], "5": [1, 2, 3, 5, 6, 7, 11, 21, 33, 43, 47, 48, 51, 65, 77, 80, 83, 86, 89, 91, 94, 95, 97, 99, 101, 103, 104, 106, 108, 109, 110, 111, 113, 115, 116, 117, 118, 123, 124, 129, 133, 135, 136, 141, 143, 146, 148, 153, 156, 157, 160, 161, 162, 173, 174, 175, 182, 189, 192, 195, 198, 200, 201, 204, 207, 208, 209, 212, 214, 215, 234, 240, 245, 246, 249], "interfac": [1, 4, 5, 6, 18, 20, 21, 22, 48, 60, 98, 107, 126, 132, 135, 158, 189, 202, 208, 214], "simul": [1, 16, 17, 59, 95, 120, 158, 159, 197, 210], "doubl": [1, 2, 5, 6, 21, 34, 58, 83, 91, 97, 98, 107, 108, 117, 122, 129, 136, 145, 152, 156, 158, 169, 181, 218, 245], "precis": [1, 4, 8, 10, 18, 61, 125, 129, 130, 136, 146, 158, 169, 174, 175, 179, 181, 183, 208, 209, 222, 223, 231, 238], "number": [1, 5, 6, 7, 9, 11, 12, 16, 17, 19, 21, 31, 34, 39, 40, 42, 50, 51, 52, 54, 58, 60, 65, 86, 89, 91, 94, 95, 101, 103, 106, 107, 108, 110, 111, 115, 116, 123, 124, 125, 126, 132, 133, 134, 135, 136, 137, 138, 140, 143, 144, 148, 149, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 168, 171, 172, 175, 181, 182, 183, 187, 188, 198, 199, 204, 211, 216, 219, 221, 222, 224, 225, 227, 233, 234, 243], "presum": 1, "singl": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 19, 20, 21, 35, 38, 41, 45, 50, 52, 53, 54, 55, 58, 59, 60, 61, 80, 86, 89, 91, 92, 95, 97, 98, 99, 101, 107, 113, 115, 118, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 144, 145, 149, 152, 153, 158, 159, 160, 161, 162, 164, 165, 168, 172, 176, 179, 188, 192, 193, 198, 204, 207, 211, 215, 219, 222, 233, 234, 238, 239, 245], "ones": [1, 2, 4, 6, 11, 17, 19, 47, 60, 91, 95, 98, 109, 113, 135, 137, 142, 151, 152, 154, 156, 158, 159, 168, 174, 175, 176, 185, 195, 202, 205, 208, 233, 245], "goe": [1, 4, 5, 21, 50, 98, 100, 101, 130, 144, 154, 158, 161, 204, 216, 245], "wai": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 18, 19, 20, 22, 29, 33, 35, 38, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 67, 72, 75, 80, 83, 89, 90, 91, 92, 94, 98, 100, 101, 103, 106, 107, 109, 111, 113, 121, 124, 125, 126, 127, 130, 132, 133, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 155, 156, 158, 160, 161, 166, 169, 172, 175, 176, 181, 185, 186, 187, 188, 190, 191, 192, 193, 195, 197, 202, 204, 205, 210, 211, 217, 220, 222, 225, 226, 227, 229, 234, 239], "doubletofloat": [1, 158], "in_kei": [1, 158], "list": [1, 5, 6, 8, 11, 12, 14, 17, 18, 19, 31, 35, 38, 42, 45, 47, 48, 49, 51, 60, 61, 68, 75, 89, 92, 95, 98, 103, 104, 106, 109, 110, 113, 115, 116, 119, 120, 125, 127, 128, 134, 135, 136, 141, 146, 151, 156, 157, 160, 161, 162, 164, 168, 169, 175, 180, 181, 186, 188, 193, 197, 199, 201, 202, 203, 205, 207, 210, 211, 215, 216, 217, 219, 222, 224, 225, 238, 239, 249], "refer": [1, 4, 5, 6, 8, 13, 19, 20, 21, 22, 29, 35, 59, 60, 61, 75, 78, 86, 91, 92, 98, 101, 103, 104, 106, 108, 111, 113, 123, 124, 125, 127, 128, 132, 133, 143, 148, 155, 156, 158, 160, 161, 162, 168, 174, 175, 181, 183, 184, 187, 189, 192, 197, 201, 202, 209, 210, 212, 213, 217, 218, 219, 221, 225, 234, 239, 240, 244, 249], "float": [1, 5, 6, 8, 9, 11, 17, 21, 47, 58, 59, 91, 94, 98, 103, 106, 108, 123, 124, 126, 135, 136, 146, 154, 155, 156, 159, 160, 162, 175, 176, 178, 181, 186, 187, 189, 192, 193, 199, 201, 205, 207, 209, 211, 216, 218, 222, 225], "in_keys_inv": 1, "befor": [1, 3, 5, 6, 8, 9, 10, 11, 12, 14, 17, 18, 20, 21, 22, 29, 34, 36, 40, 41, 42, 43, 45, 48, 50, 51, 54, 58, 59, 60, 75, 86, 91, 92, 95, 100, 101, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 120, 123, 126, 127, 133, 135, 136, 138, 140, 143, 145, 148, 151, 155, 156, 157, 158, 160, 161, 162, 164, 168, 169, 171, 173, 174, 175, 176, 179, 180, 181, 182, 184, 185, 187, 190, 192, 207, 212, 213, 215, 216, 218, 219, 221, 224, 228, 229, 230, 232, 234, 235, 236, 237, 238, 239, 241], "concaten": [1, 38, 47, 48, 81, 103, 104, 109, 115, 128, 134, 159, 192], "cattensor": 1, "leav": [1, 8, 29, 41, 48, 50, 52, 60, 61, 86, 91, 113, 126, 151, 157, 197, 210], "constant": [1, 2, 6, 21, 22, 38, 47, 58, 60, 89, 91, 98, 101, 113, 151, 159, 169, 171, 174, 181, 234, 239], "significantli": [1, 17, 104, 120, 121, 129, 148, 173, 192, 196, 216, 222, 226, 234, 243], "speed": [1, 5, 6, 10, 17, 29, 31, 34, 38, 47, 48, 61, 86, 90, 91, 94, 107, 121, 122, 123, 131, 137, 143, 146, 157, 158, 160, 163, 171, 173, 181, 196, 200, 203, 205, 211, 216, 219, 222, 232, 234], "throughput": [1, 123, 174, 222, 234], "whether": [1, 6, 8, 10, 11, 20, 48, 51, 91, 92, 94, 97, 98, 107, 111, 130, 135, 136, 142, 145, 158, 160, 168, 169, 176, 187, 219, 225, 234, 235, 244], "individu": [1, 5, 6, 12, 19, 22, 30, 48, 80, 86, 91, 92, 95, 109, 110, 115, 126, 129, 148, 152, 155, 161, 164, 169, 176, 204, 214, 218, 219, 224, 234], "approach": [1, 4, 5, 6, 20, 21, 22, 36, 55, 92, 107, 111, 131, 138, 148, 151, 152, 158, 161, 164, 175, 180, 184, 187, 197, 198, 201, 209, 211, 216, 219, 222, 229, 238], "parallelenv": [1, 158], "num_work": [1, 42, 50, 89, 117, 123, 124, 156, 168, 169, 173, 175, 234], "leverag": [1, 6, 48, 75, 111, 123, 133, 135, 144, 175, 183, 191, 205, 210, 234, 235, 238], "vector": [1, 2, 4, 5, 6, 12, 20, 21, 29, 48, 51, 60, 91, 92, 95, 97, 98, 101, 103, 104, 106, 107, 109, 115, 118, 127, 128, 136, 140, 152, 154, 164, 174, 198, 200, 201, 208, 222, 234, 240], "capabl": [1, 3, 11, 48, 60, 75, 107, 163, 168, 192, 200, 210, 218], "pytorch": [1, 2, 7, 8, 9, 11, 15, 16, 19, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 42, 43, 47, 48, 50, 51, 52, 54, 55, 58, 59, 60, 62, 66, 70, 71, 74, 75, 76, 77, 79, 80, 81, 83, 85, 86, 89, 91, 92, 100, 105, 107, 111, 112, 113, 114, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 141, 142, 143, 144, 145, 148, 149, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 178, 179, 180, 182, 184, 185, 186, 187, 188, 189, 194, 196, 197, 198, 203, 204, 205, 207, 210, 216, 217, 218, 219, 220, 222, 231, 233, 239, 240, 241], "adopt": [1, 18, 61, 154, 161, 209], "frame_skip": [1, 158], "frame": [1, 6, 145, 157, 158, 168], "count": [1, 6, 11, 17, 20, 34, 40, 42, 48, 61, 101, 135, 158, 159, 162, 164, 168, 174, 179, 192], "frames_per_batch": [1, 158], "total_fram": [1, 158], "adjust": [1, 7, 17, 29, 34, 35, 41, 51, 75, 91, 94, 99, 115, 118, 126, 149, 153, 160, 189, 245], "total": [1, 5, 7, 9, 11, 12, 13, 14, 15, 18, 19, 22, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 54, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 86, 87, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 125, 126, 127, 128, 129, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 158, 159, 161, 163, 164, 165, 166, 168, 171, 173, 175, 178, 179, 181, 184, 185, 186, 187, 188, 190, 194, 196, 198, 203, 209, 212, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237], "rais": [1, 8, 11, 17, 75, 125, 143, 146, 157, 158, 171, 197, 205, 234], "unchang": [1, 8, 91, 202], "seem": [1, 42, 51, 113, 125, 127, 219], "cheat": [1, 98, 122, 164], "compar": [1, 5, 10, 17, 18, 21, 34, 42, 58, 59, 61, 92, 98, 104, 107, 116, 117, 118, 124, 126, 127, 135, 136, 142, 143, 144, 146, 149, 152, 155, 158, 160, 162, 164, 168, 171, 173, 174, 178, 179, 184, 191, 192, 193, 200, 203, 208, 211, 216, 222, 232, 233, 234, 238], "dataset": [1, 6, 9, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 48, 51, 52, 54, 56, 58, 59, 75, 77, 92, 95, 101, 112, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 135, 137, 152, 156, 157, 161, 163, 164, 166, 168, 169, 172, 204, 208, 209, 221, 222, 234, 238], "10m": 1, "element": [1, 5, 6, 12, 17, 35, 38, 47, 48, 58, 59, 78, 91, 92, 95, 98, 101, 103, 104, 106, 116, 122, 125, 135, 143, 149, 151, 153, 158, 159, 175, 185, 186, 187, 188, 211, 219, 221, 245, 246, 249], "anoth": [1, 4, 5, 7, 8, 11, 18, 19, 21, 22, 29, 38, 41, 47, 48, 51, 59, 60, 63, 75, 83, 86, 94, 95, 98, 99, 100, 104, 107, 108, 110, 111, 113, 128, 129, 130, 132, 135, 140, 141, 151, 153, 155, 158, 160, 161, 162, 164, 171, 173, 175, 176, 179, 183, 190, 192, 193, 199, 204, 216, 217, 219, 225, 234, 235, 239, 245, 246], "ratio": [1, 115, 143, 158, 168, 175, 190], "interact": [1, 5, 6, 48, 60, 92, 97, 98, 117, 126, 130, 145, 158, 161, 169, 171, 192, 225, 245], "nutshel": [1, 186], "cautiou": 1, "deal": [1, 5, 42, 48, 50, 51, 60, 94, 107, 109, 110, 111, 123, 144, 158, 209, 236], "lead": [1, 5, 6, 48, 51, 61, 75, 81, 89, 107, 120, 130, 148, 156, 186, 198, 234, 245], "bias": [1, 30, 41, 95, 111, 236, 237], "comparison": [1, 9, 19, 92, 98, 99, 100, 124, 136, 143, 144, 173, 178, 184, 186, 190, 197, 210, 232, 233], "scale": [1, 6, 17, 30, 39, 50, 55, 61, 75, 95, 97, 111, 122, 123, 124, 135, 138, 145, 158, 159, 165, 166, 174, 176, 181, 193, 209, 218, 222, 234, 240], "help": [1, 5, 8, 10, 16, 17, 20, 21, 29, 30, 41, 48, 51, 58, 59, 60, 61, 68, 89, 92, 100, 103, 104, 106, 107, 111, 113, 122, 123, 124, 126, 132, 133, 134, 136, 137, 143, 144, 149, 154, 158, 160, 161, 162, 163, 164, 173, 174, 181, 185, 186, 187, 188, 192, 198, 203, 205, 209, 210, 211, 214, 215, 217, 218, 219, 221, 228, 230, 232, 234, 235, 238], "signal": [1, 41, 92, 94, 133, 158, 160, 190, 222, 225, 233], "magnitud": [1, 40, 91, 155, 218], "truncat": [1, 98, 108, 113, 143, 158, 159], "A": [1, 5, 6, 7, 8, 11, 12, 19, 20, 22, 29, 30, 31, 35, 38, 40, 45, 46, 47, 48, 50, 51, 52, 54, 60, 63, 64, 67, 68, 69, 72, 73, 75, 80, 81, 94, 95, 98, 99, 101, 103, 104, 106, 107, 109, 110, 111, 113, 115, 118, 121, 122, 125, 126, 127, 128, 130, 131, 135, 137, 141, 142, 151, 152, 153, 158, 159, 160, 161, 163, 164, 166, 169, 172, 173, 174, 188, 192, 208, 210, 216, 219, 224, 228, 229, 234, 236, 239, 240, 246], "thousand": [1, 106, 127, 138, 164], "500": [1, 6, 146, 159, 162, 175, 219], "statist": [1, 51, 94, 117, 122, 129, 141, 142, 155, 156, 158, 164, 168, 169, 174, 179, 190, 192, 209, 219], "arbitrari": [1, 5, 8, 29, 73, 92, 104, 123, 137, 145, 152, 169, 171, 172, 190, 225, 226], "random": [1, 6, 14, 17, 18, 19, 22, 38, 41, 42, 43, 45, 47, 50, 51, 60, 63, 64, 65, 72, 73, 75, 78, 80, 83, 92, 94, 97, 103, 104, 107, 108, 109, 110, 116, 117, 123, 124, 126, 128, 133, 134, 135, 136, 137, 145, 148, 149, 151, 155, 156, 158, 159, 160, 162, 164, 169, 171, 179, 181, 192, 202, 203, 219, 221, 222, 226, 234], "standard": [1, 5, 8, 18, 21, 22, 38, 42, 47, 51, 60, 61, 89, 92, 94, 100, 101, 107, 113, 118, 135, 138, 148, 157, 166, 171, 175, 202, 204, 211, 221, 222, 234, 245], "deviat": [1, 94, 138, 148], "observationnorm": [1, 158], "init_stat": 1, "purpos": [1, 5, 18, 19, 20, 56, 75, 80, 86, 91, 95, 99, 110, 115, 119, 124, 125, 126, 128, 135, 141, 142, 143, 153, 157, 158, 161, 162, 179, 185, 192, 209, 222, 234], "summari": [1, 106, 126, 158, 168, 173, 192, 232, 233], "over": [1, 4, 5, 6, 7, 10, 11, 16, 17, 18, 20, 21, 30, 31, 34, 35, 38, 42, 45, 47, 48, 49, 50, 51, 52, 60, 61, 77, 80, 81, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 107, 108, 110, 113, 117, 118, 122, 123, 124, 127, 132, 133, 135, 137, 141, 142, 143, 144, 145, 146, 149, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 164, 168, 169, 171, 173, 175, 179, 181, 182, 189, 192, 198, 218, 222, 234, 237, 239, 245], "earlier": [1, 4, 5, 6, 20, 21, 75, 94, 95, 98, 100, 101, 104, 107, 116, 118, 124, 158, 164, 174, 211, 218, 219], "turn": [1, 4, 5, 6, 8, 17, 18, 21, 22, 39, 48, 92, 95, 98, 108, 113, 128, 144, 151, 155, 160, 164, 185, 186, 204, 205, 240], "seen": [1, 7, 10, 11, 16, 17, 42, 45, 48, 50, 95, 98, 104, 106, 107, 108, 113, 118, 119, 152, 153, 161, 171, 219, 245, 246], "requir": [1, 2, 4, 5, 6, 8, 10, 12, 16, 17, 18, 20, 21, 22, 33, 39, 41, 48, 49, 50, 51, 54, 60, 61, 77, 86, 89, 90, 91, 99, 106, 107, 113, 115, 116, 118, 120, 124, 126, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 144, 148, 149, 151, 152, 156, 157, 158, 160, 161, 162, 163, 164, 171, 172, 173, 174, 175, 178, 179, 180, 181, 185, 186, 187, 188, 189, 193, 195, 198, 200, 201, 202, 208, 209, 210, 212, 218, 220, 221, 225, 233, 234, 243], "select": [1, 5, 10, 21, 40, 49, 60, 89, 97, 107, 146, 155, 159, 160, 162, 168, 169, 179, 181, 186, 191, 199, 225, 234, 244, 247], "recal": [1, 6, 21, 51, 60, 91, 98, 100, 106, 133, 136, 158, 169, 175, 185, 186, 187, 233], "wrap": [1, 5, 6, 10, 14, 20, 22, 31, 35, 43, 60, 78, 81, 89, 94, 101, 103, 104, 108, 109, 124, 125, 129, 133, 141, 145, 156, 158, 161, 162, 172, 180, 189, 204, 214, 218, 222, 225, 241, 245, 248], "flow": [1, 4, 5, 19, 21, 22, 29, 41, 51, 60, 66, 70, 86, 97, 109, 113, 158, 159, 168, 171, 179, 180, 181, 192, 193, 201, 234, 239, 245], "handl": [1, 5, 8, 10, 21, 48, 51, 52, 61, 86, 95, 98, 107, 113, 124, 127, 136, 137, 138, 152, 155, 157, 158, 161, 162, 163, 164, 171, 174, 179, 181, 184, 186, 188, 198, 200, 208, 217, 225, 233], "specifi": [1, 4, 5, 6, 8, 9, 11, 17, 18, 20, 21, 31, 35, 50, 51, 59, 78, 89, 91, 92, 94, 95, 98, 99, 103, 109, 110, 113, 116, 123, 124, 126, 130, 134, 136, 137, 140, 154, 155, 158, 161, 162, 168, 176, 184, 185, 186, 187, 188, 191, 192, 193, 197, 198, 199, 201, 202, 203, 209, 210, 216, 225, 227, 229, 230, 232, 234, 235, 239, 240, 243, 245], "scenario": [1, 4, 6, 61, 111, 117, 125, 159, 162, 235], "tensordictsequenti": 1, "valueoper": 1, "automat": [1, 2, 5, 6, 8, 10, 20, 22, 30, 32, 33, 35, 38, 41, 43, 44, 45, 47, 52, 56, 61, 78, 97, 99, 100, 107, 110, 114, 122, 123, 124, 125, 126, 130, 136, 138, 141, 143, 146, 148, 158, 159, 162, 165, 166, 168, 173, 174, 179, 181, 200, 202, 203, 205, 208, 209, 214, 220, 223, 225, 231, 233, 234, 238, 239, 245], "out_kei": [1, 158], "state_action_valu": [1, 159], "state_valu": 1, "built": [1, 4, 5, 6, 7, 8, 20, 21, 29, 45, 59, 61, 91, 92, 94, 95, 101, 113, 115, 116, 118, 122, 135, 136, 153, 158, 163, 169, 174, 190, 197, 205, 209, 210, 217, 219, 221, 224, 237], "present": [1, 6, 8, 16, 20, 34, 61, 134, 136, 151, 154, 155, 156, 159, 160, 162, 172, 175, 234, 241], "origin": [1, 5, 6, 7, 8, 12, 17, 21, 29, 48, 51, 58, 59, 60, 75, 89, 92, 98, 104, 113, 115, 119, 120, 125, 127, 128, 136, 141, 149, 151, 152, 153, 155, 156, 159, 171, 173, 174, 176, 178, 179, 180, 187, 192, 193, 207, 208, 209, 214, 216, 222, 239], "paper": [1, 5, 12, 14, 51, 58, 59, 61, 75, 113, 114, 118, 119, 120, 136, 158, 161, 163, 164, 166, 188], "found": [1, 4, 5, 6, 10, 14, 20, 21, 22, 40, 48, 49, 60, 81, 92, 113, 115, 116, 119, 126, 133, 134, 135, 136, 141, 142, 146, 159, 161, 162, 163, 178, 179, 180, 181, 188, 199, 208, 210, 214, 234, 245], "ddpgmlpactor": 1, "ddpgmlpqnet": 1, "sinc": [1, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19, 21, 42, 48, 50, 51, 52, 60, 75, 80, 86, 91, 92, 94, 100, 101, 103, 104, 106, 107, 115, 117, 119, 120, 126, 127, 128, 130, 131, 135, 138, 141, 142, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 169, 171, 172, 173, 176, 179, 180, 181, 182, 183, 184, 185, 186, 192, 197, 200, 203, 211, 214, 219, 225, 226, 237, 241, 245], "lazi": [1, 59], "materi": [1, 61, 124, 144, 184, 195, 201, 222, 226], "achiev": [1, 3, 6, 17, 29, 42, 48, 55, 89, 120, 125, 129, 135, 136, 143, 148, 151, 155, 156, 158, 159, 168, 173, 176, 179, 181, 196, 203, 210, 234, 238], "oper": [1, 4, 6, 13, 16, 17, 18, 19, 22, 29, 30, 35, 40, 41, 43, 45, 48, 50, 60, 61, 63, 64, 73, 78, 83, 86, 90, 94, 98, 100, 101, 106, 107, 108, 109, 110, 116, 119, 122, 125, 127, 130, 135, 136, 137, 138, 140, 141, 143, 144, 146, 148, 149, 152, 154, 157, 158, 160, 164, 168, 169, 171, 173, 179, 180, 181, 182, 183, 184, 185, 189, 191, 192, 196, 197, 198, 199, 205, 208, 210, 214, 216, 217, 218, 219, 221, 222, 225, 226, 233, 237, 238, 239, 241], "practic": [1, 5, 6, 11, 18, 21, 45, 48, 50, 51, 58, 59, 60, 61, 91, 92, 94, 98, 101, 107, 110, 114, 117, 122, 125, 127, 131, 134, 136, 143, 151, 155, 158, 165, 172, 174, 184, 185, 188, 190, 219, 220, 224, 234], "fake": [1, 6, 17, 22, 45, 51, 80, 156, 188, 192, 193, 216], "spec": [1, 158, 162, 176, 219], "ornsteinuhlenbeckprocesswrapp": 1, "suggest": [1, 4, 12, 51, 88, 128, 136, 143, 144, 145, 146, 149, 156, 168, 172, 175, 222], "ou": 1, "nois": [1, 6, 12, 51, 75, 190, 233], "reach": [1, 10, 51, 60, 61, 133, 135, 136, 145, 146, 148, 158, 162, 209, 219], "minimum": [1, 158, 162, 174, 186], "iter": [1, 3, 4, 6, 11, 12, 29, 30, 34, 35, 40, 41, 42, 45, 51, 52, 54, 60, 77, 86, 89, 91, 92, 94, 95, 100, 107, 111, 113, 116, 117, 119, 126, 131, 133, 134, 141, 143, 156, 158, 159, 160, 161, 162, 168, 169, 171, 175, 179, 189, 192, 207, 211, 214, 218, 222, 234, 237, 241], "reset": [1, 17, 34, 94, 98, 107, 117, 158, 159, 160, 162, 168, 171, 179, 190, 192, 209], "tight": 1, "per": [1, 5, 6, 8, 11, 17, 106, 122, 123, 127, 128, 129, 133, 135, 136, 138, 144, 146, 155, 162, 163, 164, 165, 168, 169, 172, 173, 174, 175, 181, 184, 189, 198, 200, 203, 205, 207, 209, 211, 219, 233, 241], "sync": [1, 10, 11, 14, 54, 122, 123, 124, 141, 145, 183, 189], "natur": [1, 5, 6, 16, 21, 22, 43, 61, 75, 77, 95, 107, 116, 120, 126, 127, 135, 136, 161, 186, 188, 192, 193, 200, 245], "resourc": [1, 52, 58, 59, 61, 75, 89, 120, 124, 133, 135, 158, 168, 173, 205, 211, 219, 234], "alloc": [1, 6, 16, 19, 20, 21, 38, 47, 54, 59, 98, 129, 135, 168, 172, 173, 188, 195, 211, 225, 241], "gpu": [1, 3, 4, 7, 12, 16, 17, 18, 30, 35, 38, 40, 41, 45, 47, 48, 51, 52, 53, 55, 56, 60, 61, 64, 73, 75, 79, 82, 83, 84, 90, 94, 99, 101, 110, 114, 117, 122, 123, 124, 125, 131, 132, 133, 134, 135, 136, 137, 143, 146, 148, 149, 152, 153, 156, 158, 159, 161, 162, 163, 168, 171, 172, 174, 175, 181, 191, 199, 200, 205, 211, 218, 219, 222, 225, 237, 238, 239], "worker": [1, 6, 7, 11, 14, 50, 51, 61, 94, 115, 121, 123, 124, 134, 135, 146, 153, 158, 161, 162, 168, 203, 205, 234], "syncdatacollector": [1, 158], "process": [1, 4, 5, 6, 11, 12, 14, 16, 18, 20, 21, 22, 31, 34, 35, 39, 40, 45, 48, 49, 50, 51, 55, 60, 61, 75, 86, 91, 92, 94, 95, 99, 107, 109, 111, 113, 114, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 135, 136, 142, 143, 145, 146, 148, 152, 153, 157, 159, 161, 162, 163, 164, 168, 172, 173, 174, 179, 181, 182, 183, 190, 191, 196, 197, 200, 201, 203, 209, 216, 219, 221, 225, 233, 234, 235, 237, 238, 241, 244, 245], "offer": [1, 11, 16, 35, 39, 40, 41, 52, 61, 91, 92, 101, 123, 137, 140, 143, 144, 205, 217, 219, 224, 225, 233, 234], "multiasyncdatacollector": [1, 158], "rollout": [1, 158], "asynchron": [1, 19, 61, 121, 122, 126, 134, 148, 154, 158, 162, 225], "manner": [1, 5, 8, 17, 29, 61, 91, 107, 158, 205], "therebi": [1, 184], "decoupl": [1, 31, 61, 151, 192], "factori": [1, 6, 98, 103, 115, 185, 186, 220], "empti": [1, 5, 6, 8, 17, 19, 21, 98, 128, 143, 157, 164, 168, 173, 181, 195, 199, 225, 233, 246], "maximum": [1, 11, 48, 60, 95, 104, 113, 126, 128, 136, 143, 158, 163, 164, 181, 189, 190, 204, 234], "non": [1, 2, 3, 5, 8, 11, 17, 20, 30, 48, 50, 52, 53, 55, 57, 60, 86, 95, 98, 100, 106, 107, 111, 113, 120, 123, 126, 129, 130, 134, 135, 136, 138, 140, 144, 146, 149, 155, 156, 159, 160, 163, 164, 168, 171, 173, 179, 181, 184, 188, 195, 216, 219, 235, 239, 246, 248], "termin": [1, 21, 52, 60, 89, 158, 159, 161, 162, 183, 199, 204, 213, 232], "max_frames_per_traj": [1, 158], "effect": [1, 5, 6, 8, 9, 11, 21, 54, 75, 92, 95, 98, 107, 127, 128, 137, 152, 155, 159, 163, 164, 173, 174, 186, 198, 218, 222, 224, 234, 243], "regist": [1, 20, 34, 41, 45, 80, 95, 108, 111, 122, 123, 133, 140, 151, 158, 174, 200, 201, 205, 208, 214, 218, 226, 236], "new": [1, 2, 4, 5, 6, 8, 12, 20, 21, 22, 28, 29, 33, 38, 40, 41, 43, 47, 48, 49, 51, 54, 60, 62, 75, 77, 81, 83, 86, 97, 98, 99, 101, 104, 106, 108, 109, 111, 113, 117, 122, 123, 124, 125, 127, 136, 140, 141, 143, 145, 148, 151, 152, 154, 155, 156, 158, 159, 160, 163, 164, 168, 175, 176, 182, 183, 184, 188, 190, 191, 192, 193, 197, 198, 199, 200, 201, 204, 205, 210, 211, 212, 213, 214, 222, 225, 227, 234, 235, 245], "stepcount": [1, 158], "infer": [1, 3, 6, 8, 9, 10, 17, 18, 19, 20, 21, 36, 38, 47, 48, 60, 61, 90, 92, 94, 95, 99, 103, 106, 107, 113, 122, 125, 126, 129, 141, 143, 158, 160, 171, 174, 175, 181, 182, 183, 188, 189, 192, 196, 199, 200, 209, 211, 212, 213, 214, 216, 221, 222, 223, 228, 230, 231, 236, 238], "manual": [1, 5, 8, 12, 20, 21, 31, 45, 48, 52, 69, 72, 73, 98, 107, 110, 111, 130, 137, 151, 152, 156, 179, 180, 181, 188, 200, 203, 214, 218, 227, 244, 245], "around": [1, 5, 6, 11, 21, 31, 35, 48, 54, 58, 59, 77, 92, 94, 95, 98, 117, 122, 128, 137, 143, 144, 149, 152, 156, 164, 168, 169, 179, 184, 185, 189, 192, 222, 226, 245, 248], "1m": [1, 117, 158], "outer": [1, 6, 123, 144], "loop": [1, 3, 4, 5, 7, 8, 11, 14, 17, 19, 22, 33, 35, 42, 45, 48, 50, 51, 59, 60, 75, 77, 86, 91, 94, 97, 107, 110, 118, 119, 124, 126, 127, 136, 137, 143, 144, 145, 152, 153, 161, 162, 169, 174, 180, 181, 219, 225, 234, 237], "equal": [1, 4, 10, 91, 98, 115, 116, 118, 125, 136, 146, 155, 158, 159, 173, 187, 205, 234], "length": [1, 7, 12, 40, 48, 51, 60, 91, 92, 95, 106, 107, 113, 115, 116, 118, 128, 136, 153, 158, 163, 164, 172, 181, 186, 188, 191, 198, 201, 205, 238, 246], "sub": [1, 6, 18, 22, 91, 108, 148, 158, 162, 168, 173, 174, 181, 245], "shape": [1, 4, 21, 29, 38, 40, 41, 47, 48, 51, 58, 59, 60, 68, 78, 86, 91, 94, 100, 103, 106, 108, 110, 123, 127, 128, 136, 137, 140, 141, 144, 152, 158, 168, 181, 182, 187, 188, 192, 195, 202, 204, 214, 219, 222, 223, 225, 231, 234, 238], "env_per_collector": 1, "traj_len": 1, "assess": 1, "mode": [1, 4, 12, 18, 36, 40, 41, 48, 51, 54, 60, 75, 81, 86, 88, 92, 97, 111, 115, 116, 117, 122, 123, 129, 130, 134, 138, 141, 143, 145, 146, 149, 156, 160, 163, 164, 165, 169, 171, 174, 176, 182, 183, 189, 190, 191, 193, 194, 205, 209, 219, 228, 229, 230, 234], "dedic": [1, 10, 54, 60, 98, 111, 134, 161, 162, 174, 201, 211, 216, 217, 218, 241, 246], "frequenc": [1, 7, 118, 126, 153, 211], "everi": [1, 2, 6, 8, 10, 16, 17, 29, 30, 31, 35, 41, 42, 45, 48, 50, 51, 60, 61, 91, 94, 95, 97, 98, 99, 117, 125, 127, 128, 129, 135, 138, 140, 146, 151, 152, 155, 156, 158, 159, 160, 162, 164, 168, 169, 175, 188, 192, 201, 211, 220, 227, 232, 234, 241], "10": [1, 3, 4, 6, 7, 8, 11, 17, 21, 30, 31, 39, 40, 41, 42, 43, 48, 52, 72, 75, 89, 91, 94, 99, 108, 111, 115, 117, 123, 124, 133, 135, 137, 138, 141, 146, 148, 156, 157, 160, 161, 162, 163, 164, 168, 169, 173, 175, 176, 182, 189, 191, 192, 195, 197, 199, 201, 202, 203, 209, 211, 214, 219, 221, 225, 229, 233, 249], "flavor": [1, 5, 21], "priorit": [1, 188], "error": [1, 4, 5, 6, 8, 10, 11, 12, 20, 34, 35, 41, 45, 48, 49, 52, 58, 60, 61, 68, 80, 91, 94, 95, 98, 103, 107, 110, 123, 125, 130, 134, 138, 154, 158, 159, 171, 184, 190, 192, 197, 201, 208, 210, 219, 234, 237, 240, 245], "higher": [1, 17, 38, 42, 47, 52, 91, 92, 95, 101, 110, 123, 124, 127, 128, 130, 140, 144, 156, 157, 158, 159, 168, 169, 179, 181, 190, 192, 196, 198, 200, 211, 216, 222, 227, 243, 245], "likelihood": [1, 34, 48, 95, 101, 107, 118, 127, 204], "regular": [1, 4, 5, 6, 8, 10, 17, 21, 107, 114, 127, 128, 134, 144, 151, 152, 166, 184, 186, 188, 208, 234], "circular": 1, "compos": [1, 5, 6, 10, 17, 19, 22, 58, 59, 81, 94, 95, 101, 109, 113, 115, 117, 118, 122, 124, 135, 138, 140, 141, 149, 152, 156, 157, 158, 161, 163, 165, 169, 175, 179, 192, 193, 197, 202, 204, 208, 209, 221, 225], "pick": [1, 6, 17, 42, 100, 127, 159, 164, 205, 224, 228, 233, 238], "tensor": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 17, 18, 19, 20, 21, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 48, 56, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 74, 75, 77, 79, 80, 82, 84, 86, 90, 91, 92, 93, 95, 97, 99, 101, 104, 107, 108, 111, 115, 116, 117, 118, 119, 122, 123, 124, 128, 129, 130, 133, 134, 135, 136, 137, 138, 140, 143, 144, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 168, 169, 171, 172, 173, 175, 179, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 195, 196, 198, 199, 201, 202, 203, 204, 205, 208, 216, 217, 218, 219, 221, 222, 224, 225, 226, 227, 233, 236, 237, 240], "physic": [1, 106, 174, 234], "memori": [1, 4, 5, 6, 8, 10, 14, 16, 17, 19, 20, 21, 38, 47, 48, 50, 54, 61, 83, 89, 95, 98, 99, 102, 105, 107, 109, 111, 115, 122, 123, 124, 131, 135, 138, 143, 144, 145, 149, 155, 161, 163, 165, 168, 172, 175, 183, 184, 187, 188, 189, 200, 203, 207, 208, 216, 218, 219, 222, 226, 238, 241], "map": [1, 6, 12, 30, 48, 51, 58, 60, 77, 92, 94, 95, 104, 106, 109, 111, 113, 115, 116, 120, 127, 137, 138, 144, 151, 152, 158, 159, 162, 173, 175, 179, 192, 193, 198, 202, 203, 204, 233, 234, 236], "arrai": [1, 6, 29, 30, 41, 42, 45, 50, 58, 59, 72, 73, 86, 91, 92, 98, 106, 107, 108, 110, 117, 127, 128, 138, 145, 156, 157, 159, 164, 175, 187, 217], "desir": [1, 5, 8, 12, 14, 48, 51, 75, 109, 111, 116, 135, 141, 155, 168, 185, 195, 214, 218, 221, 246], "hyperparamet": [1, 6, 51, 107, 111, 112, 115, 118, 122, 126, 184, 188, 232, 236], "temporari": [1, 5, 117, 126, 174, 178], "disk": [1, 4, 21, 22, 31, 94, 97, 111, 182, 183, 189, 201, 211, 219, 225, 232], "along": [1, 4, 5, 6, 7, 8, 19, 21, 29, 30, 38, 41, 47, 48, 52, 53, 54, 55, 60, 90, 91, 92, 94, 95, 97, 98, 99, 103, 104, 107, 109, 116, 117, 118, 120, 123, 124, 127, 128, 131, 132, 153, 155, 159, 161, 169, 172, 186, 195], "dimens": [1, 5, 6, 7, 12, 16, 18, 19, 30, 38, 45, 47, 48, 80, 81, 92, 94, 95, 97, 103, 104, 106, 107, 109, 115, 118, 122, 127, 137, 146, 152, 153, 157, 158, 160, 172, 185, 188, 198, 204, 211, 218, 222, 234], "feed": [1, 6, 12, 17, 42, 45, 48, 57, 60, 94, 95, 99, 104, 111, 127, 128, 133, 134, 145, 159, 164, 169, 173, 190, 221, 227, 237], "adapt": [1, 2, 89, 94, 118, 126, 175, 219], "divid": [1, 7, 8, 10, 11, 12, 17, 86, 101, 118, 127, 134, 135, 148, 151, 153, 162, 173, 174], "yield": [1, 6, 11, 12, 17, 19, 34, 36, 98, 111, 115, 119, 125, 160, 162, 187, 209, 228, 229, 230, 234], "regard": [1, 6, 11, 21, 60, 111, 143, 144, 158, 168, 245], "200": [1, 6, 9, 146, 162, 189], "random_crop_len": 1, "25": [1, 7, 20, 21, 72, 75, 91, 108, 117, 124, 156, 161, 219, 225], "balanc": [1, 6, 16, 133, 168, 214], "choic": [1, 4, 6, 8, 89, 126, 128, 234], "heterogen": [1, 191], "figur": [1, 8, 12, 20, 48, 75, 94, 117, 122, 126, 143, 148, 159, 160, 168, 169, 173, 179, 190, 192, 246, 248], "dataflow": 1, "8": [1, 3, 5, 6, 7, 17, 21, 58, 59, 89, 91, 95, 103, 104, 108, 110, 116, 117, 120, 123, 129, 133, 134, 136, 141, 143, 146, 153, 156, 157, 168, 173, 181, 182, 183, 199, 200, 201, 203, 205, 209, 211, 212, 213, 216, 218, 234, 241, 245, 246, 249], "1000": [1, 2, 17, 41, 91, 97, 99, 117, 123, 124, 125, 127, 134, 143, 158, 159, 169, 173, 174, 182, 203, 204, 214, 219, 233], "known": [1, 4, 5, 12, 40, 91, 113, 135, 136, 140, 142, 155, 159, 164, 181, 183, 193, 200, 219, 222, 233], "utd": 1, "64": [1, 5, 6, 16, 17, 21, 31, 35, 41, 89, 98, 104, 107, 115, 120, 123, 124, 134, 137, 152, 157, 160, 161, 172, 175, 198, 200, 201, 209, 219, 225], "reproduc": [1, 12, 51, 75, 94, 98, 136, 143, 158, 162, 171, 181, 219, 234], "realiz": 1, "sever": [1, 2, 3, 10, 11, 14, 17, 20, 22, 29, 35, 39, 43, 45, 51, 52, 53, 61, 75, 101, 113, 123, 127, 132, 135, 141, 145, 148, 151, 154, 156, 158, 160, 161, 168, 169, 171, 173, 174, 186, 193, 201, 208, 211, 219, 232, 233, 239], "qnet": 1, "ve": [1, 5, 6, 7, 8, 19, 20, 22, 43, 45, 49, 80, 91, 92, 94, 95, 98, 99, 107, 113, 118, 122, 125, 141, 142, 144, 152, 153, 159, 161, 169, 173, 184, 186, 187, 204, 219, 222], "_must_": 1, "off": [1, 7, 8, 14, 17, 19, 29, 41, 48, 95, 98, 111, 113, 117, 120, 124, 126, 127, 143, 153, 156, 158, 160, 161, 162, 182, 184, 204, 222, 228, 238, 240], "dictat": 1, "introduc": [1, 11, 14, 19, 20, 21, 30, 33, 40, 53, 60, 77, 80, 81, 89, 92, 101, 108, 110, 119, 120, 122, 123, 133, 143, 146, 148, 160, 162, 163, 164, 171, 172, 174, 178, 179, 181, 183, 184, 186, 187, 190, 192, 193, 196, 197, 198, 200, 202, 203, 205, 208, 210, 211, 234], "outdat": 1, "trick": [1, 6, 10, 48, 98, 130, 135, 144], "multi": [1, 5, 6, 16, 45, 48, 51, 52, 53, 55, 61, 79, 82, 91, 92, 95, 98, 101, 113, 122, 123, 131, 132, 133, 134, 136, 148, 158, 160, 163, 165, 168, 174, 175, 181, 188, 234], "altern": [1, 6, 10, 21, 47, 48, 104, 113, 117, 124, 137, 142, 146, 154, 156, 158, 164, 168, 171, 179, 187, 202, 234], "hack": [1, 136, 181, 184], "find": [1, 2, 4, 5, 6, 8, 10, 20, 21, 29, 31, 38, 47, 75, 86, 89, 94, 95, 98, 100, 103, 107, 122, 124, 127, 135, 136, 140, 141, 143, 148, 151, 156, 159, 162, 164, 168, 180, 184, 185, 186, 187, 190, 192, 197, 201, 204, 209, 210, 211, 214, 217, 219, 232, 239], "despit": [1, 75, 133], "fact": [1, 3, 5, 6, 8, 12, 17, 20, 21, 29, 38, 60, 75, 83, 91, 92, 94, 95, 98, 101, 106, 113, 125, 151, 158, 159, 169], "part": [1, 3, 5, 6, 8, 10, 13, 14, 18, 21, 34, 40, 41, 43, 48, 51, 57, 58, 59, 60, 75, 78, 89, 91, 92, 95, 100, 106, 107, 113, 116, 119, 122, 123, 125, 128, 130, 131, 134, 135, 136, 138, 142, 143, 148, 151, 158, 164, 179, 180, 183, 184, 186, 191, 197, 201, 202, 204, 205, 209, 210, 211, 214, 217, 218, 222, 233, 239, 243, 244, 245], "made": [1, 6, 10, 17, 22, 51, 89, 92, 98, 113, 120, 123, 125, 135, 164, 169, 172, 174, 187, 191, 193, 212, 213, 216, 217, 222, 234, 245], "thank": [1, 9, 17, 48, 107, 120, 126, 127, 128, 135, 136, 164, 173, 174, 181, 182, 183, 190, 197, 210], "hardupd": 1, "softupd": 1, "appropri": [1, 6, 7, 8, 40, 48, 60, 92, 107, 126, 127, 133, 151, 153, 156, 161, 169, 172, 179, 192, 204, 208, 218], "locat": [1, 6, 28, 31, 38, 47, 80, 83, 92, 94, 106, 108, 113, 135, 156, 158, 173, 175, 183, 197, 210, 211, 214, 225, 234], "adam": [1, 6, 11, 13, 34, 45, 51, 69, 99, 101, 109, 110, 135, 159, 160, 162, 241], "pretti": [1, 14, 19, 42, 98, 108, 110, 113, 144, 162, 175, 179, 198], "plot": [1, 6, 51, 75, 91, 113, 117, 126, 148, 159, 160, 169, 190], "mention": [1, 5, 6, 10, 11, 14, 51, 60, 75, 86, 98, 100, 111, 124, 135, 159, 161, 181, 192, 214], "greater": [1, 11, 48, 51, 92, 110, 125, 173, 183, 199], "concret": [1, 5, 6, 8, 11, 91, 148, 158, 184], "takeawai": [1, 114], "further": [1, 4, 5, 6, 8, 17, 19, 21, 45, 61, 75, 89, 95, 107, 113, 116, 119, 127, 141, 143, 148, 155, 158, 171, 174, 188, 190, 191, 192, 197, 205, 208, 210, 216, 224, 234, 239], "dispatch": [1, 5, 122, 154, 174, 200, 201, 218], "distpatch": 1, "iql": 1, "flexibl": [1, 2, 5, 6, 21, 22, 48, 60, 86, 91, 107, 111, 115, 122, 123, 131, 219, 227, 229], "runnable_code_remov": [1, 7, 9, 12, 13, 18, 20, 21, 22, 29, 30, 31, 34, 35, 36, 38, 39, 41, 42, 43, 45, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 73, 75, 77, 78, 80, 81, 83, 86, 89, 92, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 108, 110, 111, 113, 114, 115, 116, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 163, 164, 166, 168, 171, 178, 184, 185, 186, 187, 188, 190, 196, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236, 237], "minut": [1, 7, 9, 12, 13, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 158, 159, 163, 164, 166, 168, 169, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "001": [1, 9, 12, 13, 15, 29, 31, 35, 37, 38, 41, 42, 46, 50, 60, 75, 82, 86, 87, 91, 94, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 111, 112, 116, 117, 120, 125, 127, 128, 133, 137, 140, 143, 144, 145, 146, 149, 158, 159, 160, 163, 165, 166, 169, 171, 184, 186, 190, 194, 208, 229, 231], "second": [1, 4, 5, 6, 7, 8, 9, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 76, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 158, 159, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 178, 181, 184, 185, 186, 187, 188, 190, 196, 198, 203, 207, 209, 211, 212, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 245], "coding_ddpg": [1, 15], "jupyt": [1, 7, 9, 12, 13, 18, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 169, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "notebook": [1, 7, 9, 12, 13, 16, 18, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 57, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 169, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "ipynb": [1, 7, 9, 12, 13, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "galleri": [1, 7, 9, 12, 13, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237], "sphinx": [1, 7, 9, 12, 13, 18, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 158, 159, 163, 164, 166, 168, 171, 178, 184, 185, 186, 187, 188, 190, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 243, 244, 245, 246, 250], "build": [2, 6, 7, 17, 18, 22, 29, 31, 32, 33, 34, 35, 36, 38, 39, 45, 48, 61, 68, 69, 77, 78, 80, 84, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 106, 107, 108, 110, 113, 114, 115, 118, 119, 121, 122, 127, 128, 134, 135, 136, 138, 140, 152, 153, 158, 159, 160, 161, 162, 165, 172, 178, 179, 181, 182, 183, 189, 191, 192, 198, 208, 211, 212, 213, 219, 221, 224, 228, 230, 233, 234, 244, 249], "highli": [2, 5, 6, 10, 16, 48, 60, 89, 118, 164, 172, 174, 198, 234], "dynam": [2, 4, 5, 6, 8, 12, 15, 17, 18, 20, 21, 22, 29, 41, 52, 61, 65, 91, 102, 105, 110, 111, 120, 122, 146, 155, 158, 176, 179, 180, 191, 194, 201, 208, 209, 210, 218, 223, 227, 231, 234, 238], "explor": [2, 6, 8, 19, 21, 43, 48, 75, 122, 126, 130, 143, 145, 158, 163, 164, 217, 228, 229, 238], "note": [2, 4, 5, 6, 7, 8, 9, 12, 14, 16, 17, 18, 19, 20, 21, 29, 41, 42, 43, 45, 48, 49, 51, 57, 61, 75, 86, 91, 92, 94, 95, 98, 99, 101, 103, 104, 106, 107, 108, 111, 113, 116, 117, 118, 123, 124, 125, 129, 130, 132, 133, 134, 135, 136, 137, 140, 141, 143, 144, 146, 148, 152, 153, 154, 155, 156, 160, 161, 162, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 195, 196, 197, 198, 200, 203, 205, 210, 225, 227, 232, 233, 236, 239, 241, 243, 245], "differenti": [2, 5, 6, 16, 22, 32, 33, 38, 44, 45, 56, 78, 91, 110, 122, 152, 159, 165, 166, 186], "requires_grad": [2, 6, 8, 29, 41, 45, 63, 64, 78, 91, 98, 103, 107, 109, 110, 117, 130, 156, 175, 198, 237], "track": [2, 5, 7, 8, 30, 34, 41, 51, 91, 95, 97, 98, 101, 103, 107, 109, 110, 117, 123, 127, 128, 132, 141, 153, 156, 162, 164, 168, 201, 225, 232, 237], "auto": [2, 3, 5, 6, 8, 10, 12, 20, 54, 59, 123, 124, 143, 154, 182, 183, 199, 201, 208, 209, 219, 233, 245, 246], "std": [2, 4, 5, 6, 12, 17, 20, 21, 50, 58, 59, 94, 117, 154, 156, 157, 162, 179, 182, 184, 192, 197, 201, 208, 210, 219, 240], "cout": [2, 4, 6, 20, 21, 182, 240], "endl": [2, 6, 20, 21, 182, 201], "cpufloattyp": [2, 4, 6, 21, 201], "y": [2, 5, 7, 16, 18, 20, 21, 29, 38, 39, 41, 47, 51, 63, 64, 67, 68, 69, 72, 73, 75, 78, 86, 91, 95, 98, 100, 103, 104, 107, 109, 110, 113, 116, 118, 123, 125, 136, 153, 154, 158, 171, 172, 175, 181, 186, 190, 198, 201, 203, 233, 246], "wa": [2, 3, 4, 5, 11, 18, 20, 21, 22, 40, 42, 50, 51, 58, 59, 60, 75, 78, 81, 91, 92, 94, 95, 98, 99, 100, 101, 103, 107, 111, 113, 116, 118, 124, 126, 133, 135, 145, 149, 151, 152, 155, 157, 158, 159, 162, 163, 164, 169, 173, 174, 183, 186, 187, 201, 211, 214, 218, 219, 222, 225, 227, 245], "result": [2, 4, 5, 6, 7, 8, 9, 10, 12, 17, 18, 19, 21, 22, 29, 34, 36, 38, 41, 42, 50, 58, 59, 60, 64, 72, 78, 80, 89, 91, 92, 94, 98, 99, 103, 107, 110, 111, 114, 116, 118, 120, 123, 125, 128, 133, 135, 136, 140, 141, 143, 144, 145, 148, 149, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 169, 171, 172, 173, 174, 175, 176, 179, 183, 185, 186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 201, 202, 203, 207, 209, 210, 211, 216, 221, 222, 225, 228, 229, 230, 232, 233, 234, 238, 239, 240, 241, 243], "grad_fn": [2, 4, 22, 29, 41, 45, 78, 91, 103, 125, 130, 181], "addbackward1": 2, "z": [2, 5, 7, 21, 51, 86, 91, 98, 103, 118, 153, 186, 201, 246], "27": [2, 7, 50, 143, 162, 173, 216, 219], "mulbackward1": 2, "meanbackward0": 2, "requires_grad_": [2, 29, 78, 103], "flag": [2, 5, 21, 41, 75, 78, 91, 103, 136, 151, 164, 173, 181, 191, 197, 233], "place": [2, 5, 6, 11, 16, 20, 21, 38, 41, 43, 47, 51, 78, 86, 92, 95, 97, 101, 103, 107, 113, 116, 119, 123, 126, 133, 135, 137, 148, 152, 156, 158, 159, 164, 171, 172, 179, 184, 192, 198, 201, 203, 204, 233, 234, 239, 245, 246, 247], "randn": [2, 5, 6, 12, 21, 72, 91, 103, 109, 110, 133, 134, 141, 160, 162, 192, 198, 201, 203, 219, 241], "b": [2, 5, 6, 7, 16, 19, 21, 29, 41, 63, 64, 72, 83, 91, 98, 101, 104, 106, 108, 109, 110, 117, 118, 125, 127, 128, 141, 143, 144, 146, 153, 157, 159, 171, 189, 202, 219, 225, 246], "sumbackward0": [2, 91, 103], "backprop": [2, 41, 72, 78, 103, 107, 110, 127, 145], "scalar": [2, 5, 21, 29, 41, 48, 51, 60, 63, 78, 91, 94, 98, 103, 110, 169, 192, 199], "backward": [2, 3, 6, 8, 11, 12, 13, 14, 17, 22, 29, 34, 41, 43, 45, 51, 61, 63, 64, 72, 73, 78, 91, 92, 94, 99, 103, 104, 107, 110, 117, 122, 124, 125, 128, 131, 133, 134, 135, 140, 144, 148, 149, 152, 156, 159, 160, 161, 162, 168, 169, 203, 205, 208, 209, 218, 225, 234, 237, 241], "equival": [2, 4, 5, 11, 20, 21, 29, 41, 91, 101, 110, 136, 140, 152, 159, 161, 181, 184, 186, 188, 193, 234, 240], "print": [2, 4, 5, 6, 11, 16, 17, 19, 20, 21, 22, 30, 35, 40, 42, 43, 47, 48, 50, 51, 52, 58, 59, 72, 75, 78, 80, 86, 89, 91, 94, 95, 98, 101, 103, 106, 107, 109, 110, 111, 117, 120, 123, 124, 127, 128, 129, 132, 133, 134, 135, 136, 138, 141, 143, 151, 154, 156, 157, 159, 160, 161, 162, 164, 169, 172, 173, 174, 175, 176, 179, 181, 183, 184, 186, 189, 192, 199, 201, 202, 203, 207, 208, 209, 211, 216, 218, 219, 225, 226, 229, 234, 236, 239, 240, 241, 245], "dx": [2, 64, 78, 101, 110, 130], "grad": [2, 6, 12, 29, 41, 45, 63, 78, 91, 103, 107, 110, 124, 125, 130, 133, 135, 140, 144, 149, 160, 161, 162, 184, 198, 205, 218, 237], "5000": [2, 138, 204, 219], "got": [2, 17, 54, 92, 98, 100, 101, 103, 107, 113, 133, 154, 161, 175, 183, 192, 193, 204, 245], "matrix": [2, 5, 6, 12, 21, 29, 38, 41, 47, 91, 94, 95, 98, 100, 101, 103, 106, 107, 108, 109, 127, 128, 144, 149, 151, 164, 173, 174, 187, 188, 198, 208, 209, 214, 221, 234, 238], "explan": [2, 51, 61, 159, 169], "arriv": [2, 6, 21, 40, 113, 123, 133, 160, 201, 234], "valu": [2, 4, 5, 6, 7, 9, 12, 16, 17, 18, 19, 20, 21, 22, 29, 30, 34, 38, 39, 41, 45, 47, 48, 49, 54, 58, 59, 60, 61, 63, 75, 83, 86, 89, 91, 92, 94, 95, 98, 99, 101, 103, 104, 106, 107, 110, 113, 115, 118, 125, 126, 127, 132, 133, 135, 136, 138, 142, 145, 148, 153, 154, 159, 160, 161, 162, 163, 164, 168, 171, 172, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 196, 197, 201, 202, 204, 205, 210, 218, 219, 222, 224, 225, 232, 241, 243], "section": [2, 4, 5, 6, 7, 8, 11, 16, 17, 19, 21, 30, 31, 33, 34, 35, 36, 38, 41, 42, 45, 49, 50, 51, 75, 90, 92, 98, 99, 100, 101, 104, 106, 107, 113, 119, 125, 129, 135, 138, 143, 145, 149, 153, 156, 159, 160, 162, 173, 174, 175, 176, 179, 183, 185, 186, 193, 195, 200, 204, 208, 214, 218, 219, 234, 243, 245, 246, 247, 249], "jacobian": [2, 41, 91, 122, 140, 165, 198], "product": [2, 3, 4, 6, 38, 40, 41, 47, 60, 61, 86, 90, 91, 101, 113, 122, 123, 135, 138, 140, 164, 165, 172, 173, 174, 181, 193, 198, 202, 222, 238], "norm": [2, 17, 51, 91, 95, 109, 122, 151, 155, 165, 179], "1021": 2, "4020": 2, "314": 2, "6695": 2, "613": 2, "4944": [2, 201], "v": [2, 7, 17, 29, 41, 51, 91, 103, 104, 106, 118, 136, 140, 153, 159, 161, 175, 180, 198, 201, 202, 246], "0001": [2, 17, 89, 91, 143, 209], "kfloat": [2, 3, 59, 183, 199], "102": 2, "4000": [2, 94, 175, 233], "1024": [2, 5, 16, 19, 40, 201, 219], "0000": [2, 21, 91, 201, 246], "stop": [2, 4, 5, 21, 29, 58, 59, 78, 80, 89, 91, 103, 109, 128, 135, 146, 158, 160, 164, 168, 225], "histori": [2, 29, 38, 45, 47, 91, 98, 103, 109, 113, 117, 155, 156], "nogradguard": [2, 240], "block": [2, 5, 6, 8, 10, 17, 20, 21, 29, 30, 45, 48, 77, 78, 91, 103, 115, 116, 124, 134, 135, 143, 153, 156, 160, 161, 162, 163, 168, 200, 201, 203, 224, 227, 234, 249], "pow": [2, 5, 91, 184], "no_grad": [2, 17, 29, 40, 41, 58, 59, 78, 91, 101, 103, 104, 107, 109, 110, 117, 123, 124, 136, 145, 156, 157, 159, 161, 169, 174, 179, 181, 189, 192, 195, 205, 208, 234, 240], "Or": [2, 19, 21, 138, 162, 176, 199, 201, 245], "eq": [2, 17, 21, 48, 124, 161, 179, 192, 209, 225, 245], "bool": [2, 11, 21, 98, 136, 154, 159, 176, 181, 201, 239, 243], "is_leaf": 2, "detach_": [2, 162], "register_hook": 2, "retain_grad": 2, "doc": [2, 4, 6, 60, 91, 98, 99, 108, 132, 135, 141, 142, 160, 162, 178, 198, 214, 218, 232, 243, 244, 245, 250], "calcul": [2, 12, 29, 34, 41, 42, 48, 51, 55, 60, 75, 86, 89, 91, 92, 94, 99, 107, 109, 127, 128, 136, 145, 159, 160, 162, 163, 164, 174, 179, 186, 192, 193, 209, 237], "penalti": [2, 151, 157, 218], "h": [2, 4, 5, 6, 7, 8, 10, 20, 21, 22, 48, 118, 136, 143, 146, 153, 154, 175, 181, 183, 201, 204, 208, 210, 213, 233, 240], "model": [2, 3, 5, 8, 11, 14, 15, 20, 21, 29, 31, 32, 33, 38, 39, 40, 41, 42, 45, 47, 51, 52, 53, 55, 57, 61, 65, 67, 68, 69, 77, 80, 88, 89, 90, 91, 93, 98, 100, 101, 102, 103, 105, 107, 108, 109, 110, 112, 116, 119, 121, 122, 124, 126, 127, 128, 129, 132, 135, 140, 141, 143, 144, 151, 152, 158, 159, 160, 161, 162, 163, 165, 171, 173, 174, 180, 191, 193, 194, 197, 198, 200, 203, 204, 205, 210, 215, 216, 218, 223, 224, 226, 228, 231, 232, 237, 238, 241], "linear": [2, 5, 6, 9, 11, 14, 17, 22, 38, 41, 43, 45, 47, 57, 60, 68, 75, 80, 91, 94, 98, 108, 109, 110, 111, 115, 117, 118, 119, 124, 127, 128, 133, 134, 136, 143, 144, 148, 151, 156, 159, 160, 161, 162, 164, 169, 174, 176, 178, 179, 181, 184, 188, 190, 192, 193, 195, 198, 200, 202, 203, 207, 208, 209, 211, 214, 216, 218, 226, 229, 232, 236, 239, 241], "loss": [2, 3, 5, 6, 7, 9, 11, 14, 15, 17, 29, 35, 38, 41, 47, 65, 67, 68, 69, 72, 73, 75, 77, 80, 89, 91, 94, 97, 101, 106, 107, 110, 111, 117, 118, 119, 122, 123, 124, 127, 134, 135, 145, 146, 148, 152, 153, 156, 159, 161, 162, 164, 168, 169, 175, 179, 183, 192, 205, 208, 209, 222, 228, 232, 241], "target": [2, 3, 4, 6, 14, 16, 17, 20, 21, 34, 42, 45, 48, 54, 60, 75, 80, 92, 98, 101, 104, 106, 107, 113, 116, 119, 124, 127, 128, 134, 135, 141, 143, 152, 154, 157, 159, 160, 161, 162, 164, 169, 171, 175, 176, 179, 183, 192, 193, 197, 199, 201, 208, 209, 210, 213, 214, 219, 221, 222, 240], "mseloss": [2, 12, 34, 45, 109, 133, 134, 148, 160, 241], "grad_output": [2, 8, 10, 78, 80], "ones_lik": [2, 47, 98, 141], "create_graph": [2, 130], "gradient_penalti": 2, "dim": [2, 4, 5, 11, 19, 30, 47, 94, 98, 109, 124, 134, 155, 157, 160, 161, 162, 169, 185, 186, 199, 209, 240], "combined_loss": 2, "1042": 2, "0638": 2, "0103": 2, "0723": 2, "2543": 2, "1222": 2, "0071": 2, "0814": 2, "1683": 2, "1052": 2, "0355": 2, "document": [2, 4, 5, 6, 18, 29, 45, 51, 60, 61, 81, 86, 89, 91, 92, 95, 97, 98, 99, 103, 111, 113, 117, 122, 133, 135, 138, 140, 142, 143, 156, 161, 162, 163, 168, 171, 173, 174, 176, 186, 192, 198, 199, 202, 204, 207, 208, 209, 216, 222, 234, 239, 240, 243, 245, 246, 250], "link": [2, 4, 5, 6, 10, 12, 20, 21, 33, 35, 51, 58, 59, 90, 107, 114, 116, 119, 135, 138, 140, 180, 186, 197, 199, 201, 208, 243, 244, 249], "subclass": [2, 5, 6, 22, 30, 31, 67, 81, 91, 94, 95, 107, 110, 122, 126, 155, 161, 169, 186, 217, 218, 240], "encod": [2, 7, 38, 39, 40, 45, 47, 77, 78, 95, 102, 105, 113, 118, 119, 123, 126, 151, 153, 158, 162, 175, 181, 190, 193, 201, 218, 239], "method": [2, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 19, 21, 22, 29, 30, 36, 38, 42, 45, 48, 50, 54, 58, 59, 60, 75, 81, 86, 91, 92, 94, 95, 97, 98, 101, 103, 107, 111, 113, 115, 121, 126, 130, 133, 136, 138, 140, 141, 142, 143, 144, 145, 148, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 169, 171, 173, 179, 180, 184, 192, 193, 201, 202, 204, 209, 211, 212, 213, 216, 217, 218, 221, 229, 232, 233, 234, 245], "forward": [2, 3, 4, 8, 10, 11, 12, 14, 17, 20, 21, 22, 29, 30, 35, 41, 43, 45, 48, 51, 55, 57, 58, 59, 60, 61, 63, 64, 65, 72, 73, 77, 78, 86, 91, 94, 95, 98, 100, 101, 104, 107, 110, 111, 117, 122, 123, 124, 125, 127, 129, 130, 131, 133, 134, 135, 138, 141, 148, 149, 151, 152, 155, 156, 159, 160, 161, 162, 164, 165, 168, 169, 171, 174, 176, 179, 180, 181, 182, 183, 189, 190, 192, 197, 199, 201, 203, 204, 207, 208, 209, 214, 216, 218, 221, 222, 225, 226, 229, 234, 239, 240, 241], "detail": [2, 5, 6, 8, 10, 12, 14, 18, 20, 21, 22, 31, 34, 41, 42, 43, 51, 52, 58, 59, 60, 61, 75, 86, 95, 98, 99, 113, 116, 118, 120, 124, 126, 128, 129, 131, 133, 141, 143, 148, 149, 156, 159, 162, 163, 168, 169, 174, 176, 181, 183, 184, 185, 186, 187, 188, 189, 192, 198, 200, 201, 204, 207, 208, 212, 213, 214, 216, 217, 218, 219, 222, 233, 234, 239], "namespac": [2, 6, 8, 10, 20, 21, 30, 107, 136, 154, 176, 181, 201, 240], "inherit": [2, 11, 20, 35, 50, 60, 86, 94, 98, 99, 101, 142, 145, 148, 158, 175, 186, 188, 190, 205], "linearfunct": 2, "public": [2, 8, 10, 154, 201, 232, 246], "static": [2, 8, 10, 19, 58, 59, 60, 91, 122, 136, 140, 141, 154, 178, 180, 181, 191, 193, 201, 209, 234, 243], "option": [2, 5, 6, 8, 10, 11, 15, 21, 33, 42, 44, 46, 50, 52, 60, 61, 89, 90, 91, 92, 95, 98, 108, 121, 122, 126, 131, 134, 137, 143, 146, 148, 155, 157, 179, 180, 181, 189, 192, 193, 197, 202, 203, 205, 207, 215, 218, 219, 225, 232, 238, 239, 245, 249], "autogradcontext": [2, 8, 10], "ctx": [2, 5, 8, 10, 16, 130, 203], "save_for_backward": [2, 5, 130], "mm": [2, 5, 59, 109, 136, 181, 183, 189, 192, 199, 200, 210, 213], "unsqueez": [2, 45, 58, 59, 68, 80, 98, 109, 110, 117, 138, 152, 157, 159, 160, 162, 169, 197, 199], "expand_a": [2, 17, 179, 192], "tensor_list": [2, 8, 10, 135], "get_saved_vari": 2, "grad_input": [2, 130], "grad_weight": 2, "grad_bia": 2, "Then": [2, 12, 18, 20, 22, 42, 43, 51, 58, 59, 61, 75, 86, 100, 101, 104, 106, 107, 114, 122, 124, 133, 134, 148, 154, 155, 158, 159, 160, 162, 164, 168, 183, 190, 193, 203, 210, 212, 213, 216], "5314": 2, "2807": 2, "4864": 2, "7608": 2, "9101": 2, "0073": 2, "mulconst": [2, 80], "object": [2, 4, 5, 6, 7, 10, 11, 15, 17, 20, 21, 29, 30, 31, 34, 35, 41, 48, 51, 60, 61, 77, 91, 92, 94, 95, 98, 103, 107, 109, 110, 111, 116, 117, 118, 122, 125, 129, 135, 140, 141, 142, 153, 154, 159, 160, 161, 162, 165, 168, 169, 174, 178, 179, 192, 193, 205, 208, 209, 211, 213, 219, 224, 229, 233, 234, 236, 238], "stash": 2, "saved_data": 2, "were": [2, 3, 5, 6, 9, 12, 16, 21, 29, 51, 60, 86, 91, 95, 98, 101, 103, 107, 113, 114, 126, 132, 133, 137, 146, 151, 158, 159, 161, 163, 164, 173, 184, 197, 198, 214, 219, 222, 225], "todoubl": 2, "On": [2, 4, 5, 6, 8, 17, 19, 20, 21, 98, 107, 115, 117, 123, 133, 135, 136, 146, 151, 155, 160, 161, 171, 174, 196, 201, 214, 218, 234], "easiest": [2, 5, 9, 21, 33, 90, 107, 122, 138, 144, 156, 158, 216, 234], "tabl": [2, 14, 19, 91, 106, 108, 115, 122, 123, 135, 136, 143, 161, 162, 168, 172, 219, 225, 249], "set_data": 2, "output_nr": 2, "after": [2, 3, 5, 6, 7, 9, 10, 12, 16, 17, 18, 19, 21, 22, 29, 30, 31, 38, 41, 43, 45, 48, 51, 52, 58, 59, 60, 61, 78, 81, 89, 91, 92, 95, 100, 101, 104, 106, 107, 109, 111, 113, 115, 116, 118, 122, 123, 127, 128, 129, 132, 133, 134, 135, 136, 137, 141, 143, 145, 146, 148, 151, 153, 154, 155, 156, 157, 158, 159, 161, 162, 164, 166, 168, 169, 173, 175, 176, 178, 179, 180, 181, 182, 183, 190, 192, 193, 195, 196, 197, 199, 201, 204, 211, 212, 213, 216, 218, 219, 222, 225, 229, 232, 234, 239, 241], "bug": [2, 5, 10, 21, 97, 143], "report": [2, 10, 21, 51, 75, 89, 91, 94, 95, 99, 122, 136, 143, 160, 162, 163, 225], "fix": [2, 18, 21, 29, 48, 49, 50, 51, 113, 125, 156, 160, 214, 233, 234, 245], "soon": [2, 5, 51, 58, 59, 123, 146, 208], "overview": [2, 5, 6, 11, 52, 54, 94, 113, 120, 121, 122, 127, 128, 133, 134, 135, 141, 154, 158, 160, 161, 162, 164, 168, 184, 185, 187, 191, 194, 200, 215], "alwai": [2, 3, 4, 6, 9, 14, 16, 17, 20, 21, 39, 51, 94, 95, 99, 104, 106, 107, 113, 125, 129, 135, 136, 138, 157, 158, 159, 160, 162, 175, 181, 182, 183, 184, 190, 197, 200, 210, 239, 245], "problem": [2, 4, 6, 11, 16, 20, 21, 48, 50, 51, 57, 61, 100, 106, 107, 110, 115, 117, 126, 141, 143, 144, 148, 151, 156, 158, 160, 162, 168, 171, 173, 184, 186, 200, 219, 220, 234, 245], "question": [2, 4, 5, 6, 8, 10, 20, 21, 48, 77, 92, 123, 135, 136, 142, 164, 180, 185, 200, 219], "forum": [2, 4, 5, 6, 20, 21, 42, 81, 109, 141, 142, 180, 200], "view": [3, 10, 11, 14, 17, 22, 49, 52, 54, 55, 61, 92, 97, 98, 103, 106, 107, 109, 110, 111, 124, 126, 127, 131, 132, 133, 134, 135, 141, 143, 148, 154, 159, 160, 161, 162, 163, 164, 169, 179, 180, 188, 192, 199, 214, 217, 226, 229, 232, 243], "prerequisit": [3, 7, 52, 54, 55, 57, 114, 131, 132, 133, 134, 135, 153, 154, 160, 161, 162, 192], "frontend": [3, 10, 85, 87, 109, 122, 174, 182, 188, 208, 209], "semant": [3, 6, 20, 48, 58, 59, 68, 98, 102, 104, 105, 110, 135, 136, 186, 187, 188, 191, 194, 198, 245], "11": [3, 5, 6, 7, 11, 16, 21, 59, 72, 91, 108, 117, 123, 124, 140, 157, 162, 171, 172, 175, 189, 197, 201, 213, 215, 219, 225, 240, 245, 249], "nvidia": [3, 5, 98, 129, 135, 136, 146, 171, 218, 234, 238], "toolkit": [3, 21, 57, 141, 145, 232], "releas": [3, 4, 6, 10, 21, 40, 49, 108, 111, 118, 123, 124, 125, 138, 141, 161, 163, 168, 197, 201, 203, 208, 209, 225, 234, 245], "greatli": [3, 6, 48, 91, 107, 159], "cpu": [3, 5, 6, 8, 10, 11, 16, 17, 18, 21, 30, 35, 38, 40, 41, 42, 47, 51, 60, 73, 75, 83, 89, 91, 98, 101, 107, 108, 109, 117, 122, 124, 133, 134, 135, 136, 146, 151, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 168, 172, 175, 179, 181, 182, 183, 189, 192, 195, 199, 203, 205, 211, 214, 218, 219, 220, 222, 225, 238, 239], "overhead": [3, 5, 6, 10, 55, 108, 123, 124, 133, 144, 146, 148, 153, 157, 160, 162, 163, 168, 171, 173, 174, 219, 225, 234], "increas": [3, 5, 6, 16, 17, 18, 34, 35, 42, 75, 89, 92, 107, 123, 124, 126, 128, 131, 134, 141, 157, 168, 179, 189, 192, 202, 217, 218, 219, 222, 233, 234, 237, 238], "mostli": [3, 10, 17, 86, 91, 116, 127, 162, 164, 176], "util": [3, 5, 7, 10, 17, 20, 21, 22, 31, 35, 42, 48, 50, 52, 54, 60, 94, 97, 99, 107, 108, 110, 111, 115, 116, 117, 118, 119, 122, 123, 124, 134, 135, 136, 140, 141, 143, 144, 146, 151, 153, 154, 156, 157, 158, 161, 164, 168, 169, 171, 173, 174, 175, 179, 181, 183, 188, 189, 192, 193, 195, 197, 199, 201, 202, 205, 207, 208, 209, 210, 212, 213, 214, 217, 218, 224, 227, 232, 233, 239], "deploy": [3, 4, 22, 40, 60, 90, 111, 112, 126, 174, 197, 208, 215, 216, 222, 238, 239], "appear": [3, 11, 20, 22, 106, 214, 222, 245], "heart": [3, 48, 113, 224, 246], "veri": [3, 4, 5, 6, 8, 16, 17, 19, 20, 21, 22, 38, 43, 45, 47, 48, 58, 59, 60, 61, 65, 75, 77, 78, 86, 92, 95, 101, 103, 107, 110, 113, 115, 117, 124, 125, 127, 134, 135, 148, 151, 156, 159, 160, 162, 163, 164, 166, 168, 169, 173, 175, 179, 184, 186, 190, 198, 214, 222, 225, 233, 234, 246, 247], "time": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 19, 21, 22, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 78, 80, 81, 83, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 103, 104, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 171, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 196, 197, 198, 199, 203, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 234, 235, 236, 237, 238, 240, 243, 245], "compil": [3, 4, 6, 8, 10, 19, 20, 22, 60, 86, 100, 122, 135, 142, 165, 172, 197, 200, 205, 208, 211, 219, 225, 233, 234, 240, 243], "boost": [3, 101, 143, 144, 173, 200, 205, 208, 209, 234], "demonstr": [3, 7, 9, 14, 18, 19, 20, 22, 40, 41, 49, 56, 61, 77, 86, 92, 94, 99, 113, 121, 122, 123, 124, 125, 127, 129, 130, 133, 134, 136, 137, 140, 141, 142, 143, 149, 153, 154, 158, 160, 161, 162, 163, 168, 174, 176, 181, 182, 183, 186, 188, 190, 195, 196, 197, 207, 209, 210, 212, 213, 216, 218, 219, 222, 224, 225, 230, 237, 239, 241, 245, 246, 247], "mnist": [3, 6, 31, 42, 45, 75, 80, 94, 97, 99, 120, 121, 122, 124, 126, 129, 135, 137, 152, 161, 166, 169, 209, 221, 238], "libtorch": [3, 6, 20, 21, 182, 197, 199, 201, 208, 210, 213, 238, 240], "counterpart": [3, 134, 143, 190, 208, 234, 239], "syntax": [3, 21, 22, 47, 60, 85, 87, 88, 111, 122, 219, 229], "depict": [3, 97, 118], "chunk": [3, 5, 7, 54, 118, 135, 153], "batch": [3, 5, 6, 14, 17, 19, 31, 34, 35, 36, 40, 43, 45, 48, 50, 51, 52, 54, 55, 60, 61, 75, 80, 81, 89, 91, 92, 94, 97, 98, 99, 104, 107, 109, 111, 113, 117, 119, 121, 122, 123, 124, 125, 126, 127, 131, 134, 135, 136, 137, 138, 145, 146, 148, 149, 152, 156, 157, 158, 159, 161, 162, 163, 165, 166, 168, 169, 171, 172, 174, 175, 178, 179, 181, 186, 188, 191, 197, 198, 204, 209, 211, 218, 219, 228, 229, 230], "data_load": [3, 6, 17, 175, 179, 192, 224], "zero_grad": [3, 6, 17, 34, 45, 91, 107, 117, 123, 124, 133, 135, 156, 159, 160, 162, 169, 208, 209, 237], "nll_loss": [3, 124, 135, 161, 209], "updat": [3, 6, 10, 11, 12, 13, 14, 17, 19, 21, 34, 40, 41, 42, 48, 51, 61, 69, 72, 91, 101, 106, 107, 109, 110, 111, 117, 123, 124, 126, 129, 136, 138, 146, 158, 159, 161, 162, 168, 175, 179, 181, 184, 192, 197, 200, 205, 207, 209, 210, 216, 218, 228, 236, 241], "captur": [3, 4, 6, 20, 21, 22, 51, 60, 91, 124, 140, 171, 189, 192, 219], "But": [3, 6, 8, 10, 18, 40, 42, 43, 51, 75, 80, 92, 98, 103, 106, 116, 125, 146, 151, 152, 159, 173, 175, 179, 181, 184, 187, 198, 207, 209, 211, 216, 219, 239, 245], "slightli": [3, 5, 21, 123, 135, 157, 164, 187, 219, 234], "prealloc": 3, "reus": [3, 10, 65, 80, 107, 110, 130, 136, 140, 151, 159, 173, 174, 181, 182, 230, 234, 238], "tensoropt": 3, "floatcuda": 3, "dtype": [3, 8, 10, 47, 91, 98, 103, 130, 136, 159, 172, 175, 176, 181, 187, 192, 193, 199, 202, 207, 208, 211, 216, 218, 239], "longcuda": 3, "klong": 3, "zero": [3, 6, 11, 17, 29, 34, 39, 45, 47, 48, 91, 92, 94, 95, 98, 99, 106, 107, 109, 117, 123, 124, 127, 128, 134, 135, 149, 151, 154, 155, 156, 159, 160, 162, 164, 169, 175, 181, 184, 186, 187, 189, 193, 202, 209, 211, 218, 223, 225, 231, 233, 234, 238, 239, 241], "ktrainbatchs": 3, "28": [3, 6, 7, 31, 95, 97, 107, 137, 152, 169, 173, 197, 201, 209, 211, 219, 233], "copy_": [3, 38, 47, 108, 143, 160], "training_step": 3, "void": [3, 5, 6, 20, 21, 59, 143, 154, 183, 201, 219, 225, 233], "cudagraph": 3, "cudastream": 3, "capturestream": 3, "getstreamfrompool": 3, "setcurrentcudastream": 3, "capture_begin": 3, "capture_end": 3, "warm": [3, 19, 71, 74, 108, 168, 173, 174, 196, 219, 225, 234], "side": [3, 18, 50, 51, 106, 137, 146, 152, 154, 159, 160, 168, 183, 214, 243], "prepar": [3, 11, 17, 22, 42, 50, 51, 58, 59, 68, 69, 97, 104, 110, 111, 116, 122, 134, 136, 137, 154, 158, 160, 181, 190, 191, 193, 197, 202, 203, 207, 210, 215, 216, 224, 225, 227, 238], "cach": [3, 117, 136, 143, 168, 173, 174, 181, 234], "cubla": [3, 219], "cudnn": [3, 5, 80, 117, 129, 146, 218], "warmupstream": 3, "int": [3, 4, 5, 6, 9, 11, 16, 17, 20, 21, 50, 52, 54, 58, 59, 123, 124, 135, 136, 143, 154, 160, 161, 162, 168, 171, 175, 178, 181, 183, 199, 201, 202, 204, 208, 211, 239, 240, 243], "num_warmup_it": 3, "success": [3, 6, 21, 75, 103, 126, 143, 164, 183, 197, 199, 214], "replai": [3, 22, 78, 145], "spin": [3, 60, 94, 173], "ordinari": [3, 189], "epoch": [3, 6, 7, 9, 14, 17, 31, 34, 35, 51, 52, 54, 89, 94, 97, 101, 107, 111, 115, 117, 118, 119, 123, 124, 126, 135, 146, 153, 156, 158, 162, 169, 175, 209, 228, 232], "59584": 3, "60000": [3, 135], "3921": 3, "2051": 3, "accuraci": [3, 9, 17, 18, 35, 42, 94, 99, 107, 120, 121, 122, 123, 124, 126, 149, 155, 156, 157, 161, 166, 169, 174, 179, 181, 189, 190, 207, 215, 216, 218, 232, 237, 238], "938": [3, 6, 146], "1826": 3, "1273": 3, "960": 3, "1796": 3, "1012": [3, 146], "968": 3, "1603": 3, "0869": 3, "973": 3, "2315": 3, "0736": 3, "978": 3, "0511": [3, 181], "0704": 3, "977": [3, 146], "7": [3, 5, 6, 16, 17, 20, 21, 33, 50, 58, 59, 83, 86, 91, 103, 108, 116, 117, 123, 124, 134, 135, 145, 146, 148, 156, 157, 171, 172, 174, 175, 183, 195, 197, 199, 200, 201, 207, 209, 210, 212, 213, 215, 216, 218, 234, 239, 249], "0802": 3, "0654": 3, "979": [3, 175], "0774": 3, "0604": 3, "980": [3, 173], "0669": 3, "0544": 3, "984": [3, 175], "0219": 3, "0517": 3, "983": 3, "real": [3, 6, 18, 29, 35, 51, 53, 57, 58, 91, 100, 101, 106, 122, 124, 127, 128, 135, 148, 154, 159, 164, 171, 173, 186, 188, 192, 207, 219, 222], "0m44": 3, "287": [3, 174, 245], "018": 3, "0m1": 3, "116": [3, 181], "produc": [3, 4, 5, 6, 11, 20, 21, 22, 60, 68, 110, 113, 115, 118, 126, 137, 140, 142, 144, 146, 148, 158, 159, 164, 176, 179, 180, 181, 192, 199, 218, 222, 234, 245], "4092": 3, "2037": 3, "2039": 3, "1274": 3, "961": 3, "1779": 3, "1017": [3, 103], "1559": 3, "0871": 3, "972": 3, "2240": 3, "0735": [3, 175], "0520": 3, "0710": [3, 91], "0935": [3, 103], "0666": [3, 21], "0744": 3, "0603": 3, "981": 3, "0762": 3, "0547": 3, "0207": 3, "0525": [3, 201], "0m6": 3, "952": [3, 143], "0m7": 3, "048": [3, 200], "0m0": 3, "619": 3, "gain": [3, 5, 168, 173], "six": [3, 158, 245], "kind": [3, 5, 6, 17, 21, 34, 42, 45, 48, 58, 59, 75, 92, 99, 100, 104, 111, 120, 122, 136, 174, 192, 239], "larg": [3, 5, 6, 7, 12, 14, 16, 21, 34, 38, 40, 48, 89, 92, 95, 97, 104, 106, 107, 110, 117, 121, 122, 123, 124, 126, 129, 133, 135, 137, 138, 148, 149, 153, 158, 159, 161, 162, 163, 171, 173, 174, 175, 186, 195, 211, 218, 225, 226, 234, 243, 245], "improv": [3, 5, 6, 8, 10, 17, 19, 34, 40, 48, 55, 94, 98, 107, 121, 122, 123, 124, 129, 141, 146, 148, 151, 156, 159, 163, 164, 171, 173, 174, 181, 189, 192, 197, 200, 203, 205, 207, 208, 210, 216, 218, 219, 232, 234, 246], "due": [3, 5, 6, 16, 20, 51, 58, 60, 86, 98, 118, 123, 124, 133, 151, 156, 161, 171, 173, 179, 186, 195, 205, 209, 222, 244, 245], "heavi": [3, 6, 48, 103, 211], "impact": [3, 12, 34, 89, 160, 202, 217, 239, 241], "smaller": [3, 9, 34, 81, 95, 106, 107, 124, 156, 158, 160, 196, 201, 211, 219, 222], "nevertheless": [3, 5, 17, 21, 146, 158], "primari": [4, 5, 6, 141, 172, 173, 174, 199, 233, 234], "program": [4, 5, 16, 19, 20, 21, 22, 57, 60, 61, 95, 100, 103, 106, 127, 142, 161, 174, 192, 219, 234, 240], "languag": [4, 5, 6, 7, 15, 19, 21, 22, 42, 48, 57, 58, 59, 60, 80, 81, 95, 100, 104, 112, 116, 120, 122, 126, 127, 128, 136, 153, 162, 164, 178, 190, 200, 222, 234, 239, 240, 244, 245, 246], "suitabl": [4, 8, 39, 131, 135, 138, 211, 233], "prefer": [4, 6, 8, 52, 58, 144, 149, 154, 158, 173, 189, 218, 239], "eas": [4, 5, 86, 98, 99, 123, 174, 208, 238], "situat": [4, 21, 22, 91, 98, 129, 130, 133, 135, 175, 190], "properti": [4, 5, 6, 11, 19, 21, 22, 29, 38, 47, 91, 94, 98, 103, 106, 126, 151, 164, 173, 174, 185, 201, 208, 218, 219, 236, 240, 243], "unfavor": 4, "environ": [4, 5, 6, 11, 16, 20, 22, 33, 40, 54, 61, 86, 90, 92, 97, 111, 114, 115, 122, 123, 124, 132, 133, 134, 135, 143, 148, 154, 159, 160, 161, 162, 172, 173, 197, 199, 200, 201, 203, 204, 205, 210, 211, 214, 217, 219, 233, 234, 239, 240, 241], "latter": [4, 5, 6, 60, 61, 126, 160], "land": [4, 21, 113, 145, 186, 208, 241], "latenc": [4, 6, 122, 126, 132, 143, 157, 171, 173, 174, 182, 189, 211], "strict": [4, 111, 185, 208, 235], "bind": [4, 6, 10, 21, 122, 173, 174, 234, 245], "java": [4, 58, 174, 197, 210, 211], "rust": 4, "paragraph": [4, 6, 21, 118, 246, 249], "outlin": [4, 5, 6, 21, 215], "pure": [4, 5, 6, 10, 21, 122, 127, 130, 137, 152], "journei": [4, 6, 51, 136], "enabl": [4, 5, 6, 8, 11, 14, 16, 17, 21, 31, 40, 45, 54, 55, 58, 59, 60, 61, 77, 91, 98, 111, 118, 123, 124, 126, 129, 130, 133, 135, 136, 143, 146, 155, 157, 158, 168, 169, 172, 173, 174, 176, 180, 184, 186, 188, 190, 191, 197, 200, 205, 208, 212, 213, 214, 216, 218, 225, 227, 238, 241, 243], "vanilla": [4, 5, 6, 21, 48, 65, 101, 110, 184, 241], "eager": [4, 10, 21, 60, 86, 88, 122, 143, 146, 163, 171, 178, 190, 192, 209, 234], "discuss": [4, 5, 6, 8, 10, 14, 21, 42, 75, 81, 91, 94, 95, 99, 103, 104, 116, 123, 124, 134, 141, 142, 143, 148, 149, 171, 173, 174, 180, 184, 185, 186, 187, 216], "littl": [4, 22, 51, 61, 94, 101, 107, 113, 158, 160, 162, 163, 166, 168], "effort": [4, 48, 50, 51, 179, 190, 191, 233], "next": [4, 5, 6, 8, 9, 11, 12, 14, 17, 18, 20, 21, 31, 40, 41, 48, 50, 52, 54, 55, 58, 59, 60, 77, 80, 83, 86, 91, 94, 95, 98, 100, 104, 107, 111, 115, 117, 118, 122, 123, 124, 125, 127, 128, 129, 130, 132, 136, 137, 142, 143, 145, 148, 149, 152, 156, 159, 160, 161, 162, 164, 168, 169, 174, 175, 178, 179, 182, 183, 186, 187, 190, 192, 196, 201, 205, 208, 210, 211, 214, 222, 225, 243, 245, 246], "mechan": [4, 5, 6, 11, 29, 48, 55, 60, 99, 118, 122, 130, 142, 151, 164, 166, 168, 174, 205, 208, 209, 214], "evalu": [4, 6, 9, 12, 17, 18, 34, 36, 75, 91, 92, 97, 111, 119, 144, 149, 159, 161, 169, 171, 175, 178, 188, 209, 228, 229, 230], "onc": [4, 5, 6, 8, 10, 11, 14, 18, 19, 20, 21, 22, 29, 31, 34, 50, 51, 55, 60, 92, 94, 97, 98, 99, 100, 104, 113, 131, 138, 146, 151, 155, 157, 158, 159, 161, 164, 169, 174, 181, 183, 190, 204, 208, 211, 214, 218, 219, 227, 234], "record": [4, 6, 8, 17, 18, 21, 22, 29, 41, 48, 60, 107, 111, 122, 123, 124, 127, 129, 130, 158, 159, 161, 162, 197, 209, 222, 224, 225, 228, 239], "limit": [4, 6, 9, 10, 11, 17, 48, 75, 120, 124, 136, 137, 145, 146, 148, 152, 164, 171, 174, 179, 181, 182, 183, 189, 192, 211, 216, 219, 222, 244], "explicit": [4, 6, 19, 21, 60, 138, 146, 162, 185, 193, 202, 214, 218, 245], "pars": [4, 5, 21, 48, 50, 106, 116, 123, 124, 126, 202, 219, 245], "subject": [4, 11, 21, 40, 113, 124, 140, 164, 182, 183, 188, 197, 198, 199, 200, 203, 205, 210, 219], "constraint": [4, 6, 12, 16, 60, 86, 101, 126, 151, 158, 193, 218, 219, 239], "impos": [4, 211, 220], "guidanc": [4, 8, 173, 174, 190, 218], "offici": [4, 113, 115, 135, 159, 178, 207, 208, 239], "jit": [4, 6, 8, 17, 19, 20, 22, 58, 59, 60, 86, 111, 136, 141, 146, 171, 174, 179, 181, 182, 183, 189, 192, 196, 197, 199, 200, 201, 202, 205, 207, 208, 210, 211, 212, 213, 219, 225, 234, 239, 240], "scriptmodul": [4, 20, 21, 22, 86, 196, 210, 239, 240], "embed": [4, 7, 14, 19, 21, 48, 60, 77, 95, 100, 102, 104, 105, 109, 111, 115, 118, 119, 122, 123, 136, 153, 161, 162, 164, 169, 172, 178, 183, 188, 190, 228, 245], "resnet18": [4, 41, 117, 146, 156, 157, 168, 179, 190, 192, 240], "normal": [4, 6, 8, 11, 12, 17, 18, 19, 34, 36, 39, 48, 50, 51, 58, 59, 60, 83, 86, 92, 94, 95, 99, 101, 106, 110, 111, 117, 124, 127, 129, 135, 138, 151, 156, 157, 160, 161, 163, 164, 169, 171, 174, 179, 185, 192, 197, 202, 204, 205, 208, 209, 211, 212, 213, 216, 228, 229, 230, 234, 239, 245], "rand": [4, 5, 6, 19, 47, 86, 91, 98, 130, 173, 174, 175, 176, 182, 192, 199, 208, 211, 212, 213, 214, 234, 239, 240], "224": [4, 12, 17, 18, 50, 58, 59, 117, 138, 141, 156, 157, 173, 174, 179, 182, 183, 189, 192, 197, 199, 204, 207, 208, 211, 212, 213, 239, 240], "traced_script_modul": [4, 211], "ident": [4, 6, 54, 86, 91, 98, 99, 107, 110, 132, 141, 149, 156, 169, 181, 187, 189, 207, 219], "2698": 4, "0381": 4, "4023": 4, "3010": 4, "0448": 4, "slicebackward": 4, "circumst": [4, 5, 218], "emploi": [4, 164, 168], "particular": [4, 5, 6, 8, 11, 21, 31, 40, 42, 50, 60, 89, 91, 92, 94, 95, 106, 126, 127, 135, 137, 138, 149, 152, 161, 175, 176, 184, 185, 187, 204, 211, 234], "form": [4, 6, 9, 12, 21, 39, 45, 48, 51, 60, 100, 107, 109, 113, 116, 122, 125, 128, 138, 143, 164, 188, 195, 204, 214, 222, 224, 234, 245], "accordingli": [4, 10, 16, 20, 148, 159, 160, 183, 200, 243], "sai": [4, 5, 6, 41, 50, 98, 101, 103, 106, 113, 115, 125, 137, 144, 148, 155, 168, 210, 222, 224, 246], "mymodul": [4, 6, 195, 203], "def": [4, 5, 6, 8, 11, 16, 17, 19, 20, 21, 52, 54, 86, 91, 111, 113, 115, 117, 123, 124, 130, 133, 134, 135, 136, 138, 141, 143, 151, 154, 156, 159, 160, 161, 162, 169, 174, 175, 176, 179, 180, 181, 182, 184, 189, 192, 193, 195, 198, 201, 202, 203, 204, 205, 207, 209, 211, 214, 216, 219, 229, 239, 241, 245], "__init__": [4, 5, 6, 11, 17, 19, 20, 30, 35, 50, 52, 91, 94, 95, 101, 111, 124, 133, 134, 135, 141, 155, 159, 160, 161, 162, 169, 174, 175, 176, 179, 180, 189, 192, 195, 202, 203, 205, 207, 209, 211, 214, 216, 221, 229, 239, 245], "self": [4, 5, 6, 8, 10, 11, 17, 19, 20, 22, 31, 48, 52, 54, 60, 91, 101, 107, 108, 110, 111, 118, 122, 124, 133, 134, 135, 141, 143, 145, 151, 159, 160, 161, 162, 168, 169, 174, 175, 176, 179, 180, 181, 188, 189, 192, 195, 202, 203, 205, 207, 209, 210, 211, 214, 216, 225, 229, 239], "n": [4, 5, 6, 7, 12, 17, 20, 21, 29, 41, 47, 59, 72, 73, 86, 91, 95, 98, 107, 109, 110, 115, 118, 120, 123, 124, 133, 135, 136, 144, 145, 149, 153, 155, 159, 160, 161, 162, 164, 169, 175, 179, 181, 192, 198, 201, 204, 208, 234, 240], "super": [4, 5, 6, 11, 16, 17, 18, 19, 20, 22, 59, 91, 111, 124, 133, 134, 141, 145, 159, 160, 161, 162, 169, 174, 176, 189, 192, 195, 201, 202, 203, 207, 209, 210, 211, 214, 222, 229], "mv": [4, 109], "my_modul": 4, "20": [4, 6, 7, 17, 21, 58, 59, 61, 72, 86, 89, 91, 98, 108, 117, 124, 126, 133, 135, 141, 146, 148, 155, 160, 162, 174, 175, 182, 202, 209, 211, 219, 225, 233, 241, 249], "sm": [4, 168], "exclud": [4, 8, 41, 225], "doesn": [4, 8, 10, 13, 22, 58, 101, 103, 106, 107, 113, 125, 144, 146, 155, 171, 173, 176, 180, 184, 190, 198, 201, 216, 233, 234, 245], "yet": [4, 6, 10, 11, 16, 21, 49, 75, 91, 94, 98, 113, 135, 161, 164, 172, 176, 181, 188, 205, 208, 212, 213, 234], "could": [4, 5, 6, 8, 10, 11, 21, 51, 60, 89, 91, 95, 100, 101, 103, 104, 106, 108, 123, 124, 125, 127, 128, 135, 138, 146, 148, 158, 159, 160, 161, 162, 164, 168, 169, 173, 174, 175, 176, 184, 186, 192, 198, 205, 208, 209, 234], "ignor": [4, 17, 50, 104, 106, 111, 141, 154, 175, 176, 179, 182, 185, 186, 188, 192, 207, 218, 225, 235], "readi": [4, 6, 9, 10, 14, 20, 21, 40, 48, 58, 59, 92, 94, 99, 100, 101, 106, 107, 122, 123, 134, 135, 149, 154, 158, 160, 161, 162, 172, 175, 182, 189, 201, 204, 211, 212, 213, 216, 225, 239], "hand": [4, 5, 6, 8, 16, 21, 61, 75, 98, 100, 106, 107, 128, 135, 138, 152, 171, 174, 185, 222], "shown": [4, 6, 8, 17, 18, 19, 51, 58, 59, 91, 98, 107, 113, 116, 126, 136, 143, 145, 156, 159, 160, 162, 163, 168, 171, 173, 174, 180, 183, 185, 186, 187, 190, 204, 208, 214, 216, 222, 224, 239, 241, 243, 245], "filenam": [4, 6, 108, 116, 218], "traced_resnet_model": 4, "pt": [4, 6, 20, 21, 52, 58, 59, 111, 117, 120, 123, 124, 136, 183, 189, 197, 199, 201, 207, 208, 209, 210, 211, 212, 213, 216, 229, 240], "my_module_model": 4, "left": [4, 29, 41, 45, 48, 51, 64, 86, 91, 97, 98, 101, 106, 110, 111, 113, 135, 136, 145, 149, 158, 159, 161, 168, 169, 214, 222, 228, 238, 243, 245], "realm": [4, 6], "cross": [4, 7, 8, 13, 18, 42, 51, 94, 95, 99, 119, 126, 153, 173, 234, 237, 245], "sphere": 4, "distribut": [4, 5, 6, 15, 17, 51, 75, 77, 81, 83, 89, 94, 98, 99, 101, 106, 113, 118, 122, 123, 124, 126, 131, 132, 136, 146, 148, 154, 158, 160, 168, 173, 181, 191, 195, 201, 203, 211, 219, 232, 238, 241], "encompass": 4, "share": [4, 5, 6, 10, 11, 16, 20, 21, 38, 47, 54, 66, 70, 80, 83, 89, 103, 109, 113, 122, 123, 125, 133, 135, 145, 158, 160, 161, 162, 173, 190, 201, 208, 219, 233], "header": [4, 5, 6, 8, 20, 21, 154, 183, 197, 201, 210, 213, 219, 243, 245, 246], "cmake": [4, 6, 183, 199, 208, 240], "futur": [4, 7, 16, 19, 20, 40, 48, 58, 59, 107, 108, 109, 118, 119, 124, 134, 136, 140, 145, 153, 154, 156, 159, 160, 161, 162, 176, 178, 182, 183, 187, 197, 201, 210, 236, 239], "begin": [4, 5, 6, 7, 11, 12, 17, 20, 21, 22, 29, 41, 48, 49, 51, 54, 58, 59, 75, 86, 91, 94, 104, 106, 113, 115, 116, 118, 123, 136, 141, 153, 156, 159, 161, 168, 169, 186, 211, 216, 218, 219, 221, 224, 225, 228, 229, 230, 235, 236, 237, 245], "iostream": [4, 5, 6, 20, 21, 208], "argc": [4, 20, 21, 208, 240], "const": [4, 5, 6, 8, 10, 20, 21, 59, 143, 154, 201, 208, 210, 219, 233, 240], "char": [4, 20, 21, 59, 143, 201, 208, 240], "cerr": [4, 20, 21, 208, 240], "app": [4, 21, 120, 138, 189, 197, 208, 210, 215, 216, 238, 239], "try": [4, 6, 12, 17, 19, 20, 21, 22, 34, 38, 40, 42, 45, 47, 48, 51, 52, 57, 58, 59, 61, 75, 91, 98, 99, 100, 101, 103, 107, 108, 126, 127, 128, 141, 143, 145, 148, 149, 154, 155, 158, 159, 164, 168, 171, 173, 179, 182, 185, 192, 201, 204, 205, 208, 210, 218, 219, 222, 229, 232, 240, 245, 246], "deseri": [4, 6, 21, 111, 179, 192, 229, 240], "catch": [4, 8, 11, 20, 58, 201, 208, 210, 240], "c10": [4, 8, 10, 20, 154, 183, 201, 208, 219, 233, 240], "ok": [4, 106, 160, 245], "relev": [4, 6, 52, 57, 95, 100, 106, 113, 114, 123, 155, 228, 230, 234, 236], "accept": [4, 5, 18, 39, 89, 91, 104, 115, 116, 126, 138, 140, 144, 149, 152, 158, 161, 168, 176, 193, 195, 198, 203, 225, 234, 239], "proce": [4, 11, 22, 101, 143, 156, 164, 222, 234], "examin": [4, 11, 20, 22, 58, 59, 91, 92, 97, 99, 142], "moment": [4, 6, 11, 124, 176, 187, 199, 211], "cpp": [4, 5, 6, 8, 20, 21, 121, 122, 143, 182, 201, 208, 233, 240], "cmakelist": [4, 6, 20, 21, 201, 208, 240], "txt": [4, 5, 6, 20, 21, 48, 116, 127, 128, 136, 143, 157, 164, 181, 201, 208, 225, 240], "cmake_minimum_requir": [4, 6, 20, 21, 201, 208, 240], "fatal_error": [4, 6, 20, 21, 201, 208, 240], "custom_op": [4, 240], "find_packag": [4, 6, 20, 21, 208, 240], "add_execut": [4, 6, 20, 21, 208, 240], "target_link_librari": [4, 6, 20, 21, 201, 208, 240], "torch_librari": [4, 6, 8, 20, 21, 208, 240], "set_properti": [4, 6, 208, 240], "cxx_standard": [4, 6, 208, 240], "14": [4, 6, 20, 21, 72, 94, 117, 124, 143, 173, 201, 208, 209, 216, 219, 225, 249], "last": [4, 6, 11, 17, 21, 30, 41, 48, 51, 52, 59, 60, 75, 86, 89, 94, 95, 98, 99, 101, 104, 113, 117, 122, 125, 127, 128, 135, 141, 143, 148, 156, 158, 159, 160, 162, 164, 165, 169, 173, 175, 183, 184, 187, 207, 208, 210, 216, 218, 228, 234, 238, 239], "thing": [4, 5, 6, 8, 19, 20, 21, 22, 29, 41, 42, 45, 48, 58, 59, 86, 89, 91, 94, 98, 99, 100, 101, 103, 104, 106, 107, 113, 116, 125, 126, 130, 131, 132, 135, 138, 142, 143, 146, 151, 157, 158, 166, 174, 179, 190, 192, 201, 204, 219, 229, 237, 245], "grab": [4, 6, 51, 97, 157, 162], "latest": [4, 6, 10, 18, 89, 92, 110, 111, 122, 136, 156, 157, 158, 161, 164, 166, 171, 201, 228, 232, 243], "stabl": [4, 18, 23, 24, 25, 26, 27, 100, 113, 139, 157, 167, 170, 178, 209, 211, 218, 224, 243], "page": [4, 6, 10, 20, 21, 49, 53, 61, 107, 108, 110, 127, 138, 162, 168, 172, 197, 200, 201, 202, 206, 208, 210, 234, 247, 249], "websit": [4, 6, 92, 159, 214, 217], "unzip": [4, 6, 17, 49, 178, 179, 192, 201], "archiv": [4, 5, 6, 22, 146], "lib": [4, 5, 6, 10, 16, 20, 21, 117, 143, 182, 197, 201, 208, 233], "against": [4, 20, 21, 34, 35, 42, 60, 84, 95, 97, 135, 146, 158, 203, 208, 219, 222], "window": [4, 5, 6, 18, 42, 50, 95, 106, 133, 161, 168, 175, 199, 204, 214, 245], "debug": [4, 6, 8, 17, 22, 58, 59, 60, 80, 100, 122, 125, 165, 190, 191, 219, 233], "abi": [4, 5, 6, 20, 21, 197, 199, 201, 208], "plan": [4, 6, 10, 16, 60, 111, 123, 172, 179, 182, 187, 188, 192, 199, 201, 212], "correct": [4, 5, 6, 8, 10, 11, 12, 13, 17, 34, 41, 42, 45, 48, 60, 64, 75, 86, 89, 91, 92, 94, 95, 98, 99, 100, 101, 107, 110, 123, 124, 125, 127, 129, 133, 143, 146, 151, 158, 160, 161, 164, 166, 169, 179, 188, 192, 209, 218, 243], "laid": 4, "within": [4, 5, 16, 19, 21, 61, 86, 91, 92, 97, 107, 108, 109, 130, 136, 141, 143, 151, 155, 159, 161, 173, 174, 181, 187, 188, 190, 199, 201, 204, 219, 226, 234, 243, 245], "mkdir": [4, 6, 21, 178, 189, 201], "dcmake_prefix_path": [4, 6, 20, 21, 208, 240], "config": [4, 6, 10, 18, 89, 124, 126, 136, 157, 173, 174, 176, 181, 192, 208, 209], "someth": [4, 5, 6, 11, 17, 21, 22, 42, 89, 94, 98, 101, 103, 113, 116, 135, 143, 156, 157, 164, 198, 219, 222, 233, 245], "root": [4, 5, 6, 20, 21, 29, 31, 41, 50, 51, 94, 100, 109, 129, 143, 161, 162, 175, 183, 197, 204, 208, 211, 214, 224, 232, 239, 243], "4b5a67132e81": 4, "identif": [4, 6, 20, 21, 208], "gnu": [4, 5, 6, 20, 21, 208, 234], "cxx": [4, 6, 20, 21, 197, 199, 201, 208], "check": [4, 5, 6, 7, 8, 13, 17, 18, 20, 21, 22, 30, 33, 34, 35, 38, 40, 41, 42, 43, 48, 49, 51, 54, 58, 59, 75, 77, 86, 91, 94, 95, 98, 99, 100, 103, 107, 108, 109, 115, 116, 122, 123, 126, 133, 135, 138, 140, 141, 143, 146, 152, 153, 155, 157, 158, 161, 173, 175, 183, 187, 188, 199, 201, 204, 208, 210, 211, 214, 218, 225, 239, 240], "usr": [4, 6, 16, 20, 21, 135, 189, 208], "cc": [4, 6, 20, 21, 41, 119, 197, 199, 208], "detect": [4, 6, 11, 12, 16, 20, 21, 51, 77, 95, 122, 138, 157, 168, 171, 208, 221, 234], "info": [4, 5, 6, 20, 21, 119, 132, 135, 136, 145, 159, 172, 181, 200, 208, 209, 216, 224], "pthread": [4, 5, 6, 20, 21, 201, 208], "pthread_creat": [4, 6, 20, 21, 208], "thread": [4, 5, 6, 8, 9, 19, 20, 21, 51, 61, 108, 133, 134, 136, 148, 157, 160, 161, 162, 173, 174, 178, 179, 189, 205, 208, 214, 219, 225, 233, 234], "scan": [4, 6, 20, 21, 94, 95], "50": [4, 6, 7, 17, 19, 20, 21, 51, 52, 58, 91, 94, 107, 146, 155, 159, 162, 174, 175, 179, 181, 192, 196, 209, 211, 216, 234], "cmakefil": [4, 6, 20, 21], "dir": [4, 6, 20, 21, 97, 126, 197, 201, 211, 233], "o": [4, 5, 6, 7, 20, 21, 118, 136, 149, 153, 219, 245], "100": [4, 6, 9, 17, 19, 20, 21, 38, 47, 72, 91, 101, 110, 117, 124, 133, 143, 146, 148, 157, 158, 159, 162, 169, 173, 174, 175, 179, 182, 192, 209, 219, 233], "suppli": [4, 6, 103, 146, 157, 245], "binari": [4, 6, 18, 20, 21, 48, 51, 98, 135, 146, 171, 175, 183, 185, 191, 197, 201, 203, 207, 208, 210, 211], "incompat": [4, 192], "1d": [4, 68, 95, 110, 198, 234], "4d": [4, 45, 80, 146], "path_to_model": 4, "successfulli": [4, 6, 20, 49, 58, 59, 60, 120, 126, 135, 143, 161, 186, 189, 199, 213, 215, 221, 224, 227, 228, 229, 230, 235, 236, 237, 240], "coupl": [4, 33, 48, 90, 98, 99, 106, 123, 130, 137, 169, 175, 180, 196, 234], "awai": [4, 5, 6, 21, 45, 60, 95, 97, 100, 101, 103, 113, 148, 158, 159, 160, 187, 222, 245], "ivalu": [4, 21, 58, 154, 199, 201, 208, 211, 240], "push_back": [4, 20, 21, 208, 240], "totensor": [4, 17, 21, 50, 58, 59, 94, 116, 117, 124, 135, 138, 156, 157, 161, 169, 179, 182, 183, 192, 197, 199, 204, 208, 209, 211, 240], "slice": [4, 5, 38, 47, 83, 91, 104, 107, 127, 155, 188, 199, 233], "eras": [4, 22], "org": [4, 6, 23, 24, 25, 26, 27, 32, 40, 43, 44, 48, 58, 59, 76, 79, 85, 93, 95, 97, 99, 102, 113, 117, 123, 124, 127, 128, 136, 139, 140, 141, 142, 156, 157, 164, 167, 170, 171, 178, 182, 183, 185, 187, 189, 191, 196, 197, 198, 199, 201, 204, 209, 210, 211, 212, 214, 218, 222, 223, 240, 243, 245], "cppdoc": [4, 6], "pariti": 4, "manipul": [4, 38, 39, 60, 94, 97, 110, 142, 179, 181, 204], "five": [4, 9, 113], "ideal": [4, 6, 31, 58, 59, 91, 94, 98, 148, 164, 174, 192, 200], "variabl": [4, 5, 6, 7, 8, 18, 20, 21, 29, 40, 48, 60, 78, 89, 91, 98, 100, 101, 103, 107, 114, 118, 127, 132, 135, 138, 143, 153, 160, 163, 173, 186, 188, 198, 199, 200, 201, 210, 214, 230, 239], "kcuda": [4, 6], "live": [4, 6, 10, 98, 122, 125, 134, 161, 162, 187, 205, 232, 245], "hopefulli": [4, 6, 49, 50, 75, 86, 101, 111, 235], "equip": [4, 5, 130, 184], "concept": [4, 6, 11, 20, 33, 34, 54, 57, 90, 103, 107, 110, 114, 122, 126, 145, 160, 164, 192, 193, 225, 233], "close": [4, 6, 9, 17, 21, 51, 61, 91, 95, 98, 100, 123, 126, 136, 169, 178, 181, 232, 234, 239], "Of": [4, 21, 103, 107, 125, 133, 135, 169, 185, 187, 214], "cours": [4, 6, 17, 21, 52, 57, 91, 92, 98, 103, 106, 107, 125, 133, 135, 158, 169, 204, 214], "did": [4, 6, 8, 17, 21, 22, 42, 51, 60, 91, 94, 95, 98, 113, 135, 138, 140, 151, 158, 161, 164, 173, 179, 219, 245], "cover": [4, 5, 14, 16, 20, 22, 31, 45, 57, 58, 59, 98, 113, 114, 118, 120, 122, 123, 126, 135, 154, 158, 161, 162, 169, 171, 172, 186, 188, 192, 203, 208, 218, 232, 233, 239], "extend": [4, 5, 6, 8, 17, 51, 58, 59, 61, 89, 113, 122, 124, 128, 134, 157, 161, 162, 172, 174, 176, 201, 208, 209, 234], "insid": [4, 5, 6, 10, 14, 16, 20, 21, 30, 34, 43, 168, 175, 190, 198, 200, 211, 245], "shortli": [4, 160], "html": [4, 23, 24, 25, 26, 27, 32, 43, 44, 76, 79, 85, 93, 102, 113, 114, 119, 123, 124, 136, 139, 141, 142, 156, 167, 170, 178, 182, 183, 185, 187, 196, 197, 218, 222, 223, 245], "peter": 5, "goldsborough": 5, "plethora": 5, "relat": [5, 11, 51, 60, 91, 92, 98, 99, 103, 106, 113, 143, 151, 179, 219, 234, 245], "algebra": [5, 38, 47, 94, 98, 101], "wrangl": 5, "novel": [5, 92], "research": [5, 6, 17, 21, 22, 48, 51, 60, 75, 77, 86, 92, 98, 101, 114, 115, 135, 136, 149, 152, 155, 178, 205], "modul": [5, 7, 9, 12, 13, 14, 16, 17, 19, 20, 21, 30, 35, 36, 39, 40, 42, 43, 45, 48, 52, 54, 58, 59, 66, 68, 70, 80, 81, 91, 92, 94, 98, 99, 101, 106, 109, 111, 112, 115, 116, 117, 118, 119, 122, 123, 124, 125, 127, 129, 133, 135, 141, 142, 143, 146, 149, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 166, 169, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 183, 189, 191, 192, 196, 199, 201, 202, 203, 208, 209, 210, 211, 214, 215, 216, 219, 221, 222, 225, 227, 229, 230, 234, 236, 238, 239, 240, 244, 245, 246], "power": [5, 6, 21, 41, 48, 56, 65, 75, 77, 89, 91, 94, 101, 107, 110, 124, 126, 135, 143, 145, 149, 154, 155, 157, 164, 182, 187, 189, 215, 219, 245], "spare": [5, 6], "deriv": [5, 6, 10, 21, 22, 29, 34, 38, 41, 47, 78, 80, 91, 98, 101, 103, 104, 106, 109, 110, 125, 130, 140, 144, 190, 234], "express": [5, 21, 91, 94, 95, 98, 100, 114, 136, 186, 192, 193, 202, 245], "better": [5, 6, 17, 19, 31, 34, 35, 42, 51, 55, 61, 81, 91, 94, 95, 97, 106, 107, 108, 113, 115, 122, 126, 127, 128, 138, 143, 144, 145, 152, 156, 158, 159, 164, 168, 169, 173, 174, 179, 184, 185, 190, 192, 193, 200, 211, 219, 234], "frequent": [5, 20, 21, 29, 77, 106, 110, 124, 172, 173, 174, 186, 208], "expens": [5, 38, 108, 138, 162, 174, 225, 233], "plausibl": 5, "address": [5, 12, 16, 20, 95, 135, 160, 161, 173, 192, 209, 246], "nativ": [5, 6, 8, 21, 40, 54, 89, 120, 122, 123, 136, 162, 173, 174, 176, 184, 187, 192, 205, 208, 211, 225, 233, 234, 238], "intend": [5, 6, 8, 12, 21, 91, 124, 143, 146, 184, 192, 203, 221, 234], "much": [5, 6, 8, 10, 12, 17, 21, 22, 34, 51, 55, 75, 91, 92, 100, 101, 106, 107, 111, 120, 123, 125, 126, 141, 144, 145, 157, 158, 161, 162, 164, 168, 169, 171, 173, 184, 187, 193, 207, 214, 215, 216, 218, 219, 222, 232, 234, 235, 238, 243, 245], "boilerpl": [5, 6, 17, 42, 101, 169, 184], "degre": [5, 34, 64, 95, 110, 126, 164, 168, 187], "matter": [5, 134, 184, 186, 218], "organ": [5, 8, 21, 50, 94, 111, 127, 148, 219, 228, 246], "tackl": [5, 108], "decid": [5, 6, 8, 10, 16, 51, 89, 91, 159, 172, 187, 191, 237], "contribut": [5, 51, 61, 92, 98, 136, 146, 168, 173], "upstream": [5, 208, 234], "rest": [5, 6, 42, 117, 122, 142, 156, 158, 160, 161, 165, 186, 207, 222, 245, 246], "chase": [5, 113], "someon": [5, 164], "fire": [5, 133], "dai": [5, 40], "head": [5, 7, 19, 33, 40, 77, 95, 108, 113, 133, 153, 156, 163, 175, 188], "straight": [5, 6, 21, 138, 164], "recurr": [5, 42, 48, 60, 81, 84, 100, 104, 109, 118, 127, 128, 151, 164, 222], "unit": [5, 6, 22, 48, 95, 98, 109, 123, 124, 144, 155, 158, 159, 164, 173, 174, 182, 221, 234], "superior": [5, 118], "lstm": [5, 15, 42, 48, 80, 81, 95, 102, 105, 109, 120, 122, 127, 128, 162, 178, 180, 190, 216, 222, 238], "lack": [5, 92, 184], "forget": [5, 6, 107, 111, 156, 171, 183], "gate": [5, 48, 95], "exponenti": [5, 48, 91, 98, 101, 103, 151, 159], "elu": [5, 109], "never": [5, 57, 91, 100, 101, 106, 125, 155, 166], "lltm": 5, "long": [5, 6, 10, 18, 21, 48, 49, 89, 95, 98, 101, 102, 103, 105, 107, 113, 123, 125, 128, 136, 142, 143, 148, 151, 159, 162, 168, 181, 201, 211, 219, 222, 224, 233, 234, 237, 245, 246], "term": [5, 6, 38, 51, 75, 91, 92, 95, 99, 101, 102, 103, 105, 108, 123, 138, 149, 155, 158, 187, 192, 193, 195, 222, 226, 245, 246], "signific": [5, 6, 9, 17, 40, 51, 58, 59, 92, 123, 129, 136, 142, 143, 144, 146, 158, 163, 168, 171, 174, 196, 209, 211, 218, 219, 222, 245], "lstmcell": 5, "cell": [5, 19, 21, 22, 49, 60, 77, 83, 91, 92, 94, 95, 98, 99, 108, 159, 163, 222, 234, 246], "plain": [5, 6, 21, 48, 107, 127, 128, 164, 233], "input_featur": 5, "state_s": 5, "candid": [5, 143, 234], "reset_paramet": 5, "stdv": 5, "math": [5, 10, 72, 86, 91, 103, 109, 110, 149, 157, 159, 222, 234, 249], "sqrt": [5, 86, 107, 184, 195], "uniform_": [5, 6, 162, 195], "old_h": 5, "old_cel": 5, "cat": [5, 18, 19, 38, 42, 47, 92, 94, 100, 103, 109, 134, 138, 143, 159, 162, 164, 169, 175, 217], "gate_weight": 5, "f": [5, 7, 8, 11, 12, 16, 17, 20, 29, 40, 41, 45, 47, 52, 54, 72, 91, 101, 107, 109, 110, 111, 113, 117, 118, 123, 124, 125, 133, 134, 135, 136, 143, 144, 153, 154, 156, 157, 159, 160, 161, 162, 169, 179, 181, 182, 183, 192, 197, 198, 203, 204, 205, 209, 214, 219, 229, 240, 241, 245], "split": [5, 7, 8, 16, 17, 18, 19, 43, 48, 51, 81, 86, 89, 94, 97, 99, 113, 122, 127, 128, 133, 134, 136, 141, 148, 153, 158, 161, 162, 164, 175, 179, 181, 192, 203, 214], "input_g": 5, "sigmoid": [5, 6, 51, 95, 109, 176, 193, 234], "output_g": 5, "tanh": [5, 6, 51, 95, 101, 109, 158, 234], "candidate_cel": 5, "new_cel": 5, "hidden": [5, 7, 19, 48, 60, 92, 95, 100, 104, 107, 126, 127, 128, 141, 153, 162, 163, 164, 192, 217, 222, 243], "new_h": 5, "batch_siz": [5, 6, 7, 17, 18, 31, 48, 50, 51, 54, 89, 91, 109, 113, 117, 118, 123, 124, 134, 135, 136, 153, 156, 159, 160, 161, 168, 169, 172, 173, 174, 175, 179, 181, 192, 198, 208, 209, 218], "rnn": [5, 19, 22, 43, 48, 60, 61, 95, 109, 118, 122, 134, 151, 161, 164, 165, 234], "new_c": 5, "intel": [5, 122, 135, 143, 146, 199, 238], "mkl": [5, 143, 225], "nnpack": 5, "why": [5, 6, 8, 11, 22, 42, 51, 86, 92, 101, 106, 111, 114, 130, 133, 138, 143, 164, 171, 185, 187, 219, 245], "room": [5, 148, 245], "obviou": [5, 113, 219], "knowledg": [5, 48, 51, 57, 75, 101, 114, 143, 145, 245], "execut": [5, 6, 7, 8, 11, 14, 15, 18, 19, 20, 21, 22, 29, 30, 37, 40, 41, 43, 46, 60, 61, 70, 74, 78, 80, 82, 87, 91, 94, 96, 98, 100, 105, 112, 121, 122, 125, 126, 134, 135, 142, 143, 146, 148, 154, 158, 159, 161, 162, 163, 165, 171, 173, 174, 179, 180, 181, 182, 189, 194, 196, 197, 199, 200, 201, 203, 211, 212, 213, 214, 218, 222, 231, 233, 239, 240], "kernel": [5, 6, 8, 13, 16, 21, 95, 98, 107, 109, 122, 137, 143, 146, 148, 151, 152, 163, 164, 165, 168, 171, 173, 174, 188, 200, 205, 219, 221, 225, 234], "involv": [5, 8, 9, 17, 21, 22, 33, 60, 86, 91, 92, 98, 100, 103, 111, 121, 125, 127, 132, 138, 145, 162, 164, 179, 188, 226, 229, 234], "launch": [5, 6, 19, 52, 61, 115, 126, 132, 133, 148, 160, 161, 162, 163, 168, 173, 199, 209, 219, 225, 234], "amount": [5, 17, 22, 75, 111, 133, 155, 171, 211, 225, 229, 234], "becom": [5, 6, 11, 19, 51, 61, 75, 77, 80, 86, 92, 130, 144, 146, 168, 169, 173, 192, 205, 218, 239], "furthermor": [5, 17, 137, 144, 169, 173, 193, 212, 213, 219], "interpret": [5, 6, 21, 22, 55, 86, 92, 106, 122, 127, 128, 136, 164, 171, 191, 205, 219, 223, 231, 233, 238, 245], "slow": [5, 6, 8, 34, 40, 124, 173, 216, 225, 234], "down": [5, 8, 10, 11, 17, 30, 31, 40, 89, 91, 95, 97, 101, 107, 124, 143, 144, 145, 161, 166, 169, 173, 184, 233, 234, 243], "therefor": [5, 6, 9, 17, 48, 50, 60, 111, 113, 115, 121, 133, 134, 146, 149, 154, 155, 161, 162, 173, 186, 187, 199, 211, 218, 227, 245], "rewrit": [5, 19, 43, 60, 151, 193, 198, 199, 239], "fuse": [5, 17, 122, 143, 156, 157, 165, 173, 174, 176, 178, 179, 188, 189, 199, 215, 238, 239], "group": [5, 11, 16, 17, 48, 61, 95, 98, 108, 113, 121, 122, 123, 124, 128, 129, 131, 133, 134, 135, 143, 158, 172, 175, 205, 219, 241, 245, 246], "profit": 5, "fewer": [5, 11, 129, 144], "visibl": [5, 20, 21, 42, 89, 97, 175, 179, 232], "global": [5, 6, 22, 48, 55, 60, 89, 118, 138, 159, 161, 166, 179, 203, 205, 220, 233, 234, 239], "aten": [5, 8, 10, 21, 40, 91, 108, 143, 168, 174, 179, 181, 183, 192, 208, 214, 225, 233], "translat": [5, 21, 22, 48, 60, 112, 116, 122, 127, 149, 165, 182, 186, 204, 234, 239], "benefit": [5, 6, 9, 16, 40, 41, 86, 89, 120, 123, 140, 146, 156, 163, 173, 192, 205, 208, 218, 222, 234], "massiv": [5, 22, 42, 103, 106, 208], "parallel": [5, 6, 11, 14, 15, 16, 42, 44, 46, 48, 50, 54, 75, 81, 89, 94, 98, 111, 122, 126, 131, 135, 136, 149, 158, 160, 161, 162, 165, 172, 173, 205, 218, 225, 227, 241], "ahead": [5, 20, 34, 94, 169, 176, 183, 222, 234, 240], "cpp_extens": [5, 10, 21, 154, 201, 219], "load": [5, 16, 17, 18, 19, 21, 29, 30, 32, 33, 34, 38, 39, 40, 41, 45, 50, 51, 54, 75, 77, 89, 94, 98, 99, 100, 107, 109, 112, 113, 116, 122, 124, 127, 138, 143, 146, 158, 168, 169, 175, 178, 179, 181, 182, 189, 190, 197, 199, 201, 204, 208, 209, 210, 212, 213, 218, 223, 231, 233, 238], "setup": [5, 6, 7, 10, 14, 17, 20, 33, 40, 51, 52, 54, 90, 123, 124, 126, 133, 154, 162, 183, 186, 187, 197, 198, 199, 219, 233, 238], "lltm_cpp": 5, "ext_modul": [5, 10, 21, 154], "cppextens": [5, 10, 21, 154], "cmdclass": [5, 10, 21, 154], "build_ext": [5, 10, 21, 154], "buildextens": [5, 10, 21, 154], "conveni": [5, 8, 20, 21, 42, 45, 48, 92, 103, 107, 125, 127, 128, 137, 144, 154, 158, 185, 187, 204, 208, 218, 219, 233, 239], "wrapper": [5, 6, 8, 54, 107, 111, 123, 124, 130, 145, 158, 227], "include_dir": [5, 10, 154], "include_path": 5, "manag": [5, 20, 30, 41, 48, 61, 91, 107, 108, 113, 121, 131, 132, 133, 148, 151, 163, 168, 174, 205, 218, 219, 220, 225, 226, 234], "And": [5, 6, 10, 20, 21, 22, 51, 92, 103, 107, 113, 130, 143, 144, 146, 149, 157, 168, 169, 171, 173, 174, 190, 193, 204, 219, 233], "overal": [5, 17, 40, 48, 95, 123, 124, 135, 148, 159, 192, 193, 216, 219, 234], "d_sigmoid": 5, "bit": [5, 21, 22, 68, 94, 98, 108, 110, 113, 117, 157, 158, 159, 164, 184, 192, 200, 209, 216, 219, 222], "pybind11": [5, 8, 20, 21, 154, 219], "datatyp": [5, 21, 38, 47, 73, 94, 98, 108, 208, 218, 222, 234], "Its": [5, 101, 188, 245], "inspect": [5, 21, 80, 91, 123, 126, 142, 163, 166, 171, 179, 181, 205, 219], "notic": [5, 8, 19, 20, 21, 22, 29, 40, 41, 42, 51, 60, 75, 86, 91, 94, 98, 101, 111, 130, 135, 138, 143, 145, 148, 151, 152, 156, 158, 168, 171, 173, 174, 183, 184, 186, 190, 224, 229, 237, 240], "dispos": 5, "nvcc": 5, "workaround": [5, 21, 81, 86, 130, 140], "logic": [5, 6, 11, 21, 34, 39, 86, 100, 124, 126, 132, 134, 155, 161, 162, 174, 180, 195, 205], "sigmoidalphablendforwardcuda": 5, "port": [5, 14, 135, 161, 204], "entir": [5, 6, 14, 16, 17, 22, 45, 48, 52, 60, 80, 101, 104, 107, 117, 118, 122, 123, 124, 127, 129, 134, 141, 148, 152, 155, 156, 158, 162, 164, 173, 179, 184, 185, 186, 189, 192, 201, 218, 226, 234, 238, 245], "lltm_forward": 5, "addmm": [5, 6, 108, 143, 183, 199, 200, 225], "transpos": [5, 6, 12, 38, 47, 48, 51, 109, 117, 143, 156, 159, 169, 188, 199], "alpha": [5, 6, 145, 184, 246], "respect": [5, 14, 29, 31, 33, 34, 35, 41, 48, 51, 63, 64, 72, 91, 92, 101, 103, 110, 114, 125, 134, 140, 143, 144, 152, 158, 162, 164, 168, 173, 174, 203, 234, 236], "ultim": [5, 17, 48, 51, 60, 86, 184, 200], "plop": [5, 21], "autograd": [5, 12, 14, 19, 22, 30, 31, 33, 34, 35, 36, 38, 39, 40, 44, 45, 46, 56, 57, 59, 61, 62, 68, 79, 80, 82, 84, 90, 92, 93, 94, 95, 97, 98, 99, 103, 107, 109, 122, 127, 128, 130, 133, 134, 143, 144, 149, 152, 159, 160, 161, 164, 165, 174, 198, 201, 203, 204, 205, 214, 218, 234, 240], "nice": [5, 48, 83, 107, 152], "dig": [5, 92, 101, 163], "deeper": [5, 11, 12, 35, 92, 98, 101, 142, 143, 163, 174, 240], "interest": [5, 6, 10, 18, 21, 22, 42, 48, 50, 58, 59, 89, 91, 92, 101, 113, 117, 123, 126, 144, 151, 156, 158, 166, 173, 175, 198, 219, 222, 233, 236, 237, 245], "alex": 5, "grave": 5, "thesi": 5, "d_tanh": 5, "relu": [5, 6, 12, 17, 21, 45, 51, 91, 95, 101, 107, 109, 111, 124, 133, 134, 143, 156, 157, 159, 160, 161, 162, 169, 174, 178, 179, 198, 207, 208, 209, 211, 218, 229, 234, 239], "exp": [5, 91, 100, 101, 130, 159, 186], "d_elu": 5, "mask": [5, 58, 77, 92, 95, 108, 118, 119, 122, 151, 155, 159, 175, 184, 185, 187, 188, 191, 208], "type_a": 5, "lltm_backward": 5, "grad_h": 5, "grad_cel": 5, "d_output_g": 5, "d_tanh_new_cel": 5, "d_new_cel": 5, "d_old_cel": 5, "d_candidate_cel": 5, "d_input_g": 5, "d_gate": 5, "d_weight": 5, "d_bia": 5, "keepdim": [5, 17, 124, 161, 179, 192, 209], "d_x": 5, "d_old_h": 5, "d_input": 5, "span": [5, 77, 100, 133, 148, 168, 214, 246], "four": [5, 16, 20, 61, 86, 94, 95, 98, 110, 115, 120, 123, 134, 135, 148, 169, 211, 216, 245, 246], "pybind11_modul": [5, 154], "torch_extension_nam": [5, 154], "macro": [5, 6, 8, 21], "maintain": [5, 10, 20, 29, 30, 31, 41, 48, 75, 95, 104, 122, 131, 135, 145, 159, 162, 173, 174, 189, 218, 241], "mismatch": [5, 61], "nasti": 5, "hard": [5, 6, 8, 19, 31, 101, 126, 155, 219], "At": [5, 6, 8, 18, 21, 41, 45, 48, 49, 86, 89, 104, 107, 110, 116, 123, 124, 140, 145, 156, 158, 159, 160, 163, 164, 168, 184, 187, 199, 211, 224, 225, 244], "point": [5, 6, 8, 10, 11, 16, 17, 18, 20, 21, 41, 45, 48, 49, 50, 51, 52, 57, 58, 60, 86, 91, 94, 95, 98, 100, 103, 104, 106, 107, 109, 110, 124, 125, 126, 130, 131, 133, 142, 145, 148, 149, 156, 158, 160, 164, 169, 178, 179, 181, 184, 186, 187, 189, 192, 193, 201, 209, 211, 216, 222, 224, 232, 234, 243, 244, 245], "bdist_egg": 5, "egg_info": [5, 21], "egg": [5, 21], "pkg": [5, 21], "dependency_link": [5, 21], "top": [5, 6, 8, 17, 18, 20, 21, 33, 49, 51, 90, 92, 97, 107, 115, 135, 138, 156, 157, 162, 163, 168, 169, 173, 175, 179, 192, 202, 214, 215, 217, 240, 243, 247], "top_level": [5, 21], "manifest": [5, 21, 186, 189], "bdist": 5, "x86_64": [5, 16, 21, 197, 201], "install_lib": 5, "temp": [5, 17, 21, 136, 179, 181, 192], "gcc": [5, 21, 143], "miniconda": [5, 16, 21], "compiler_compat": [5, 21], "wl": [5, 20, 21], "sysroot": [5, 21], "wsign": [5, 21], "dndebug": [5, 21], "g": [5, 6, 7, 8, 10, 11, 16, 21, 22, 40, 41, 48, 50, 51, 57, 60, 61, 81, 89, 91, 94, 95, 98, 101, 106, 109, 117, 118, 122, 124, 126, 127, 128, 133, 135, 136, 137, 143, 152, 153, 154, 158, 160, 162, 164, 168, 173, 176, 179, 181, 187, 188, 191, 193, 198, 199, 219, 225, 233, 234, 245], "fwrapv": [5, 21], "o3": [5, 21, 219], "wall": [5, 21, 100, 142, 219], "wstrict": [5, 21], "prototyp": [5, 10, 11, 21, 31, 61, 188, 189, 193, 194, 198, 199, 203], "fpic": [5, 21], "site": [5, 16, 20, 21, 49, 51, 58, 59, 141, 142, 164, 182, 204, 212, 213, 215, 225, 233, 245], "csrc": [5, 20, 21, 154, 183, 210], "th": [5, 21, 50, 101, 106, 135, 145], "thc": [5, 21], "7m": [5, 21, 117], "dtorch_api_include_extension_h": [5, 21], "dtorch_extension_nam": [5, 21], "d_glibcxx_use_cxx11_abi": [5, 21], "cc1plu": [5, 21], "warn": [5, 17, 21, 40, 50, 136, 143, 179, 181, 182, 184, 185, 186, 187, 192, 205, 219, 225, 233, 239], "valid": [5, 7, 18, 21, 34, 48, 89, 95, 97, 99, 108, 111, 113, 115, 117, 118, 123, 124, 126, 129, 130, 153, 154, 156, 175, 179, 185, 186, 192, 197, 210, 219], "objc": [5, 21], "l": [5, 7, 12, 21, 41, 50, 51, 91, 101, 109, 118, 153, 158, 159, 189, 219], "rpath": [5, 21], "cpython": [5, 21, 233], "37m": [5, 21], "stub": [5, 156, 202, 211, 246], "loader": [5, 6, 35, 42, 81, 99, 107, 158, 161, 175, 210, 219], "byte": [5, 136, 138, 178, 201], "37": [5, 7, 108, 157, 162, 174, 225], "pyc": 5, "native_lib": 5, "zip_saf": 5, "analyz": [5, 17, 21, 60, 122, 158, 171, 181, 233], "__pycache__": 5, "__file__": [5, 154, 219], "dist": [5, 11, 16, 109, 123, 124, 133, 135, 154, 161, 172, 241], "py3": 5, "remov": [5, 17, 48, 51, 52, 59, 60, 107, 108, 109, 114, 116, 125, 133, 136, 141, 143, 157, 163, 164, 171, 175, 179, 180, 181, 184, 185, 189, 192, 197, 205, 216, 219, 233, 239, 243], "everyth": [5, 41, 89, 98, 101, 126, 127, 130, 138, 156, 157, 158, 159, 160, 164, 169, 182, 183, 203, 204, 211], "finish": [5, 6, 14, 21, 43, 58, 94, 133, 134, 135, 148, 160, 162, 169, 183, 197, 203, 207, 211, 214, 221, 234], "ubuntu": [5, 6, 201], "16": [5, 7, 17, 21, 89, 91, 94, 95, 111, 117, 133, 146, 153, 156, 157, 162, 169, 174, 182, 189, 197, 201, 219, 229, 249], "04": [5, 7, 119, 165, 175, 219], "recent": [5, 48, 77, 104, 108, 113, 115, 135, 136, 143, 149, 151, 156, 159, 168, 201], "maco": [5, 6, 135], "clang": [5, 197, 199], "worst": [5, 136], "resolv": [5, 21, 141, 146, 174, 186], "symbol": [5, 22, 115, 119, 141, 179, 192, 219, 233, 245], "linker": [5, 21, 197], "pycapsul": [5, 21], "builtin": [5, 154, 219, 233], "arg0": 5, "arg1": [5, 161], "arg2": [5, 161], "arg3": 5, "arg4": 5, "citizen": [5, 21, 184, 186], "lltmfunction": 5, "staticmethod": [5, 130, 160], "contigu": [5, 8, 30, 146, 189, 202, 207, 211, 234], "saved_tensor": [5, 130], "benchmark": [5, 31, 40, 108, 117, 122, 126, 136, 143, 144, 157, 163, 171, 173, 174, 182, 188, 208, 209, 225, 231, 233, 234, 238], "measur": [5, 12, 19, 34, 91, 92, 94, 95, 106, 124, 136, 142, 144, 148, 158, 159, 163, 166, 171, 173, 174, 190, 196, 203, 211, 218, 219, 225, 233, 238], "durat": [5, 154, 159, 168, 174, 245], "32": [5, 16, 17, 19, 54, 72, 89, 94, 95, 98, 104, 108, 117, 124, 136, 149, 152, 157, 161, 162, 168, 173, 174, 175, 209, 216, 219], "128": [5, 6, 20, 50, 51, 54, 89, 124, 134, 135, 136, 137, 148, 157, 159, 160, 161, 162, 175, 181, 193, 200, 203, 208, 219, 233], "_": [5, 11, 12, 17, 19, 32, 38, 47, 48, 51, 60, 83, 91, 93, 98, 100, 107, 117, 134, 135, 136, 138, 141, 149, 156, 158, 159, 160, 162, 169, 173, 174, 178, 179, 181, 192, 197, 203, 204, 218, 222, 241, 245], "rang": [5, 6, 11, 12, 16, 17, 19, 39, 40, 42, 50, 51, 52, 60, 72, 75, 89, 91, 92, 107, 110, 117, 123, 124, 126, 134, 135, 136, 141, 156, 157, 159, 160, 162, 164, 168, 169, 173, 174, 175, 176, 181, 189, 202, 203, 209, 214, 217, 218, 222, 225, 234, 241], "100000": [5, 58, 59, 136, 219], "3f": [5, 17], "wrote": [5, 21, 138, 171, 175, 245], "post": [5, 6, 11, 18, 48, 58, 59, 122, 123, 124, 126, 136, 138, 146, 148, 166, 173, 174, 180, 181, 191, 193, 194, 209, 217], "my": [5, 19, 40, 49, 100, 106, 196, 232, 245], "machin": [5, 6, 16, 18, 19, 22, 33, 35, 39, 42, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 61, 75, 89, 90, 91, 92, 116, 119, 122, 123, 124, 126, 131, 132, 133, 134, 135, 142, 152, 157, 161, 162, 163, 164, 165, 173, 175, 181, 189, 196, 214, 232, 234], "506": 5, "480": [5, 225], "444": 5, "694": 5, "349": [5, 94, 175], "335": [5, 146, 162, 241], "443": [5, 162, 225], "523": 5, "speedup": [5, 19, 40, 42, 110, 137, 143, 148, 152, 174, 178, 179, 211, 234], "30": [5, 6, 7, 17, 43, 91, 101, 115, 122, 123, 146, 155, 160, 162, 175, 179, 192, 219, 225], "albeit": [5, 216], "major": [5, 10, 11, 17, 95, 98, 106, 117, 143, 163, 171, 173, 174, 187, 205, 241], "particularli": [5, 13, 52, 107, 151, 164], "engin": [5, 6, 18, 29, 41, 61, 89, 91, 124, 157, 162, 175, 182, 198, 200, 208, 216, 243], "wonder": [5, 101], "abstract": [5, 11, 31, 50, 57, 89, 98, 99, 107, 109, 110, 113, 126, 135, 141, 154, 158, 246], "correspondingli": 5, "big": [5, 40, 51, 95, 100, 106, 110, 128, 137, 158, 164, 189], "win": [5, 115, 181], "No": [5, 6, 52, 60, 143, 176, 197], "cuda_devic": 5, "creation": [5, 6, 10, 98, 187, 195, 201], "assert": [5, 11, 16, 17, 20, 133, 141, 143, 161, 163, 169, 189, 193, 198, 201, 202], "is_avail": [5, 6, 12, 40, 47, 89, 91, 98, 109, 117, 154, 156, 159, 161, 175], "synchron": [5, 11, 14, 54, 55, 61, 133, 135, 148, 158, 160, 161, 168, 171, 173, 174, 203, 214, 218, 219, 241], "1e6": [5, 17, 136, 179, 181, 192, 216, 241], "1e5": 5, "again": [5, 6, 9, 19, 22, 42, 49, 60, 80, 91, 92, 95, 97, 98, 100, 107, 113, 116, 118, 120, 125, 129, 135, 160, 162, 164, 168, 171, 173, 211, 219, 224, 229, 245], "187": [5, 219], "719": 5, "410": [5, 146], "815": 5, "149": 5, "802": [5, 143], "393": [5, 72, 174], "458": [5, 143], "That": [5, 6, 21, 41, 42, 43, 48, 91, 92, 94, 98, 101, 103, 104, 106, 107, 116, 127, 134, 140, 142, 144, 146, 148, 149, 158, 163, 168, 175, 184, 185, 187, 211, 212, 222, 233, 238, 245], "great": [5, 48, 60, 110, 111, 113, 186, 192, 219, 236, 245], "pull": [5, 7, 19, 92, 98, 99, 142, 153, 204], "dive": [5, 6, 11, 21, 35, 133, 143, 156, 233], "elabor": [5, 6, 143, 160], "fly": [5, 21, 50, 100, 115, 158, 216], "background": [5, 6, 21, 30, 58, 59, 75, 97, 113, 157, 169, 175, 245], "tmp": [5, 21, 143, 207, 211, 216, 225], "torch_extens": 5, "emit": [5, 6, 100], "ninja": 5, "verbos": [5, 21, 132, 174, 200, 201, 246], "complic": [5, 100, 101, 106, 107, 110, 126, 174, 188, 192, 198, 202, 218, 219, 239], "techniqu": [5, 9, 14, 17, 19, 48, 60, 100, 106, 122, 129, 130, 131, 142, 148, 151, 155, 156, 162, 174, 184, 188, 196, 197, 216, 222, 234], "fine": [5, 6, 17, 48, 50, 91, 100, 113, 121, 125, 134, 135, 143, 156, 157, 168, 175, 181, 183, 184, 218, 219, 233, 234], "system": [5, 6, 8, 10, 12, 20, 21, 22, 54, 78, 122, 126, 135, 138, 151, 157, 158, 160, 172, 173, 174, 199, 200, 201, 204, 221, 234], "increment": [5, 11, 60, 86, 103, 107, 135, 159], "thu": [5, 6, 8, 10, 17, 18, 19, 21, 29, 36, 48, 86, 89, 107, 123, 137, 141, 164, 174, 192, 195, 201, 205, 214, 219, 225, 234, 239, 245], "didn": [5, 8, 20, 78, 92, 142, 160, 178, 198, 245], "prospect": 5, "pointwis": [5, 8, 141, 146], "declar": [5, 6, 13, 21, 60, 75, 80, 115, 201, 211, 239], "cu": 5, "ensur": [5, 8, 9, 10, 11, 12, 17, 20, 35, 48, 52, 55, 60, 64, 107, 108, 110, 111, 115, 116, 132, 135, 140, 153, 158, 159, 161, 163, 173, 175, 189, 195, 219, 221, 222, 224, 228, 230, 237, 240], "lltm_cuda": 5, "lltm_cuda_forward": 5, "lltm_cuda_backward": 5, "check_cuda": 5, "torch_check": [5, 8], "is_cuda": 5, "check_contigu": 5, "is_contigu": [5, 146, 233], "check_input": 5, "lltm_cuda_kernel": 5, "cannot": [5, 6, 11, 16, 20, 21, 48, 60, 61, 98, 110, 111, 113, 130, 133, 135, 146, 148, 156, 158, 190, 196, 198, 229, 244], "peek": 5, "cuda_runtim": 5, "templat": [5, 8, 20, 21, 59, 112, 135, 143, 201, 202, 209, 243], "typenam": [5, 201], "scalar_t": [5, 143], "__device__": 5, "__forceinline__": 5, "specif": [5, 6, 8, 9, 10, 11, 16, 17, 20, 21, 22, 31, 35, 42, 54, 57, 58, 59, 75, 89, 91, 92, 94, 95, 97, 99, 101, 103, 107, 109, 111, 114, 123, 124, 127, 128, 129, 133, 135, 136, 143, 148, 155, 156, 158, 160, 161, 162, 163, 164, 168, 169, 173, 174, 175, 176, 181, 182, 185, 188, 193, 197, 199, 200, 203, 208, 214, 217, 222, 225, 229, 233, 238, 239, 241, 245], "fmax": 5, "fmin": 5, "d_relu": 5, "wish": [5, 6, 21, 51, 60, 75, 92, 98, 111, 113, 149, 152, 161, 176, 181, 185, 218, 228, 230, 246], "explicitli": [5, 6, 16, 22, 34, 38, 41, 47, 51, 52, 60, 89, 91, 103, 132, 146, 162, 163, 166, 173, 174, 179, 187, 188, 193, 214, 234], "zeros_lik": [5, 98, 141, 160, 205], "dim3": 5, "at_dispatch_floating_typ": 5, "lltm_forward_cuda": 5, "lltm_cuda_forward_kernel": 5, "indic": [5, 6, 10, 11, 21, 30, 48, 60, 63, 64, 91, 92, 94, 95, 97, 100, 101, 106, 108, 109, 110, 115, 116, 119, 126, 127, 136, 143, 155, 158, 159, 161, 168, 169, 173, 174, 175, 181, 184, 186, 187, 190, 193, 200, 217, 219, 240, 243, 245], "runtim": [5, 8, 15, 16, 19, 21, 22, 38, 49, 60, 86, 90, 91, 94, 98, 108, 122, 129, 142, 168, 171, 173, 174, 178, 181, 199, 200, 218, 219, 222, 225, 227, 237, 238], "back": [5, 6, 8, 10, 17, 18, 20, 21, 29, 42, 45, 50, 58, 59, 60, 75, 83, 89, 91, 98, 103, 107, 108, 113, 125, 127, 138, 146, 148, 158, 160, 161, 162, 164, 173, 183, 184, 188, 189, 204, 222, 234, 245], "determin": [5, 6, 8, 11, 17, 38, 47, 92, 94, 98, 99, 100, 103, 106, 126, 137, 141, 151, 152, 155, 159, 171, 179, 188, 219, 222, 225, 226, 234], "conceptu": [5, 6, 29, 41, 48, 60, 110, 174, 233], "scalartyp": 5, "messag": [5, 48, 91, 135, 136, 181, 200, 201, 210, 213, 239], "alia": [5, 10, 98], "instanti": [5, 6, 10, 19, 20, 22, 31, 36, 50, 51, 65, 67, 86, 94, 107, 110, 113, 119, 126, 154, 155, 159, 172, 195, 222], "retriev": [5, 6, 14, 19, 29, 31, 48, 125, 126, 158, 160, 161, 174, 214], "at_dispatch_all_typ": 5, "sens": [5, 8, 12, 106, 107, 113, 137, 169, 245], "routin": [5, 6, 21], "convolut": [5, 6, 8, 12, 13, 18, 51, 60, 92, 94, 98, 107, 111, 117, 120, 122, 146, 149, 155, 156, 165, 166, 173, 174, 179, 193, 199, 200, 208, 211, 214, 218, 221, 225, 226, 236, 237, 239], "harder": [5, 181], "ourselv": [5, 6, 34, 48, 129, 158], "grid": [5, 97, 99, 107, 117, 156, 166, 169], "fill": [5, 6, 83, 94, 106, 107, 127, 173, 185, 186, 201, 211], "matric": [5, 12, 21, 22, 38, 47, 91, 103, 144, 151, 200], "2048": [5, 16, 117], "heard": 5, "introductori": [5, 81], "fairli": [5, 107, 113, 135, 159], "ever": [5, 6, 21, 98, 125], "__global__": 5, "__restrict__": 5, "size_t": 5, "column": [5, 7, 16, 21, 91, 98, 101, 103, 108, 118, 127, 143, 144, 149, 153, 159, 168, 185, 186, 187, 225, 246], "blockidx": 5, "blockdim": 5, "threadidx": 5, "index": [5, 6, 31, 38, 39, 42, 47, 48, 50, 58, 59, 60, 98, 100, 101, 103, 104, 106, 107, 108, 115, 116, 119, 120, 124, 125, 126, 127, 135, 138, 151, 159, 160, 164, 171, 173, 175, 188, 198, 204, 243, 249], "gates_row": 5, "primarili": [5, 161, 171, 218], "imagin": [5, 91, 98, 100, 106, 130, 135, 151, 164, 219], "giant": [5, 164], "million": [5, 115, 117, 120, 123, 173], "serial": [5, 6, 10, 21, 22, 35, 36, 60, 107, 111, 122, 173, 179, 192, 214, 219, 228, 229], "faster": [5, 6, 8, 9, 12, 17, 48, 55, 58, 59, 75, 95, 98, 107, 111, 123, 132, 137, 144, 146, 152, 160, 164, 171, 174, 175, 179, 188, 196, 207, 211, 215, 216, 218, 219, 222, 233, 234, 235, 238], "right": [5, 6, 8, 10, 12, 18, 21, 29, 33, 38, 41, 47, 48, 51, 64, 91, 95, 97, 101, 103, 106, 110, 113, 118, 135, 136, 145, 149, 156, 158, 159, 160, 164, 168, 175, 181, 190, 198, 214, 222, 239, 245], "inde": [5, 58, 59, 129, 144, 158, 163, 171, 186, 187, 219, 234], "agnost": [5, 60, 109, 220], "ineffici": [5, 173], "readabl": [5, 22, 31, 50, 92, 98, 100, 109, 128, 138, 168, 204, 219, 233], "especi": [5, 17, 48, 51, 60, 75, 92, 98, 113, 123, 133, 142, 149, 174, 185, 209, 211, 216], "dimension": [5, 30, 38, 45, 47, 48, 51, 57, 60, 72, 73, 91, 95, 97, 98, 103, 104, 106, 110, 113, 146, 155, 164, 169, 187, 200, 211], "stride": [5, 6, 17, 51, 92, 95, 113, 124, 129, 134, 143, 146, 174, 176, 187, 207], "row": [5, 16, 21, 50, 75, 91, 95, 98, 101, 103, 104, 106, 107, 116, 126, 127, 144, 156, 159, 160, 173, 174, 185, 187, 198, 201, 214, 246], "arithmet": [5, 17, 38, 94, 98, 181, 222], "fortun": [5, 6, 10, 21, 89, 135, 219], "expos": [5, 6, 8, 20, 21, 99, 113, 122, 138, 162, 178, 192, 199, 201, 204, 234], "foo": [5, 19, 20, 141, 161, 179, 192, 195, 202, 233, 245, 246], "12": [5, 7, 21, 40, 58, 59, 91, 94, 103, 108, 117, 123, 124, 143, 148, 153, 160, 169, 176, 193, 197, 201, 209, 210, 213, 215, 219, 245, 249], "hold": [5, 14, 16, 45, 60, 63, 64, 65, 67, 68, 69, 78, 89, 107, 110, 123, 124, 132, 134, 138, 159, 160, 162, 234], "foo_a": 5, "packed_accessor64": 5, "packed_accessor32": 5, "pack": [5, 48, 115, 143, 158, 160, 162, 201, 203, 211, 239], "integ": [5, 6, 8, 39, 60, 94, 98, 101, 103, 106, 113, 115, 126, 155, 187, 192, 200, 216, 222, 224, 225, 248], "fundament": [5, 48, 90, 93, 95, 103, 106, 110, 122, 145, 185, 233], "packedtensoraccessor32": 5, "restrictptrtrait": 5, "decompos": [5, 10, 148], "packedaccessor32": 5, "variant": [5, 48, 60, 94, 95, 97, 99, 129, 157], "int32_t": 5, "packedaccessor64": 5, "slower": [5, 55, 133, 148, 157, 159, 173, 175], "host": [5, 7, 16, 33, 53, 90, 100, 123, 124, 133, 134, 135, 148, 153, 161, 162, 168, 205, 225, 232, 234], "reshap": [5, 6, 12, 17, 95, 98, 106, 107, 109, 141, 179, 183, 188, 192, 199, 209], "pattern": [5, 19, 95, 97, 135, 141, 143, 151, 161, 174, 179, 180, 181, 184, 186, 192, 195, 208], "lltm_cuda_backward_kernel": 5, "lltm_backward_cuda": 5, "d_gate_weight": 5, "cudaextens": [5, 154], "hassl": [5, 6], "entail": 5, "simpler": [5, 80, 107, 129, 140, 151, 192, 198, 219], "fastest": [5, 148, 163], "129": [5, 108, 182], "431": 5, "304": [5, 48, 174], "641": [5, 146], "faq": [5, 20, 21], "sit": [6, 40, 148, 151, 244, 246, 248], "atop": 6, "substanti": [6, 126], "codebas": [6, 10], "foundat": [6, 158], "underli": [6, 8, 21, 38, 47, 75, 83, 98, 111, 126, 137, 143, 148, 152, 161, 179, 186, 187, 188, 205, 227], "popular": [6, 68, 75, 77, 110, 126, 136, 174, 208, 209, 244], "stochast": [6, 7, 34, 45, 51, 65, 91, 94, 99, 107, 110, 115, 118, 135, 153, 158, 159], "descent": [6, 7, 34, 41, 45, 65, 91, 94, 99, 107, 109, 110, 115, 118, 135, 153, 237], "digit": [6, 45, 94, 107, 122, 123, 124], "whirlwind": 6, "wet": 6, "appetit": 6, "watch": [6, 99, 113, 131, 135], "lightn": [6, 126], "talk": [6, 8, 48, 51, 54, 94, 103, 115, 135, 158, 161], "cppcon": 6, "2018": [6, 119, 136], "quick": [6, 30, 47, 58, 59, 91, 101, 104, 106, 120, 122, 123, 127, 133, 137, 144, 152, 204, 219, 222, 223, 231, 238, 240], "humor": 6, "sweep": [6, 163], "philosophi": [6, 113], "ecosystem": 6, "descript": [6, 49, 61, 123, 124, 143, 158, 160, 161, 162, 163, 178, 219, 232, 234, 246], "embark": 6, "excit": [6, 20, 21, 142], "team": [6, 115, 126, 136, 159], "job": [6, 43, 51, 52, 53, 124, 126, 131, 132, 133, 135, 211], "reinforc": [6, 61, 99, 122, 145, 160, 161, 165], "game": [6, 42, 51, 81, 145], "tractabl": [6, 100], "multithread": [6, 41, 55, 108, 205, 214, 219], "lock": [6, 22, 55, 134, 135, 160, 161, 174, 205, 244], "gil": [6, 55, 61, 133, 205], "multiprocess": [6, 11, 31, 35, 50, 52, 54, 55, 109, 123, 124, 133, 134, 135, 158, 161, 162, 203, 205, 241], "scalabl": [6, 126, 184, 200, 208, 234], "shortcom": [6, 186], "neuroevolut": 6, "owner": [6, 160, 161, 162], "anyth": [6, 13, 42, 72, 73, 94, 95, 98, 100, 103, 104, 106, 107, 110, 138, 157, 178, 179, 214, 232, 245, 246], "serv": [6, 56, 61, 86, 94, 104, 110, 122, 127, 133, 138, 142, 145, 148, 154, 161, 162, 173, 174, 186, 203, 204, 218, 219, 233, 234], "web": [6, 204, 238, 245], "server": [6, 14, 22, 61, 120, 121, 122, 127, 133, 148, 154, 162, 174, 176, 181, 189, 204, 205, 208, 216, 238], "3d": [6, 77, 95, 97, 103, 104, 192, 234], "graphic": [6, 163, 199], "photo": [6, 92], "softwar": [6, 136, 148, 154, 173, 199, 204, 245], "integr": [6, 10, 21, 33, 80, 89, 108, 126, 169, 173, 174, 176, 193, 199, 214, 217, 236], "remain": [6, 7, 89, 91, 120, 135, 141, 153, 155, 164, 176, 186, 188, 190, 202, 234], "forth": [6, 107, 148, 173, 246], "retain": [6, 38, 47, 78, 83, 98, 111], "intuit": [6, 51, 75, 80, 94, 98, 101, 111, 143, 148, 164, 185, 214, 224, 229], "tradit": [6, 40, 51, 101, 144, 161], "compet": [6, 113, 115, 120, 126, 173, 174], "complement": 6, "alik": 6, "love": [6, 113], "simplic": [6, 75, 123, 129, 158, 159, 210, 219], "core": [6, 8, 10, 11, 40, 43, 57, 60, 78, 100, 101, 110, 111, 115, 135, 143, 146, 157, 168, 174, 189, 191, 192, 197, 210, 214, 218, 233, 234], "principl": [6, 8, 104, 106, 122, 126], "curiou": [6, 137, 152], "tri": [6, 16, 51, 91, 100, 106, 113, 159, 199, 218], "experienc": [6, 86], "ask": [6, 20, 21, 60, 92, 94, 95, 128, 158, 202, 219], "rememb": [6, 42, 51, 59, 75, 78, 104, 107, 108, 111, 138, 144, 145, 164, 219, 227, 228, 229, 230], "dot": [6, 29, 51, 104, 106, 122, 144, 164, 165, 173, 174, 198, 219], "colon": [6, 245], "minim": [6, 10, 12, 21, 34, 51, 61, 63, 64, 67, 68, 69, 72, 73, 75, 91, 101, 106, 107, 110, 122, 123, 126, 132, 136, 143, 159, 171, 179, 181, 184, 197, 202, 222, 237], "verifi": [6, 18, 58, 59, 86, 91, 98, 114, 116, 120, 130, 137, 140, 141, 144, 146, 155, 157, 173, 174, 175, 199, 208, 214, 240], "zip": [6, 16, 48, 49, 51, 111, 116, 136, 159, 160, 162, 169, 175, 178, 181, 201, 205, 211], "too": [6, 10, 17, 42, 64, 68, 89, 94, 95, 100, 106, 107, 108, 110, 133, 138, 148, 155, 158, 159, 160, 162, 164, 184, 216, 229, 233, 243, 245, 246], "cu90": 6, "url": [6, 17, 119, 168, 171, 201, 210, 232, 243], "wget": [6, 16, 77, 178, 201], "nightli": [6, 16, 77, 123, 124, 136, 140, 171, 172, 182, 183, 191, 197, 198, 201, 209], "dep": 6, "tini": [6, 124, 148], "three": [6, 10, 12, 31, 34, 50, 51, 61, 64, 75, 86, 89, 91, 92, 97, 98, 100, 107, 110, 111, 113, 119, 122, 128, 135, 146, 151, 154, 158, 162, 163, 164, 166, 168, 169, 172, 173, 174, 187, 214, 216, 225, 240, 245, 246], "ey": [6, 18, 21, 198, 201, 245], "fledg": 6, "visual": [6, 22, 41, 51, 75, 77, 94, 99, 122, 123, 125, 126, 130, 142, 158, 168, 173, 174, 186, 232, 238], "studio": [6, 58, 197, 210, 212, 215], "qmake": 6, "makefil": 6, "comfort": 6, "box": [6, 8, 10, 11, 39, 75, 113, 126, 130, 135, 157, 160, 168, 173, 174, 175, 198, 200, 208, 213, 214, 217, 245], "cmake_prefix_path": [6, 20, 21], "invok": [6, 8, 20, 21, 22, 133, 134, 140, 142, 143, 154, 161, 162, 174, 183, 186, 196, 200, 214, 234], "agre": [6, 21, 136, 241], "break": [6, 8, 10, 11, 17, 30, 31, 91, 95, 111, 113, 138, 159, 160, 162, 171, 184, 229, 245], "unexpect": [6, 50, 186, 190, 234], "pwd": [6, 201, 214], "fa350df05ecf": 6, "home": [6, 38, 47, 113, 184, 189, 197, 199, 202, 206, 210], "enter": [6, 48, 60, 123, 133, 135], "ran": [6, 106, 158, 161, 163, 197, 219], "me": [6, 40, 48, 164, 245, 246], "extens": [6, 7, 15, 20, 21, 51, 92, 111, 122, 127, 130, 135, 153, 173, 184, 186, 192, 209, 219, 224, 228, 229, 238], "besid": [6, 21, 94, 106, 151, 160, 209, 217, 234, 245], "encapsul": [6, 34, 45, 95, 99, 160], "buffer": [6, 42, 45, 59, 78, 109, 111, 123, 129, 133, 137, 140, 145, 149, 151, 152, 155, 159, 174, 183, 195, 199, 201, 211, 228, 236, 237], "nest": [6, 30, 41, 94, 98, 109, 141, 158, 160, 162, 163, 191, 245, 246], "similarli": [6, 9, 12, 20, 50, 60, 83, 92, 98, 113, 116, 124, 125, 126, 134, 143, 144, 176, 187], "w": [6, 7, 29, 34, 41, 45, 75, 78, 104, 106, 118, 123, 136, 146, 153, 162, 168, 175, 181, 182, 210], "struct": [6, 20, 201, 239], "int64_t": [6, 8, 21], "register_paramet": [6, 195], "reflect": [6, 8, 21, 38, 47, 94, 98, 158, 190], "magic": [6, 101, 128, 135, 144], "behind": [6, 8, 21, 43, 101, 107, 110, 129, 159, 176, 185, 187, 191, 195, 245], "scene": [6, 21, 58, 59, 107, 110, 113, 195], "another_bia": 6, "recurs": [6, 14, 42, 60, 109, 195, 207, 232], "0808": 6, "8613": 6, "2017": [6, 75, 119], "5206": 6, "5353": 6, "3740": 6, "0976": 6, "4786": 6, "4928": 6, "1434": 6, "4713": 6, "1735": 6, "3293": [6, 175], "3467": 6, "3858": 6, "1980": 6, "1986": 6, "1975": 6, "4278": 6, "1831": 6, "2709": 6, "3730": 6, "4307": 6, "3236": 6, "0629": 6, "2038": 6, "4638": 6, "2023": 6, "1230": 6, "0516": 6, "aptli": [6, 13], "register_modul": 6, "dropout": [6, 17, 18, 36, 48, 60, 75, 95, 107, 109, 111, 124, 126, 128, 156, 160, 162, 164, 188, 189, 209, 228, 229, 230, 239, 240], "conv2d": [6, 12, 17, 42, 45, 51, 80, 94, 107, 111, 124, 129, 134, 141, 157, 161, 169, 174, 176, 179, 192, 200, 207, 208, 209, 211, 214, 216, 225, 229, 234, 239], "subtleti": [6, 187], "initi": [6, 8, 11, 14, 16, 17, 18, 19, 20, 21, 22, 30, 31, 34, 41, 48, 54, 60, 64, 72, 73, 75, 83, 92, 94, 98, 99, 101, 104, 106, 107, 108, 110, 111, 117, 123, 124, 127, 128, 137, 141, 143, 146, 155, 156, 157, 159, 160, 161, 162, 164, 168, 172, 187, 191, 192, 196, 199, 204, 211, 214, 217, 219, 222, 240, 245], "bodi": [6, 113, 143, 245, 246], "upon": [6, 48, 55, 81, 117, 135, 140, 164, 169, 171, 192, 217, 234, 243], "p": [6, 7, 16, 17, 48, 68, 95, 100, 106, 107, 109, 110, 118, 123, 124, 129, 134, 135, 136, 141, 146, 149, 153, 156, 160, 161, 162, 175, 179, 181, 192, 199, 200, 201, 203, 205], "0345": [6, 181], "4456": 6, "6313": 6, "3585": [6, 175], "4008": [6, 21], "1647": 6, "2891": 6, "0527": 6, "0354": 6, "3084": 6, "2025": 6, "0343": [6, 201], "1824": 6, "4630": 6, "2862": 6, "2500": [6, 117], "0420": 6, "3679": 6, "1482": 6, "0460": 6, "1967": 6, "2132": 6, "1992": 6, "4257": 6, "0739": 6, "01": [6, 7, 11, 17, 41, 45, 91, 108, 112, 135, 156, 162, 175, 209, 241, 246], "6861": 6, "1166": 6, "45": [6, 7, 126, 143, 162, 173, 197], "0333": 6, "9983": 6, "0705": 6, "named_paramet": [6, 30], "ordereddict": [6, 175], "13": [6, 21, 72, 94, 108, 117, 162, 173, 211, 214, 245, 249], "48": [6, 7, 91, 127, 143, 146, 169, 197, 225], "1863": 6, "8611": 6, "1228": 6, "3269": 6, "9858": 6, "0339": 6, "2484": 6, "2035": 6, "2103": 6, "0715": 6, "2975": 6, "4350": 6, "1878": 6, "3616": 6, "1050": 6, "4982": 6, "0335": [6, 181], "1605": 6, "4963": 6, "4099": 6, "2883": [6, 103], "1818": 6, "3447": 6, "1501": 6, "0215": 6, "0250": 6, "0408": 6, "3756": 6, "2149": 6, "3636": 6, "8559": 6, "1572": 6, "1069": 6, "1247": 6, "8060": 6, "topic": [6, 48, 58, 59, 61, 75, 92, 98, 114, 121, 173, 205], "devour": 6, "menu": [6, 49, 243, 245], "pipelin": [6, 14, 15, 61, 107, 113, 122, 138, 158, 160, 165, 173, 174, 175, 222], "briefli": [6, 34, 61, 122, 158, 171, 200], "who": [6, 40, 48, 57, 75, 81, 113, 135, 214, 219, 245], "heap": 6, "referenc": [6, 134, 162, 222], "lower": [6, 49, 75, 95, 97, 123, 126, 133, 136, 140, 143, 151, 156, 158, 159, 169, 176, 181, 187, 190, 211, 233, 246], "heavili": [6, 113, 164, 173], "influenc": [6, 51, 95], "ergonom": 6, "far": [6, 7, 18, 20, 45, 48, 58, 59, 64, 91, 94, 95, 98, 100, 101, 110, 115, 118, 125, 135, 138, 148, 153, 155, 159, 164, 173, 184, 219, 245], "stack": [6, 8, 19, 20, 38, 47, 80, 94, 108, 137, 145, 149, 154, 160, 164, 168, 169, 188, 198], "shared_ptr": [6, 20], "cognit": 6, "everywher": [6, 98, 106], "make_shar": 6, "though": [6, 10, 21, 45, 75, 91, 98, 100, 113, 117, 129, 130, 137, 138, 142, 152, 158, 169, 184, 208, 219, 233], "stai": [6, 123, 158, 159, 160, 173, 216], "shorten": [6, 21], "wait": [6, 14, 19, 128, 133, 134, 135, 154, 159, 160, 161, 162, 168, 173, 225, 234], "hell": 6, "lot": [6, 8, 10, 17, 19, 50, 81, 91, 100, 107, 113, 120, 124, 135, 149, 161, 164, 168, 171, 173, 184, 218, 219, 222, 233], "came": [6, 51, 185], "scheme": [6, 16, 99, 122, 184, 195], "hide": [6, 119, 129, 158, 198], "reserv": [6, 10, 136, 168], "simplifi": [6, 10, 80, 107, 133, 134, 164, 174, 175, 184, 187, 191, 192], "linearimpl": 6, "torch_modul": 6, "brief": [6, 61, 91, 100, 158, 201], "typedef": 6, "among": [6, 8, 20, 52, 58, 59, 89, 99, 155, 168, 173, 193, 216, 217], "holder": [6, 119, 247], "arrow": [6, 41, 190], "resembl": [6, 12, 21, 58, 59, 100, 131, 159], "extra": [6, 8, 55, 94, 98, 103, 104, 107, 127, 128, 129, 134, 140, 151, 158, 164, 171, 174, 175, 189, 208, 211, 225, 233, 234], "netimpl": 6, "subtl": [6, 98, 218], "deserv": [6, 113], "construct": [6, 18, 19, 20, 22, 29, 45, 51, 60, 61, 65, 67, 86, 110, 117, 122, 128, 130, 134, 137, 144, 148, 152, 158, 159, 161, 164, 175, 180, 188, 191, 192, 193, 195, 198, 209, 218, 221, 236, 241, 245, 246], "null": [6, 58, 201, 211, 214], "tricki": [6, 130, 141, 173], "had": [6, 21, 40, 45, 50, 91, 94, 98, 104, 107, 110, 113, 151, 159, 169, 192, 208, 214], "nullptr": [6, 201], "familiar": [6, 8, 10, 20, 33, 34, 38, 42, 47, 52, 53, 55, 57, 60, 86, 90, 94, 98, 99, 100, 107, 111, 122, 123, 125, 131, 132, 135, 138, 145, 161, 214, 219, 233], "pythonista": 6, "disadvantag": [6, 111, 229], "said": [6, 21, 22, 40, 145, 158, 184, 185, 245], "introduct": [6, 11, 44, 46, 52, 53, 54, 55, 56, 81, 85, 86, 91, 95, 101, 102, 105, 112, 122, 131, 132, 143, 186, 208, 219, 234, 238, 240], "sooner": [6, 123], "technic": [6, 21, 135, 184], "henceforth": 6, "recap": [6, 45, 159, 187], "adversari": [6, 42, 81, 99, 112, 122], "architectur": [6, 9, 22, 30, 51, 55, 60, 75, 86, 95, 98, 100, 109, 122, 123, 126, 131, 137, 149, 155, 163, 169, 171, 172, 173, 174, 192, 208, 214, 216, 218, 234], "distinct": [6, 19, 51, 98, 106, 123, 162, 169], "transform": [6, 12, 15, 17, 18, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 48, 51, 58, 59, 60, 77, 89, 91, 92, 94, 98, 99, 108, 109, 112, 113, 116, 117, 122, 124, 135, 137, 138, 140, 141, 143, 145, 149, 151, 156, 157, 161, 164, 165, 168, 169, 175, 179, 181, 188, 192, 197, 204, 205, 208, 209, 219, 221, 233, 234], "probabl": [6, 8, 20, 30, 48, 51, 58, 59, 60, 77, 92, 95, 98, 100, 103, 106, 118, 119, 124, 125, 126, 127, 128, 157, 159, 169, 175, 188], "judg": 6, "closer": [6, 91, 159, 174, 192], "authent": 6, "theori": [6, 48, 51, 60, 91, 125, 245], "delic": 6, "tandem": 6, "indistinguish": 6, "fool": [6, 48, 75], "excel": [6, 50, 169], "realist": [6, 19, 60, 188], "2d": [6, 30, 51, 95, 107, 127, 141, 160, 172, 239], "dcgangeneratorimpl": 6, "knoises": 6, "conv1": [6, 45, 95, 111, 124, 141, 152, 155, 156, 161, 169, 179, 209, 229], "convtranspose2dopt": 6, "256": [6, 17, 50, 89, 117, 125, 134, 145, 164, 173, 175, 179, 192, 193, 200, 225], "batch_norm1": 6, "conv2": [6, 80, 95, 111, 124, 141, 161, 169, 209, 229], "pad": [6, 17, 40, 48, 60, 77, 95, 113, 115, 119, 129, 134, 136, 163, 186, 188, 234], "batch_norm2": 6, "conv3": 6, "batch_norm3": 6, "conv4": 6, "convtranspose2d": 6, "batchnorm2d": [6, 17, 51, 107, 129, 134, 141, 142, 176, 207, 211, 234, 239], "dcgangener": 6, "chosen": [6, 18, 20, 92, 95, 159, 171, 218, 219], "student": [6, 113], "harm": 6, "discoveri": 6, "fed": [6, 12, 35, 48, 51, 61, 113, 119, 134, 138, 148, 174], "soylent": 6, "regularli": [6, 52], "channel": [6, 10, 12, 17, 19, 41, 42, 51, 92, 94, 95, 98, 107, 109, 122, 123, 138, 155, 165, 169, 175, 181, 201, 203, 204, 208, 221, 234, 244], "moduleopt": 6, "linearopt": 6, "leaki": [6, 51], "squash": [6, 145], "sequenti": [6, 7, 12, 17, 48, 68, 95, 106, 109, 110, 118, 119, 134, 141, 151, 153, 156, 181, 188, 189, 195, 198, 234, 241], "orient": [6, 166], "layer": [6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 29, 35, 36, 40, 41, 45, 48, 51, 54, 60, 68, 75, 80, 89, 91, 94, 97, 98, 99, 101, 107, 109, 110, 111, 115, 117, 118, 119, 122, 123, 124, 126, 127, 128, 134, 146, 148, 151, 153, 155, 156, 157, 158, 161, 162, 164, 166, 173, 174, 175, 181, 193, 203, 217, 218, 221, 222, 226, 228, 229, 230, 235, 236, 239, 240], "conv2dopt": 6, "leakyrelu": [6, 51, 109], "leakyreluopt": 6, "negative_slop": 6, "composit": [6, 11, 22, 57, 101, 144, 158], "third": [6, 8, 12, 20, 21, 51, 63, 64, 65, 67, 68, 69, 72, 73, 95, 98, 104, 110, 122, 130, 154, 164, 172, 184, 190, 198, 246], "fourth": [6, 65, 110, 130, 189], "knob": [6, 173, 174], "truli": [6, 48, 145], "sampler": [6, 17, 31, 54, 99, 109, 123, 124, 136, 158, 166, 179, 181, 192, 224], "collat": [6, 50, 246], "wherev": 6, "make_data_load": 6, "unique_ptr": 6, "spawn": [6, 11, 16, 48, 51, 52, 54, 124, 133, 134, 135, 148, 160, 161, 162, 203, 241], "concurr": [6, 108, 126, 134, 148, 173, 174, 234], "kbatchsiz": 6, "dataloaderopt": 6, "consol": [6, 169, 183], "label": [6, 31, 34, 35, 39, 41, 42, 50, 51, 58, 59, 75, 77, 80, 89, 91, 92, 94, 97, 98, 99, 101, 106, 108, 109, 115, 117, 120, 123, 127, 133, 134, 136, 148, 156, 157, 160, 164, 169, 175, 181, 201, 204, 209, 214, 219, 221, 224, 225, 238, 241, 245], "field": [6, 10, 11, 30, 48, 95, 104, 106, 113, 135, 160, 168, 175, 186, 193, 205, 211], "rebuild": [6, 219], "danc": [6, 12], "generator_optim": 6, "adamopt": 6, "2e": [6, 91, 136], "beta": [6, 15, 122, 165, 187, 205, 222, 234], "make_tupl": 6, "discriminator_optim": 6, "5e": 6, "adagrad": [6, 99, 109, 110, 187, 191, 194], "lbfg": [6, 12, 109], "rmsprop": [6, 34, 45, 69, 101, 109, 110], "sgd": [6, 7, 17, 34, 41, 42, 45, 67, 69, 89, 91, 99, 101, 107, 109, 110, 111, 115, 117, 118, 133, 134, 135, 148, 153, 156, 160, 161, 162, 166, 169, 175, 208, 209, 228, 229, 230, 236, 237], "date": [6, 10, 75, 115, 123, 161, 197, 208, 246], "exhaust": [6, 11], "knumberofepoch": 6, "batch_index": 6, "real_imag": 6, "real_label": 6, "real_output": 6, "d_loss_real": 6, "binary_cross_entropi": [6, 218], "fake_imag": 6, "fake_label": 6, "fake_output": 6, "d_loss_fak": 6, "d_loss": 6, "fill_": [6, 83, 168], "g_loss": 6, "printf": 6, "r": [6, 7, 11, 17, 34, 40, 41, 45, 75, 78, 86, 100, 118, 122, 143, 144, 145, 146, 149, 153, 159, 160, 162, 173, 175, 179, 192, 197, 198, 201, 208, 219, 234, 245], "2ld": 6, "3ld": 6, "4f": [6, 117, 123, 124, 156], "batches_per_epoch": 6, "uniformli": [6, 89, 159, 234], "robust": [6, 48, 52, 53, 75, 98, 159], "smooth": 6, "propag": [6, 10, 14, 29, 34, 41, 43, 45, 51, 80, 103, 104, 107, 127, 130, 140, 146, 158, 174, 234], "repeat": [6, 16, 17, 21, 91, 128, 158, 168, 173, 179, 184, 192, 203, 211, 225, 233], "spiel": 6, "progress": [6, 8, 51, 52, 97, 99, 109, 156, 164, 169, 193, 246], "observ": [6, 17, 45, 50, 61, 99, 116, 117, 123, 124, 126, 136, 145, 146, 158, 159, 160, 162, 163, 164, 171, 173, 176, 178, 179, 181, 187, 192, 193, 196, 218, 219, 222, 226, 234, 241], "meaning": [6, 48, 60, 146], "3c0711f20896": 6, "dcga": 6, "6876": 6, "1304": 6, "3776": 6, "3101": 6, "300": [6, 123, 162, 175, 219, 233], "3652": 6, "6626": 6, "400": [6, 58, 59, 111, 136, 175, 181, 219, 233], "8057": 6, "2795": [6, 219], "3531": 6, "4452": 6, "600": [6, 120, 146, 159, 240], "3501": [6, 103], "0811": 6, "700": 6, "3581": 6, "5623": 6, "800": 6, "6423": 6, "7385": 6, "900": 6, "3592": 6, "7333": 6, "4660": 6, "5242": 6, "6364": 6, "0886": [6, 91], "3717": 6, "8103": 6, "0201": 6, "3544": 6, "4522": 6, "6545": 6, "quickli": [6, 33, 42, 100, 101, 106, 107, 110, 159, 164, 205, 209, 222, 238], "onto": [6, 8, 14, 16, 42, 95, 97, 98, 122, 148, 161, 162, 195, 234], "somewher": [6, 21, 95, 100, 101, 111], "kcpu": [6, 199], "whose": [6, 40, 60, 86, 91, 92, 106, 123, 125, 146, 182, 193, 217, 219], "insert": [6, 12, 17, 95, 119, 136, 156, 162, 176, 178, 179, 192, 193, 216, 239], "op": [6, 10, 11, 19, 20, 21, 47, 122, 123, 124, 129, 133, 135, 136, 141, 143, 146, 157, 168, 173, 174, 175, 176, 178, 179, 181, 182, 183, 185, 186, 188, 192, 195, 200, 201, 203, 209, 210, 211, 218, 234, 239], "previou": [6, 11, 14, 20, 21, 34, 48, 52, 54, 58, 59, 98, 99, 107, 117, 120, 123, 127, 128, 130, 131, 132, 134, 145, 148, 155, 156, 158, 159, 160, 162, 163, 164, 168, 169, 171, 173, 174, 179, 192, 200, 201, 211, 219, 226, 234, 243], "resid": [6, 134], "downstream": [6, 113], "portabl": 6, "augment": [6, 50, 107, 117, 119, 120, 122, 156, 166, 175], "period": [6, 48, 51, 126, 145, 168, 173], "crash": [6, 61], "middl": [6, 245], "procedur": [6, 21, 45, 121, 156, 159, 166], "restor": [6, 75, 111, 146, 229, 236], "session": [6, 18, 89, 222, 245], "interv": [6, 91, 126, 162], "kcheckpointeveri": 6, "str": [6, 16, 17, 123, 136, 138, 141, 158, 161, 181, 189, 196, 201, 202, 204, 205], "checkpoint_count": 6, "counter": [6, 11, 48, 51, 135], "bump": 6, "beta1": [6, 51], "krestorefromcheckpoint": 6, "intermediari": [6, 125], "xxx": [6, 50], "matplotlib": [6, 12, 31, 51, 56, 91, 92, 94, 97, 117, 156, 159, 164, 169], "argpars": [6, 123, 124, 136, 160, 161, 162, 181], "pyplot": [6, 12, 91, 107, 117, 156, 159, 169], "plt": [6, 12, 91, 117, 156, 159, 164, 169], "parser": [6, 100, 123, 124, 160, 161, 162, 245], "argumentpars": [6, 123, 124, 160, 161, 162], "add_argu": [6, 123, 124, 160, 161, 162], "png": [6, 50, 175], "parse_arg": [6, 123, 124, 160, 161, 162], "sample_fil": [6, 138], "mul": [6, 47, 91, 143, 192, 199, 219, 233], "255": [6, 12, 59, 138, 176, 193, 204, 225], "uint8": [6, 98, 175, 193], "numpi": [6, 12, 15, 17, 39, 42, 50, 56, 71, 73, 74, 91, 107, 108, 109, 117, 122, 130, 136, 156, 157, 159, 162, 169, 171, 175, 179, 181, 184, 191, 192, 197, 217, 233], "axi": [6, 19, 103, 104, 109, 117, 127, 136, 155, 156, 181], "subplot": [6, 117, 156], "imshow": [6, 12, 117, 156, 169], "cmap": [6, 169], "grai": [6, 120, 145, 183], "get_xaxi": 6, "set_vis": 6, "get_yaxi": 6, "savefig": 6, "out_fil": 6, "17": [6, 19, 21, 58, 59, 72, 94, 108, 113, 117, 143, 182, 196, 219, 249], "57": [6, 7, 108, 127, 143, 225], "4953": 6, "0195": [6, 181], "3610": 6, "8148": 6, "4072": 6, "36760": 6, "4444": 6, "3761": 6, "8790": 6, "3977": 6, "3315": 6, "120": [6, 111, 117, 134, 148, 156, 162, 169, 225, 229], "8084": 6, "hoorai": [6, 22], "ball": 6, "court": 6, "digest": [6, 233], "necess": [6, 48, 97], "broad": [6, 56, 92, 99], "space": [6, 20, 48, 51, 60, 75, 91, 92, 95, 100, 104, 106, 113, 115, 126, 145, 158, 159, 162, 164, 169, 189, 245, 246], "consult": [6, 192, 217, 244], "stuck": 6, "whenev": [6, 20, 52, 67, 98, 100, 101, 200, 237], "rate": [6, 7, 34, 41, 51, 89, 94, 95, 99, 101, 115, 117, 118, 123, 124, 126, 145, 153, 156, 159, 161, 175, 205, 224, 232, 234], "pritam": [7, 14, 153], "damania": [7, 14, 153], "torchtext": [7, 35, 40, 49, 94, 99, 112, 113, 122, 127, 153, 164, 224], "positionalencod": [7, 118, 153], "inject": [7, 118, 153], "posit": [7, 92, 95, 101, 113, 118, 119, 122, 136, 151, 153, 158, 159, 164, 217, 243], "token": [7, 40, 48, 60, 77, 106, 113, 115, 116, 118, 119, 123, 128, 153, 164, 181, 234], "sine": [7, 110, 118, 153], "cosin": [7, 118, 153], "replica": [7, 54, 55, 61, 124, 133, 135, 148, 241], "drive": [7, 14, 22, 51, 58, 59, 60, 91, 94, 95, 122, 145, 153, 184, 203], "largest": [7, 60, 107, 153, 159, 181], "belong": [7, 33, 127, 136, 153, 204, 245], "transformerencod": [7, 40, 95, 118, 153], "nlayer": [7, 153, 162], "transformerencoderlay": [7, 40, 95, 118, 153, 163], "decod": [7, 95, 100, 113, 123, 153, 162, 174, 218, 239], "run_work": [7, 134, 160, 161, 162, 203], "wikitext": [7, 9, 118, 153, 178], "torchdata": [7, 49, 113, 115, 116, 118, 119, 153], "vocab": [7, 77, 101, 104, 115, 118, 119, 136, 153, 181], "numeric": [7, 118, 119, 153], "batchifi": [7, 118, 153], "arrang": [7, 110, 118, 153], "trim": [7, 118, 153, 164, 233], "alphabet": [7, 118, 153], "26": [7, 21, 118, 143, 145, 146, 153, 157, 162], "bmatrix": [7, 104, 118, 153], "text": [7, 31, 42, 51, 75, 77, 86, 92, 100, 101, 103, 104, 106, 112, 113, 118, 119, 121, 122, 123, 127, 128, 135, 136, 138, 153, 158, 159, 164, 168, 178, 191, 214, 217, 232, 238, 246, 248], "c": [7, 12, 16, 17, 19, 22, 41, 63, 64, 72, 86, 91, 92, 97, 98, 106, 109, 110, 111, 115, 118, 122, 128, 130, 135, 136, 138, 141, 143, 146, 153, 157, 162, 163, 172, 183, 202, 209, 211, 213, 214, 218, 219, 232, 238, 239, 246], "ldot": [7, 118, 153], "rightarrow": [7, 100, 118, 135, 153, 159], "j": [7, 20, 21, 29, 41, 58, 59, 75, 91, 100, 104, 117, 118, 136, 153, 164, 189], "k": [7, 12, 17, 58, 59, 92, 100, 118, 136, 153, 160, 161, 175, 179, 192, 202], "u": [7, 115, 118, 119, 153, 189], "treat": [7, 60, 77, 91, 106, 113, 118, 152, 153, 160, 171, 196, 239], "get_batch": [7, 118, 153], "subdivid": [7, 8, 118, 153], "bptt": [7, 118, 153], "4096": [7, 16, 153, 172], "billion": [7, 123, 153], "rpc": [7, 108, 122, 133, 148, 153, 205, 238], "rref": [7, 14, 61, 134, 153, 160, 161, 203, 205], "expans": [7, 134, 153], "replic": [7, 14, 16, 55, 60, 61, 81, 122, 124, 131, 133, 135, 148, 161, 162], "distributeddataparallel": [7, 14, 54, 55, 121, 123, 124, 135, 154, 162, 172, 218, 241], "crossentropyloss": [7, 14, 17, 34, 101, 109, 115, 117, 118, 153, 156, 162, 169, 179, 192, 208], "steplr": [7, 109, 115, 117, 118, 123, 124, 153, 156, 175], "clip_grad_norm_": [7, 118, 153], "togeth": [7, 11, 19, 22, 30, 36, 48, 50, 59, 60, 77, 86, 94, 95, 98, 99, 103, 107, 113, 119, 124, 129, 137, 153, 158, 160, 162, 164, 183, 192, 193, 205, 233, 239], "prevent": [7, 34, 48, 54, 78, 107, 108, 118, 119, 125, 128, 133, 143, 145, 153, 218, 219], "explod": [7, 48, 95, 118, 153], "rank": [7, 11, 14, 16, 40, 43, 52, 54, 122, 123, 124, 133, 134, 135, 154, 160, 161, 162, 172, 203, 241, 243], "lr": [7, 11, 17, 45, 51, 89, 91, 94, 107, 109, 111, 117, 123, 124, 133, 134, 135, 143, 145, 156, 159, 160, 161, 162, 169, 175, 205, 208, 209, 229, 241], "00": [7, 15, 37, 46, 70, 74, 82, 87, 91, 94, 96, 105, 108, 112, 117, 143, 162, 165, 175, 182, 194, 231], "ms": [7, 17, 143, 157, 173, 174], "778": 7, "97": [7, 143, 162], "43": [7, 120, 148, 219], "31": [7, 91, 123, 143, 193, 219, 225, 233], "ppl": 7, "6432469059895903232": 7, "90": [7, 136, 162], "44": [7, 117, 143, 162], "21245447128217366528": 7, "699": [7, 72], "89": [7, 143, 162, 173], "21176949187407757312": 7, "87": [7, 108, 162, 219], "62": [7, 162], "23975861229620961280": 7, "698": 7, "86": [7, 143, 157, 162, 219], "41": [7, 124, 157, 173, 219, 225], "1193312915629888256": 7, "40": [7, 113, 124, 145, 146, 162, 164, 173, 175, 190, 219], "69": [7, 181, 219], "471605759847546240": 7, "34": [7, 108, 157, 211, 219, 225, 233], "42812308420836458496": 7, "33": [7, 157, 162, 173, 174, 182, 219], "68": [7, 50, 127, 136, 143, 174, 219], "68839569686012223488": 7, "08": [7, 91, 123, 143, 162, 209, 219], "80": [7, 89, 126, 146, 162, 222], "22": [7, 117, 143, 146, 162, 197, 219], "09": [7, 48, 143, 162, 173], "75": [7, 20, 21, 117, 124, 148, 156, 175, 222], "768": [7, 136, 146, 181], "51": [7, 91, 120, 127, 146, 148, 162, 173], "36": [7, 115, 157], "6063529544668166": 7, "769": [7, 175], "23": [7, 117, 143, 162, 173, 219, 225, 233, 246], "17651211266236086": 7, "3798441739584": 7, "56": [7, 17, 72, 146, 157, 173, 219, 225], "29": [7, 136, 157, 162, 201, 219], "5203636967575": 7, "47": [7, 89, 127, 146, 219, 225], "2212498693571": 7, "05": [7, 18, 19, 75, 115, 123, 134, 159, 162, 176, 207], "2015144761281": 7, "13121380184": 7, "92": [7, 219], "14653799192": 7, "39": [7, 124, 127, 162, 219], "24": [7, 17, 91, 113, 117, 143, 157, 219], "98": [7, 50, 143, 162, 182], "361681": 7, "287876": 7, "61": [7, 17, 108, 146], "164364": 7, "60": [7, 31, 81, 109, 117, 123, 127, 128, 146, 156, 157, 162, 164, 169, 175, 225], "159095": 7, "697": 7, "54261": 7, "91": [7, 162, 219], "72": [7, 157, 219], "53372": 7, "49": [7, 91, 146, 148, 162, 175, 181, 219], "78": [7, 219], "47948": 7, "35": [7, 146, 196, 209], "79": [7, 143, 219, 225], "48664": 7, "42": [7, 21, 72, 112, 117, 127, 136, 162, 173, 181, 201, 219], "96": [7, 17, 117, 143, 162], "38": [7, 108, 162, 174, 233], "46": [7, 136, 143, 146, 157, 173], "000": [7, 15, 17, 18, 22, 30, 31, 33, 34, 36, 37, 39, 43, 45, 46, 63, 64, 65, 67, 68, 69, 70, 73, 74, 78, 80, 81, 82, 83, 89, 92, 95, 96, 108, 111, 112, 113, 114, 115, 118, 119, 126, 129, 138, 141, 142, 145, 146, 147, 148, 151, 152, 153, 155, 164, 165, 168, 169, 173, 178, 185, 187, 188, 194, 196, 198, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237], "ddp_pipelin": [7, 15], "respons": [8, 11, 14, 16, 48, 60, 91, 92, 99, 107, 122, 129, 133, 135, 138, 160, 161, 164, 171, 174, 201, 203, 204, 217, 245], "nontrivi": [8, 202], "cut": [8, 113, 120, 122, 245], "concern": [8, 19, 61, 101, 184, 192, 205, 209], "rule": [8, 20, 29, 41, 45, 60, 91, 98, 104, 125, 137, 144, 151, 152, 158, 159, 179, 218], "vmap": [8, 122, 140, 144, 149, 152, 191, 194], "statement": [8, 19, 22, 29, 41, 43, 60, 164, 180, 218, 220, 245], "convers": [8, 48, 91, 98, 111, 146, 164, 174, 184, 189, 205, 211, 216, 222], "basic": [8, 11, 14, 21, 29, 30, 31, 34, 35, 36, 38, 39, 48, 53, 55, 56, 57, 61, 73, 77, 88, 90, 91, 94, 95, 98, 106, 107, 110, 113, 115, 122, 127, 129, 143, 158, 163, 185, 188, 219, 232, 238, 239, 246], "registr": [8, 10, 20, 21, 201, 208, 209, 214], "highest": [8, 17, 42, 48, 58, 59, 60, 97, 128, 159], "prioriti": [8, 179], "transfer": [8, 15, 20, 42, 50, 58, 59, 83, 107, 111, 112, 122, 135, 157, 161, 168, 175, 199, 216, 220, 235, 239, 244], "redispatch": 8, "happen": [8, 19, 21, 22, 29, 30, 31, 34, 41, 51, 91, 94, 95, 98, 101, 107, 123, 130, 135, 155, 160, 168, 169, 181, 192, 201, 202, 219, 234, 237], "unlik": [8, 12, 60, 92, 98, 110, 125, 140, 141, 146, 156, 164], "style": [8, 60, 113, 115, 175, 201, 222, 243, 245, 246], "abid": [8, 51], "myop": 8, "myadd": [8, 10], "myadd_cpu": 8, "self_": 8, "other_": 8, "torch_internal_assert": 8, "devicetyp": 8, "self_ptr": 8, "data_ptr": [8, 21, 59, 201], "other_ptr": 8, "result_ptr": 8, "numel": [8, 160, 184, 233], "torch_library_impl": [8, 10], "impl": [8, 10, 233], "myadd_cuda": 8, "boundari": [8, 61, 134, 158], "myops_cpu": 8, "myops_cuda": 8, "xla": [8, 10], "torch_xla": [8, 10], "useabl": 8, "behav": [8, 18, 60, 83, 98, 107, 146, 151, 160, 214, 247], "autogradnotimplementedfallback": 8, "notimpl": 8, "node": [8, 16, 18, 21, 29, 41, 45, 52, 53, 54, 55, 63, 91, 97, 100, 109, 110, 121, 123, 131, 132, 133, 141, 142, 143, 161, 164, 173, 193, 234, 239], "preserv": [8, 20, 22, 98, 122, 134, 146, 155, 174, 180, 185, 211, 222, 236, 245], "require_grad": 8, "ness": 8, "pin": [8, 99, 125, 234, 244], "lost": 8, "mutat": [8, 10, 110, 137, 152, 198], "alias": [8, 10], "adinplaceorview": 8, "bookkeep": [8, 219], "autogradnotimplementedinplaceorviewfallback": 8, "logi": 8, "properli": [8, 9, 10, 21, 49, 54, 119, 130, 133, 135, 146, 148, 151, 158, 160, 161, 162, 164, 173, 183, 184, 186, 189, 195, 202, 212, 213, 222, 227], "annot": [8, 10, 16, 19, 20, 21, 31, 50, 60, 101, 119, 136, 171, 174, 205, 219], "guess": [8, 34, 41, 48, 51, 113, 127, 164], "twist": [8, 113], "constitut": 8, "hood": [8, 17, 48, 51, 53, 55, 110, 125, 144, 145, 162, 187, 188, 203, 205], "singleton": [8, 161], "findschemaorthrow": 8, "decltyp": 8, "qualifi": [8, 20], "overload": [8, 20], "typic": [8, 11, 17, 19, 31, 38, 41, 45, 47, 53, 54, 58, 59, 94, 100, 101, 106, 115, 120, 126, 129, 131, 143, 158, 161, 171, 173, 174, 193, 204, 208, 209, 216, 218, 220, 222, 234], "cast": [8, 16, 73, 108, 123, 218], "lookup": [8, 14, 106, 115, 162, 172], "typo": 8, "myaddfunct": [8, 10], "autononvariabletypemod": [8, 10, 59, 201], "myadd_autograd": [8, 10], "except": [8, 11, 21, 38, 41, 47, 48, 51, 58, 59, 61, 78, 83, 92, 95, 98, 101, 104, 117, 127, 134, 136, 137, 138, 140, 141, 144, 146, 148, 152, 154, 156, 164, 188, 191, 195, 198, 199, 208, 210], "raii": 8, "guard": [8, 59, 133, 201], "infinit": 8, "overflow": [8, 48, 218, 222], "send": [8, 10, 11, 12, 42, 43, 61, 80, 89, 115, 135, 138, 145, 154, 156, 160, 161, 162, 203, 225], "consider": [8, 10, 18, 124], "handler": [8, 174], "autogradcpu": 8, "autogradcuda": 8, "pythondispatch": 8, "_python_dispatch": 8, "isn": [8, 91, 100, 118, 140, 141, 157, 169, 186, 219, 221, 227, 228, 229, 230, 235, 236, 243, 245], "glorifi": 8, "add_cpu": 8, "add_cuda": 8, "unsupport": [8, 171, 174], "decentr": 8, "importantli": [8, 17, 21, 40, 130, 184, 219], "parti": [8, 20, 21, 154], "aspect": [8, 75, 135, 175, 219], "patch": [8, 10, 159], "dispatchkei": [8, 10], "varieti": [8, 30, 48, 91, 92, 95, 99, 107, 111, 128, 187], "fallback": [8, 10, 181], "behavior": [8, 10, 11, 12, 20, 22, 34, 48, 50, 95, 104, 107, 142, 143, 146, 148, 158, 185, 186, 192, 195, 211, 234], "opt": [8, 20, 107, 109, 126, 134, 146, 154, 161, 162, 195], "amp": [8, 61, 146, 200, 208, 238], "incom": [8, 94, 168, 204], "float16": [8, 123, 136, 146, 200, 218], "float32": [8, 21, 47, 123, 157, 159, 162, 175, 193, 218, 234], "matmul": [8, 21, 47, 143, 198, 200, 201, 218, 234], "impair": 8, "converg": [8, 34, 48, 51, 64, 99, 110, 111, 135, 151, 159, 164, 218, 222, 235, 238], "hypothet": 8, "autocast_mod": 8, "mymatmul_autocast": 8, "excludedispatchkeyguard": 8, "no_autocast": 8, "mymatmul": 8, "cached_cast": 8, "khalf": 8, "elig": 8, "polici": [8, 122, 124, 145, 159, 160, 162], "mixtur": 8, "meanwhil": [8, 125, 143, 185, 208], "float64": [8, 47], "unaffect": 8, "forc": [8, 21, 48, 60, 95, 122, 127, 164, 171, 184, 186, 218, 234, 243], "fallthrough": 8, "occur": [8, 11, 21, 22, 52, 77, 80, 116, 143, 146, 160, 161, 168, 174, 181, 225], "fall": [8, 92, 151, 159], "aren": [8, 130, 186, 234, 237], "dri": 8, "reduct": [8, 9, 58, 59, 98, 120, 123, 124, 125, 129, 136, 154, 168, 178, 184, 186, 191, 211, 218, 222], "gemm": [8, 143, 173, 174], "unless": [8, 18, 38, 47, 98, 101, 136, 158, 179, 181, 198], "categori": [8, 10, 17, 75, 92, 98, 117, 127, 128, 168, 179, 192, 201], "promote_typ": 8, "widest": 8, "safest": 8, "my_multiple_input_op_autocast": 8, "t0": [8, 123, 219], "t1": [8, 47, 219], "optimist": 8, "exec_typ": 8, "my_multiple_input_op": 8, "myadd_autocast": 8, "gymnast": 8, "invoc": [8, 22, 142, 160, 174, 214], "stabil": [8, 159], "41478": 8, "jame": [9, 22, 113, 142], "reed": [9, 22, 142], "seth": [9, 17, 33], "weidman": [9, 17], "corpu": [9, 48, 49, 60, 136], "preprocess": [9, 18, 40, 50, 58, 59, 60, 107, 112, 113, 122, 127, 164, 182, 197, 222], "train": [9, 10, 12, 14, 15, 16, 18, 21, 29, 33, 34, 35, 39, 40, 41, 44, 45, 46, 50, 53, 55, 56, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 72, 73, 75, 77, 81, 86, 90, 92, 93, 95, 98, 100, 104, 106, 107, 110, 113, 116, 118, 119, 120, 122, 124, 126, 129, 133, 136, 141, 146, 147, 148, 149, 151, 152, 154, 157, 160, 161, 162, 163, 165, 168, 171, 172, 173, 175, 180, 181, 182, 186, 189, 191, 193, 194, 200, 204, 205, 212, 213, 215, 218, 221, 222, 224, 225, 227, 228, 229, 230, 232, 235, 236, 238, 239, 240, 241], "gpt": [9, 53, 124, 131, 132], "almost": [9, 12, 17, 83, 104, 106, 124, 157, 173], "quantize_dynam": [9, 136, 216, 222], "int8": [9, 17, 98, 136, 157, 174, 181, 192, 193, 200, 209, 211, 216, 222], "macbook": [9, 17, 136, 164], "pro": [9, 17, 90, 136], "welcom": [9, 17, 136, 181, 182, 183, 190, 197, 210], "dynamic_quantization_tutori": [9, 15, 222], "outsid": [10, 21, 43, 60, 122, 129, 168, 184, 245], "repo": [10, 16, 17, 53, 58, 59, 120, 122, 127, 131, 135, 136, 160, 161, 175, 189, 209], "solut": [10, 51, 60, 111, 122, 134, 143, 148, 152, 171, 173, 186, 188, 219, 234], "pr": [10, 169, 208, 233], "propos": [10, 151, 184, 186], "request": [10, 22, 29, 41, 89, 98, 107, 120, 123, 138, 151, 157, 160, 161, 173, 174, 186, 187, 203, 204, 205], "hardwar": [10, 18, 30, 38, 47, 60, 98, 135, 137, 144, 146, 148, 152, 154, 155, 174, 192, 200, 208, 209, 211, 220, 222, 234], "googl": [10, 19, 22, 33, 40, 48, 51, 77, 97, 120, 122, 136, 158, 159, 168, 197, 201, 224, 243], "tpu": [10, 154, 237], "chip": [10, 174, 183], "layout": [10, 174, 184, 187, 191, 234], "spars": [10, 14, 95, 101, 106, 155, 186, 191, 194], "quantiz": [10, 15, 58, 59, 117, 122, 174, 189, 191, 194, 200, 207, 215, 223, 231, 238, 239], "enforc": [10, 20, 60, 126, 148, 151, 184, 185], "mainli": [10, 16, 136, 143, 168, 171, 193, 209], "haven": [10, 21, 89, 91, 94, 98, 100, 104, 106, 137, 142, 152, 175, 205], "addtion": 10, "identifi": [10, 31, 52, 54, 75, 92, 107, 108, 113, 132, 145, 146, 155, 161, 174, 175, 179, 181, 187, 193, 234], "carri": [10, 48, 51, 91, 98, 103, 131, 146, 164], "privateuse1": 10, "autogradprivateuse1": 10, "privateuse2": 10, "autogradprivateuse2": 10, "privateuse3": 10, "autogradprivateuse3": 10, "tensorimpl": [10, 219, 233], "storag": [10, 99, 103, 111, 125, 137, 146, 158, 168, 184, 186, 187, 195, 202, 211, 218, 227], "dispatchkeyset": 10, "ks": 10, "caffe2": [10, 86, 182], "typemeta": 10, "data_typ": [10, 103], "opaquetensorimpl": 10, "tweak": [10, 48, 237], "overrid": [10, 47, 50, 59, 94, 101, 142, 146, 148, 154, 181, 183, 201], "vulkan": [10, 191, 239], "submit": [10, 208], "dispath": 10, "src": [10, 11, 119, 135, 154, 199, 201, 210, 233], "registrationdeclar": 10, "snippet": [10, 19, 58, 59, 123, 124, 135, 138, 143, 154, 163, 173, 181, 184, 192, 201, 210, 216, 218, 234, 238, 239], "ab": [10, 171, 179, 200, 225], "schema": [10, 18, 21, 201], "abs_": 10, "abs_out": 10, "absolute_": 10, "absolute_out": 10, "angl": [10, 106], "angle_out": 10, "sgn": 10, "uniqu": [10, 48, 52, 54, 57, 100, 101, 104, 106, 116, 123, 132, 161, 164, 175, 184, 222], "boolean": [10, 75, 239], "impli": [10, 104, 136, 233], "schema_my_op1": 10, "my_op1": 10, "schema_my_op2": 10, "my_op2": 10, "schema_my_op2_backward": 10, "my_op2_backward": 10, "zoom": [10, 97, 126, 168], "1600": [10, 219, 233], "grow": [10, 48, 61, 101, 125, 131, 172], "unrealist": 10, "classifi": [10, 12, 17, 30, 41, 44, 45, 46, 51, 56, 75, 89, 94, 95, 111, 117, 122, 128, 136, 145, 164, 165, 175, 189, 217, 238, 246], "metadata": [10, 20, 158, 169, 243], "accompani": 10, "comment": [10, 135, 164, 183, 184, 198, 208, 209, 210, 220, 245], "sacrif": [10, 155], "max_pool2d": [10, 124, 161, 199, 209, 225], "formula": [10, 140, 158, 188], "mathemat": [10, 13, 41, 47, 64, 91, 94, 95, 103, 135, 158], "worri": [10, 51, 101, 130, 133, 162], "my_op": [10, 21, 201], "squeez": [10, 98, 109, 136, 148, 169, 181], "max": [10, 11, 17, 48, 51, 58, 59, 60, 95, 117, 124, 126, 135, 136, 138, 156, 158, 159, 169, 175, 179, 181, 188, 192, 193, 204, 234, 241, 243], "op_backward": 10, "proper": [10, 29, 123, 133, 146, 148, 158, 162, 173, 184, 234], "rare": [10, 48, 117, 118, 164, 234], "assumpt": [10, 60, 75, 106, 107, 149], "myadd_schema": 10, "my_add": 10, "setuptool": [10, 154], "_xlac": 10, "torch_xla_sourc": 10, "extra_compile_arg": 10, "library_dir": 10, "extra_link_arg": 10, "make_relative_rpath": 10, "seamlessli": [10, 52, 80, 219], "nm": [10, 208], "torchvsion": 10, "adhoc": 10, "unbox": 10, "potenti": [10, 22, 75, 91, 100, 123, 161, 175, 191, 192, 205, 248], "wiki": [10, 140, 146], "suit": [10, 92, 108, 138, 158, 179, 191, 192, 194, 222], "ship": [10, 42, 61, 94, 113], "guarante": [10, 132, 135, 146, 155, 161, 162, 173, 185], "delet": [10, 125, 133, 162, 183, 239], "old": [10, 17, 111, 113, 120, 155, 168, 178, 179, 188, 211, 216], "until": [10, 48, 60, 91, 113, 123, 128, 134, 135, 143, 158, 160, 161, 162, 168, 184, 203, 219], "interrupt": [10, 52, 89, 164], "quarterli": 10, "cadenc": 10, "join": [10, 16, 38, 47, 48, 49, 52, 60, 61, 117, 121, 124, 127, 133, 134, 135, 136, 156, 160, 161, 162, 175, 181, 203, 219, 241], "announc": [10, 115], "slack": [10, 42, 81], "Not": [10, 58, 59, 113, 133, 157, 241], "search": [10, 16, 48, 77, 113, 122, 126, 143, 155, 197, 243], "instantiate_device_type_test": 10, "testtorchdevicetyp": 10, "testviewop": 10, "testtensordeviceop": 10, "testtypepromot": 10, "etc": [10, 42, 43, 45, 48, 50, 57, 61, 69, 81, 94, 95, 98, 100, 101, 103, 107, 109, 111, 155, 158, 159, 164, 173, 174, 178, 179, 186, 193, 203, 205, 208, 219, 221, 234, 236, 243, 245], "__reduce_ex__": 10, "monkei": 10, "direct": [10, 21, 22, 29, 41, 45, 51, 75, 91, 92, 94, 99, 106, 113, 126, 135, 136, 140, 145, 149, 151, 164, 187, 204, 205, 238, 249], "suppos": [10, 20, 100, 101, 106, 124, 138, 175, 176, 205, 208], "vice": [10, 21, 38, 47, 83, 216], "versa": [10, 21, 38, 47, 83, 216], "Such": [10, 11, 91, 222], "seamless": [10, 80], "coverag": [10, 140, 144, 146, 188, 192, 218], "comprehens": [10, 19, 38, 47, 81, 92, 122, 143, 233], "bahavior": 10, "refactor": [10, 111, 131, 229], "codegen": [10, 143], "dev": [10, 101, 136, 157, 181, 191, 201, 214, 218, 232], "andrew": [11, 176], "gu": 11, "shard": [11, 61, 121, 122, 131, 172, 203, 238], "saw": [11, 19, 21, 34, 48, 59, 60, 94, 95, 98, 101, 103, 140, 141, 144, 145], "skeleton": 11, "implicitli": [11, 41, 48, 91, 124, 130, 163, 214], "schedul": [11, 89, 99, 117, 118, 123, 124, 133, 156, 159, 168, 173, 175, 225, 234], "particip": [11, 61, 95, 113, 132, 134, 161, 218, 234], "hang": [11, 54, 61, 113, 128], "persist": [11, 20, 36, 218, 245], "facilit": [11, 48, 60, 92, 98, 111], "earli": [11, 21, 51, 89, 113, 133, 135, 176, 186], "shadow": [11, 190], "hook": [11, 133, 155, 165, 226], "os": [11, 16, 17, 48, 49, 52, 54, 60, 117, 123, 124, 133, 134, 135, 136, 154, 156, 157, 160, 161, 162, 172, 175, 179, 181, 189, 192, 201, 203, 204, 216, 219, 241], "mp": [11, 30, 35, 52, 54, 123, 124, 133, 134, 135, 160, 161, 162, 203, 241], "ddp": [11, 14, 52, 53, 61, 122, 123, 124, 132, 168, 241], "nccl": [11, 16, 52, 54, 123, 124, 133, 135, 168, 172], "world_siz": [11, 14, 16, 52, 54, 123, 124, 133, 134, 135, 154, 160, 161, 162, 172, 203, 241], "num_input": 11, "master_addr": [11, 16, 52, 54, 124, 133, 134, 135, 154, 160, 161, 162, 172, 203, 241], "localhost": [11, 16, 52, 54, 97, 124, 127, 133, 134, 138, 154, 160, 161, 162, 168, 169, 172, 203, 204, 232, 241], "master_port": [11, 16, 52, 54, 124, 133, 134, 135, 154, 160, 161, 162, 172, 203, 241], "29500": [11, 16, 134, 135, 154, 160, 161, 162, 172, 203, 241], "init_process_group": [11, 14, 16, 52, 54, 61, 123, 124, 133, 135, 154, 172, 241], "device_id": [11, 54, 111, 123, 133, 227, 241], "nproc": [11, 52, 54, 124, 133, 134, 160, 162, 203, 241], "__name__": [11, 50, 52, 54, 123, 124, 133, 134, 135, 136, 138, 160, 161, 162, 181, 182, 189, 203, 204, 214, 241], "__main__": [11, 50, 52, 54, 123, 124, 133, 134, 135, 138, 160, 161, 162, 182, 189, 203, 204, 214, 219, 241], "arbitrarili": [11, 48, 226], "prior": [11, 17, 40, 51, 91, 95, 115, 133, 145, 155, 169, 173, 174, 192, 203], "notabl": [11, 17, 89, 189], "addition": [11, 12, 34, 115, 125, 126, 133, 173, 174, 175, 188], "divide_by_initial_world_s": 11, "world": [11, 16, 21, 35, 40, 53, 58, 59, 91, 98, 101, 115, 135, 138, 142, 145, 148, 154, 159, 160, 161, 188, 245], "nonetheless": [11, 245], "mind": [11, 38, 48, 51, 86, 132, 149, 173, 207, 245], "preliminari": [11, 136], "delv": [11, 143], "insight": [11, 75, 135, 163, 219, 233], "join_hook": 11, "kwarg": [11, 19, 111, 134, 142, 146, 158, 161, 195, 205], "join_devic": 11, "join_process_group": 11, "processgroup": [11, 14, 16, 61, 121, 122, 162, 234], "throw_on_early_termin": 11, "explain": [11, 12, 18, 21, 45, 51, 61, 75, 92, 101, 107, 143, 148, 171, 173, 222, 225], "joinconfig": 11, "_join_config": 11, "main_hook": 11, "none": [11, 16, 17, 48, 78, 89, 91, 103, 107, 113, 117, 123, 124, 134, 135, 136, 137, 141, 143, 146, 152, 156, 159, 161, 172, 175, 176, 179, 181, 189, 192, 195, 200, 202, 204, 205, 232, 239, 243, 245], "repeatedli": [11, 95, 158, 162], "post_hook": 11, "is_last_join": 11, "broadcast": [11, 61, 68, 107, 110, 133, 135, 154, 233, 241], "vacuou": 11, "contextlib": [11, 117], "nullcontext": 11, "conform": 11, "interleav": 11, "syncbatchnorm": [11, 54], "__exit__": 11, "heartbeat": 11, "notify_join_context": 11, "serializ": 11, "fulli": [11, 12, 18, 19, 20, 33, 80, 89, 90, 94, 95, 107, 109, 117, 121, 122, 126, 131, 146, 149, 156, 159, 161, 163, 168, 173, 179, 186, 189, 192, 200, 208, 221], "proceed": [11, 45], "overlap": [11, 19, 55, 61, 123, 124, 127, 131, 133, 148, 168, 173, 234], "moreov": [11, 61, 184, 208, 219], "permit": [11, 218, 245], "customiz": [11, 190], "idea": [11, 21, 57, 60, 75, 86, 101, 103, 106, 110, 129, 143, 148, 151, 159, 160, 162, 164, 173, 184, 198, 203, 205, 214, 219, 222, 234, 241, 245], "counterjoinhook": 11, "sync_max_count": 11, "all_reduc": [11, 61, 123, 124, 135, 154], "get_rank": [11, 133, 135], "process_group": 11, "common_rank": 11, "find_common_rank": 11, "max_count": 11, "__call__": [11, 50, 155], "meth": [11, 245], "to_consid": 11, "reduceop": [11, 123, 124, 135], "device_count": [11, 52, 54, 89, 98, 124, 133], "highlight": [11, 48, 60, 86, 114, 123, 163, 168, 171, 203, 208, 209, 245], "alexi": 12, "jacq": 12, "winston": 12, "her": [12, 40, 113, 154], "leon": [12, 113], "gati": 12, "alexand": 12, "ecker": 12, "matthia": 12, "bethg": 12, "artist": 12, "distanc": [12, 63, 64, 67, 68, 69, 72, 73, 91, 110], "d_c": 12, "d_": 12, "indispens": [12, 158], "pil": [12, 18, 39, 50, 58, 59, 117, 138, 157, 175, 197, 204], "pretrain": [12, 18, 40, 41, 58, 59, 75, 77, 92, 106, 113, 117, 122, 136, 138, 156, 157, 164, 173, 174, 178, 179, 181, 182, 183, 189, 190, 192, 197, 199, 204, 208, 209, 210, 211, 240], "longer": [12, 40, 51, 80, 91, 101, 107, 110, 113, 125, 143, 148, 155, 159, 160, 171, 173, 174, 188, 192, 219, 234, 243], "throughout": [12, 22, 51, 104, 135, 148, 158, 169, 173, 174, 186], "resiz": [12, 17, 18, 45, 51, 77, 117, 138, 156, 179, 192, 204, 208], "unabl": [12, 21, 137, 152, 186], "caff": 12, "picasso": 12, "reconvert": 12, "correctli": [12, 48, 51, 58, 59, 60, 75, 91, 92, 94, 114, 122, 127, 140, 146, 155, 157, 171, 186, 204, 212, 213, 237, 239], "f_": [12, 158], "xl": 12, "w_": [12, 106], "cl": [12, 77, 136, 180], "squar": [12, 34, 45, 50, 63, 64, 67, 68, 69, 72, 73, 91, 95, 98, 110, 118, 129, 130, 145, 151, 159, 176], "contentloss": 12, "recomput": [12, 129, 131, 151, 234], "act": [12, 20, 41, 48, 91, 95, 98, 113, 126, 155, 159, 161], "gram": 12, "g_": [12, 245], "hat": [12, 104, 113], "counteract": 12, "caus": [12, 19, 20, 61, 75, 91, 98, 107, 125, 143, 157, 160, 164, 168, 173, 174, 184, 190, 214, 216, 220, 234, 239, 243], "pool": [12, 16, 51, 61, 95, 107, 109, 111, 116, 169, 172, 174, 189, 229], "tend": [12, 91, 95], "sl": 12, "19": [12, 21, 60, 91, 117, 127, 143, 159, 175, 225, 246, 249], "vgg": 12, "child": [12, 60, 108, 168, 181, 246], "connect": [12, 45, 59, 89, 94, 95, 106, 109, 117, 135, 140, 142, 149, 155, 156, 157, 159, 173, 193, 201, 207, 211, 221, 245], "485": [12, 17, 50, 58, 59, 117, 138, 156, 157, 179, 192, 197, 204], "456": [12, 17, 50, 58, 59, 117, 138, 156, 157, 179, 192, 197, 204], "406": [12, 17, 50, 58, 59, 117, 138, 156, 157, 179, 192, 197, 204], "229": [12, 17, 50, 58, 59, 117, 138, 156, 157, 179, 192, 197, 204], "225": [12, 17, 50, 58, 59, 108, 117, 138, 156, 157, 179, 192, 197, 204], "vgg19": [12, 146], "maxpool2d": [12, 45, 111, 134, 142, 169, 229], "align": [12, 122, 164, 175, 185, 190, 214, 245], "depth": [12, 51, 55, 61, 91, 94, 98, 103, 125, 143, 234, 243], "immedi": [12, 16, 19, 38, 47, 51, 95, 98, 104, 134, 135, 160, 161, 164, 168], "input_img": 12, "content_img": 12, "bfg": 12, "closur": [12, 205], "reevalu": 12, "exce": [12, 75, 129, 158, 172, 216], "sphinx_gallery_thumbnail_numb": [12, 127], "neural_style_tutori": [12, 15], "paszk": [13, 135, 159], "dziedzic": 13, "shall": [13, 45, 51], "learnabl": [13, 45, 67, 110, 111, 122, 195, 236], "badfftfunct": 13, "literatur": [13, 159], "confusingli": 13, "correl": [13, 95, 107, 143], "filter": [13, 48, 92, 125, 136, 156, 164, 181, 201, 233], "flip": [13, 19, 144, 175], "wrt": [13, 130], "numpy_extensions_tutori": [13, 15], "yi": 14, "wang": [14, 143, 145], "paradigm": [14, 61, 110, 121, 133, 134, 161, 162], "dens": [14, 184], "fc": [14, 41, 117, 134, 145, 156, 195], "trainer": [14, 54, 126, 131, 160, 161, 162], "hybrid": [14, 85, 87, 109], "pipedream": 14, "embeddingbag": [14, 16, 115], "respond": [14, 92, 145, 161], "amongst": [14, 185], "themselv": [14, 95, 186, 192], "remotemodul": 14, "kick": [14, 29, 41, 113, 160, 161, 162], "remot": [14, 61, 121, 126, 134, 160, 161, 162, 203, 205], "hybridmodel": 14, "allreduc": [14, 61, 133, 154, 234], "firstli": [14, 143, 159], "tcp": [14, 54, 131, 132, 135, 203], "init_method": [14, 133, 135], "_run_train": [14, 162], "rpc_async": [14, 134, 160, 162], "exit": [14, 140, 160, 161, 162], "remote_emb_modul": 14, "distributedoptim": [14, 134, 161, 162, 203, 205], "remote_paramet": 14, "cannnot": 14, "get_next_batch": [14, 160, 162], "003": [15, 194], "advanc": [15, 17, 21, 41, 58, 59, 89, 102, 105, 121, 122, 133, 173, 184, 187, 191, 194, 198, 205, 208, 209, 222, 234, 238, 246], "mb": [15, 17, 37, 46, 70, 74, 82, 87, 96, 105, 108, 112, 124, 136, 165, 172, 179, 181, 192, 194, 216, 225, 231, 241], "torchrl": [15, 122, 165], "ddpg": [15, 122], "scipi": [15, 42, 122, 130, 171], "onnx": [15, 86, 122], "super_resolution_with_onnxruntim": [15, 18], "embeddingplann": [16, 122], "conda": [16, 21, 92, 97, 135, 143, 172, 182, 183, 191, 209, 211, 217, 232, 233], "cudatoolkit": [16, 172], "sudo": [16, 199], "rm": [16, 203, 211], "miniconda3": [16, 20, 233], "py37_4": 16, "sh": [16, 133, 183, 189, 197, 199, 207, 210, 211, 214], "anaconda": [16, 92, 135, 232], "chmod": 16, "bash": [16, 118, 145, 159, 214], "fbgemm": [16, 17, 120, 172, 176, 178, 179, 216], "pip3": [16, 49, 123, 124, 158, 159, 172, 182, 183], "ipython": [16, 108, 159], "colab": [16, 22, 33, 38, 40, 47, 77, 90, 97, 107, 115, 120, 122, 136, 144, 156, 158, 159, 172, 175, 224], "cp": [16, 199, 201, 204], "restart": [16, 21, 58, 59, 92, 97, 132, 159], "newli": [16, 117, 135, 205], "python37": 16, "dynload": 16, "enviro": 16, "spmd": 16, "mimic": [16, 17, 148, 156, 181, 184], "launcher": [16, 201], "embeddingbagcollect": 16, "bag": [16, 33, 115, 169, 172], "ebc": [16, 172], "vs": [16, 51, 80, 97, 99, 123, 168, 169, 173, 174, 186, 189, 191, 192, 193], "parameterconstraint": 16, "hint": [16, 91, 100, 104, 125, 135, 160, 168], "placement": [16, 173], "evenli": [16, 91, 118], "intra": [16, 19, 123, 136], "interconnect": [16, 78, 173, 221], "nvlink": [16, 203], "data_parallel": [16, 81], "meta": [16, 126, 137, 152, 158, 172, 173, 174, 193, 195, 226, 238, 249], "planner": 16, "embedding_typ": 16, "embeddingcomputekernel": 16, "shardingtyp": 16, "dict": [16, 48, 50, 141, 158, 175, 190, 193, 202, 205, 218], "large_table_cnt": 16, "small_table_cnt": 16, "large_t": 16, "embeddingbagconfig": [16, 172], "large_table_": 16, "embedding_dim": [16, 95, 109, 172], "num_embed": [16, 109, 172], "feature_nam": [16, 172], "large_table_feature_": 16, "poolingtyp": [16, 172], "small_tabl": 16, "small_table_": 16, "small_table_feature_": 16, "gen_constraint": 16, "sharding_typ": 16, "table_wis": 16, "large_table_constraint": 16, "small_table_constraint": 16, "mimick": 16, "single_rank_execut": 16, "embeddingbagcollectionshard": 16, "model_parallel": 16, "embeddingshardingplann": 16, "topolog": [16, 136, 181, 208, 214], "moduleshard": 16, "shardingenv": 16, "init_distributed_single_host": 16, "pyre": 16, "fixm": 16, "set_devic": [16, 52, 54, 123, 124], "compute_devic": 16, "pg": 16, "sharder": [16, 172], "shardingplan": 16, "collective_plan": 16, "sharded_model": 16, "from_process_group": 16, "spmd_sharing_simul": 16, "get_context": 16, "arg": [16, 17, 19, 52, 54, 103, 109, 111, 123, 124, 133, 134, 135, 136, 141, 142, 156, 159, 160, 161, 162, 171, 181, 189, 193, 203, 205, 208, 241, 249], "exitcod": 16, "de": [16, 20, 164], "factor": [16, 18, 95, 117, 156, 159, 160, 171, 180, 222], "medium": [16, 123, 175, 245], "large_table_0": 16, "parametershard": 16, "compute_kernel": 16, "batched_fus": 16, "sharding_spec": 16, "enumerableshardingspec": 16, "shardmetadata": 16, "shard_offset": 16, "shard_siz": 16, "large_table_1": 16, "small_table_0": 16, "small_table_1": 16, "finer": [16, 31, 61, 174, 225], "halv": [16, 108], "row_wis": 16, "512": [16, 123, 134, 175, 200, 208, 219, 225], "imbal": [16, 173, 234], "vertic": [16, 19, 243, 245], "column_wis": 16, "unfortu": 16, "batched_dens": 16, "raghuraman": [17, 136, 156], "krishnamoorthi": [17, 136, 156], "jerri": [17, 178, 179, 180, 192, 193], "zhang": [17, 178, 179, 180, 192, 193], "decreas": [17, 35, 48, 75, 107, 173, 174, 187, 211, 239], "mobilenetv2": [17, 183, 191, 211], "np": [17, 47, 50, 72, 100, 110, 117, 136, 156, 157, 162, 169, 175, 179, 181, 185, 192, 197, 233], "dataload": [17, 29, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 51, 54, 75, 89, 112, 115, 117, 123, 124, 135, 136, 156, 161, 168, 169, 175, 179, 181, 192, 208, 209, 223, 224, 234], "filterwarn": [17, 179, 192], "deprecationwarn": [17, 179, 192], "ao": [17, 176, 178, 179, 192], "seed": [17, 51, 75, 94, 123, 124, 135, 136, 160, 162, 179, 181, 192], "manual_se": [17, 98, 103, 123, 124, 135, 136, 160, 179, 181, 192, 241], "191009": [17, 179, 192], "modif": [17, 18, 19, 89, 100, 107, 129, 135, 155, 158, 161, 166, 169, 179, 189, 233], "floatfunct": 17, "quantstub": [17, 179, 207, 211, 216], "dequantstub": [17, 179, 207, 211, 216], "relu6": [17, 109], "_make_divis": 17, "divisor": 17, "min_valu": 17, "tf": [17, 97], "divis": [17, 98], "tensorflow": [17, 57, 97, 100, 110], "blob": [17, 21, 124, 141, 168, 176, 179, 199, 243], "slim": [17, 110], "mobilenet": [17, 58, 59, 157, 189], "param": [17, 50, 111, 117, 123, 124, 130, 133, 135, 137, 140, 152, 156, 161, 162, 175, 176, 184, 205, 239, 241], "new_v": 17, "round": [17, 123, 160, 219, 222, 233], "convbnrelu": 17, "in_plan": [17, 134], "out_plan": [17, 134], "kernel_s": [17, 124, 134, 176, 207, 209], "momentum": [17, 41, 42, 65, 69, 89, 94, 99, 107, 110, 111, 117, 129, 135, 156, 160, 169, 175, 176, 205, 207, 208, 209, 228, 229, 230, 236, 237], "inplac": [17, 109, 124, 134, 156, 178, 190, 207, 211, 216], "invertedresidu": 17, "inp": [17, 117, 141, 156, 161], "oup": 17, "expand_ratio": 17, "hidden_dim": [17, 95], "use_res_connect": 17, "pw": 17, "dw": 17, "conv": [17, 51, 95, 109, 129, 141, 142, 146, 156, 161, 174, 178, 179, 193, 207, 211, 214, 225, 239], "skip_add": 17, "num_class": [17, 40, 134, 160, 169, 175], "width_mult": 17, "inverted_residual_set": 17, "round_nearest": 17, "v2": [17, 58, 59, 114, 157, 200], "width": [17, 41, 42, 45, 58, 59, 80, 95, 98, 126, 149, 174, 175, 245], "input_channel": 17, "last_channel": 17, "1280": [17, 175], "160": [17, 136, 162, 207, 219, 225], "320": [17, 209], "len": [17, 50, 54, 107, 115, 117, 123, 124, 135, 136, 141, 156, 159, 160, 161, 169, 172, 175, 181, 193, 202, 205, 209], "valueerror": [17, 205], "invert": [17, 122, 158, 185], "residu": 17, "output_channel": 17, "quant": [17, 156, 176, 181, 189, 192, 193, 207, 211, 216], "dequant": [17, 156, 176, 179, 181, 189, 192, 193, 207, 209, 211, 216], "isinst": [17, 134, 141, 179, 181, 192], "init": [17, 20, 21, 59, 134, 189, 195, 207, 210, 213], "kaiming_normal_": [17, 134], "fan_out": [17, 134], "zeros_": 17, "elif": [17, 134, 136, 181, 205], "ones_": 17, "normal_": 17, "bn": [17, 129, 141, 142, 156, 176, 178, 207, 211], "fuse_model": [17, 156, 189], "fuse_modul": [17, 156], "idx": [17, 31, 156, 157, 169, 175], "averagemet": [17, 179, 192], "fmt": [17, 179, 192, 202], "val": [17, 20, 117, 123, 156, 157, 179, 192], "avg": [17, 91, 179, 192, 225], "__str__": [17, 179, 192], "fmtstr": [17, 179, 192], "__dict__": [17, 179, 192], "topk": [17, 127, 179, 192, 209, 240], "maxk": [17, 58, 59, 179, 192], "pred": [17, 107, 117, 124, 136, 156, 161, 169, 179, 181, 192, 209], "correct_k": [17, 179, 192], "mul_": [17, 179, 192, 205], "criterion": [17, 45, 115, 117, 156, 159, 162, 164, 169, 179, 192, 208], "neval_batch": 17, "top1": [17, 179, 192, 209], "acc": [17, 117, 156, 179, 192], "2f": [17, 124, 157, 160, 162, 173, 174, 179, 192, 216], "top5": [17, 179, 192, 240], "cnt": [17, 179, 192], "acc1": [17, 179, 192], "acc5": [17, 179, 192], "load_model": [17, 179, 192], "state_dict": [17, 36, 48, 52, 54, 89, 117, 123, 124, 133, 136, 155, 156, 159, 179, 192, 208, 216, 218, 221, 223, 224, 227, 228, 230, 231, 235, 238], "load_state_dict": [17, 36, 52, 89, 99, 111, 117, 133, 156, 159, 179, 192, 209, 218, 229, 235], "print_size_of_model": [17, 136, 179, 181, 192], "getsiz": [17, 136, 179, 181, 192, 216], "data_path": [17, 179, 192], "prepare_data_load": [17, 179, 192], "randomresizedcrop": [17, 117, 179, 192], "randomhorizontalflip": [17, 50, 117, 156, 175, 179, 192], "dataset_test": [17, 175, 179, 192], "centercrop": [17, 117, 138, 156, 179, 192, 204], "train_sampl": [17, 179, 192], "randomsampl": [17, 136, 179, 181, 192], "test_sampl": [17, 179, 192], "sequentialsampl": [17, 136, 179, 181, 192], "train_batch_s": [17, 179, 192], "data_loader_test": [17, 175, 179, 192], "eval_batch_s": [17, 136, 179, 181, 192], "saved_model_dir": [17, 179, 192], "float_model_fil": [17, 179, 192], "mobilenet_pretrained_float": 17, "scripted_float_model_fil": [17, 179, 192], "mobilenet_quantization_script": 17, "scripted_quantized_model_fil": 17, "mobilenet_quantization_scripted_quant": 17, "float_model": [17, 178, 179, 181, 190, 192], "fusion": [17, 142, 143, 174, 179, 205, 207, 208, 234, 239], "baselin": [17, 19, 92, 192, 219, 233], "un": [17, 98, 164], "num_eval_batch": 17, "71": [17, 19, 50, 143, 162], "sophist": [17, 110, 158], "num_calibration_batch": 17, "mymodel": [17, 176], "min": [17, 51, 95, 117, 135, 154, 156, 158, 160, 162, 173, 174, 175, 192, 193], "estim": [17, 45, 50, 51, 95, 126, 158, 159, 164, 204, 219], "qconfig": [17, 156, 176, 178, 179, 180, 181, 192, 193, 207, 211, 216], "default_qconfig": [17, 179], "calibr": [17, 176, 178, 180, 209, 211], "4x": [17, 123, 174, 178, 179, 222], "exercis": [17, 42, 135, 156, 173, 218], "x86": [17, 120, 176, 178, 179, 189, 197, 200, 210, 216], "basi": [17, 123, 136, 245], "histogram": [17, 190, 192, 232], "per_channel_quantized_model": 17, "get_default_qconfig": [17, 178, 179, 192, 207, 211, 216], "67": [17, 108, 143, 174, 176, 181], "wors": [17, 202], "qat": [17, 156, 176], "workflow": [17, 33, 58, 59, 88, 89, 122, 124, 187, 191, 193, 222, 238], "train_one_epoch": [17, 175], "ntrain_batch": 17, "avgloss": 17, "5f": 17, "start_tim": 17, "global_avg": 17, "qat_model": 17, "get_default_qat_qconfig": [17, 216], "prepare_qat": [17, 156, 216], "accur": [17, 75, 89, 94, 108, 126, 142, 162, 171, 186], "toward": [17, 48, 60, 128, 159, 179, 222], "freez": [17, 41, 117, 156, 174, 191, 194, 208, 234], "tune": [17, 34, 107, 112, 113, 121, 122, 124, 126, 156, 157, 173, 175, 181, 209, 222, 223, 231, 233, 238], "num_train_batch": 17, "nepoch": 17, "disable_observ": 17, "intrins": [17, 176], "freeze_bn_stat": 17, "quantized_model": [17, 136, 178, 179, 181, 192], "confirm": [17, 18, 58, 59, 89, 92, 107, 123, 144, 160, 240], "allud": [17, 75], "run_benchmark": 17, "img_load": 17, "elaps": [17, 124, 164, 181], "num_batch": [17, 134, 135], "enumer": [17, 89, 99, 117, 124, 156, 157, 161, 168, 169, 208, 209], "num_imag": [17, 117], "0f": [17, 117, 156, 209], "platform": [18, 21, 98, 133, 135, 189, 200, 210, 214, 234, 240], "prove": [18, 173], "onnxruntim": 18, "wide": [18, 30, 61, 91, 95, 107, 127, 128, 135, 136, 148, 154, 164, 201, 205, 217, 234, 249], "superresolut": 18, "shi": 18, "et": [18, 48, 51, 60, 75, 135, 155, 164, 248], "al": [18, 48, 51, 60, 75, 155, 164], "upscal": 18, "ycbcr": 18, "ordinarili": [18, 218], "torch_model": 18, "batchnorm": [18, 51, 54, 111, 141, 146, 179, 189, 192, 234, 236, 239], "ax": [18, 50, 101, 104, 117, 122, 127, 156, 164, 165, 169], "dynamic_ax": 18, "torch_out": 18, "super_resolut": 18, "bundl": [18, 59, 189, 197, 201, 210], "ml": [18, 33, 75, 98, 121, 122, 126, 191, 211, 232], "proto": [18, 109], "checker": [18, 109], "check_model": [18, 109], "onnx_model": 18, "rtol": 18, "1e": [18, 72, 89, 95, 110, 129, 156, 159, 160, 162, 176, 207], "03": [18, 91, 94, 119, 120, 161, 162, 175, 233, 246], "atol": 18, "contact": [18, 123, 198, 246], "famou": [18, 75], "224x224": [18, 92, 157, 204], "cb": 18, "cr": 18, "grayscal": [18, 31, 145], "blue": [18, 41, 58, 59, 123, 214, 245], "red": [18, 58, 59, 60, 169, 190, 214], "chroma": 18, "sensit": [18, 131, 140, 179, 232], "human": [18, 48, 75, 92, 109, 115, 128, 136, 138, 145, 164, 204, 245], "mobil": [18, 58, 59, 120, 122, 176, 182, 183, 189, 191, 199, 201, 202, 207, 216, 223, 238], "deploi": [18, 53, 58, 59, 112, 122, 126, 132, 155, 157, 165, 202, 238, 239], "cloud": [18, 33, 53, 90, 107], "inferenc": [18, 36], "azur": [18, 168], "servic": [18, 48, 138, 157, 201, 208, 245], "inter": [19, 122, 132, 149], "workload": [19, 21, 61, 108, 121, 122, 132, 133, 168, 173, 174, 179, 192, 205, 208, 238], "fragment": [19, 174, 234], "subset": [19, 21, 58, 59, 60, 86, 89, 94, 97, 117, 135, 154, 156, 175, 186, 187, 219, 239, 240], "fork": [19, 159], "fn": [19, 135, 140, 143, 171], "callabl": [19, 39, 50, 107, 168, 171, 179, 202, 217], "fut": [19, 160, 162], "neg": [19, 34, 48, 92, 95, 100, 101, 107, 113, 136, 143, 155, 158, 217, 239], "x_normal": 19, "x_parallel": 19, "async": [19, 160, 162], "sort": [19, 22, 95, 100, 104, 108, 116, 136, 157, 175, 181, 202, 225, 234], "parlanc": 19, "revers": [19, 41, 48, 60, 91, 140, 149, 151, 157, 164], "bidirectionalrecurrentlstm": 19, "cell_f": 19, "input_s": 19, "hidden_s": [19, 48, 60, 91, 239], "cell_b": 19, "output_f": 19, "x_rev": 19, "output_b": 19, "output_b_rev": 19, "lstmensembl": 19, "n_model": 19, "modulelist": [19, 151], "en": [19, 140, 164, 243], "demo": [19, 22, 43, 58, 59, 113, 138, 154, 168, 197, 201, 210, 216, 245], "took": [19, 91, 120, 135, 142, 163, 171, 173, 174, 182], "future_f": 19, "stuff": [19, 245], "deleg": [19, 182], "worth": [19, 21, 51, 113, 161, 222], "profil": [19, 40, 112, 122, 124, 163, 165, 173, 190, 219, 223, 231, 234, 238], "chrome": [19, 91, 163, 168, 225], "prof": [19, 40, 163, 225], "export_chrome_trac": [19, 163], "json": [19, 108, 127, 138, 163, 204, 225], "navig": [19, 61, 168, 169, 197, 214, 243], "button": [19, 49, 51, 58, 59, 183, 213, 214, 243, 245], "timelin": [19, 168, 174, 214], "horizont": 19, "opportun": [19, 86, 148, 205, 234], "breviti": [19, 21, 184, 222], "intro": [19, 32, 33, 37, 54, 57, 101, 121, 138, 169], "tracer": [19, 197], "simultan": [20, 22, 29, 41, 55, 122, 126, 135, 157, 234], "member": [20, 67, 81, 110, 156, 191, 211], "portion": [20, 155, 214, 233, 245], "custom_class": 20, "mystackclass": 20, "customclasshold": 20, "stack_": 20, "push": [20, 51, 75, 95, 144, 159, 198, 207, 211], "pop": [20, 95, 136, 181], "pop_back": 20, "intrusive_ptr": [20, 154, 219, 233], "make_intrus": [20, 154], "merg": [20, 43, 92, 95, 157, 159, 208], "elem": 20, "smart": 20, "oppos": [20, 48, 51, 117, 135, 144, 149, 161, 219], "class_": 20, "my_class": 20, "contructor": 20, "stateless": [20, 137, 140], "yourclass": 20, "ref": [20, 192, 245], "unari": 20, "add_librari": [20, 21, 201], "cmake_cxx_standard": [20, 201], "custom_class_project": 20, "rh": 20, "devtoolset": 20, "torchbind_tutori": 20, "libcustom_class": 20, "load_librari": [20, 21], "loaded_librari": 20, "bar": [20, 48, 141, 161, 171, 179, 192, 195, 214, 243, 245], "manipulate_inst": 20, "s2": [20, 94], "do_stack": 20, "hi": [20, 113, 145, 188, 245, 246], "mom": 20, "wow": 20, "filesystem": [20, 94, 135], "treatment": [20, 113, 186, 187, 188, 222], "cpp_inference_exampl": 20, "foobarbaz": 20, "tostr": 20, "add_subdirectori": [20, 21], "drill": [20, 91, 233], "momfoobarbaz": 20, "incred": 20, "make_custom_class": 20, "event": [20, 108, 113, 123, 124, 160, 171, 174, 225, 232], "tocustomclass": 20, "iscustomclass": 20, "export_attr": 20, "runtimeerror": [20, 119, 154, 157], "__torch__": 20, "def_pickl": 20, "pushivalueimpl": 20, "pickler": 20, "__getstate__": 20, "__setstate__": 20, "pickl": [20, 36, 107, 111, 211, 219, 229], "salient": 20, "wherea": [20, 107, 148, 169, 185, 186], "confus": [20, 21, 107, 127, 140, 185, 186, 187, 192, 211], "trycustomop": 20, "relax": [20, 151], "standalon": [20, 52, 218, 245], "blend": [20, 21], "smoothli": [20, 21], "subsequ": [21, 75, 92, 111, 119, 160, 162, 164, 171, 174, 234, 237], "resort": 21, "emb": [21, 104, 106, 162, 246], "opencv": [21, 42, 201], "vision": [21, 35, 42, 50, 58, 59, 92, 95, 112, 122, 182, 189, 191, 197, 210, 211, 217, 240], "mat": [21, 201], "warpperspect": [21, 201], "perspect": [21, 103, 158, 174], "warp_perspect": [21, 201], "warp": [21, 201], "image_mat": [21, 201], "cv": [21, 188, 201], "col": [21, 156, 201], "cv_32fc1": [21, 201], "warp_mat": [21, 201], "output_mat": [21, 201], "dsize": [21, 201], "output_tensor": 21, "from_blob": [21, 59, 183, 201], "ptr": [21, 201], "short": [21, 22, 95, 98, 100, 102, 105, 115, 121, 128, 135, 151, 158, 164, 166, 222, 234, 237, 245, 246], "opencv2": [21, 201], "hpp": [21, 154, 201], "alongsid": [21, 140, 169, 218], "goodi": 21, "raw": [21, 30, 42, 48, 61, 68, 110, 113, 119, 225, 243], "hardcod": [21, 129], "strikingli": 21, "opaqu": [21, 233], "flat": 21, "scope": [21, 60, 95, 98, 103, 108, 125, 174, 214], "dealloc": [21, 168, 174, 234], "invalid": [21, 134, 185, 186, 187, 205, 219, 234], "safe": [21, 141, 182, 202], "quot": [21, 117, 246], "metaprogram": 21, "experiment": [21, 60, 124, 126, 141, 162, 176, 209, 232, 234], "target_compile_featur": 21, "privat": [21, 58, 59, 115, 154, 155, 184, 201], "cxx_std_14": 21, "opencv_cor": 21, "opencv_imgproc": 21, "libwarp_perspect": 21, "sensat": 21, "0x7f618fc6fa50": 21, "3218": 21, "4611": 21, "4636": 21, "3746": 21, "0978": 21, "5005": 21, "3245": 21, "0169": 21, "4458": 21, "1862": 21, "1692": 21, "noteworthi": 21, "frozen": [21, 29, 41, 145, 156, 181, 196], "prim": [21, 181], "revel": 21, "drop": [21, 95, 97, 131, 162, 173, 212, 213, 243], "restrict": [21, 22, 48, 86, 135, 168, 176, 197, 198], "script_method": [21, 86], "tensortobool": 21, "block0": 21, "block1": 21, "15": [21, 43, 58, 59, 75, 91, 94, 95, 116, 117, 156, 169, 175, 182, 196, 219, 225, 245, 249], "21": [21, 58, 59, 103, 108, 115, 117, 157, 175, 201, 219, 225, 233], "abil": [21, 60, 61, 98, 107, 111, 125, 135, 166, 169, 171, 186, 199], "sent": [21, 135, 138, 160, 203], "wire": 21, "showcas": [21, 65, 123, 149, 173, 174, 191], "dlopen": 21, "example_app": 21, "cxx_range_for": 21, "throw": [21, 61, 91, 98, 119, 138, 160], "errorreport": 21, "mayb": [21, 103, 106, 137, 191, 245], "subdirectori": [21, 51, 175], "prefix": [21, 113, 123, 125, 136, 168, 181, 219, 233, 241, 245], "inconveni": [21, 184], "altogeth": [21, 149, 186, 243], "nb": [21, 91, 99, 198, 204], "impress": [21, 143], "opencv_photo": 21, "happi": [21, 141, 142], "4125": 21, "8262": 21, "5345": 21, "6111": [21, 219], "3997": [21, 77], "4683": 21, "5969": 21, "0850": 21, "0698": 21, "4597": 21, "0926": 21, "5727": 21, "9319": 21, "4834": 21, "1747": [21, 117], "0162": 21, "9521": 21, "6269": 21, "lastli": [21, 89, 122, 210], "driver": [21, 94, 98], "infrastructur": 21, "vener": 21, "beforehand": [21, 149, 193, 216], "is_python_modul": [21, 201], "extra_ldflag": [21, 201], "lopencv_cor": [21, 201], "lopencv_imgproc": [21, 201], "approxim": [21, 48, 92, 123, 129, 142, 145, 149, 155, 159, 173, 181, 221, 234], "0x7f3e0f840b10": 21, "load_inlin": [21, 201, 219], "op_sourc": [21, 201], "cpp_sourc": [21, 201, 219], "exclus": [21, 155], "rout": [21, 60, 138, 143, 204], "quirki": 21, "with_opt": 21, "no_python_abi_suffix": 21, "bottom": [21, 100, 168, 214, 243], "omit": [21, 91, 108, 143, 158, 174, 178, 189, 192, 225, 233], "suffix": [21, 38, 47, 143], "tag": [21, 50, 57, 95, 106, 201, 232, 245], "0x7ff51c5b7bd0": 21, "jamesre": 22, "fb": 22, "michael": [22, 40, 100, 218], "suo": 22, "rev2": 22, "hierarchi": [22, 60, 174], "3x4": 22, "my_cel": 22, "redefin": 22, "mycel": 22, "succinctli": [22, 151], "mydecisiong": [22, 239], "tape": [22, 40, 78], "light": [22, 51, 94, 97, 98, 129, 201, 217, 245], "rewind": 22, "tracedmodul": [22, 60, 86, 239], "ir": [22, 109, 141, 143, 180, 205], "commonli": [22, 39, 48, 69, 89, 95, 110, 157, 164, 168, 176, 205, 208, 226, 234, 246], "acquir": [22, 98, 111, 134, 155, 158, 162], "broader": 22, "traced_cel": [22, 239], "laden": 22, "submodul": [22, 48, 60, 86, 95, 151, 195, 207, 210, 216, 222], "branch": [22, 91, 174, 175, 199, 208, 212, 213], "nowher": 22, "faithfulli": [22, 184], "analysi": [22, 89, 91, 99, 115, 124, 142, 143, 163, 168, 173, 214, 222, 233], "decis": [22, 91, 102, 105, 184, 185, 187, 200, 212, 213, 234], "inlin": [22, 51, 60, 91, 94, 97, 99, 141, 143, 159, 184, 191, 196, 246, 249], "freestand": 22, "neurip": 22, "1hiicg6jrkbnr5hvk2": 22, "vnmi88vi9puzej": 22, "intro_to_torchscript_tutori": [22, 112, 196], "audio_data_augmentation_tutori": [23, 25], "redirect": [23, 24, 25, 26, 27, 28, 76, 139, 150, 167, 170, 177, 206], "audio_datasets_tutori": 24, "audio_feature_extractions_tutori": 26, "audio_io_tutori": 27, "quickstart": [29, 30, 31, 32, 33, 34, 36, 38, 39, 122, 212], "accord": [29, 98, 99, 111, 115, 120, 143, 145, 155, 159, 163, 187, 195, 200], "frac": [29, 41, 64, 86, 91, 100, 101, 103, 106, 110, 125, 130, 135, 158, 159, 245], "partial": [29, 41, 89, 91, 103, 111, 113, 123, 124, 125, 144, 205, 208, 235, 238, 245], "leaf": [29, 41, 91, 180], "retain_graph": [29, 198], "surround": [29, 60], "acycl": [29, 41, 78], "dag": 29, "chain": [29, 41, 57, 91, 98, 101, 115, 129, 143, 160, 186, 193], "accumul": [29, 41, 45, 48, 51, 78, 91, 94, 103, 115, 130, 145, 159, 160, 161, 162, 175, 218, 222, 237], "recreat": [29, 41, 172, 201], "scratch": [29, 41, 48, 52, 100, 111, 114, 117, 119, 122, 165, 235, 238, 239], "vec": [29, 41, 91], "langl": 29, "x_1": [29, 103, 116, 149, 245], "x_n": [29, 51], "rangl": 29, "y_1": [29, 103, 116], "y_m": 29, "ccc": [29, 41, 91], "y_": [29, 41, 91, 100], "x_": [29, 41, 91, 245], "cdot": [29, 41, 51, 91, 106, 125], "vdot": [29, 41, 91], "ddot": [29, 41, 91], "v_1": 29, "v_m": 29, "life": [29, 113, 127, 128], "autogradqs_tutori": [29, 32, 37], "compris": [30, 31, 51, 60, 111, 230], "fashionmnist": [30, 31, 33, 35, 39, 169], "acceler": [30, 35, 38, 40, 47, 56, 77, 98, 110, 148, 174, 183, 189, 200, 208, 222, 234], "neuralnetwork": [30, 182], "minibatch": [30, 31, 97, 107, 137, 152], "28x28": [30, 107, 169, 221], "784": [30, 97, 107, 137, 169], "nonlinear": [30, 134], "phenomena": 30, "seq_modul": 30, "logit": [30, 34, 118, 136, 181], "infti": [30, 159], "parameter": 30, "preview": 30, "buildmodel_tutori": [30, 32, 37], "messi": 31, "modular": [31, 109, 111, 118, 236], "primit": [31, 35, 81, 110, 122, 144, 174, 200], "domain": [31, 35, 48, 49, 75, 99, 122, 158, 188, 234, 246], "audio": [31, 42, 122, 139, 167, 170], "fashion": [31, 48, 60, 97, 99, 123, 126, 134, 161, 166, 169, 208], "zalando": 31, "articl": [31, 113, 116], "internet": [31, 157, 224], "target_transform": [31, 35, 39], "training_data": [31, 104], "img_dir": 31, "csv": [31, 48, 50, 123], "annotations_fil": 31, "tshirt1": 31, "tshirt2": 31, "ankleboot999": 31, "read_imag": 31, "img_label": 31, "tupl": [31, 38, 47, 58, 59, 60, 83, 94, 95, 98, 104, 106, 109, 115, 116, 136, 141, 159, 175, 179, 181, 187, 193, 202, 222, 224, 233, 240], "reshuffl": 31, "overfit": [31, 94, 107, 111, 128, 156], "train_featur": 31, "train_label": 31, "shuffl": [31, 35, 50, 54, 94, 99, 107, 115, 116, 117, 123, 124, 135, 156, 157, 161, 168, 169, 175, 209], "grain": [31, 61, 91, 123, 135, 168, 218, 219, 233], "data_tutori": [31, 32, 37], "beginn": [32, 43, 44, 79, 85, 90, 93, 102, 110, 112, 122, 196, 197, 222], "quickstart_tutori": [32, 35, 37], "tensorqs_tutori": [32, 37, 38], "tensor_tutori": [32, 44, 46, 47], "dataquickstart_tutori": 32, "transforms_tutori": [32, 37, 39], "autograd_tutori": [32, 41, 44, 46], "optimization_tutori": [32, 34, 37], "saveloadrun_tutori": [32, 36, 37], "sphx_glr_beginner_basics_intro": [32, 37], "sphx_glr_beginner_basics_autogradqs_tutori": [32, 37], "sphx_glr_beginner_basics_buildmodel_tutori": [32, 37], "sphx_glr_beginner_basics_saveloadrun_tutori": [32, 37], "sphx_glr_beginner_basics_transforms_tutori": [32, 37], "sphx_glr_beginner_basics_optimization_tutori": [32, 37], "sphx_glr_beginner_basics_data_tutori": [32, 37], "sphx_glr_beginner_basics_quickstart_tutori": [32, 37], "sphx_glr_beginner_basics_tensorqs_tutori": [32, 37], "suraj": [33, 52, 53, 54, 55, 108, 131, 132, 145, 173], "subramanian": [33, 52, 53, 54, 55, 108, 131, 132, 145, 173], "juarez": 33, "cassi": 33, "breviu": 33, "dmitri": 33, "soshnikov": 33, "ari": 33, "bornstein": 33, "shirt": [33, 169], "trouser": [33, 169], "pullov": [33, 169], "dress": [33, 169], "coat": [33, 169], "sandal": [33, 169], "sneaker": [33, 169], "ankl": [33, 169], "boot": [33, 157, 169], "microsoft": [33, 136, 168], "walkthrough": [34, 41, 47, 108, 213], "backpropag": [34, 35, 41, 45, 48, 57, 75, 91, 100, 101, 104, 106, 107, 110, 125, 145], "3blue1brown": [34, 41], "unpredict": [34, 91, 133], "jump": [34, 75, 104, 138, 145], "untrain": 34, "answer": [34, 77, 92, 95, 101, 135, 136, 142, 164, 239], "dissimilar": [34, 98, 106], "regress": [34, 107, 136, 166, 181, 219, 232], "nllloss": [34, 101, 109, 115, 127], "classif": [34, 42, 51, 58, 59, 75, 77, 89, 92, 94, 98, 99, 101, 112, 117, 120, 122, 124, 128, 136, 157, 166, 175, 181, 199, 212, 213, 237], "logsoftmax": [34, 109, 115, 127], "deposit": [34, 41], "train_loop": 34, "test_loop": 34, "warmstart": [34, 223, 231, 238], "torchaudio": [35, 49, 94, 99, 122, 123, 124, 157, 182, 224], "cifar": [35, 42, 94, 169], "coco": [35, 175], "conduct": [35, 92, 143, 154], "dictionari": [35, 36, 48, 58, 59, 106, 111, 127, 128, 138, 152, 158, 160, 161, 164, 181, 190, 228, 229, 230, 236, 238], "fail": [36, 78, 91, 98, 111, 143, 157, 159, 163, 171, 191, 201, 208, 210, 218, 228, 229, 230], "inconsist": [36, 111, 143, 228, 229, 230], "checkpoint": [36, 48, 60, 61, 77, 89, 117, 131, 208, 218, 223, 229, 231, 236, 238], "004": 37, "beginner_bas": 37, "ndarrai": [38, 39, 47, 98, 109], "elimin": [38, 108, 129, 137, 143, 144, 157, 180, 205], "overridden": [38, 47], "breez": [38, 47, 83], "subtli": [38, 47], "y1": [38, 175], "y2": 38, "y3": 38, "wise": [38, 47, 75, 98, 101, 109, 135, 143, 146, 149], "z1": [38, 143], "z2": 38, "z3": 38, "aggreg": [38, 41, 94, 108, 145, 185, 225], "operand": [38, 91], "denot": [38, 101, 104, 184, 185, 188, 245], "t_": [38, 47, 245], "problemat": [38, 47, 143, 151, 234, 245], "discourag": [38, 47, 158], "hot": [39, 48, 75, 95, 106, 127, 128, 164], "floattensor": [39, 98, 175], "intens": [39, 86, 143, 174, 200, 234], "scatter_": [39, 134, 160], "gschwind": 40, "bt": 40, "fastpath": 40, "multiheadattent": [40, 118, 163], "multihead": 40, "mha": [40, 185], "exploit": [40, 145, 164], "sparsiti": [40, 106, 122, 155, 184, 186, 191, 194], "nlp": [40, 94, 95, 101, 104, 106, 113, 114, 115, 116, 119, 122, 136, 165, 174, 181, 188, 218, 222, 234, 239], "criteria": [40, 51], "blog": [40, 123, 124, 127, 131, 173, 217], "xlm": [40, 136, 181], "predefin": [40, 48, 107, 158, 193, 209, 234], "__version__": [40, 136, 157, 181, 183, 199, 201, 210], "robertaclassificationhead": 40, "to_tensor": [40, 185, 186], "xlmr_larg": 40, "xlmr_large_encod": 40, "classifier_head": 40, "input_dim": [40, 207, 211], "get_model": [40, 160], "small_input_batch": 40, "hello": [40, 48, 58, 59, 101, 138], "big_input_batch": 40, "princ": 40, "genoa": 40, "lucca": 40, "famili": 40, "estat": 40, "buonapart": 40, "war": 40, "defend": [40, 75], "infami": 40, "horror": 40, "perpetr": 40, "antichrist": 40, "believ": [40, 185], "he": [40, 113, 141, 145, 164], "friend": [40, 48], "faith": 40, "slave": 40, "frighten": 40, "juli": 40, "1805": 40, "speaker": 40, "anna": 40, "pavlovna": 40, "scherer": 40, "maid": 40, "honor": [40, 98], "empress": 40, "marya": 40, "fedorovna": 40, "she": [40, 113, 164], "greet": [40, 138], "vasili": 40, "kuragin": 40, "man": [40, 113, 115, 245, 246], "recept": 40, "cough": 40, "suffer": [40, 61, 95, 113, 168, 205], "la": 40, "gripp": 40, "st": 40, "petersburg": 40, "elit": [40, 244, 246, 248], "input_batch": [40, 58, 59, 157], "model_input": 40, "padding_valu": 40, "_transformer_encoder_layer_fwd": 40, "use_cuda": [40, 75, 91, 225], "enable_nested_tensor": 40, "prop": 41, "proportion": 41, "travers": [41, 162, 209], "height": [41, 45, 58, 59, 80, 95, 98, 174, 175, 214, 245], "3a": [41, 157], "9a": 41, "2b": 41, "dq": 41, "bf": 41, "external_grad": 41, "finetun": [41, 112, 122, 125], "resnet": [41, 42, 81, 92, 125, 134, 148, 156, 168, 179, 192, 211, 216, 234], "unfrozen": 41, "exclusionari": 41, "autodiff": [41, 122, 144], "pillow": [42, 94, 204], "librosa": 42, "cython": 42, "nltk": 42, "spaci": [42, 116, 119], "imagenet": [42, 50, 81, 92, 117, 120, 138, 156, 157, 179, 192, 204], "viz": [42, 92], "huge": [42, 101, 106, 110, 133, 148], "airplan": [42, 94], "automobil": [42, 94], "bird": [42, 94], "deer": [42, 94], "dog": [42, 58, 59, 94, 113, 175, 183, 197, 217], "frog": [42, 94], "hors": [42, 94], "truck": [42, 94], "3x32x32": 42, "color": [42, 51, 58, 59, 92, 94, 95, 97, 98, 126, 145, 146, 157, 169, 175, 204, 245], "32x32": [42, 45, 94, 169], "extrem": [42, 106, 146, 245], "pilimag": 42, "brokenpipeerror": 42, "fun": [42, 48, 158, 222], "entropi": [42, 51, 94, 95, 99, 119, 237], "learnt": 42, "truth": [42, 75, 175, 191], "okai": 42, "wasn": [42, 100, 103], "energi": [42, 48, 60, 245], "chanc": [42, 48, 145, 239], "randomli": [42, 50, 51, 72, 73, 89, 94, 95, 110, 128, 136, 145, 159, 164, 181, 222], "hmmm": 42, "plai": [42, 48, 51, 81, 101, 122, 158, 165, 174], "face": [42, 50, 51, 60, 75, 77, 81, 113, 143, 192], "chat": [42, 48, 60, 81, 164], "cifar10_tutori": [42, 44, 46], "sung": 43, "kim": 43, "jenni": 43, "kang": 43, "mytensor": 43, "my_tensor": [43, 111, 227], "parallelli": 43, "getitem": [43, 115], "cnn": [43, 120, 122, 149, 151, 152, 166, 174, 175, 208, 216], "capsul": 43, "monitor": [43, 107, 113, 135, 174], "output_s": [43, 175], "former_torchi": [43, 79], "parallelism_tutori": [43, 79, 81, 82], "data_parallel_tutori": [43, 44, 46], "neural_networks_tutori": [44, 45, 46], "gentl": [44, 46, 55, 56, 121], "glimps": 45, "convnet": [45, 84, 92, 145, 156, 161], "learning_r": [45, 72, 110, 136], "lenet": [45, 75, 94, 97, 99, 155, 209], "mini": [45, 48, 51, 80, 81, 97, 104, 107, 138, 152, 157, 169, 197, 209], "nsampl": [45, 80], "nchannel": [45, 80], "least": [45, 58, 59, 75, 98, 111, 113, 126, 128, 133, 145, 157, 164, 189, 205, 211, 219, 222, 229, 241, 245, 246], "flatten": [45, 68, 107, 110, 124, 134, 156, 161, 202], "clear": [45, 50, 75, 91, 100, 101, 106, 125, 143, 162, 186, 204, 219], "sub_": 45, "nesterov": [45, 111], "026": 46, "beginner_blitz": 46, "024": [46, 47, 200], "x_data": 47, "np_arrai": 47, "x_np": 47, "from_numpi": [47, 160, 162], "x_one": 47, "Ones": 47, "x_rand": 47, "rand_lik": [47, 98], "8823": 47, "9150": 47, "3829": 47, "9593": 47, "rand_tensor": 47, "ones_tensor": 47, "zeros_tensor": 47, "3904": 47, "6009": 47, "2566": 47, "7936": 47, "9408": 47, "1332": 47, "add_": [47, 83, 98, 184, 199, 205], "matthew": [48, 60, 88, 111], "inkawhich": [48, 51, 60, 75, 86, 88, 111], "movi": [48, 49, 60, 92, 113], "cornel": [48, 49, 60], "dialog": [48, 49], "artifici": [48, 60, 221], "intellig": 48, "onlin": [48, 136, 145, 158, 161], "helpdesk": 48, "bot": [48, 60], "compani": [48, 115], "IT": 48, "teach": [48, 51, 164], "boom": 48, "am": [48, 57, 103, 113, 128, 164, 201], "hospit": [48, 113], "lawyer": 48, "arrest": 48, "kid": 48, "sorri": 48, "san": [48, 113], "francisco": [48, 107, 113], "goodby": 48, "luong": [48, 60, 164], "jointli": [48, 164], "acknowledg": [48, 135], "borrow": [48, 61, 124, 134, 162], "yuan": [48, 60, 210], "kuei": [48, 60], "wu": [48, 60], "ywk991112": [48, 60], "sean": [48, 60, 127, 128, 164], "robertson": [48, 60, 127, 128, 164], "spro": [48, 60], "floydhub": [48, 60], "textutil": [48, 60], "reformat": 48, "rich": [48, 214], "charact": [48, 60, 106, 113, 122, 131, 158, 164, 165, 245], "220": [48, 162], "579": [48, 146], "292": [48, 89], "035": 48, "617": 48, "713": [48, 94], "utter": [48, 49], "divers": 48, "variat": [48, 99, 107, 130, 184, 196, 219, 233], "formal": [48, 184], "sentiment": [48, 112], "datafil": 48, "tab": [48, 97, 99, 116, 164, 169, 183, 214], "sentenc": [48, 60, 95, 100, 101, 104, 106, 113, 119, 128, 135, 136, 164, 188, 245], "jsonl": [48, 49], "loadlinesandconvers": 48, "lineid": 48, "characterid": 48, "conversationid": 48, "movieid": 48, "extractsentencepair": 48, "formatted_movie_lin": 48, "unescap": 48, "delimit": [48, 115, 116], "busi": [48, 115, 128, 173], "vocabulari": [48, 60, 94, 95, 106, 115, 119, 136, 188, 234], "implicit": [48, 91, 214, 234, 245], "discret": [48, 208, 245], "encount": [48, 60, 109, 123, 143, 171, 234, 239], "voc": [48, 60], "addword": 48, "addsent": 48, "infrequ": 48, "unicod": [48, 127, 128, 164], "ascii": [48, 106, 127, 128, 164], "unicodetoascii": 48, "letter": [48, 60, 127, 128, 164, 246], "lowercas": [48, 60, 107, 164], "punctuat": [48, 164], "normalizestr": [48, 60], "aid": [48, 111, 113, 230], "max_length": [48, 60, 136, 181, 239], "threshold": [48, 109, 126, 158, 162, 234], "filterpair": 48, "stackoverflow": [48, 127, 128, 159, 164, 219], "518232": [48, 127, 128, 164], "2809427": [48, 127, 128, 164], "tactic": 48, "benefici": [48, 60, 95, 121, 158, 237], "soften": 48, "difficulti": [48, 158], "min_count": 48, "massag": 48, "accommod": 48, "shorter": [48, 50, 107, 116, 164, 168, 184], "eos_token": [48, 60], "english": [48, 101, 104, 113, 116, 119, 127, 164], "indexesfromsent": [48, 60], "zeropad": 48, "inputvar": 48, "outputvar": 48, "pad_token": [48, 60, 136], "batch2traindata": 48, "bunch": [48, 127, 128, 214], "aforement": [48, 209], "brain": 48, "sutskev": 48, "discov": [48, 113, 135, 161], "accomplish": [48, 51, 149, 195, 219, 233], "jeddy92": [48, 60], "io": [48, 50, 58, 60, 97, 120, 122, 138, 160, 163, 178, 191, 201, 204, 215, 216, 238, 239], "ts_seq2seq_intro": [48, 60], "invent": [48, 51, 158], "cho": [48, 173, 174], "2014": [48, 51, 117], "bidirect": [48, 60, 122, 136], "gru": [48, 60, 95, 109, 127, 128, 164], "past": [48, 49, 99, 103, 189, 204, 245], "colah": 48, "2015": 48, "unpack": [48, 98, 136, 180, 181, 199, 201], "pack_padded_sequ": [48, 60], "pad_packed_sequ": [48, 60], "input_seq": [48, 239], "input_length": [48, 60, 123, 239], "n_layer": [48, 60, 239], "num_direct": 48, "sole": [48, 168], "combat": [48, 106], "bahdanau": [48, 164], "groundwork": 48, "score": [48, 60, 92, 100, 104, 106, 108, 136, 164, 175, 181, 217], "h_t": [48, 104], "_s": 48, "summar": [48, 50, 107, 112, 114, 120, 121, 123, 126, 136, 168, 174], "attn": [48, 60, 164], "softmax": [48, 60, 95, 104, 106, 107, 109, 118, 157, 160, 162, 169, 188, 240], "unidirect": [48, 60], "input_step": 48, "last_hidden": 48, "encoder_output": 48, "num_word": 48, "masknllloss": 48, "clever": [48, 101, 113], "teacher": [48, 164], "teacher_forcing_ratio": [48, 164], "wheel": [48, 158, 191], "instabl": [48, 164], "craft": [48, 75, 106, 128], "clip": [48, 75, 117, 156, 158, 159], "essenc": [48, 103, 245], "nan": [48, 185], "overshoot": 48, "steep": 48, "cliff": 48, "goodfellow": [48, 51, 75], "2016": 48, "www": [48, 136, 164, 243, 245], "deeplearningbook": 48, "sos_token": [48, 60, 239], "realiti": [48, 51, 60, 75, 103, 107, 156, 163, 233], "tie": 48, "trainit": [48, 164], "n_iter": 48, "explanatori": 48, "lift": [48, 58, 59, 113, 198, 211], "tarbal": 48, "NOT": [48, 60, 83, 86, 111, 130, 131, 133, 201, 227, 229], "decoder_output": 48, "greedysearchdecod": [48, 239], "searcher": [48, 60], "evaluateinput": [48, 60], "press": [48, 51, 245], "gracefulli": [48, 52, 161], "prompt": [48, 49, 60, 204], "regardless": [48, 98, 99, 144, 161, 246], "attn_model": [48, 60], "concat": [48, 60, 103, 109, 179, 193], "loadfilenam": [48, 60], "save_dir": [48, 60], "model_nam": [48, 60, 123, 208], "corpus_nam": [48, 49, 60], "encoder_n_lay": [48, 60], "decoder_n_lay": [48, 60, 239], "_checkpoint": [48, 60, 123], "tar": [48, 60, 77, 111, 228, 245], "checkpoint_it": [48, 60], "uncom": [48, 50, 60, 64, 73, 94, 97, 103, 107, 110, 224], "folk": 48, "congratul": [48, 125, 221, 224, 227, 228, 229, 230, 235, 236, 237], "tailor": [48, 135], "cool": [48, 51, 152, 183, 198], "002": [48, 51, 77, 112, 123], "chatbot_tutori": [48, 112], "meet": [49, 51, 195, 209, 219], "uninstal": [49, 136], "reinstal": 49, "ye": [49, 136, 182, 224], "account": [49, 107, 118, 164, 169, 181], "chatbot": [49, 60, 112, 239], "browser": [49, 97, 99, 138, 168, 245], "subfold": 49, "visit": [49, 111, 113, 127, 138, 209], "in_": 49, "_colab": 49, "_name": 49, "mount": 49, "gdrive": 49, "upload": [49, 232], "rerun": [49, 192], "evolv": [49, 143, 149], "sasank": [50, 117, 156], "chilamkurthi": [50, 117, 156], "trivial": [50, 55, 98, 125, 138, 195, 202, 239], "scikit": [50, 136], "panda": [50, 75, 120], "facial": 50, "pose": 50, "landmark": 50, "dlib": 50, "image_nam": 50, "part_0_x": 50, "part_0_i": 50, "part_1_x": 50, "part_1_i": 50, "part_2_x": 50, "part_67_x": 50, "part_67_i": 50, "0805personali01": 50, "83": [50, 173, 233], "84": [50, 108, 111, 145, 169, 173, 182, 229], "134": [50, 197], "1084239450_e76e00b7e7": 50, "70": [50, 146, 162, 174, 175, 219], "236": 50, "257": [50, 219], "312": [50, 146], "65": [50, 162, 207, 219], "person": [50, 58, 59, 113, 175], "img_nam": 50, "__len__": [50, 107, 135, 159, 175], "__getitem__": [50, 107, 135, 175], "randomcrop": [50, 156], "crop": [50, 94, 126, 166, 175, 204], "swap": [50, 101, 109, 136, 158, 179, 181, 188, 190], "tsfm": 50, "transformed_sampl": 50, "extern": [50, 111, 126, 142, 143, 202, 228, 234, 243, 245], "safer": [50, 219], "stick": [50, 113, 135, 146, 243], "randint": [50, 51, 136, 181, 208], "lose": [50, 52, 98, 145, 215, 222, 238, 243], "collate_fn": [50, 115, 175], "indent": [50, 219, 245], "imagefold": [50, 51, 94, 117, 156], "ant": [50, 117, 156, 248], "xxy": 50, "jpeg": [50, 138, 204], "xxz": 50, "bee": [50, 117, 156, 245], "123": [50, 162, 246], "nsdf3": 50, "asd932_": 50, "data_transform": [50, 117, 156], "randomsizedcrop": 50, "hymenoptera_dataset": 50, "hymenoptera_data": [50, 117, 156], "dataset_load": 50, "data_loading_tutori": [50, 112], "nathan": [51, 75, 86, 88], "celebr": [51, 122], "pictur": [51, 75, 164], "thorough": [51, 173, 174], "shed": [51, 217], "timer": [51, 164, 182, 223, 231], "spend": [51, 219, 225], "sake": [51, 127, 155, 159, 227, 228, 229, 230, 235, 236], "ian": 51, "constantli": [51, 75, 159], "outsmart": 51, "equilibrium": 51, "perfect": [51, 91, 186], "confid": [51, 92, 94, 99, 101, 126, 158, 159, 169, 218], "notat": [51, 75, 109], "chw": [51, 157], "3x64x64": 51, "thought": [51, 113, 116, 185, 233, 245], "latent": [51, 106], "p_": 51, "p_g": 51, "minimax": 51, "logd": 51, "underset": 51, "mathbb": [51, 86, 149, 159], "sim": 51, "radford": 51, "unsupervis": 51, "drawn": [51, 107, 158], "rgb": [51, 58, 59, 94, 138, 145, 157, 175, 204], "volum": [51, 124], "tip": [51, 58, 59, 90, 106, 169, 238], "manualse": 51, "10000": [51, 94, 159, 162, 219, 233], "dataroot": 51, "image_s": 51, "spatial": [51, 92, 94, 95, 122, 165, 175], "64x64": 51, "nc": [51, 91], "nz": 51, "ngf": 51, "ndf": 51, "num_epoch": [51, 117, 156, 175], "0002": 51, "ngpu": 51, "celeb": 51, "img_align_celeba": 51, "celeba": 51, "188242": 51, "173822": 51, "284702": 51, "537394": 51, "stdev": 51, "02": [51, 91, 143, 148, 162], "weights_init": 51, "reiniti": 51, "netg": 51, "netd": 51, "critic": [51, 75, 86, 132, 188, 205, 211, 216, 233], "downsampl": [51, 94, 134, 145], "promot": 51, "healthi": 51, "bceloss": [51, 109], "ell": [51, 164], "l_1": 51, "l_n": 51, "quad": [51, 159], "y_n": 51, "bce": 51, "equat": [51, 136, 159, 221, 226, 245], "gt": [51, 108, 239], "gaussian": [51, 126, 158], "fixed_nois": 51, "establish": [51, 60, 222], "Be": [51, 91, 227], "somewhat": 51, "incorrect": [51, 91, 94, 125, 130, 171, 239], "collaps": 51, "went": [51, 95, 98, 143, 192], "wrong": [51, 75, 101, 127, 143, 171, 190], "ganhack": 51, "ascend": 51, "secondli": [51, 182], "loss_d": 51, "loss_g": 51, "theoret": [51, 184], "versu": [51, 75, 122, 200], "anim": [51, 94], "music": 51, "dcgan_faces_tutori": [51, 112], "mingpt": [52, 53, 54, 55, 131, 132], "aw": [52, 54, 124, 131, 132, 173, 174], "p3": [52, 53, 54, 64, 110, 131, 132], "8xlarg": [52, 54], "youtub": [52, 53, 54, 55, 91, 92, 94, 95, 97, 98, 99, 122, 131, 132, 172], "failur": [52, 61, 132, 133, 143], "disrupt": 52, "suscept": 52, "elast": [52, 123, 133], "attempt": [52, 91, 98, 101, 123, 200], "minutia": 52, "multinod": [52, 131, 172], "load_snapshot": 52, "snapshot_path": 52, "train_step": 52, "should_checkpoint": 52, "save_snapshot": 52, "membership": [52, 132], "intervent": [52, 181], "envvari": 52, "ddp_setup": [52, 54], "12355": [52, 54, 124, 133], "local_rank": [52, 123, 132, 136, 181], "gpu_id": [52, 54, 132], "_save_snapshot": 52, "model_st": 52, "epochs_run": 52, "_load_snapshot": 52, "max_epoch": 52, "_run_epoch": [52, 54], "total_epoch": [52, 54], "save_everi": [52, 54], "nproc_per_nod": [52, 123, 133], "migrat": [52, 54, 173], "fault": [53, 54, 55, 60, 61, 89, 131, 132], "toler": [53, 54, 55, 61, 89, 91, 131, 132], "cluster": [53, 97, 123, 126, 131, 132, 133, 135], "torchrun": [53, 123, 131, 132], "amazon": 53, "ec2": [53, 124], "gentli": 53, "stat": [54, 123, 158, 168, 175, 225, 233], "convert_sync_batchnorm": 54, "mytraindataset": 54, "distributedsampl": [54, 55, 123, 124, 136, 181], "destroy_process_group": [54, 123, 124, 133], "excess": [54, 208, 218], "train_data": 54, "train_dataset": [54, 123, 208], "set_epoch": [54, 123, 124], "b_sz": 54, "_run_batch": 54, "ckp": 54, "_save_checkpoint": 54, "gather": [54, 81, 92, 97, 133, 135, 142, 158, 159, 191, 198, 218], "load_train_obj": 54, "prepare_dataload": 54, "shorthand": [54, 245], "ring": 55, "destroi": [55, 91, 140, 246], "soumith": [56, 84, 135], "chintala": [56, 84, 135], "scientif": [56, 95, 98, 110], "cifar10": [56, 89, 94, 168, 208, 237], "robert": [57, 100, 101, 103, 104, 106, 222], "guthri": [57, 100, 101, 103, 104, 106, 222], "peopl": [57, 101, 113, 117, 181, 245], "theano": [57, 100], "kera": [57, 100, 110], "dynet": [57, 100], "speech": [57, 75, 95, 100, 106, 122, 128, 234], "russel": 57, "norvig": 57, "book": 57, "rip": 57, "jeff": [58, 59, 120], "tang": [58, 59, 120], "review": [58, 59, 80, 92, 113, 131, 136, 156, 173, 174, 184, 185, 187, 208], "jeremiah": [58, 59], "chung": [58, 59, 126], "region": [58, 59, 92, 98, 126, 142, 166, 173, 174, 175, 214, 218, 234], "bicycl": [58, 59], "bu": [58, 59], "car": [58, 59, 113], "autonom": [58, 59], "favor": [58, 126, 149, 158], "pitfal": [58, 59], "beyond": [58, 59, 61, 95, 98, 103, 154, 155], "ndk": [58, 201, 212, 215], "torchscript": [58, 59, 112, 120, 122, 138, 141, 146, 174, 181, 182, 183, 189, 191, 194, 202, 211, 212, 213, 216, 225, 238], "recip": [58, 59, 61, 108, 120, 122, 174, 183, 189, 197, 199, 201, 203, 204, 205, 210, 214, 217, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230, 235, 236, 237, 240, 241], "deeplabv3_script": [58, 59, 197, 210], "deeplabv3_resnet50": [58, 59, 197, 210, 211], "resnet101": [58, 146], "hub": [58, 59, 117, 197, 210, 211], "v0": [58, 59, 122, 145, 159, 197, 210, 211, 242], "scriptedm": [58, 59], "168mb": [58, 59], "input_imag": [58, 59], "deeplab": [58, 59, 197], "input_tensor": [58, 59, 157, 189, 204], "400x400": [58, 59], "oncreat": [58, 201], "mainact": [58, 199, 201, 210], "assetfilepath": [58, 201, 210], "ioexcept": [58, 201], "imagesegment": [58, 197, 210], "breakpoint": [58, 59], "73": [58, 143, 162, 173, 219], "inputtensor": [58, 154, 199], "tensorimageutil": [58, 211], "bitmaptofloat32tensor": 58, "bitmap": 58, "torchvision_norm_mean_rgb": [58, 211], "torchvision_norm_std_rgb": [58, 211], "getdataasfloatarrai": 58, "outtensor": 58, "todictstringkei": 58, "pytorch_vision_deeplabv3_resnet101": [58, 59], "outputtensor": [58, 59, 154, 182, 183, 199, 211], "getwidth": 58, "getheight": 58, "emul": [58, 145, 181, 197], "consum": [58, 59, 77, 108, 118, 125, 143, 148, 158, 160, 162, 163, 179, 183, 190, 193, 204, 225, 234, 240], "bulk": [58, 59, 129], "heaviest": [58, 59], "intvalu": 58, "classnum": [58, 59], "maxi": [58, 59], "maxj": [58, 59], "maxnum": [58, 59], "green": [58, 59, 60, 100, 113, 123, 169], "sheep": [58, 59], "black": [58, 59, 75, 95, 107, 126, 160, 164], "0xffff0000": 58, "0xff00ff00": 58, "0xff0000ff": 58, "0xff000000": 58, "outputbitmap": 58, "imageview": 58, "bmpsegment": 58, "createscaledbitmap": 58, "getconfig": 58, "setpixel": 58, "setimagebitmap": 58, "textview": 58, "helloworld": [59, 182, 183, 212, 213], "deeplabv3_resnet101": 59, "viewcontrol": [59, 210], "swift": [59, 210, 213], "uiviewcontrol": 59, "var": [59, 83, 117, 182, 201], "uiimag": 59, "func": [59, 122, 137, 140, 144, 149, 152, 198], "viewdidload": 59, "torchmodul": [59, 183, 210, 213], "filepath": [59, 210], "forresourc": [59, 210], "oftyp": [59, 210], "fileatpath": [59, 210], "fatalerror": [59, 210], "predictimag": [59, 183], "unsign": [59, 143, 219], "imagebuff": [59, 183], "autogradmod": [59, 201], "non_var_type_mod": 59, "nsmutablearrai": 59, "floatinput": 59, "nil": [59, 210], "addobject": 59, "outputdict": 59, "_impl": [59, 182, 183, 210], "togenericdict": 59, "floatbuff": [59, 199, 211], "temporarili": [59, 91], "nsmutabledata": 59, "datawithlength": 59, "sizeof": [59, 201], "mutablebyt": 59, "floatvalu": 59, "uiimageview": 59, "convertrgbbuffertouiimag": 59, "uiimagehelp": 59, "uitextview": 59, "segmentimag": 59, "phase": [60, 78, 80, 107, 117, 135, 156, 162, 182, 189, 193, 197, 225], "imper": 60, "idiomat": 60, "defer": 60, "optimiz": 60, "decor": [60, 61, 86, 91, 109, 121, 145, 160, 171, 234], "caveat": [60, 113, 133, 160, 219], "inspir": [60, 116, 135, 144, 149, 163, 198, 222], "remind": [60, 113, 173], "necessarili": [60, 130], "cooper": [60, 208], "chronolog": 60, "encoderrnn": [60, 239], "attend": [60, 118], "decoder_input": 60, "greedili": 60, "decoded_word": 60, "_length": 60, "adher": [60, 195], "diff": [60, 219, 233], "stem": 60, "freedom": [60, 164], "__constants__": [60, 239], "liter": [60, 246], "_devic": [60, 239], "_sos_token": [60, 239], "pep": [60, 245], "3107": [60, 117], "mypi": 60, "longtensor": [60, 106, 128, 134, 160, 162], "index2word": [60, 164], "evaluateexampl": 60, "stdin": 60, "map_loc": [60, 111, 133, 218, 227], "test_seq": 60, "num": [60, 136, 160, 181], "_word": 60, "int64": [60, 98, 172, 175, 187], "test_seq_length": 60, "traced_encod": [60, 239], "manufactur": 60, "presenc": [60, 95, 171, 217], "compli": 60, "unscript": [60, 240], "scripted_search": 60, "traced_decod": [60, 239], "script_modul": 60, "deploy_seq2seq_hybrid_frontend_tutori": [60, 112], "shen": [61, 124, 133, 134, 148, 154, 160, 162], "li": [61, 124, 133, 134, 135, 148, 154, 160, 162, 171, 173, 174], "categor": [61, 97, 160, 162, 174], "technolog": [61, 122, 135, 205, 238], "v1": [61, 134, 159, 160, 162, 178, 203, 219], "lifetim": [61, 162], "c10d": [61, 133, 154, 234], "all_gath": [61, 123, 124, 135, 154], "p2p": 61, "isend": [61, 135], "gradual": [61, 86], "willing": [61, 113], "lowest": [61, 124, 155], "hurdl": 61, "vldb": 61, "starter": 61, "unbalanc": 61, "zeroredundancyoptim": [61, 154, 238], "footprint": [61, 108, 123, 124, 131, 207, 216, 218, 241], "uneven": [61, 121], "growth": [61, 187], "recoveri": [61, 133], "sometim": [61, 95, 98, 110, 125, 130, 132, 133, 144, 159, 162, 164, 186, 187, 234], "inevit": [61, 133], "oom": [61, 123, 218], "recov": [61, 123, 124, 133, 146], "desynchron": 61, "agent": [61, 122, 159, 160, 162, 165], "pillar": 61, "protocol": [61, 115], "spirit": [61, 136, 245], "hogwild": 61, "ps": [61, 160, 161, 162], "async_execut": [61, 121, 122, 160], "polynomi": [63, 64, 65, 67, 68, 69, 72, 73, 110], "sin": [63, 64, 67, 68, 69, 72, 73, 91, 98, 110, 234, 245], "pi": [63, 64, 67, 68, 69, 72, 73, 91, 110, 122, 159, 245], "euclidean": [63, 64, 67, 68, 69, 72, 73, 91, 110], "polynomial_autograd": 63, "bx": [64, 110], "cx": [64, 101, 110], "p_3": [64, 110], "5x": [64, 110], "3x": [64, 110, 174, 200, 211, 218, 234], "legendr": [64, 110], "polynomial_custom_funct": 64, "strang": [65, 86, 110, 245], "fifth": [65, 110, 246], "tough": [65, 110, 113], "dynamic_net": [65, 70], "polynomial_modul": [67, 70], "2000": [68, 72, 94, 110, 169, 219, 241], "flaten": [68, 110], "mse": [68, 95, 110], "polynomial_nn": [68, 70], "polynomial_optim": [69, 70], "beginner_examples_nn": 70, "99": [72, 110, 159, 162], "1546": 72, "0365145892183": 72, "199": 72, "1095": [72, 103], "8992907857576": 72, "299": [72, 91], "777": [72, 175], "6096767345516": 72, "399": 72, "552": 72, "5352611528602": 72, "499": 72, "3692169177716": 72, "599": 72, "280": [72, 162], "80664270842703": 72, "201": 72, "19883404382793": 72, "799": [72, 175], "144": 72, "89548639133625": 72, "899": [72, 143, 240], "105": 72, "07298180275444": 72, "999": [72, 169], "76": [72, 91, 146, 162, 219], "90616893555887": 72, "1099": 72, "982896477615675": 72, "1199": 72, "89011969702015": 72, "1299": 72, "9212810307606": 72, "1399": 72, "869417918780947": 72, "1499": 72, "880874497663395": 72, "1599": 72, "35185928109817": 72, "1699": 72, "855296144964393": 72, "1799": 72, "08909475122299": 72, "1899": 72, "839566794279794": 72, "1999": 72, "955552494109163": 72, "04887728059779718": 72, "854335392917212": 72, "008432144224579809": 72, "09298823470267067": 72, "linspac": [72, 91, 110], "y_pred": [72, 110], "grad_y_pr": [72, 110], "grad_a": [72, 110], "grad_b": [72, 110], "grad_c": [72, 110], "grad_d": [72, 110], "364": [72, 74, 94], "polynomial_numpi": [72, 74], "biggest": 73, "polynomial_tensor": [73, 74], "365": 74, "beginner_examples_tensor": 74, "appreci": [75, 100, 113], "overlook": [75, 219], "secur": 75, "awar": [75, 91, 98, 126, 135, 136, 146, 163, 173, 180, 182, 183, 184], "vulner": 75, "surpris": [75, 151], "impercept": 75, "perturb": [75, 92], "drastic": 75, "overarch": 75, "misclassif": 75, "alter": [75, 111, 222, 226, 236], "har": 75, "remark": 75, "mathbf": 75, "theta": [75, 101, 158, 245], "nabla_": [75, 101], "007": 75, "misclassifi": 75, "gibbon": 75, "clearli": [75, 126, 184, 185], "motiv": [75, 143, 161, 176, 185, 186, 188, 193], "degrad": 75, "pretrained_model": 75, "fgsm_attack": 75, "clean": [75, 123, 124, 133, 182, 184, 190, 245], "data_grad": 75, "_imag": 75, "_grad": 75, "strength": [75, 169, 190], "_data": 75, "trend": [75, 168], "curv": [75, 148, 168, 169], "linearli": 75, "lunch": [75, 189], "BUT": [75, 103], "percept": 75, "tradeoff": [75, 122, 125, 126, 135, 158], "titl": [75, 117, 127, 156, 159, 164, 213, 225], "evid": 75, "nip": [75, 119], "defens": 75, "competit": [75, 137, 152], "defenc": 75, "perhap": [75, 127, 155, 239], "dirti": 75, "fgsm_tutori": [75, 112], "torchvision_tutori": 76, "multimod": [77, 122], "ow": 77, "ubiquit": 77, "caption": [77, 245, 248], "vqa": 77, "unimod": 77, "contrast": [77, 128, 148, 152, 174, 184], "textvqa": 77, "bert": [77, 95, 122, 124, 174, 191, 216, 222], "hug": [77, 143], "dl": [77, 174, 200, 201, 209, 245], "fbaipublicfil": 77, "pythia": 77, "gz": [77, 245, 246], "xf": 77, "prepend": 77, "exclam": 77, "34602": 77, "unknown": [77, 116, 204], "uniform": [77, 113, 173, 195], "berttoken": [77, 136, 181], "flava_model_for_classif": 77, "mlp": [77, 137, 173], "toi": [77, 124, 133, 141, 148, 162, 172], "mdetr": 77, "omnivor": 77, "multitask": 77, "flava_finetuning_tutori": [77, 112], "flush": [78, 97, 183, 201, 218, 232, 245], "twice": [78, 91, 107, 130, 168, 219, 225, 241], "retain_vari": 78, "freed": [78, 123, 192], "autograd_tutorial_old": [78, 79, 82], "tensor_tutorial_old": [79, 82, 83], "nnft_tutori": [79, 80, 82], "redesign": 80, "concatt": 80, "caddtabl": 80, "nngraph": 80, "input1": 80, "input2": 80, "held": [80, 127, 161], "pdb": 80, "debugg": [80, 107], "err": 80, "penn": [80, 175], "bank": 80, "becam": [81, 201], "inaccess": 81, "clash": 81, "mpi": [81, 135], "scatter": [81, 133, 135], "parallel_appli": 81, "clariti": [81, 141, 222], "blitz": [81, 109, 127, 128, 164, 169], "beginner_former_torchi": 82, "uniniti": [83, 195], "postfix": 83, "narrow": [83, 143, 188], "narrow_": 83, "lua": [83, 84, 127, 128, 164], "camelcas": 83, "anymor": [83, 232], "indexadd": 83, "index_add_": 83, "chartensor": 83, "learning_hybrid_frontend_through_example_tutori": [85, 86, 87], "hybrid_frontend": 85, "introduction_to_hybrid_frontend_tutori": 85, "shini": 86, "avenu": 86, "enjoi": [86, 145], "aquaint": 86, "bridg": [86, 213], "gap": 86, "refin": 86, "proven": [86, 118, 187], "resouc": 86, "consumpt": [86, 94, 95, 97, 99, 108, 123, 126, 143, 155, 168, 204, 238, 241], "discrep": 86, "interwork": 86, "intrus": 86, "broken": [86, 103, 119, 174], "stand": [86, 91, 98, 107, 113, 145, 187, 245], "seek": [86, 92], "epsilon": [86, 129, 158, 159], "biggl": 86, "lfloor": 86, "prod_": 86, "biggr": 86, "rfloor": 86, "hline": 86, "190": [86, 162, 219], "4377": 86, "59051": 86, "2x": [86, 130, 173, 174, 178], "accomod": [86, 131], "beginner_hybrid_frontend": 87, "dramat": [89, 107], "industri": [89, 92], "tensorboard": [89, 90, 91, 92, 93, 94, 95, 98, 99, 122, 126, 165, 223, 225, 231, 238], "slight": [89, 130, 138, 220], "trial": [89, 126, 218], "train_cifar": 89, "data_dir": [89, 117, 123, 136, 156, 181], "l1": [89, 155, 174], "l2": [89, 95, 155], "get_checkpoint": 89, "checkpoint_st": 89, "to_dict": 89, "start_epoch": 89, "net_state_dict": 89, "optimizer_state_dict": [89, 111, 208], "luckili": [89, 143, 186, 219], "trainload": [89, 169], "fraction": [89, 219], "checkpoint_data": 89, "from_dict": 89, "val_loss": [89, 123], "val_step": 89, "bad": [89, 113, 125, 138, 174], "wast": [89, 138, 168, 188, 191, 195, 219, 226], "loguniform": [89, 219], "ashaschedul": 89, "functool": [89, 123, 124], "gpus_per_tri": 89, "resources_per_tri": 89, "num_sampl": [89, 123], "checkpoint_at_end": 89, "000668163": 89, "31479": 89, "0977": 89, "0331514": 89, "31605": 89, "0983": 89, "000150295": 89, "30755": 89, "1023": 89, "0128248": 89, "66912": 89, "4391": 89, "00464561": 89, "7316": 89, "3463": 89, "00031556": 89, "19409": 89, "1736": [89, 175], "00574329": 89, "85679": 89, "3368": 89, "00325652": 89, "30272": 89, "0984": 89, "000342987": 89, "76044": 89, "003734": 89, "53101": 89, "4761": [89, 103], "0037339984519545164": 89, "5310075663924216": 89, "4737": 89, "hyperparameter_tuning_tutori": [89, 112], "brad": 90, "heintz": 90, "captum": [90, 93, 223, 231, 238], "rapid": [91, 187], "rigidli": 91, "sign": [91, 151, 197], "contextu": 91, "nudg": [91, 94, 99], "calculu": 91, "expand": [91, 103, 113, 143, 169, 174, 182, 188, 189, 202], "ticker": 91, "2618": 91, "5236": 91, "7854": 91, "0472": 91, "3090": [91, 201], "5708": 91, "8326": 91, "0944": 91, "3562": 91, "6180": 91, "8798": 91, "1416": 91, "4034": 91, "6652": 91, "9270": 91, "1888": 91, "4506": 91, "7124": 91, "9742": 91, "2360": 91, "4978": 91, "7596": 91, "0214": 91, "2832": 91, "line2d": 91, "0x7ff0b4f6afe0": 91, "0000e": 91, "5882e": 91, "0711e": 91, "6603e": 91, "6593e": 91, "7423e": 91, "7485e": 91, "07": [91, 108, 123, 175, 207, 233], "sinbackward0": 91, "1764e": 91, "4142e": 91, "7321e": 91, "9319e": 91, "4969e": 91, "mulbackward0": 91, "5176e": 91, "8236e": 91, "5763e": 91, "1421e": 91, "3205e": 91, "3185e": 91, "7684e": 91, "addbackward0": [91, 103], "next_funct": 91, "na": [91, 165], "0x7ff0b4fcc580": 91, "0x7ff0b4fcd810": 91, "accumulategrad": 91, "machineri": [91, 219], "3850e": 91, "0x7ff0ce6a1d50": 91, "co": [91, 106, 225, 234, 246], "ins": 91, "dim_in": 91, "dim_out": 91, "tinymodel": 91, "layer1": [91, 156, 159], "layer2": [91, 148, 156, 159], "some_input": 91, "ideal_output": 91, "0920": 91, "0916": 91, "0121": [91, 175], "0083": [91, 175], "0055": [91, 103], "0367": 91, "0221": 91, "0276": 91, "0086": 91, "0157": [91, 181], "slicebackward0": 91, "211": [91, 225], "2634": [91, 175], "8997": 91, "9572": 91, "3021": 91, "8887": 91, "3192": 91, "5169": 91, "4319": 91, "1732": 91, "3835": 91, "0791": 91, "0098": 91, "0064": [91, 175], "0106": [91, 181], "0293": 91, "0186": 91, "0300": 91, "0088": 91, "0211": 91, "set_to_non": [91, 234], "2095": 91, "9459": 91, "3306": 91, "5096": 91, "5471": 91, "5391": 91, "3370": 91, "6386": 91, "5141": 91, "1419": 91, "blow": [91, 113], "b1": 91, "b2": 91, "c1": [91, 94, 143], "c2": 91, "c3": [91, 94], "add_tensors1": 91, "add_tensors2": 91, "enable_grad": 91, "0670": 91, "3890": 91, "7264": [91, 219], "3559": 91, "6584": 91, "sin_": 91, "handi": [91, 94, 107, 135, 145, 169], "bake": [91, 141], "run_on_gpu": 91, "prf": 91, "key_averag": [91, 108], "sort_bi": [91, 108, 225], "self_cpu_time_tot": [91, 225], "div": [91, 143, 184], "711m": 91, "711u": 91, "929m": 91, "929u": 91, "81": [91, 120, 143], "465m": 91, "465u": 91, "451m": 91, "451u": 91, "cudadevicesynchron": 91, "18": [91, 108, 117, 127, 143, 156, 157, 162, 175, 216, 219, 249], "000u": [91, 143, 225], "196m": 91, "380m": 91, "preced": [91, 98, 129, 141, 174, 179, 192, 245], "4868": 91, "425": 91, "4009": 91, "1082": [91, 219], "9885": 91, "0240e": 91, "hessian": [91, 122, 165, 198], "exp_add": 91, "7212": 91, "2079": 91, "1137": 91, "2080": 91, "2604": 91, "4415": 91, "5220": 91, "9867": 91, "4288": 91, "4623": 91, "5950": 91, "1102": 91, "do_some_doubl": 91, "my_gradi": 91, "vjp": [91, 144, 149, 198], "665": 91, "7186": 91, "866": [91, 146], "7054": 91, "58": [91, 146, 209], "4194": 91, "jvp": [91, 140, 144], "vhp": [91, 122, 165], "hvp": [91, 122, 165], "946": [91, 96], "autogradyt_tutori": [91, 93, 96], "latin": 92, "increasingli": 92, "area": [92, 95, 113, 169, 175, 187, 217, 247], "neuron": [92, 217], "analag": 92, "ablat": 92, "permut": [92, 109, 146, 157, 180], "valuabl": [92, 164], "certainli": [92, 113, 142, 185, 187, 222], "plotli": [92, 126], "enhanc": [92, 115, 138, 166, 200, 205, 245], "attr": [92, 154, 200], "widget": 92, "toolset": 92, "flask": [92, 113, 122, 165, 238], "compress": [92, 155, 184, 187, 202, 209], "renam": [92, 138, 176, 179, 182, 192], "virtual": [92, 154], "affect": [92, 95, 99, 113, 130, 148, 173, 234], "img": [92, 117, 138, 156, 169, 175], "recogn": [92, 95, 138, 154, 221], "visualize_image_attr": 92, "integrated_gradi": 92, "strongest": [92, 94, 95, 99], "visualize_image_attr_multipl": 92, "heat": [92, 157], "upsampl": 92, "interpol": [92, 245], "layerattribut": 92, "teapot": 92, "trilobit": 92, "fossil": 92, "attributionvisu": 92, "bring": [92, 113, 158, 168, 187, 198, 205, 222, 225, 234], "imagefeatur": 92, "heatmap": 92, "captumyt": [92, 96], "introyt": 93, "rst": [93, 243, 245], "introyt1_tutori": [93, 94, 96], "tensors_deeper_tutori": [93, 96, 98], "modelsyt_tutori": [93, 95, 96], "tensorboardyt_tutori": [93, 96, 97], "trainingyt_tutori": 93, "captumyt_tutori": 93, "sphx_glr_beginner_introyt_modelsyt_tutori": [93, 96], "sphx_glr_beginner_introyt_tensors_deeper_tutori": [93, 96], "sphx_glr_beginner_introyt_captumyt": [93, 96], "sphx_glr_beginner_introyt_introyt1_tutori": [93, 96], "sphx_glr_beginner_introyt_trainingyt": [93, 96], "sphx_glr_beginner_introyt_tensorboardyt_tutori": [93, 96], "sphx_glr_beginner_introyt_autogradyt_tutori": [93, 96], "5x3": 94, "helpfulli": 94, "prng": 94, "r3": 94, "r1": 94, "r2": 94, "trigonometr": [94, 98], "singular": [94, 151, 163], "decomposit": [94, 143], "diagram": [94, 118, 159], "earliest": 94, "explos": 94, "handwritten": [94, 124], "abridg": 94, "s4": 94, "f5": 94, "f6": 94, "ten": [94, 97], "spot": [94, 97, 98, 127], "artifact": [94, 131], "gist": 94, "tile": [94, 97, 99, 200], "hasn": [94, 113], "shouldn": [94, 155], "center": [94, 95, 99, 159, 168, 234], "concatdataset": 94, "trainset": [94, 169], "50000": 94, "4914": 94, "4822": 94, "4465": [94, 103], "2470": 94, "2435": 94, "2616": 94, "rotat": [94, 97, 166, 169], "vehicl": [94, 162], "told": [94, 158], "strip": [94, 233], "ingredi": [94, 119], "inner": [94, 158, 174, 246], "imposs": [94, 100, 198], "235": [94, 108], "940": 94, "6000": 94, "8000": [94, 233], "573": 94, "507": 94, "12000": 94, "442": 94, "378": 94, "319": [94, 225], "284": [94, 162], "267": 94, "monoton": 94, "descend": 94, "memor": 94, "roughli": [94, 100, 110, 123, 133, 143, 148, 178, 234], "lin": [95, 136, 156, 202], "nearbi": [95, 113], "lenet5": 95, "1x32x32": 95, "liken": 95, "5x5": 95, "3x5": 95, "6x28x28": 95, "2x2": 95, "6x14x14": 95, "sought": 95, "3x3": 95, "16x12x12": 95, "16x6x6": 95, "576": 95, "edg": [95, 110, 120, 122, 142, 168, 176, 192, 193, 221, 245], "instrument": [95, 142, 238], "dna": 95, "nucleotid": 95, "moder": 95, "tagger": [95, 100], "noun": 95, "verb": 95, "vocab_s": [95, 136, 181, 208], "tagset_s": 95, "log_softmax": [95, 107, 124, 161, 209], "transformerdecod": [95, 118], "subcompon": 95, "transformerdecoderlay": 95, "twin": 95, "maxpool": [95, 156, 193], "quadrant": 95, "6x6": 95, "vanish": [95, 101], "offset": [95, 115], "neighborhood": 95, "steepest": 95, "feasibl": [95, 124], "hardtanh": [95, 109, 239], "950": 96, "beginner_introyt": 96, "trainingyt": [96, 99], "garment": 97, "tb": 97, "gfile": 97, "tensorflow_stub": 97, "add_imag": [97, 169], "summarywrit": [97, 169, 232], "log_dir": [97, 126, 169], "logdir": [97, 168, 169, 232], "6006": [97, 168, 169, 232], "efficaci": 97, "add_graph": [97, 169], "add_embed": [97, 169], "chart": 97, "projector": 97, "toggl": [97, 173, 241], "night": [97, 169, 246], "icon": [97, 201, 243, 245], "dark": 97, "attach": [98, 159, 190, 202, 204], "terminolog": [98, 103], "likewis": 98, "assur": 98, "random1": 98, "random3": 98, "random2": 98, "random4": 98, "rng": [98, 135], "_like": [98, 146], "extent": 98, "empty_lik": [98, 146, 184, 202], "int16": [98, 192, 222], "cue": 98, "unlabel": 98, "intent": [98, 185, 192, 193, 201, 245], "int32": [98, 136, 181, 192, 193, 222], "bfloat": 98, "subtract": [98, 234], "2x4": 98, "1x4": 98, "3rd": [98, 200, 208], "2nd": [98, 104, 161], "hundr": [98, 120], "invers": [98, 185, 203], "bitwis": [98, 218], "inventori": [98, 99], "occupi": [98, 214], "discard": [98, 123, 124, 168, 225, 233], "underscor": 98, "deepli": 98, "neither": [98, 148, 176], "nor": [98, 135, 141, 176, 184], "mid": 98, "unifi": [98, 129, 190, 217], "someplac": 98, "ram": [98, 123, 211], "colloqui": 98, "fragil": 98, "robustli": 98, "whichev": 98, "thrown": [98, 187, 199], "226": 98, "zeroth": 98, "bracket": [98, 176, 245], "rescu": 98, "squeeze_": 98, "unsqueeze_": [98, 204], "radic": 98, "parenthes": 98, "comma": 98, "convinc": 98, "kinship": 98, "autom": [99, 110, 126, 142, 146, 179], "outcom": [99, 126], "saniti": [99, 126, 158, 192, 240], "chose": [99, 157, 171], "garmentclassifi": 99, "kit": 100, "opposit": [100, 185], "difficult": [100, 113, 144, 151, 164, 186, 190, 198], "constitu": 100, "fat": [100, 113], "exception": 100, "entiti": [100, 106, 172, 236, 237, 245], "recognit": [100, 122, 200, 234], "strong": [100, 173, 187, 245], "ner": 100, "sound": [100, 103, 110], "scari": 100, "viterbi": [100, 104], "sum_": [100, 106, 159], "psi_i": 100, "sum_i": 100, "partit": [100, 135, 148, 153, 234], "emiss": 100, "timestep": [100, 104, 127, 128, 159], "textbf": 100, "psi_": 100, "y_i": [100, 104], "x_i": [100, 101], "tran": 100, "h_i": [100, 104], "collin": 100, "prepare_sequ": 100, "anywai": [100, 103], "gold": [100, 164], "perceptron": [100, 173], "score_sent": 100, "advanced_tutori": [100, 102, 105], "workhors": 101, "plu": [101, 115], "2x5": 101, "acx": 101, "ac": [101, 248], "sigma": [101, 158], "plenti": 101, "shy": 101, "linearit": 101, "sum_j": 101, "x_j": 101, "unseen": [101, 106], "supervis": [101, 166], "eta": [101, 175], "vari": [101, 129, 145, 164, 171, 178, 179, 186, 188, 211, 218, 222], "spanish": [101, 127, 128], "bow": 101, "word_to_ix": [101, 104, 106], "bowclassifi": 101, "creo": 101, "bigger": [101, 127, 128, 157, 245], "deep_learning_tutori": [101, 102, 105], "pytorch_tutori": [102, 103, 105], "word_embeddings_tutori": [102, 105, 106], "lexic": [102, 105], "sequence_models_tutori": [102, 104, 105, 222], "bi": [102, 105, 136], "crf": [102, 105], "_c": [103, 181, 182], "0x7ff0a8886db0": 103, "v_data": 103, "m_data": 103, "2x2x2": 103, "t_data": 103, "5256": 103, "7502": 103, "6540": 103, "6095": 103, "1002": 103, "6092": 103, "9798": 103, "6091": 103, "7121": 103, "3037": 103, "7773": 103, "2515": 103, "2223": 103, "6871": 103, "2284": 103, "4676": 103, "6970": 103, "1608": 103, "6995": 103, "1991": 103, "8657": 103, "2444": 103, "6629": 103, "8073": 103, "1759": 103, "2456": 103, "0612": 103, "6177": 103, "7981": 103, "1316": 103, "8793": 103, "0721": 103, "1578": [103, 175], "7735": 103, "0457": [103, 181], "1530": 103, "4757": 103, "1110": 103, "2927": 103, "0288": 103, "4533": 103, "1422": 103, "2486": 103, "7754": 103, "0255": 103, "0233": 103, "5962": 103, "4285": 103, "7869": [103, 117], "6103": 103, "7040": 103, "1853": 103, "9962": 103, "8313": 103, "z_1": 103, "x_2": [103, 116, 149, 245], "y_2": [103, 116], "z_2": 103, "complain": 103, "8029": 103, "2366": 103, "2857": 103, "6898": 103, "6331": 103, "8795": 103, "6842": 103, "2912": [103, 117], "8317": 103, "5525": 103, "6355": 103, "3968": 103, "6571": 103, "6428": 103, "9803": 103, "0421": 103, "8206": 103, "3133": 103, "1352": 103, "3773": 103, "2824": 103, "5667": 103, "4303": 103, "5009": 103, "5438": 103, "4057": 103, "1341": 103, "1473": 103, "6272": 103, "0939": 103, "2381": 103, "1115": 103, "7703": 103, "3459": 103, "5119": 103, "6933": 103, "1668": 103, "9999": 103, "4175": 103, "2127": 103, "8400": 103, "4200": 103, "6240": 103, "9773": 103, "8748": 103, "9873": 103, "0594": 103, "4919": 103, "2423": 103, "3126": [103, 117], "5038": 103, "6223": 103, "4481": 103, "2856": 103, "3880": 103, "1435": 103, "6512": 103, "1032": 103, "6937": 103, "vagu": 103, "programm": [103, 106, 192, 245], "obvious": [103, 162], "0x7ff0ce6cebf0": 103, "0x7ff0ceb5e8c0": 103, "x_0": [103, 245], "overbrac": [103, 104, 106], "y_0": 103, "z_0": 103, "gloss": 103, "challeng": [103, 104, 124, 135, 141, 151, 159, 219], "new_z": 103, "NO": 103, "forgotten": 103, "0x7ff0ceb5e050": 103, "022": [103, 105], "classic": [104, 107, 113, 146, 151, 166], "markov": 104, "myriad": 104, "cow": 104, "q_": [104, 106, 145], "1st": [104, 124], "reader": [104, 135, 148, 173, 233, 245], "unfamiliar": 104, "w_1": 104, "w_m": 104, "w_i": [104, 106], "_i": [104, 181], "_1": [104, 239], "_m": 104, "argmax": [104, 124, 136, 161, 181, 209], "_j": 104, "ah_i": 104, "affin": [104, 129, 166, 173, 176, 207, 234], "affix": [104, 106], "bear": 104, "ly": 104, "adverb": 104, "c_w": 104, "x_w": 104, "po": [104, 175], "025": 105, "beginner_nlp": 105, "capit": [106, 245], "enorm": 106, "drawback": 106, "notion": [106, 119, 175], "mathematician": 106, "physicist": 106, "wouldn": [106, 124], "role": [106, 155, 162, 174, 245], "somehow": 106, "orthograph": 106, "linguist": 106, "hypothesi": 106, "coffe": 106, "phi": [106, 245], "pain": [106, 113], "earth": [106, 113], "herself": 106, "ith": [106, 188], "shakespear": [106, 163], "sonnet": 106, "word_i": 106, "context_s": 106, "beauti": 106, "cbow": 106, "probabilist": [106, 158], "percent": 106, "q_w": 106, "raw_text": 106, "dedupl": 106, "jeremi": 107, "howard": [107, 145, 154], "rachel": 107, "thoma": 107, "ingham": 107, "elegantli": [107, 221], "concis": 107, "nearli": [107, 169, 219], "pathlib": [107, 123, 189], "trail": [107, 243], "signifi": 107, "xavier": 107, "initialis": 107, "prewritten": 107, "bs": 107, "talli": 107, "set_trac": 107, "logist": 107, "cross_entropi": 107, "clearer": [107, 169], "uppercas": 107, "zero_": [107, 154, 162], "prone": [107, 192], "gone": [107, 113, 125], "xb": 107, "faciallandmarkdataset": 107, "tensordataset": [107, 109, 136, 181], "x_train": 107, "y_train": 107, "start_i": 107, "end_i": 107, "yb": 107, "train_d": 107, "cleaner": [107, 184, 186, 191, 192], "train_dl": 107, "loss_batch": 107, "rid": [107, 144, 205], "avgpool2d": 107, "adaptiveavgpool2d": [107, 134], "lucki": [107, 155], "rent": [107, 246], "hour": 107, "mnist_sampl": 107, "fastai": 107, "practition": [107, 135, 187], "promis": 107, "nn_tutori": [107, 112], "quicker": 108, "bottleneck": [108, 123, 132, 134, 160, 168, 171, 173, 174, 214], "record_funct": [108, 143, 225], "incur": [108, 203], "investig": [108, 113, 146, 155, 171, 233], "with_stack": [108, 168, 225], "group_by_stack_n": 108, "traceback": [108, 143], "193a910735e8": 108, "stacktrac": 108, "mem": [108, 175, 225], "88": [108, 162, 173, 192], "212": 108, "953": 108, "mnt": [108, 135], "xarfus": 108, "au": 108, "715": 108, "848m": 108, "350": [108, 136], "151u": 108, "293": [108, 146], "342u": 108, "095u": 108, "931": 108, "93": [108, 162, 219], "006": 108, "476": 108, "338": 108, "759m": 108, "as_strid": [108, 143], "281": [108, 146], "808u": 108, "275": 108, "721u": 108, "_local": 108, "268": 108, "650u": [108, 225], "_scalar_dens": 108, "347": 108, "argwher": 108, "nonzero": [108, 175, 234], "089m": 108, "402m": 108, "491m": 108, "119": [108, 181], "441": 108, "587u": 108, "_numpi": 108, "395": [108, 162], "602u": 108, "801m": 108, "xxxx": 109, "alexnet": [109, 146], "printable_graph": 109, "tensor_seq": 109, "ret": [109, 157, 160, 202], "disable_cuda": 109, "convxd": 109, "maxpoolxd": 109, "batchnormxd": 109, "dropout2d": [109, 161, 209], "l1loss": 109, "ctcloss": 109, "poissonnllloss": 109, "kldivloss": 109, "bcewithlogitsloss": 109, "marginrankingloss": 109, "hingeembeddingloss": 109, "multilabelmarginloss": 109, "smoothl1loss": [109, 159], "softmarginloss": 109, "multilabelsoftmarginloss": 109, "cosineembeddingloss": 109, "multimarginloss": 109, "tripletmarginloss": 109, "selu": 109, "prelu": 109, "rrelu": 109, "celu": 109, "gelu": 109, "hardshrink": 109, "logsigmoid": 109, "softplu": 109, "softshrink": 109, "softsign": 109, "tanhshrink": 109, "softmin": 109, "softmax2d": 109, "adaptivesoftmaxwithloss": 109, "adadelta": [109, 124], "adamw": [109, 123, 159], "sparseadam": 109, "adamax": 109, "asgd": 109, "rprop": 109, "lr_schedul": [109, 117, 123, 124, 156, 175], "lambdalr": 109, "multiplicativelr": 109, "multisteplr": 109, "exponentiallr": 109, "cosineannealinglr": 109, "reducelronplateau": 109, "cycliclr": 109, "onecyclelr": 109, "cosineannealingwarmrestart": 109, "xsampler": 109, "subsetrandom": 109, "weightedrandom": 109, "justin": 110, "johnson": 110, "brows": 110, "utf": [110, 136, 201, 245, 246], "modern": [110, 171, 182, 189], "50x": 110, "hairi": 110, "thankfulli": 110, "wave": 110, "tflearn": 110, "burden": [110, 164, 234], "unpickl": 111, "facil": 111, "running_mean": [111, 141, 236], "themodelclass": 111, "fc1": [111, 124, 137, 161, 169, 181, 209, 229], "fc2": [111, 124, 161, 169, 181, 209, 229], "fc3": [111, 169, 229], "param_tensor": 111, "var_nam": 111, "param_group": [111, 205], "dampen": 111, "weight_decai": [111, 156, 175, 205], "4675713712": 111, "4675713784": 111, "4675714000": 111, "4675714072": 111, "4675714216": 111, "4675714288": 111, "4675714432": 111, "4675714504": 111, "4675714648": 111, "4675714720": 111, "_use_new_zipfile_seri": 111, "best_model_st": 111, "deepcopi": [111, 141, 156, 179, 192], "exact": [111, 129, 138, 163, 181, 229], "model_script": 111, "model_state_dict": [111, 208], "theoptimizerclass": 111, "alon": [111, 164, 169], "modela_state_dict": 111, "modela": 111, "modelb_state_dict": 111, "modelb": 111, "optimizera_state_dict": 111, "optimizera": 111, "optimizerb_state_dict": 111, "optimizerb": 111, "themodelaclass": 111, "themodelbclass": 111, "theoptimizeraclass": 111, "theoptimizerbclass": 111, "gan": [111, 122, 151, 230], "ensembl": [111, 122, 165, 230], "usabl": [111, 141, 235], "remap": [111, 227], "overwrit": [111, 227], "saving_loading_model": [111, 112], "459": 112, "transfer_learning_tutori": [112, 117], "446": [112, 117], "torchmultimod": [112, 122], "flava": 112, "dcgan": [112, 122], "seq2seq": 112, "vt_tutori": [112, 120], "torchtext_custom_dataset_tutori": [112, 116], "text_sentiment_ngrams_tutori": [112, 115], "transformer_tutori": [112, 118], "template_tutori": [112, 114], "rai": [112, 122], "t5": [112, 121], "t5_tutori": [112, 113], "translation_transform": [112, 119], "pendo": 113, "abbo": 113, "joe": [113, 133], "cum": 113, "cnndm": 113, "imdb": 113, "multi30k": [113, 119], "eo": [113, 116, 119, 128, 164], "sentencepiec": 113, "t5transform": 113, "t5_base_gener": 113, "greedi": [113, 119, 159], "beam": 113, "datapip": [113, 116], "appendix": 113, "batch_prefix": 113, "cnndm_batch_siz": 113, "cnndm_datapip": 113, "rows2columnar": 113, "cnndm_dataload": 113, "sst2": 113, "german": [113, 116, 119, 127, 128], "year": [113, 149, 151], "tattoo": 113, "decad": [113, 173], "australia": 113, "campaign": 113, "honest": 113, "london": 113, "stephen": 113, "hendri": 113, "fame": [113, 248], "supermodel": 113, "sydnei": 113, "australian": 113, "fan": [113, 157], "him": 113, "hotel": 113, "heartthrob": 113, "strai": 113, "pooch": 113, "buri": 113, "stagger": 113, "farm": 113, "dirt": 113, "emaci": 113, "disloc": 113, "jaw": 113, "leg": 113, "injuri": [113, 245], "cave": 113, "sinu": 113, "caviti": 113, "surgeri": 113, "breath": 113, "theia": 113, "bulli": 113, "breed": 113, "appar": [113, 156], "whack": 113, "hammer": 113, "miracl": 113, "sara": 113, "mellado": 113, "mohammad": 113, "javad": 113, "zarif": 113, "iran": 113, "sunni": 113, "fridai": 113, "morn": 113, "cold": [113, 164], "rejoin": 113, "spent": [113, 163, 168, 173, 174, 219, 222, 225], "john": 113, "kerri": 113, "foreign": 113, "minist": 113, "takeov": 113, "iranian": 113, "consul": 113, "tweet": 113, "american": 113, "week": 113, "ebola": 113, "west": 113, "africa": 113, "discharg": 113, "clinician": 113, "health": 113, "boston": 113, "viru": 113, "sierra": 113, "march": 113, "diagnos": [113, 132], "diseas": 113, "maryland": 113, "nation": 113, "institut": 113, "patient": 113, "fair": [113, 189], "campu": 113, "polic": 113, "offic": 113, "affair": 113, "admit": 113, "noos": 113, "wednesdai": 113, "incid": 113, "racist": 113, "colleg": 113, "duke": 113, "univers": [113, 115, 159, 173, 245], "disciplinari": 113, "school": 113, "rope": 113, "input_text": 113, "sci": [113, 115], "fi": 113, "tv": 113, "underfund": 113, "misunderstood": 113, "babylon": 113, "star": 113, "trek": 113, "silli": [113, 125], "prosthet": 113, "cheap": 113, "cardboard": 113, "stilt": 113, "dialogu": 113, "cg": 113, "painfulli": 113, "overcom": 113, "clich\u00e9d": 113, "uninspir": 113, "viewer": [113, 225], "emot": 113, "genr": 113, "serious": 113, "cf": 113, "seriou": 113, "foolish": 113, "spark": 113, "Their": [113, 185, 187], "reaction": 113, "wooden": [113, 245], "maker": 113, "rubbish": 113, "gene": 113, "roddenberri": 113, "ash": 113, "orbit": 113, "dull": 113, "poorli": [113, 127], "advert": 113, "trudg": 113, "trabant": 113, "lumber": 113, "spoiler": 113, "kill": 113, "actor": [113, 158], "jeeez": 113, "dalla": 113, "entertain": 113, "rental": 113, "fight": 113, "van": 113, "damm": 113, "shoot": 113, "battl": 113, "shell": [113, 201, 204, 207, 211], "shotgun": 113, "terrorist": 113, "bomb": 113, "br": 113, "inclus": 113, "rabbit": 113, "hardli": 113, "profound": 113, "stereotyp": 113, "angri": 113, "veteran": 113, "terrifi": 113, "illeg": 113, "alien": 113, "crook": 113, "cop": 113, "indiffer": 113, "bitchi": 113, "ladi": 113, "station": 113, "politician": 113, "federal": 113, "typecast": 113, "mexican": 113, "hollywood": 113, "1940": 113, "passabl": 113, "villain": 113, "knew": 113, "gui": [113, 214, 238, 245], "weren": [113, 137, 152], "desert": 113, "simplist": 113, "hamlet": 113, "annoi": [113, 144], "vd": 113, "daughter": 113, "film": 113, "semi": 113, "alright": 113, "dam": 113, "disappoint": [113, 115], "shot": [113, 160], "budget": [113, 158], "poor": 113, "orang": [113, 125, 157], "ein": 113, "mann": 113, "einem": 113, "orangen": 113, "hut": 113, "der": 113, "etwa": 113, "schaut": 113, "mit": [113, 138], "orangefarbenen": 113, "anstarrt": 113, "terrier": 113, "lush": 113, "grass": 113, "front": [113, 137, 155, 173, 174], "fenc": 113, "l\u00e4uft": 113, "auf": 113, "\u00fcppigem": 113, "gr\u00fcnem": 113, "gra": 113, "vor": 113, "wei\u00dfen": 113, "zaun": 113, "\u00fcber": 113, "saftig": 113, "gr\u00fcne": 113, "girl": 113, "karat": 113, "m\u00e4dchen": 113, "bricht": 113, "einen": 113, "st\u00f6ck": 113, "frontkick": 113, "karateanzug": 113, "brett": 113, "tritt": 113, "wear": 113, "winter": 113, "jacket": 113, "helmet": 113, "snow": 113, "snowmobil": 113, "f\u00fcnf": 113, "menschen": 113, "winterjacken": 113, "und": 113, "helmen": 113, "stehen": 113, "im": 113, "schnee": 113, "schneemobilen": 113, "hintergrund": 113, "leut": 113, "roof": 113, "hous": 113, "die": 113, "fixieren": 113, "da": 113, "dach": 113, "haus": 113, "reparieren": 113, "firstnam": 114, "lastnam": 114, "gallery_pattern": 114, "neural_style_transfer_tutori": 114, "_build": 114, "beginner_sourc": 114, "link1": 114, "link2": 114, "portalock": [115, 118], "ag_new": 115, "train_it": [115, 118], "fear": 115, "pension": 115, "union": [115, 176], "turner": 115, "newal": 115, "stricken": 115, "firm": 115, "feder": 115, "mogul": 115, "race": [115, 135, 205], "spaceflight": 115, "toronto": 115, "canada": [115, 246], "rocket": 115, "ansari": 115, "prize": 115, "contest": 115, "fund": 115, "suborbit": 115, "flight": 115, "ky": 115, "grant": 115, "studi": [115, 122, 126, 155, 173], "peptid": 115, "ap": [115, 175], "chemistri": 115, "louisvil": 115, "amino": 115, "acid": 115, "protein": 115, "revisit": [115, 185, 245], "build_vocab_from_iter": 115, "475": [115, 162], "5297": 115, "text_pipelin": 115, "label_pipelin": 115, "sport": 115, "tec": 115, "95": [115, 126, 162, 174, 175, 176], "random_split": 115, "golf": 115, "anupam": 116, "sharma": 116, "legaci": 116, "tatoeba": [116, 164], "deu": 116, "en_core_web_sm": [116, 119], "de_core_news_sm": [116, 119], "fileopen": 116, "data_pip": 116, "gettoken": 116, "min_freq": 116, "unk": [116, 118], "special_first": 116, "source_vocab": 116, "get_ito": 116, "bucketbatch": 116, "batch_num": 116, "bucket_num": 116, "sort_kei": 116, "x_3": [116, 245], "y_3": 116, "x_4": [116, 245], "y_4": 116, "cs231n": 117, "licens": [117, 136, 138, 166], "bsd": [117, 166], "tempfil": [117, 133], "temporarydirectori": 117, "ion": [117, 156, 159], "exitstack": 117, "0x7ff099c618a0": 117, "todai": [117, 156, 186, 211], "image_dataset": [117, 156], "dataset_s": [117, 156], "class_nam": [117, 138, 156, 204], "paus": [117, 159, 160], "make_grid": [117, 156, 169], "train_model": [117, 156], "tempdir": 117, "best_model_params_path": 117, "best_model_param": 117, "best_acc": [117, 156], "running_loss": [117, 156, 169], "running_correct": [117, 156], "set_grad_en": [117, 156], "epoch_loss": [117, 135, 156], "epoch_acc": [117, 156], "time_elaps": [117, 156], "visualize_model": [117, 156], "was_train": [117, 156], "images_so_far": 117, "fig": [117, 156, 169], "set_titl": [117, 156, 169], "model_ft": [117, 156], "imagenet1k_v1": [117, 138], "num_ftr": [117, 156], "in_featur": [117, 124, 156, 175, 176, 195, 226], "optimizer_ft": [117, 156], "decai": [117, 156, 159, 205], "exp_lr_schedul": [117, 156], "step_siz": [117, 123, 124, 156, 175], "gamma": [117, 123, 124, 145, 156, 159, 160, 162, 175], "f37072fd": 117, "jenkin": 117, "81m": 117, "100mb": 117, "102mb": 117, "8m": 117, "166mb": 117, "151mb": 117, "4775": 117, "7623": 117, "8954": 117, "5323": 117, "7951": 117, "6082": [117, 175], "7451": 117, "4204": [117, 175], "8115": 117, "2608": 117, "9020": 117, "6025": 117, "7664": 117, "3379": [117, 175], "8693": 117, "4247": 117, "8361": 117, "3077": 117, "4792": 117, "8033": 117, "3131": 117, "8758": 117, "3779": 117, "8402": 117, "2509": 117, "9216": [117, 124, 161], "3769": 117, "1969": 117, "9346": 117, "2320": 117, "9098": 117, "1765": 117, "2686": 117, "8811": 117, "1755": 117, "9542": 117, "3681": 117, "8648": 117, "1655": 117, "9412": 117, "3147": 117, "8607": 117, "2235": 117, "2222": 117, "9057": 117, "1724": 117, "8770": 117, "1667": 117, "2734": 117, "8852": 117, "1946": 117, "9281": 117, "2934": 117, "8730": 117, "2185": 117, "9016": 117, "1741": 117, "2487": 117, "8975": 117, "1622": 117, "2644": 117, "2031": 117, "9221": 117, "1715": 117, "2564": 117, "1782": 117, "2649": 117, "1874": 117, "3226": 117, "1823": 117, "2866": 117, "8525": 117, "1861": 117, "3106": 117, "8689": 117, "1743": 117, "5s": 117, "954248": 117, "model_conv": 117, "optimizer_conv": 117, "6996": 117, "6516": 117, "4233": 117, "2656": 117, "4603": 117, "1847": 117, "9477": 117, "3096": 117, "8566": 117, "4427": 117, "8156": 117, "1630": 117, "5505": 117, "7828": 117, "1643": 117, "3004": 117, "1744": 117, "4083": 117, "1892": 117, "4483": 117, "7910": 117, "1984": 117, "3335": [117, 201], "8279": 117, "1942": 117, "2413": 117, "8934": 117, "2001": 117, "1801": 117, "3032": 117, "1669": 117, "3587": 117, "1900": 117, "2771": 117, "8893": 117, "2317": 117, "3064": 117, "1909": 117, "4243": 117, "8238": 117, "2227": 117, "3297": 117, "1916": 117, "4235": 117, "1766": 117, "2003": 117, "1821": 117, "3762": 117, "1842": 117, "3485": [117, 175], "2166": 117, "3625": 117, "3840": 117, "8320": 117, "1768": 117, "0m": 117, "ioff": [117, 156, 159], "visualize_model_predict": 117, "img_path": [117, 175], "72100438_73de9f17af": 117, "checkout": [117, 183, 199], "paralleliz": 118, "draw": 118, "unnorm": [118, 119, 169], "inbuilt": [119, 151], "1756": 119, "issuecom": 119, "1163664163": 119, "unk_idx": 119, "club": 119, "bo": 119, "tgt": 119, "3f5ee243547dee91fbd053c1c4a845aa": 119, "pdf": 119, "sea": 119, "harvard": 119, "edu": 119, "geeta": [120, 173], "chauhan": [120, 173], "facebook": [120, 122, 135, 197, 210], "android": [120, 122, 189, 191, 215, 216, 238, 239], "2012": [120, 246], "distil": [120, 182, 209], "timm": 120, "269": [120, 146], "timber": [120, 183], "wolf": [120, 183], "grei": [120, 169, 183], "cani": [120, 183], "lupu": [120, 183], "fbdeit_script": 120, "346mb": 120, "qnnpack": [120, 157, 176, 207, 211, 216], "fbdeit_quantized_script": 120, "89mb": 120, "74": [120, 162, 181, 219], "scripted_quantized_model": 120, "fbdeit_optimized_scripted_quant": 120, "1236": 120, "69m": 120, "1226": 120, "72m": 120, "593": 120, "19m": 120, "598": 120, "01m": 120, "percentag": [120, 155, 173], "52": [120, 127, 146, 173], "n0": 120, "torigin": 120, "n1": 120, "tscript": 120, "n2": 120, "n3": 120, "n4": 120, "tlite": 120, "spread": 121, "demand": 121, "distributeddata": 121, "huggingfac": [121, 123, 124, 181], "hf": 121, "dataparallel": [121, 122, 125, 136, 148, 181, 218, 234], "plug": [121, 154, 166, 211], "tangent": [122, 140, 165], "bite": [122, 238], "resampl": 122, "waveform": [122, 224], "wav2vec2": 122, "dqn": [122, 165], "cartpol": [122, 159, 162], "openai": [122, 145, 158, 159, 160, 162], "proxim": [122, 158], "pendulum": [122, 158], "mario": [122, 151, 165], "densenet": [122, 138, 204], "121": [122, 138, 143, 225], "fuser": [122, 165, 234], "fx": [122, 143, 165, 176, 191, 192, 193, 194, 209], "nchw": [122, 146, 174, 208, 211], "raspberri": 122, "nerur": 122, "netork": 122, "exploresever": 122, "quantiti": [122, 144, 149, 152], "plugin": [122, 168, 201], "deit": 122, "constriant": 122, "orthogon": [122, 151], "symmetr": [122, 136, 151, 192, 193], "prune": [122, 151, 165, 209], "sparsifi": [122, 155], "grok": 122, "torchserv": [122, 160, 204], "torchx": 122, "inductor": [122, 165, 192], "scaled_dot_product_attent": [122, 163], "paral": 122, "fsdp": [122, 131], "segment": [122, 197, 210], "deeplabv3": [122, 197, 210], "torchrec": 122, "distributedmodelparallel": 122, "incorpor": [122, 163, 246], "sheet": 122, "hamid": [123, 124, 173, 174], "shojanazeri": [123, 124, 173, 174], "wright": 123, "rohan": [123, 161], "varma": [123, 161], "yanli": [123, 124], "zhao": [123, 124], "wikihow": 123, "p4dn": 123, "a100": [123, 125, 152, 171, 172], "pressur": 123, "fdsp": 123, "reduce_scatt": [123, 124], "xxl": 123, "3b": [123, 157], "whl": [123, 124, 136, 156, 171, 182, 183], "cu113": [123, 124], "torch_nightli": [123, 124, 136, 156, 182, 183], "wikihowal": 123, "wikihowsep": 123, "cs": 123, "summarization_dataset": 123, "t5_train": 123, "autotoken": 123, "gpt2tokenizerfast": 123, "t5token": 123, "t5forconditionalgener": 123, "modeling_t5": 123, "t5block": 123, "checkpoint_wrapp": 123, "checkpointimpl": 123, "apply_activation_checkpointing_wrapp": 123, "fullyshardeddataparallel": [123, 124, 154], "mixedprecis": 123, "backwardprefetch": [123, 124], "shardingstrategi": 123, "fullstatedictconfig": 123, "statedicttyp": 123, "transformer_auto_wrap_polici": 123, "enable_wrap": [123, 124], "tqdm": [123, 136, 158, 181], "datetim": 123, "cleanup": [123, 124, 133], "setup_model": 123, "from_pretrain": [123, 136, 181, 208], "get_date_of_run": 123, "2022": [123, 175], "12_pm": 123, "date_of_run": 123, "strftime": 123, "s_": [123, 159], "format_metrics_to_gb": 123, "gigabyt": 123, "metric_num": 123, "g_gigabyt": 123, "ndigit": 123, "train_load": [123, 124, 161, 168, 208, 209], "fsdp_loss": 123, "inner_pbar": 123, "colour": 123, "desc": [123, 136, 181], "r0": 123, "input_id": [123, 136, 181], "source_id": 123, "attention_mask": [123, 136, 181], "source_mask": 123, "target_id": 123, "train_accuraci": 123, "val_load": 123, "fsdp_main": [123, 124], "load_dataset": 123, "type_path": 123, "output_length": 123, "print_text": 123, "1500": [123, 219], "150": [123, 162], "val_dataset": 123, "sampler1": [123, 124], "num_replica": [123, 124], "sampler2": [123, 124], "train_kwarg": [123, 124], "test_kwarg": [123, 124], "test_batch_s": [123, 124], "cuda_kwarg": [123, 124], "pin_memori": [123, 124, 234], "t5_auto_wrap_polici": 123, "transformer_layer_cl": 123, "sharding_strategi": 123, "shard_grad_op": 123, "zero2": 123, "full_shard": 123, "zero3": 123, "init_start_ev": [123, 124], "enable_tim": [123, 124], "init_end_ev": [123, 124], "bf16_readi": 123, "is_bf16_support": 123, "loosevers": 123, "is_nccl_avail": 123, "mp_polici": 123, "bfsixteen": 123, "fp32": [123, 131, 136, 146, 174, 176, 181, 183, 200, 209, 222], "auto_wrap_polici": [123, 124], "mixed_precis": 123, "current_devic": [123, 218], "best_val_loss": 123, "inf": [123, 186, 188, 190], "curr_val_loss": 123, "file_save_nam": 123, "time_of_run": 123, "dur": 123, "train_acc_track": 123, "val_acc_track": 123, "training_start_tim": 123, "track_memori": 123, "mem_alloc_track": 123, "mem_reserved_track": 123, "run_valid": 123, "zone": 123, "memory_alloc": 123, "memory_reserv": 123, "save_model": [123, 124], "save_polici": 123, "offload_to_cpu": 123, "rank0_onli": 123, "state_dict_typ": 123, "full_state_dict": 123, "cpu_stat": 123, "currepoch": 123, "save_nam": 123, "barrier": [123, 124, 133, 135, 136, 173, 181], "metavar": [123, 124, 160, 162], "store_tru": [123, 124], "store_fals": 123, "nnode": [123, 133], "transfom": 123, "mhsa": 123, "ffn": 123, "fsdp_auto_wrap_polici": [123, 124], "fp16": [123, 146, 183], "bfloat16": [123, 200, 218, 234], "amper": [123, 149, 152, 218], "v100": [123, 171, 172], "slowdown": [123, 125], "percis": 123, "granular": [123, 143, 174, 181, 225, 234], "fpsixteen": 123, "param_dtyp": 123, "reduce_dtyp": 123, "buffer_dtyp": 123, "fp32_polici": 123, "grad_bf16": 123, "backward_pr": 123, "backward_prefetch": 123, "backward_post": 123, "offload": [123, 124], "allgath": [123, 124, 154, 234], "1t": [124, 131], "fsdp_mnist": 124, "size_based_auto_wrap_polici": 124, "default_auto_wrap_polici": 124, "fully_sharded_data_parallel": 124, "cpuoffload": 124, "dropout1": [124, 161], "dropout2": [124, 161], "ddp_loss": 124, "batch_idx": [124, 208, 209], "tloss": [124, 209], "6f": [124, 209], "test_load": [124, 161, 209], "view_a": [124, 161, 209], "test_loss": 124, "1307": [124, 135, 161, 209], "3081": [124, 135, 161, 209], "dataset1": 124, "dataset2": 124, "my_auto_wrap_polici": 124, "min_num_param": 124, "elapsed_tim": 124, "sec": [124, 136], "mnist_cnn": 124, "110": [124, 162, 181, 219], "85": [124, 136, 219], "67462890625sec": 124, "_fsdp_wrapped_modul": 124, "flattenparamswrapp": 124, "_fpw_modul": 124, "out_featur": [124, 176], "peak": [124, 129, 157, 241], "g4dn": 124, "xlarg": 124, "seal": 124, "met": 124, "20000": 124, "89130859375sec": 124, "auto_wrap": 124, "66": [124, 219], "cpu_offload": 124, "offload_param": 124, "ddp_mnist": 124, "77766015625sec": 124, "broadli": 125, "torchviz": [125, 130], "_save": 125, "kept": [125, 127, 246], "costli": [125, 234], "_saved_self": 125, "_saved_oth": 125, "cycl": [125, 168, 200, 219, 225], "thumb": [125, 144, 158, 218], "pack_hook": 125, "unpack_hook": 125, "harmless": 125, "debat": 125, "__repr__": [125, 219], "152": 125, "48gb": 125, "5gb": 125, "6x": [125, 174, 211], "naiv": [125, 144, 152, 163], "leak": 125, "autograd_saved_tensors_hooks_tutori": [125, 165], "david": [126, 246], "eriksson": 126, "balandat": 126, "methodolog": [126, 174, 205, 208], "runnabl": [126, 143, 237], "laptop": [126, 189], "satisfi": [126, 190, 195, 234], "sustain": 126, "trade": [126, 222], "botorch": 126, "bayesian": 126, "mnist_train_na": [126, 147, 165], "appdef": 126, "kubernet": 126, "local_cwd": 126, "fetch": [126, 128, 134, 160, 161, 162, 173, 174], "proxi": [126, 184, 187, 219], "tensorboardcurvemetr": 126, "curve_nam": 126, "lower_is_bett": 126, "multiobjectiveoptimizationconfig": 126, "constrain": [126, 151], "94": [126, 225], "generationstrategi": 126, "statu": [126, 162, 246], "scheduleropt": 126, "max_pending_tri": 126, "datafram": 126, "pareto": 126, "frontier": 126, "hover": [126, 157], "surrog": 126, "uncertainti": 126, "num_param": 126, "val_acc": 126, "contour": 126, "hidden_size_1": 126, "kiuk": 126, "tristan": [126, 157], "rice": [126, 157], "ax_multiobjective_nas_tutori": [126, 147, 165], "surnam": 127, "spell": 127, "hinton": 127, "scottish": 127, "irish": 127, "schmidhub": 127, "czech": 127, "dutch": 127, "unreason": [127, 128], "roman": [127, 246], "category_lin": [127, 128], "all_categori": 127, "n_categori": [127, 128], "n_letter": 127, "0s": [127, 181], "line_length": 127, "all_lett": 127, "linetotensor": 127, "lettertotensor": 127, "precomput": 127, "greatest": [127, 218], "print_everi": [127, 128], "histor": [127, 128], "all_loss": [127, 128], "minu": [127, 168], "tick": 127, "bright": 127, "incorrectli": 127, "chines": [127, 128], "korean": 127, "italian": 127, "greek": 127, "bottl": [127, 143], "hazaki": 127, "japanes": 127, "polish": [127, 244], "5533": 127, "yournam": 127, "gender": 127, "writer": [127, 136, 141, 157, 158, 169, 181, 232], "subreddit": 127, "char_rnn_classification_tutori": [127, 165], "russian": 128, "ru": 128, "rovakov": 128, "uantov": 128, "shavakov": 128, "ger": 128, "gerren": 128, "ereng": 128, "rosher": 128, "spa": 128, "salla": 128, "parer": 128, "allan": 128, "chi": 128, "chan": 128, "iun": 128, "o2o": 128, "muscl": 128, "fuzz": 128, "chao": 128, "consecut": [128, 145, 148, 157, 174], "abcd": 128, "randomtrainingexampl": 128, "timesinc": 128, "timestamp": [128, 142, 214], "plot_everi": 128, "output_nam": 128, "fiction": 128, "countri": 128, "citi": 128, "char_rnn_generation_tutori": [128, 165], "adjac": [129, 245], "dilat": [129, 134], "ep": [129, 141, 162, 176, 184, 193, 207], "track_running_statist": 129, "denomin": 129, "nenadmarku": [129, 141], "eventu": [129, 230], "gradcheck": [129, 130, 140, 234], "fusedconvbn": 129, "geforc": 129, "rtx": 129, "3070": 129, "56gb": 129, "unfus": [129, 141], "68gb": 129, "shallow": 129, "custom_function_conv_bn_tutori": [129, 165], "grad_out": 130, "finit": [130, 149], "differenc": 130, "magnifi": 130, "gradgradcheck": [130, 234], "grad_x": 130, "make_dot": 130, "dout": 130, "ouptut": 130, "sinh": 130, "cosh": 130, "expx": 130, "expnegx": 130, "_grad_out_exp": 130, "_grad_out_negexp": 130, "sinhbad": 130, "cube_backward": 130, "cubebackward": 130, "cube_forward": 130, "cube_backward_backward": 130, "sav_grad_out": 130, "cube_backward_backward_grad_out": 130, "cube": 130, "dgrad_out": 130, "conclud": [130, 148, 193], "reachabl": [131, 132, 135], "2xlarg": [131, 132], "hydra": 131, "slurm": [131, 132, 133], "char_dataset": 131, "gpt2_train_cfg": 131, "yaml": [131, 197, 209, 210], "snapshot": [131, 201, 210], "bucket": [131, 234], "capac": [131, 158, 159, 234], "aggress": 131, "trillion": 131, "rendezv": [132, 154], "multigpu": 132, "nccl_debug": 132, "nccl_socket_ifnam": 132, "eth0": 132, "zhu": [133, 143], "trigger": [133, 143, 160, 162, 234], "clarifi": 133, "gloo": [133, 135, 154, 168, 172, 241], "filestor": 133, "tcpstore": 133, "libtmp": 133, "some_fil": 133, "toymodel": [133, 148], "net1": 133, "net2": 133, "demo_bas": 133, "ddp_model": [133, 241], "loss_fn": [133, 134, 160, 241], "run_demo": 133, "demo_fn": 133, "loc": [133, 158, 218], "caution": 133, "timeout": [133, 154], "straggler": [133, 168], "delai": [133, 160, 173], "spike": [133, 157], "AND": [133, 239], "torchelast": 133, "demo_checkpoint": 133, "checkpoint_path": 133, "gettempdir": 133, "toympmodel": 133, "dev0": 133, "dev1": 133, "output_devic": 133, "demo_model_parallel": 133, "mp_model": 133, "ddp_mp_model": 133, "n_gpu": [133, 136, 181], "elastic_ddp": 133, "rdzv_id": 133, "rdzv_backend": 133, "rdzv_endpoint": 133, "29400": 133, "aka": [133, 144, 146, 156, 208, 211], "scontrol": 133, "hostnam": 133, "slurm_nodelist": 133, "srun": 133, "torchrun_script": 133, "rpc_sync": [134, 160, 161, 162, 203], "embeddingt": [134, 162, 172], "amort": [134, 158, 160, 234], "resnetbas": 134, "conv1x1": 134, "inplan": 134, "width_per_group": 134, "norm_lay": 134, "_lock": 134, "_block": 134, "_norm_lay": 134, "base_width": 134, "_make_lay": 134, "plane": 134, "previous_dil": 134, "parameter_rref": [134, 162, 203], "caller": [134, 161, 203], "calle": [134, 160, 161, 203], "resnetshard1": 134, "seq": 134, "constant_": 134, "x_rref": 134, "to_her": 134, "resnetshard2": 134, "distresnet50": 134, "micro": [134, 173, 174], "y_rref": 134, "num_split": 134, "p1_rref": 134, "p2_rref": 134, "xs": 134, "out_futur": 134, "z_fut": 134, "wait_al": [134, 160], "remote_param": [134, 161, 162], "worker1": [134, 203], "worker2": 134, "dist_autograd": [134, 161, 162], "context_id": [134, 161, 162], "image_w": [134, 160], "image_h": [134, 160], "run_mast": 134, "one_hot_indic": [134, 160], "random_": [134, 160], "passiv": [134, 160, 162], "init_rpc": [134, 160, 161, 162, 203], "shutdown": [134, 160, 161, 162, 203], "tensorpiperpcbackendopt": [134, 203], "num_worker_thread": [134, 203], "rpc_backend_opt": [134, 203], "tik": [134, 160, 203], "tok": [134, 160, 203], "s\u00e9b": 135, "arnold": 135, "sysadmin": 135, "coordin": [135, 166, 175, 187], "pdsh": 135, "clustershel": 135, "init_process": 135, "127": [135, 176, 193], "set_start_method": 135, "ip": 135, "recv": [135, 162], "irecv": 135, "dst": 135, "req": 135, "undefin": [135, 148, 184, 185, 186], "behaviour": 135, "fanci": 135, "baidu": 135, "deepspeech": 135, "communc": 135, "new_group": 135, "commut": 135, "scatter_list": 135, "gather_list": 135, "tnt": 135, "splitdataset": 135, "data_idx": 135, "datapartition": 135, "1234": 135, "data_len": 135, "part_len": 135, "partition_dataset": 135, "get_world_s": 135, "bsz": 135, "partition_s": 135, "train_set": [135, 168], "30000": 135, "ceil": 135, "average_gradi": 135, "voil\u00e0": 135, "send_buff": 135, "recv_buff": 135, "accum": 135, "send_req": 135, "bandwidth": [135, 168, 191], "subsect": [135, 245], "eleg": 135, "smi": [135, 218], "mvapich2": 135, "ipc": 135, "recompil": [135, 141, 171], "requisit": 135, "forg": [135, 209], "openmpi": 135, "mpirun": 135, "myscript": 135, "handshak": 135, "superflu": 135, "everybodi": 135, "readili": 135, "fcntl": 135, "nf": 135, "sharedfil": 135, "23456": 135, "socket": [135, 143, 173, 174, 234], "everyon": [135, 232], "unclear": [135, 148], "natalia": 135, "gimelshein": 135, "draft": 135, "jianyu": 136, "huang": [136, 154], "jessica": [136, 156], "paraphras": 136, "mrpc": [136, 181], "dolan": 136, "brockett": 136, "2005": 136, "imbalanc": 136, "f1": [136, 171, 181], "sklearn": 136, "tochvis": 136, "cu101": [136, 156], "bertconfig": [136, 181], "bertforsequenceclassif": [136, 181], "glue_compute_metr": [136, 181], "compute_metr": [136, 181], "glue_output_mod": [136, 181], "output_mod": [136, 181], "glue_processor": [136, 181], "processor": [136, 173, 181, 200, 208, 234], "glue_convert_examples_to_featur": [136, 181], "convert_examples_to_featur": [136, 181], "logger": [136, 181, 190], "getlogg": [136, 181], "basicconfig": [136, 181], "asctim": [136, 181], "levelnam": [136, 181], "datefmt": [136, 181], "modeling_util": [136, 181], "setlevel": [136, 181], "set_num_thread": [136, 157, 181], "__config__": [136, 181], "parallel_info": [136, 181], "sep": 136, "glue_data": [136, 181], "download_glue_data": [136, 181], "uncas": [136, 174, 181], "glue_dir": [136, 181], "task_nam": [136, 181], "out_dir": [136, 181], "run_glu": 136, "model_typ": [136, 181], "model_name_or_path": [136, 181], "do_train": 136, "do_ev": 136, "do_lower_cas": [136, 181], "max_seq_length": [136, 181], "per_gpu_eval_batch_s": [136, 181], "per_gpu_train_batch_s": 136, "num_train_epoch": 136, "save_step": 136, "output_dir": [136, 181], "label_list": [136, 181], "get_label": [136, 181], "overwrite_cach": [136, 181], "set_se": [136, 181], "copyright": [136, 246], "inc": 136, "corpor": 136, "apach": [136, 173, 174], "complianc": 136, "law": [136, 188], "AS": 136, "IS": 136, "warranti": 136, "OR": [136, 232], "OF": 136, "govern": [136, 160], "permiss": 136, "mnli": [136, 181], "mi": [136, 181, 248], "eval_task_nam": [136, 181], "eval_outputs_dir": [136, 181], "eval_task": [136, 181], "eval_output_dir": [136, 181], "eval_dataset": [136, 181], "load_and_cache_exampl": [136, 181], "makedir": [136, 181], "eval_sampl": [136, 181], "eval_dataload": [136, 181, 209], "eval_loss": 136, "nb_eval_step": [136, 181], "out_label_id": [136, 181], "distilbert": [136, 181], "token_type_id": [136, 181], "xlnet": [136, 181], "roberta": [136, 181], "segment_id": [136, 181], "tmp_eval_loss": 136, "output_eval_fil": [136, 181], "eval_result": [136, 181], "cached_features_fil": [136, 181], "cached_": [136, 181], "get_dev_exampl": [136, 181], "get_train_exampl": [136, 181], "pad_on_left": 136, "convert_tokens_to_id": 136, "pad_token_segment_id": 136, "all_input_id": [136, 181], "all_attention_mask": [136, 181], "all_token_type_id": [136, 181], "all_label": [136, 181], "qint8": [136, 176, 216], "438": [136, 181], "181": [136, 219], "30522": 136, "time_model_evalu": [136, 181], "eval_start_tim": [136, 181], "eval_end_tim": [136, 181], "eval_duration_tim": [136, 181], "1f": [136, 169, 181], "408": [136, 174], "prec": [136, 146], "9019": 136, "902": [136, 181], "8788": 136, "8956": 136, "asymmetr": [136, 193], "openmp": [136, 173, 200, 214], "tbb": 136, "ids_tensor": [136, 181], "dummy_input": [136, 181, 212, 213, 239, 240], "traced_model": [136, 141, 181], "bert_traced_eager_qu": 136, "loaded_quantized_model": [136, 179, 192], "implic": [136, 181], "devlin": 136, "lee": 136, "toutanova": 136, "zafrir": 136, "boudoukh": 136, "izsak": 136, "wasserblat": 136, "2019": 136, "q8bert": 136, "8bit": 136, "tradition": [137, 195], "pretend": [137, 152], "stack_module_st": 137, "functional_cal": [137, 149, 152], "num_model": 137, "in_dim": [137, 152, 198], "avinash": 138, "sajjanshetti": 138, "refresh": [138, 169], "endpoint": [138, 204], "class_id": [138, 204], "n02124075": 138, "egyptian_cat": [138, 204], "flask_env": 138, "flask_app": [138, 204], "_static": 138, "y_hat": [138, 204], "imagenet_class_index": 138, "get_predict": [138, 204], "unnecessarili": 138, "redundantli": 138, "img_byt": 138, "image_byt": 138, "jsonifi": [138, 204], "TO": [138, 239], "densenet121": [138, 146, 204], "transform_imag": [138, 204], "my_transform": [138, 204], "bytesio": 138, "predicted_idx": 138, "resp": 138, "ui": [138, 157, 232, 238, 244], "streamer": 138, "queue": [138, 234], "flask_rest_api_tutori": [138, 165], "forced_alignment_tutori": 139, "incomplet": 140, "eagerli": 140, "primal": [140, 245], "dual": [140, 245], "dual_level": 140, "fresh": [140, 218], "mandatori": [140, 158], "check_forward_ad": 140, "check_backward_ad": 140, "check_undefined_grad": 140, "check_batched_grad": 140, "functorch": 140, "downsid": 140, "reformul": [140, 149], "ft": 140, "make_functional_with_buff": 140, "analog": [140, 186, 187], "consolid": [140, 160], "wikipedia": 140, "dual_numb": 140, "forward_ad_usag": [140, 165], "horac": 141, "fold": [141, 174, 179, 192, 239, 246], "orig": 141, "wrappedbatchnorm": 141, "mod": [141, 189, 196], "bn1": [141, 156], "symbolic_trac": [141, 142], "fuse_conv_bn_ev": 141, "batch_norm": [141, 225], "fused_conv": 141, "fuse_conv_bn_weight": 141, "running_var": 141, "conv_w": 141, "conv_b": 141, "bn_rm": 141, "bn_rv": 141, "bn_ep": 141, "bn_w": 141, "bn_b": 141, "bn_var_rsqrt": 141, "rsqrt": 141, "_parent_nam": 141, "qualnam": 141, "atom": 141, "baz": 141, "rsplit": 141, "replace_node_modul": 141, "new_modul": 141, "parent_nam": 141, "setattr": 141, "graphmodul": [141, 142, 176], "fx_model": 141, "named_modul": 141, "call_modul": 141, "replace_all_uses_with": 141, "erase_nod": 141, "lint": 141, "simplif": [141, 222], "fused_model": 141, "assert_allclos": 141, "rn18": 141, "fused_rn18": 141, "jit_rn18": 141, "conclus": 141, "tracker": [141, 142], "fx_conv_bn_fus": [141, 165], "longest": 142, "nicer": 142, "tabul": [142, 171], "ca": 142, "profilinginterpret": 142, "clock": [142, 219], "51393": 142, "fx_profiling_tutori": [142, 165], "xuan": 143, "liao": 143, "haozh": 143, "jiong": [143, 173, 174, 193], "gong": [143, 173, 174, 193], "weihan": 143, "intricaci": 143, "troubleshoot": 143, "pinpoint": [143, 174], "torch_compile_debug": 143, "xx": 143, "dump": [143, 183, 200, 210], "_inductor": 143, "model___20": 143, "torchinductor_root": 143, "rx": 143, "crxfi2ybd7yp5sbj2pnhw33wfhtdw7wumvrobyp5sjvdui5ktjc2": 143, "fx_graph_runn": 143, "fx_graph_transform": 143, "ir_post_fus": 143, "ir_pre_fus": 143, "output_cod": 143, "triton": [143, 171], "gv": 143, "cgv6n5aotqjo5w4vknjibhengeycuattfto532hkxpozszcgxr3x": 143, "dynamo": [143, 192], "aot_eag": 143, "aot": 143, "tmp2": 143, "tmp1": 143, "_dynamo": [143, 171, 192], "exc": 143, "backendcompilerfail": 143, "cppcompileerror": 143, "xg": 143, "cxga5tk3b4lkwoxyigrtocjp5s7vc5cg2ikuscf6bk6pjqip2bhx": 143, "max_propagate_nan": 143, "tmp3": 143, "tmp0": 143, "deduct": 143, "substitut": [143, 144, 193, 245], "deduc": 143, "in_ptr0": 143, "in_ptr1": 143, "out_ptr0": 143, "pragma": 143, "ivdep": 143, "i0": 143, "static_cast": 143, "0l": 143, "8390l": 143, "1l": 143, "i1": 143, "8l": 143, "buf0": 143, "schedulernod": 143, "computedbuff": 143, "memorydep": 143, "c0": 143, "67120": 143, "unmet_depend": 143, "met_depend": 143, "arg0_1": 143, "8390": 143, "arg1_1": 143, "nodeus": 143, "can_inplac": 143, "buf0_loop_bodi": 143, "var_rang": 143, "z0": 143, "index0": 143, "index1": 143, "get_index": 143, "get_index_1": 143, "load_1": 143, "get_index_2": 143, "silent": [143, 171], "minifi": 143, "delta": [143, 159, 219, 233], "dead": 143, "unus": [143, 154], "minif": 143, "allclos": [143, 198], "tol": 143, "test_script": 143, "expected_result": 143, "actual_result": 143, "assertionerror": 143, "torchdynamo_repro_aft": 143, "torchdynamo_repro_level": 143, "mobilebertforquestionansw": 143, "xeon": [143, 146, 173, 200, 208], "platinum": [143, 173], "8358": 143, "60ghz": 143, "kmp_blocktim": [143, 234], "kmp_set": 143, "kmp_affin": [143, 234], "compact": [143, 202, 234], "ld_preload": [143, 234], "conda_prefix": [143, 219], "dirnam": [143, 154, 214], "libiomp5": [143, 234], "libjemalloc": 143, "malloc_conf": 143, "oversize_threshold": 143, "background_thread": 143, "metadata_thp": 143, "dirty_decay_m": 143, "muzzy_decay_m": 143, "numactl": [143, 234], "bench": [143, 173, 174], "eager_t": 143, "num_it": 143, "inductor_t": 143, "1023553796113": 143, "339": 143, "95180135127157": 143, "359459053287382": 143, "355x": 143, "enable_kernel_profil": 143, "370": 143, "814m": 143, "362": 143, "161": [143, 207], "276m": 143, "363": 143, "416m": 143, "488": [143, 175, 219], "154m": 143, "194": 143, "clamp_min": 143, "444m": 143, "bmm": [143, 188, 200, 219], "258m": 143, "profilerstep": 143, "810": 143, "920m": 143, "447m": 143, "_softmax": 143, "087m": 143, "376": [143, 182], "888m": 143, "77": 143, "430m": 143, "502m": 143, "161m": 143, "850": 143, "377m": 143, "386": [143, 162], "index_select": 143, "986": 143, "420m": 143, "703": 143, "656": [143, 241], "963": 143, "864m": 143, "_mkl_linear": 143, "231": [143, 219, 225], "573m": [143, 225], "992m": 143, "336": [143, 225], "642m": 143, "graph_0_cpp_fused_constant_pad_nd_embedding_0": 143, "915": 143, "911": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_151": 143, "901": [143, 181], "graph_0_cpp_fused__mkl_linear_add_mul_relu_226": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_361": 143, "898": [143, 240], "graph_0_cpp_fused__mkl_linear_add_mul_relu_121": 143, "895": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_31": 143, "893": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_76": 143, "892": [143, 157, 219, 240], "graph_0_cpp_fused__mkl_linear_add_mul_relu_256": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_346": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_241": 143, "891": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_316": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_91": 143, "890": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_106": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_211": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_61": 143, "889": 143, "graph_0_cpp_fused__mkl_linear_add_mul_relu_286": 143, "graph_0_cpp_fused_": 143, "63x": 143, "cblas_sgemm_comput": 143, "339m": 143, "94x": 143, "cpp_fused__mkl_linear_add_mul_relu_151": 143, "clrlgu27q4ggd472umdzwsu6qcpqxcuusjxqvx2hwitjbujiiz7z": 143, "neck": 143, "780875144992024": 143, "9588955780491233": 143, "0286805751604735": 143, "smallest": [143, 155], "solid": 143, "analyt": [143, 243], "hotspot": [143, 173, 174], "phenomenon": 143, "inductor_debug_cpu": [143, 165], "jax": [144, 149, 198], "argnum": 144, "microsecond": [144, 163, 207, 211, 219], "millisecond": [144, 154, 182, 211, 234], "get_perf": 144, "rigor": [144, 222], "taller": 144, "wider": 144, "hessiani": 144, "overwhelm": 144, "jacobians_hessian": [144, 165], "yuansong": 145, "feng": [145, 154], "steven": 145, "guo": 145, "cheatsheet": 145, "companion": 145, "bro": 145, "ne": [145, 164, 225], "tube": 145, "mushroom": 145, "next_stat": [145, 159], "240": [145, 162, 225], "pipe": 145, "sky": 145, "grayscaleobserv": 145, "resizeobserv": 145, "skipfram": 145, "framestack": 145, "movement": 145, "exploration_r": 145, "marionet": 145, "ddqn": 145, "theta_": 145, "_e": 145, "argmax_": 145, "_t": 145, "td_target": 145, "td_t": 145, "td_e": 145, "leftarrow": 145, "nabla": [145, 245], "episod": [145, 159, 160, 162], "mario_rl_tutori": [145, 165], "vitali": 146, "fedyunin": 146, "densest": 146, "4x4": 146, "10x3x16x16": 146, "minor": [146, 156, 162, 169, 208, 209], "ambigu": [146, 185, 186], "n1hw": 146, "contrari": [146, 155], "restrid": 146, "unintend": 146, "domin": [146, 196, 222], "apex": 146, "main_amp": 146, "resnet50": [146, 148, 157, 160, 173, 174, 208, 234], "o2": 146, "opt_level": 146, "keep_batchnorm_fp32": 146, "nonetyp": 146, "loss_scal": 146, "7603": 146, "cast_model_typ": 146, "patch_torch_funct": 146, "master_weight": 146, "125": [146, 225], "230": [146, 162], "949": 146, "6735125184": 146, "6735": 146, "259": 146, "562": 146, "773": 146, "481": 146, "355": 146, "693": 146, "6968704462": 146, "6852": 146, "55": [146, 173, 197, 219], "258": [146, 245], "461": 146, "775": 146, "089": 146, "433": 146, "965": 146, "7877287269": 146, "7194": 146, "833": 146, "771": 146, "710": 146, "487": 146, "8285319805": 146, "7467": 146, "54": [146, 148, 174, 219], "260": [146, 162], "380": 146, "770": 146, "090": 146, "525": 146, "908": 146, "7370464802": 146, "7447": 146, "360": 146, "623": 146, "555": 146, "728": 146, "7592862844": 146, "7472": 146, "53": [146, 225, 246], "917": 146, "345": [146, 175], "774": 146, "746": [146, 219], "115": [146, 181], "9698858261": 146, "9218": 146, "286": 146, "324": [146, 175], "597": 146, "659": 146, "2505953312": 146, "0879": 146, "767": [146, 211], "785": 146, "7579724789": 146, "7580": 146, "198": 146, "482": 146, "135": [146, 157, 219], "414": 146, "716": [146, 219], "7007197738": 146, "7293": 146, "250": [146, 162, 225], "387": 146, "1010": 146, "516": [146, 159, 165], "7113101482": 146, "7233": 146, "667": 146, "197": 146, "340": 146, "1013": 146, "023": 146, "588": 146, "333": 146, "8943189979": 146, "7661": 146, "541": 146, "7113249302": 146, "9551": 146, "1011": 146, "163": 146, "683": 146, "574": 146, "8537774086": 146, "7716": 146, "279": 146, "453": 146, "7595844269": 146, "3413": 146, "429": 146, "827": 146, "743": 146, "883": 146, "8196096420": 146, "4011": 146, "volta": [146, 218, 234], "mnasnet0_5": 146, "mnasnet0_75": 146, "mnasnet1_0": 146, "mnasnet1_3": 146, "mobilenet_v2": [146, 157, 175, 182, 183, 189, 199, 211, 212, 213, 216], "resnet152": 146, "resnet34": 146, "resnext50_32x4d": 146, "shufflenet_v2_x0_5": [146, 157], "shufflenet_v2_x1_0": [146, 157], "shufflenet_v2_x1_5": [146, 157], "shufflenet_v2_x2_0": [146, 157], "squeezenet1_0": 146, "squeezenet1_1": 146, "vgg11": 146, "vgg11_bn": 146, "vgg13": 146, "vgg13_bn": 146, "vgg16": 146, "vgg16_bn": 146, "vgg19_bn": 146, "wide_resnet101_2": 146, "wide_resnet50_2": 146, "ic": 146, "lake": [146, 208], "newer": [146, 152, 234], "densenet161": 146, "densenet169": 146, "googlenet": [146, 157, 216], "inception_v3": [146, 157], "resnext101_32x8d": [146, 157], "spite": 146, "nc11": 146, "memory_format_tutori": [146, 165], "stitch": [148, 160, 161], "deterior": 148, "layer3": [148, 156, 159], "quantit": 148, "modelparallelresnet50": 148, "timeit": [148, 211, 222, 233], "idl": [148, 160, 168, 225], "destin": [148, 162, 203], "split_siz": 148, "prev": 148, "model_parallel_tutori": [148, 165], "j_": 149, "diagon": 149, "asymptot": 149, "i_o": 149, "i_": 149, "e_o": 149, "textrm": 149, "_o": 149, "tensorfloat": 149, "sacrific": [149, 189], "empirical_ntk_ntk_vp": 149, "luck": 149, "neural_tangent_kernel": [149, 165], "deprec": [150, 177, 206], "homepag": [150, 177], "lezcano": 151, "surprisingli": 151, "ill": 151, "frobeniu": 151, "spectral": 151, "lipschitz": 151, "x\u1d40": 151, "upper": [151, 225, 246], "triangular": 151, "reimplement": [151, 155], "skew": [151, 168, 225], "unparametr": 151, "linearsymmetr": 151, "moduledict": 151, "parametrizationlist": 151, "caylei": 151, "spd": 151, "right_invers": 151, "upgrad": [151, 157, 168, 191, 232], "strongli": [151, 245], "remove_parametr": 151, "parametri": 151, "leave_parametr": 151, "privaci": [152, 155], "sample_grad": 152, "compute_loss": 152, "ft_compute_grad": 152, "0th": [152, 155, 188], "25x": 152, "opacu": 152, "per_sample_grad": [152, 165], "pipeline_tutori": [153, 165], "tian": 154, "si": 154, "processgroupnccl": 154, "processgroupgloo": 154, "processgroupmpi": 154, "ucc": 154, "oneccl": [154, 234], "trainum": 154, "emerg": 154, "backenddummi": 154, "chrono": 154, "allgatheropt": 154, "allreduceopt": 154, "workdummi": 154, "optyp": 154, "recvanysourc": 154, "irrelev": 154, "future_": 154, "iscomplet": 154, "issuccess": 154, "kunsettimeout": 154, "getfutur": 154, "outputtensorvec": 154, "listtyp": 154, "tensortyp": 154, "markcomplet": 154, "createbackenddummi": 154, "backenddummyconstructor": 154, "__attribute__": 154, "register_backend": 154, "cpp_function": [154, 219], "libraries_dir": 154, "abspath": 154, "dummy_collect": 154, "michela": 155, "paganini": 155, "biolog": 155, "batteri": 155, "lightweight": [155, 204, 218, 238], "subnetwork": 155, "lotteri": 155, "ticket": 155, "destruct": [155, 174], "0a0": [155, 183, 199], "8e8a5e0": 155, "lecun": 155, "1998": 155, "unprun": 155, "basepruningmethod": 155, "adequ": [155, 158], "weight_orig": 155, "_orig": 155, "intact": [155, 160], "weight_mask": 155, "_mask": 155, "forward_pre_hook": 155, "l1_unstructur": 155, "bias_orig": 155, "bias_mask": 155, "pruningcontain": 155, "compute_mask": 155, "ln_structur": 155, "perman": 155, "undo": 155, "reassign": 155, "global_unstructur": 155, "induc": 155, "apply_mask": 155, "unstructur": 155, "preprun": 155, "pruning_typ": 155, "pruning_tutori": [155, 165], "zafar": 156, "takhirov": 156, "initializaion": 156, "unfreez": 156, "figsiz": [156, 169], "set_xtick": 156, "set_ytick": 156, "nrow": 156, "best_model_wt": 156, "current_row": 156, "current_col": 156, "lbl": 156, "jdx": 156, "model_f": 156, "isol": 156, "create_combined_model": 156, "model_fe_featur": 156, "layer4": 156, "avgpool": 156, "new_head": 156, "new_model": 156, "tight_layout": 156, "default_qat_qconfig": 156, "model_ft_tun": 156, "model_quantized_and_train": 156, "4gb": [157, 211], "2gb": 157, "accessori": 157, "sink": [157, 245], "5v": 157, "usb": 157, "sd": 157, "card": [157, 163], "8gb": 157, "arm": [157, 216], "64bit": 157, "aarch64": 157, "arm64": [157, 183, 197, 199, 207, 211], "raspberrypi": 157, "raspios_arm64": 157, "rpi": 157, "sdcard": 157, "start_x": 157, "128m": 157, "gpu_mem": 157, "commment": 157, "camera_auto_detect": 157, "v4l2": 157, "reboot": 157, "video4linux2": 157, "video0": 157, "picamera": 157, "36fp": 157, "30fp": 157, "framer": 157, "cv2": 157, "cap": [157, 158], "videocaptur": 157, "cap_prop_frame_width": 157, "cap_prop_frame_height": 157, "cap_prop_fp": 157, "bgr": 157, "mobilenet_v3_larg": 157, "109": 157, "233": [157, 162], "885": 157, "204": [157, 219], "195": [157, 162], "132": 157, "59": [157, 159, 165, 175, 219, 225], "82": 157, "prequant": 157, "20fp": 157, "cap_v4l2": 157, "last_log": 157, "frame_count": 157, "htop": [157, 173], "mug": 157, "allevi": 157, "farama": 158, "gymnasium": [158, 159], "repetit": [158, 219], "mujoco": 158, "maximis": 158, "clipppoloss": 158, "theta_k": 158, "pi_": 158, "exceed": 158, "shift": [158, 245], "lingua": 158, "franca": 158, "errat": 158, "hamper": 158, "reactiv": 158, "xy": 158, "sub_batch_s": 158, "deepmind": [158, 166], "interchang": 158, "panel": [158, 168], "transmit": [158, 245], "env_nam": 158, "gymwrapp": 158, "loos": 158, "supplementari": 158, "stringent": 158, "observation_spec": 158, "reward_spec": 158, "input_spec": 158, "action_spec": 158, "check_env_spec": 158, "n_step": [158, 160, 162], "mu_": 158, "brought": 158, "d_ob": 158, "d_action": 158, "mu": [158, 245], "normalparamextractor": 158, "carrier": 158, "probabilisticactor": 158, "tanhnorm": 158, "discount": [158, 159, 160], "datacollector": 158, "multisyncdatacollector": 158, "refil": [158, 211], "replaybuff": 158, "gae": 158, "value_target": 158, "videorecord": 158, "reinforcement_ppo": [158, 165], "tower": 159, "cart": 159, "pole": 159, "upright": 159, "consequ": 159, "veloc": 159, "classic_control": 159, "namedtupl": 159, "dequ": 159, "itertool": [159, 162, 193], "is_ipython": 159, "get_backend": 159, "decorrel": 159, "replaymemori": 159, "cyclic": 159, "maxlen": 159, "formul": 159, "cumul": [159, 172], "r_": 159, "t_0": 159, "r_t": 159, "uncertain": 159, "tempor": 159, "max_a": 159, "obei": 159, "bellman": 159, "huber": 159, "outlier": 159, "noisi": [159, 219, 233], "mathcal": 159, "le": [159, 164], "mathrm": 159, "n_observ": 159, "n_action": 159, "left0exp": 159, "right0exp": 159, "select_act": [159, 160, 162], "eps_start": 159, "eps_end": 159, "eps_decai": 159, "plot_dur": 159, "underneath": 159, "tau": 159, "005": [159, 175], "action_spac": 159, "policy_net": 159, "target_net": 159, "amsgrad": 159, "steps_don": 159, "eps_threshold": 159, "episode_dur": 159, "show_result": 159, "durations_t": 159, "clf": 159, "xlabel": 159, "ylabel": 159, "unfold": [159, 164], "gcf": 159, "clear_output": 159, "optimize_model": 159, "s_t": 159, "a_t": 159, "soft": 159, "19343": 159, "3343043": 159, "non_final_mask": 159, "non_final_next_st": 159, "state_batch": 159, "action_batch": 159, "reward_batch": 159, "next_state_valu": 159, "expected_state_action_valu": 159, "clip_grad_value_": 159, "num_episod": [159, 160], "insuffici": [159, 173], "i_episod": [159, 160, 162], "\u03b8": 159, "\u03c4": 159, "target_net_state_dict": 159, "policy_net_state_dict": 159, "reinforcement_q_learn": [159, 165], "unblock": 160, "callback": 160, "update_and_fetch_model": 160, "future_model": 160, "notifi": 160, "batch_update_s": 160, "batchupdateparameterserv": 160, "curr_update_s": 160, "ps_rref": 160, "local_valu": [160, 161], "setti": 160, "set_result": 160, "get_worker_info": [160, 162], "543": 160, "affine1": [160, 162], "affine2": [160, 162], "action_scor": [160, 162], "select_action_batch": 160, "run_episod": [160, 162], "agent_rref": [160, 162], "ep_reward": [160, 162], "num_step": 160, "start_step": 160, "curr_reward": 160, "prob": [160, 162, 169], "saved_log_prob": [160, 162], "rob": 160, "ob_rref": [160, 162], "running_reward": [160, 162], "ob_rank": [160, 162], "ob_info": [160, 162], "observer_nam": [160, 162], "future_act": 160, "pending_st": 160, "select_acion": 160, "ob_id": [160, 162], "log_prob": [160, 162], "oberv": [160, 162], "policy_loss": [160, 162], "n_episod": 160, "print_log": 160, "rank0": [160, 162], "agent_nam": [160, 162], "last_reward": [160, 162], "tlast": [160, 162], "taverag": [160, 162], "occasion": [161, 164], "num_gpu": 161, "next_devic": 161, "call_method": 161, "remote_method": 161, "foo_inst": 161, "parameterserv": 161, "input_devic": 161, "intention": [161, 162, 203], "miscellan": 161, "verif": 161, "get_dist_gradi": 161, "get_gradi": 161, "get_param_rref": 161, "cid": 161, "cpu_grad": 161, "k_cpu": 161, "v_cpu": 161, "paramt": 161, "param_rref": [161, 162], "run_parameter_serv": 161, "param_serv": 161, "global_lock": 161, "get_parameter_serv": 161, "parameter_serv": 161, "shut": 161, "offlin": 161, "trainernet": 161, "param_server_rref": 161, "get_global_param_rref": 161, "paramat": 161, "model_output": 161, "run_training_loop": 161, "nueral": 161, "get_accuraci": 161, "correct_sum": 161, "trainer_": 161, "traffic": [161, 173], "listen": [161, 204], "subprocess": [161, 219, 234], "rpc_parameter_serv": 161, "solver": 162, "formatter_class": 162, "argumentdefaultshelpformatt": 162, "log_interv": 162, "report_reward": 162, "_max_episode_step": 162, "finfo": 162, "reward_threshold": 162, "finish_episod": 162, "min_reward": 162, "distinguish": [162, 169], "surpass": 162, "ob": [162, 193], "ctrl": 162, "111": [162, 173, 181, 219, 240], "131": 162, "130": 162, "137": 162, "140": 162, "104": 162, "170": [162, 175], "126": 162, "180": [162, 219], "213": 162, "322": 162, "165": 162, "272": 162, "210": 162, "168": 162, "184": [162, 181], "208": [162, 217], "247": 162, "270": [162, 175], "405": 162, "290": 162, "464": [162, 175], "3163778435275": 162, "rnnmodel": 162, "ntoken": 162, "ninp": 162, "nhid": 162, "emb_table_rref": 162, "decoder_rref": 162, "_remote_method": 162, "rremot": 162, "_parameter_rref": 162, "run_train": 162, "nindic": 162, "driss": 163, "guessou": 163, "flashattent": 163, "hyper": 163, "mapper": 163, "flash": 163, "andrej": 163, "karpathi": 163, "nanogpt": 163, "causalselfattent": 163, "mine": [163, 245], "166": 163, "616": 163, "726": 163, "amaz": 163, "compiled_causal_attention_trac": 163, "reveal": [163, 171, 217, 219], "concentr": 163, "causaulselfattent": 163, "6090": 163, "49m": 163, "3273": 163, "17m": 163, "commit": [163, 191, 200], "ae3a8d5": 163, "sdp_kernel": 163, "scaled_dot_product_attention_tutori": [163, 165], "french": 164, "il": 164, "est": [164, 168, 248], "peindr": 164, "tableau": 164, "paint": 164, "pourquoi": 164, "pa": 164, "essay": 164, "ce": 164, "vin": 164, "delicieux": 164, "delici": 164, "wine": 164, "poet": 164, "romancier": 164, "novelist": 164, "vou": 164, "trop": 164, "maigr": 164, "skinni": 164, "condens": [164, 202, 233], "phrase": [164, 245], "eng": [164, 189], "manyth": 164, "anki": 164, "fra": 164, "froid": 164, "dozen": 164, "lang": [164, 201, 244], "word2index": 164, "word2count": 164, "apostroph": 164, "je": 164, "sui": 164, "noir": 164, "attn_appli": 164, "exhibit": [164, 234], "coher": 164, "grammar": 164, "wander": 164, "plot_loss": 164, "judgement": 164, "matshow": 164, "iot": 164, "word2vec": 164, "glove": 164, "autoencod": 164, "seq2seq_translation_tutori": [164, 165], "531": 165, "torch_compile_tutori": [165, 171], "sdpa": 165, "spatial_transformer_tutori": [165, 166], "sphx_glr_intermediate_mnist_train_na": 165, "tensorboard_profiler_tutori": [165, 168], "ghassen": 166, "hamrouni": 166, "geometr": 166, "invari": [166, 185], "boil": 166, "affine_grid": 166, "grid_sampl": 166, "speech_recognition_pipeline_tutori": 167, "warmup": [168, 189, 196, 211, 225], "on_trace_readi": [168, 225], "tensorboard_trace_handl": 168, "record_shap": [168, 225], "profile_memori": [168, 225], "torch_tb_profil": 168, "pytorch_profil": 168, "breakdown": 168, "dropdown": 168, "callstack": 168, "multiprocessor": 168, "occup": 168, "tooltip": 168, "toolbar": 168, "keyboard": [168, 245], "mous": [168, 245], "resnet18_4work": 168, "76m": [168, 179], "132m": 168, "torchtbprofil": 168, "memory_demo_1_10": 168, "gpu0": 168, "drag": [168, 169, 212, 213], "children": [168, 225], "distributed_bert": 168, "testset": 169, "testload": 169, "plot_classes_pr": 169, "matplotlib_imshow": 169, "one_channel": 169, "npimg": 169, "fashion_mnist_experiment_1": 169, "datait": 169, "img_grid": 169, "four_fashion_mnist_imag": 169, "select_n_random": 169, "datapoint": 169, "perm": 169, "randperm": [169, 175], "class_label": 169, "lab": 169, "label_img": 169, "thoroughli": 169, "images_to_prob": 169, "preds_tensor": 169, "el": 169, "arang": 169, "add_subplot": 169, "xtick": 169, "ytick": 169, "add_scalar": [169, 232], "add_figur": 169, "global_step": [169, 232], "scroll": [169, 243, 247], "3000": 169, "test_siz": 169, "class_prob": 169, "class_probs_batch": 169, "test_prob": 169, "test_label": 169, "add_pr_curve_tensorboard": 169, "class_index": 169, "tensorboard_truth": 169, "tensorboard_prob": 169, "add_pr_curv": 169, "poke": 169, "tacotron2_pipeline_tutori": 170, "william": 171, "wen": 171, "h100": 171, "elsewher": 171, "torchinductor": 171, "torchtriton": 171, "cu117": [171, 245], "struggl": 171, "fn1": 171, "fn2": 171, "f2": 171, "disallow": 171, "bytecod": [171, 210], "unoptim": 171, "resum": [171, 228, 230, 238], "fullgraph": 171, "dlrm": [172, 234], "dmp": 172, "datastructur": 172, "k80": 172, "appripri": 172, "product_t": 172, "user_t": 172, "101": 172, "202": 172, "303": [172, 175], "product_eb": 172, "jag": [172, 188], "404": 172, "505": 172, "606": [172, 175], "keyedtensor": 172, "3x64": 172, "pooled_embed": 172, "criteo": 172, "terabyt": 172, "jean": [173, 174], "saroufim": [173, 174], "ashok": [173, 174], "emani": [173, 174], "tl": [173, 181], "dr": [173, 181], "numa": [173, 174], "upi": 173, "fma": [173, 174], "dp": [173, 174], "hyperthread": 173, "contend": 173, "ultra": 173, "cpu_launcher_en": [173, 174], "toepliz": 173, "use_logical_cor": 173, "vtune": [173, 238], "8180m": 173, "omp_num_thread": [173, 234], "982": 173, "__kmp_fork_barri": 173, "589": 173, "neglig": 173, "887": 173, "530": 173, "lscpu": 173, "112": [173, 181, 197, 225], "llc": [173, 174], "asid": 173, "get_num_thread": 173, "node_id": [173, 174], "base_handl": 173, "56x4": 173, "affinit": [173, 174], "stall": [173, 174], "amplifi": 173, "slot": 173, "uop": [173, 174], "__sched_yield": 173, "disassoci": 173, "exacerb": 173, "core_51": 173, "8180": 173, "tid": 173, "97097": 173, "cpu_81": 173, "cpu_14": 173, "cpu_5": 173, "cpu_70": 173, "cpu_100": 173, "cpu_24": 173, "num_physical_cor": 173, "94290": 173, "cpu_78": 173, "cpu_108": 173, "omp": 173, "microarchitectur": 173, "onednn": [173, 174, 200, 208, 214], "immens": [173, 174], "ning": [173, 174], "jing": [173, 174], "xu": [173, 174, 182, 183], "71x": 174, "20x": 174, "toplev": 174, "pmu": 174, "perf": [174, 183], "mispredict": 174, "hierarch": 174, "retir": 174, "specul": 174, "cancel": [174, 219, 234], "untun": 174, "subsystem": 174, "l3": 174, "dram": 174, "prefetch": 174, "starv": 174, "wll": 174, "uncomplet": 174, "oneapi": [174, 214], "deconvolut": [174, 217], "emit_itt": [174, 214], "intel_extension_for_pytorch": [174, 208], "ipex_en": 174, "submetr": 174, "unnecessari": [174, 203, 237], "spinlock": 174, "arena": 174, "enable_tcmalloc": 174, "enable_jemalloc": 174, "use_default_alloc": 174, "range_push": [174, 214], "step_": 174, "range_pop": [174, 214], "step_x": 174, "step_99": 174, "308": 174, "261": 174, "843": 174, "8960": 174, "cpu_launcher_arg": 174, "561": 174, "688": 174, "251": 174, "401": 174, "392": 174, "bf16": [174, 200], "intercept": 174, "ipex": [174, 208], "8x": 174, "851": 174, "310": [174, 219], "7x": 174, "803": 174, "248": 174, "eltwis": 174, "elementwis": [174, 234], "nhwc": [174, 189, 208, 211], "disable_auto_channels_last": 174, "channels_last": [174, 189, 200, 207, 208, 211], "reorder": [174, 200, 214, 234], "215": 174, "731": [174, 240], "634": 174, "fudan": 175, "databas": 175, "pedestrian": 175, "keypoint": 175, "x0": 175, "y0": 175, "x1": 175, "int64tensor": 175, "image_id": 175, "iscrowd": 175, "uint8tensor": 175, "pycocotool": 175, "gautamchitni": 175, "cocoapi": 175, "cocodataset": 175, "pythonapi": 175, "get_height_and_width": 175, "pennfudanp": 175, "pedmask": 175, "fudanped00001_mask": 175, "fudanped00002_mask": 175, "fudanped00003_mask": 175, "fudanped00004_mask": 175, "pngimag": 175, "fudanped00001": 175, "fudanped00002": 175, "fudanped00003": 175, "fudanped00004": 175, "pennfudandataset": 175, "listdir": 175, "mask_path": 175, "obj_id": 175, "num_obj": 175, "xmin": 175, "xmax": 175, "ymin": 175, "ymax": 175, "as_tensor": [175, 186], "crowd": 175, "modelzoo": 175, "faster_rcnn": 175, "fastrcnnpredictor": 175, "fasterrcnn_resnet50_fpn": 175, "roi_head": 175, "box_predictor": 175, "cls_score": 175, "fasterrcnn": 175, "rpn": 175, "anchorgener": 175, "out_channel": 175, "anchor": 175, "anchor_gener": 175, "aspect_ratio": 175, "featmap_nam": 175, "roi_pool": 175, "multiscaleroialign": 175, "sampling_ratio": 175, "rpn_anchor_gener": 175, "box_roi_pool": 175, "mask_rcnn": 175, "maskrcnnpredictor": 175, "get_model_instance_segment": 175, "maskrcnn_resnet50_fpn": 175, "in_features_mask": 175, "mask_predictor": 175, "conv5_mask": 175, "in_channel": 175, "hidden_lay": 175, "predictor": 175, "get_transform": 175, "piltotensor": 175, "convertimagedtyp": 175, "tolist": 175, "0005": 175, "print_freq": 175, "000090": 175, "5213": 175, "loss_classifi": 175, "8025": 175, "loss_box_reg": 175, "loss_mask": 175, "4265": 175, "loss_object": 175, "0190": 175, "loss_rpn_box_reg": 175, "0099": 175, "3121": 175, "3024": 175, "000936": 175, "3007": 175, "5313": 175, "3979": 175, "4719": 175, "2454": 175, "2272": 175, "6089": 175, "7953": 175, "0197": 175, "0228": 175, "0141": 175, "4198": 175, "0298": 175, "5081": 175, "001783": 175, "7567": 175, "1056": 175, "2221": 175, "3319": 175, "2002": 175, "2106": 175, "2904": 175, "5332": 175, "0146": 175, "0176": 175, "0094": 175, "0123": 175, "0035": 175, "002629": 175, "4705": 175, "8935": 175, "0991": 175, "2517": 175, "1957": 175, "1970": 175, "0061": 175, "0140": 175, "0075": 175, "0118": 175, "3403": 175, "0044": 175, "003476": 175, "3901": 175, "7568": 175, "0648": 175, "1207": 175, "1705": 175, "0018": [175, 181], "0113": [175, 181], "0112": 175, "3407": 175, "004323": 175, "3237": 175, "6703": 175, "0474": 175, "1731": 175, "1109": 175, "1561": 175, "1658": 175, "3201": 175, "0015": [175, 181], "0093": 175, "0116": 175, "0043": 175, "005000": 175, "2540": 175, "0309": 175, "1526": 175, "0463": 175, "1405": 175, "1568": 175, "2945": 175, "0012": [175, 181], "3489": 175, "0042": 175, "3570": 175, "model_tim": 175, "2152": 175, "evaluator_tim": 175, "0133": 175, "1701": 175, "0628": 175, "0687": 175, "0039": 175, "0022": [175, 181], "0828": 175, "iou": 175, "bbox": 175, "maxdet": 175, "780": 175, "313": 175, "582": 175, "612": 175, "672": 175, "650": 175, "755": 175, "664": 175, "segm": 175, "704": 175, "871": 175, "325": 175, "727": 175, "316": 175, "748": [175, 219], "749": 175, "673": 175, "758": 175, "969": 175, "935": 175, "592": 175, "831": 175, "844": 175, "870": [175, 219], "761": 175, "919": 175, "341": 175, "788": 175, "818": 175, "train2017": 175, "prepare_fx": [176, 178, 179, 180, 192], "convert_fx": [176, 178, 179, 180, 192], "default_weight_observ": 176, "get_default_qconfig_map": 176, "minmaxobserv": [176, 193], "backend_config": 176, "backendpatternconfig": 176, "dtypewithconstraint": 176, "observationtyp": 176, "quantize_fx": [176, 178, 179, 192], "fp32_linear": 176, "quant1": 176, "dequant1": 176, "quant2": 176, "dequant2": 176, "fp32_conv_relu": 176, "quint8_with_constraint": 176, "quint8": 176, "quant_min_lower_bound": 176, "quant_max_upper_bound": 176, "scale_min_lower_bound": 176, "weighted_int8_dtype_config": 176, "input_dtyp": 176, "output_dtyp": 176, "weight_dtyp": 176, "bias_dtyp": 176, "fuse_conv2d_relu": 176, "is_qat": 176, "convrelu2d": [176, 179], "linear_config": 176, "set_pattern": 176, "set_observation_typ": 176, "output_use_different_observer_as_input": 176, "add_dtype_config": 176, "set_root_modul": 176, "set_qat_modul": 176, "set_reference_quantized_modul": 176, "conv_relu_config": 176, "set_fused_modul": 176, "set_fuser_method": 176, "fused_conv_relu_config": 176, "my_backend": 176, "set_backend_pattern_config": 176, "quant_max": [176, 193], "activation_observ": 176, "with_arg": [176, 193], "quant_min": [176, 193], "qconfig_map": [176, 178, 179, 180], "set_object_typ": [176, 179, 192], "use_bn": 176, "example_input": [176, 178, 179, 180, 192], "quantizedlinear": 176, "012136868201196194": 176, "zero_point": [176, 181, 193], "qscheme": [176, 193], "per_tensor_affin": [176, 193], "quantizedconvrelu2d": 176, "0029353597201406956": 176, "linear_input_scale_0": 176, "linear_input_zero_point_0": 176, "quantize_per_tensor": [176, 181, 209], "dequantize_2": 176, "015307803638279438": 176, "track_running_stat": [176, 207], "dequantize_1": 176, "get_fbgemm_backend_config": 176, "get_qnnpack_backend_config": 176, "xnnpack": [176, 192, 193], "get_native_backend_config": 176, "tensorrt": 176, "rfc": [176, 185, 245], "0019": [176, 181], "tldr": [178, 179], "default_dynamic_qconfig": [178, 181], "qconfigmap": [178, 180, 192, 193], "release": 178, "set_glob": [178, 179, 180, 192], "prepared_model": [178, 179, 192], "s3": 178, "amazonaw": 178, "metamind": 178, "asset": [178, 199, 201, 212], "word_language_model_quant": 178, "forunct": 178, "fx_graph_mode_ptq_dynam": [178, 194], "charl": 179, "hernandez": 179, "traceabl": 179, "unlock": [179, 181, 205], "identitc": [179, 192], "resnet18_pretrained_float": [179, 192], "fuse_fx": [179, 192], "recursivescriptmodul": [179, 181, 192], "model_to_quant": [179, 192], "qconfig_opt": [179, 192], "set_module_name_regex": 179, "set_module_nam": [179, 192], "set_module_name_object_type_ord": 179, "object_typ": 179, "module_name_regex": 179, "module_nam": 179, "serila": [179, 192], "fx_graph_mode_model_file_path": 179, "resnet18_fx_graph_mode_quant": 179, "erro": 179, "convrelu": 179, "moduleattributeerror": 179, "_modul": 179, "conv1_weight_after_fus": 179, "conv1_weight_after_qu": 179, "resnet18_script": [179, 192], "eager_quantized_model": 179, "eager_mode_model_fil": 179, "resnet18_eager_mode_quant": 179, "aibench": 179, "192": 179, "48m": 179, "63m": 179, "non_traceable_code_1": 180, "traceable_cod": 180, "non_traceable_code_2": 180, "fp32traceabl": 180, "traceable_submodul": 180, "traceable_code_1": 180, "traceable_code_2": 180, "model_fp32": 180, "non_traceable_cod": 180, "fp32nontrac": 180, "non_traceable_submodul": 180, "prepare_custom_config_dict": 180, "non_traceable_module_nam": 180, "non_traceable_module_class": 180, "mnontrac": 180, "model_prepar": 180, "todo": [180, 243], "transpose_for_scor": 180, "new_x_shap": 180, "num_attention_head": 180, "attention_head_s": 180, "custommodul": 180, "observednontrac": 180, "classmethod": 180, "from_float": 180, "from_observ": 180, "staticquantnontrac": 180, "float_to_observed_custom_module_class": 180, "convert_custom_config_dict": 180, "observed_to_quantized_custom_module_class": 180, "model_quant": [180, 212, 213, 216, 239], "thee": 180, "dynamicquantnontrac": 180, "weightonlyquantmnontrac": 180, "test_custom_module_class": 180, "test_quantize_fx": 180, "supriya": 181, "rao": 181, "per_channel_dynamic_qconfig": 181, "quantize_dynamic_jit": 181, "ts_model": 181, "installaion": 181, "necesessari": 181, "lenght": 181, "overwritten": [181, 237], "qconfig_glob": 181, "qconfig_sub": 181, "qconfig_fc": 181, "242141": 181, "354759": 181, "188": [181, 219], "157": 181, "4s": 181, "quantized_model_debug": 181, "prepare_dynamic_jit": 181, "convert_dynamic_jit": 181, "406429": 181, "897": 181, "getattr": [181, 202], "113": 181, "4_scale_0": 181, "114": 181, "4_zero_point_0": 181, "4_axis_0": 181, "4_scalar_type_0": 181, "quantize_per_channel": 181, "1640": 181, "_choose_qparams_per_tensor": 181, "98304": 181, "linear_dynam": 181, "0257": 181, "0269": 181, "0158": 181, "0764": 181, "0548": 181, "0325": 181, "0423": 181, "0528": 181, "1382": 181, "0069": 181, "0275": 181, "0253": 181, "0090": 181, "0512": 181, "0555": 181, "0277": 181, "0543": 181, "0539": 181, "0943": 181, "0619": 181, "1040": 181, "0598": 181, "0465": 181, "0009": 181, "0949": 181, "0097": 181, "0183": 181, "0085": 181, "clonebackward": 181, "0011": 181, "0010": 181, "0034": 181, "0013": 181, "0016": 181, "0036": 181, "0014": 181, "0008": 181, "0023": 181, "0031": 181, "0024": 181, "016605": 181, "182": 181, "878029": 181, "jit_model_path_float": 181, "jit_model_path_eag": 181, "jit_model_path_graph": 181, "tao": [182, 183], "npu": [182, 211], "solidifi": [182, 189], "coremltool": 182, "0b5": 182, "protobuf": 182, "to_backend": 182, "_coreml": 182, "compilespec": 182, "tensorspec": 182, "coremlcomputeunit": 182, "mobilenetv2_spec": 182, "allow_low_precis": 182, "compile_spec": 182, "_jit_to_backend": 182, "coreml": 182, "_save_for_lite_interpret": [182, 183, 189, 197, 210, 211], "mobilenetv2_coreml": 182, "ptl": [182, 197, 210, 211], "cpuandgpu": 182, "mil": 182, "384": 182, "385": 182, "1496": 182, "anaconda3": 182, "name_sanitization_util": 182, "userwarn": 182, "647": 182, "var_647": 182, "msg": [182, 204], "new_nam": 182, "138": 182, "495": [182, 219], "1977": 182, "backend_detail": 182, "codegen_backend_modul": 182, "desktop": [182, 183, 201], "cocoapod": [182, 183, 197, 210, 213], "podfil": [182, 210, 213], "pod": [182, 197, 210, 213, 215, 238], "lite": [182, 197, 210], "client": [183, 211], "prepack": [183, 201, 239], "pytorch_root": [183, 199], "use_pytorch_metal_export": 183, "ON": [183, 190, 207, 211], "41237a4": [183, 199], "optimize_for_mobil": [183, 189, 199, 207, 210, 211, 212, 213, 239], "mobile_optim": [183, 189, 199, 207, 210, 212, 213, 239], "scripted_model": 183, "optimized_model": 183, "export_opnam": [183, 210], "mobilenetv2_met": 183, "optimized_mobil": 183, "adaptive_avg_pool2d": 183, "copy_to_host": 183, "metal_prepack": 183, "conv2d_run": 183, "conect": 183, "slighli": 183, "malamut": 183, "malemut": 183, "alaskan": 183, "eskimo": 183, "huski": 183, "ios_arch": [183, 211], "use_pytorch_met": 183, "build_io": [183, 197, 210, 211], "a9": 183, "nsarrai": 183, "nsnumber": 183, "inferencemod": 183, "metalperformanceshad": 183, "1369": 184, "weed": 184, "state_sum": 184, "addcmul_": 184, "addcdiv_": 184, "clr": 184, "_make_spars": 184, "grad_indic": 184, "sparse_coo_tensor": [184, 187], "coalesc": [184, 218], "_indic": 184, "grad_valu": 184, "_valu": 184, "sparse_mask": [184, 187], "std_valu": 184, "sqrt_": 184, "state_sum2": 184, "masked_grad": 184, "get_data": [184, 186], "std2": 184, "masked_tensor": [184, 186, 187], "to_spars": [184, 187], "param2": [184, 195], "glanc": 184, "dodg": 184, "make_spars": 184, "diverg": [184, 186, 219, 234], "brittl": 184, "argu": 184, "densif": 184, "csc": [184, 187], "bsr": [184, 187], "bsc": 184, "conflat": 184, "disentangl": 184, "purposefulli": 184, "relianc": 184, "unreli": [184, 186], "maskedarrai": [184, 191], "maskedtensor_adagrad": [184, 194], "maskedtensor_overview": [185, 186, 187, 194], "unspecifi": [185, 186, 187, 191], "intersect": 185, "logical_or": 185, "mt0": 185, "get_mask": [185, 186], "mt1": 185, "ma": 185, "masked_arrai": 185, "mask0": 185, "mask1": 185, "necessit": 185, "maskedtensor_advanced_semant": [185, 194], "as_masked_tensor": 186, "afterthought": 186, "born": 186, "recur": 186, "unresolv": 186, "inabl": 186, "10729": 186, "troubl": 186, "52248": 186, "frustrat": 186, "4132": 186, "67180": 186, "longstand": 186, "aris": 186, "unsaf": 186, "61474": 186, "nanmax": 186, "nanmin": 186, "lend": 186, "primer": 187, "substructur": 187, "sparse_coo": 187, "sparse_csr": 187, "ndim": 187, "nse": 187, "sparse_tensor_data": 187, "sparse_tensor_mask": 187, "dense_masked_tensor": 187, "to_sparse_coo": 187, "to_sparse_csr": 187, "nuanc": 187, "crow_indic": 187, "col_indic": 187, "nnz": 187, "to_dens": 187, "is_spars": 187, "is_sparse_coo": 187, "is_sparse_csr": 187, "mt": 187, "mt2": 187, "surfac": 187, "vast": 187, "synergi": 187, "invest": 187, "maskedtensor_spars": [187, 194], "nt": 188, "poss": 188, "irregularli": 188, "legal": 188, "techinqu": 188, "semnat": 188, "zipf": 188, "need_weight": 188, "_scaled_dot_product_attent": 188, "sdp": 188, "_nnapi": 189, "convert_model_to_nnapi": 189, "bundled_input": [189, 197, 202], "make_mobilenetv2_nnapi": 189, "output_dir_path": 189, "quantize_mod": 189, "quantize_cor": 189, "quantize_ifac": 189, "input_float": 189, "nnapi_nhwc": 189, "memory_format": [189, 199, 200, 205, 207, 208, 211], "nnapi_model": 189, "bundlewrapp": 189, "augment_model_with_bundled_input": 189, "bundle_large_tensor": [189, 197], "quant_": 189, "quant_ful": 189, "speed_benchmark_torch": [189, 207, 211], "pthreadpool_s": 189, "use_bundled_input": 189, "use_caching_alloc": 189, "200gb": 189, "googlesourc": [189, 199], "envsetup": 189, "aosp_x86_64": 189, "j16": 189, "lib64": 189, "libneuralnetwork": 189, "ctype": 189, "cdll": 189, "loadlibrari": [189, 201], "get_all_bundled_input": [189, 202], "qmodel": 190, "compare_weight": 190, "wt_compare_dict": 190, "sqnr": 190, "relationship": 190, "nomin": 190, "compare_model_output": 190, "white_list": 190, "outputlogg": 190, "default_numeric_suite_compare_model_output_white_list": 190, "myoutputlogg": 190, "prepare_model_with_stub": 190, "shadowlogg": 190, "compare_model_stub": 190, "quantizablebasicblock": 190, "myshadowlogg": 190, "db": [190, 192], "numeric_suite_tutori": [190, 194], "pypi": [191, 209], "engag": 191, "pt2": 191, "nnapi": 191, "autovector": [191, 198], "nestedtensor": [191, 194], "maskedtensor": [191, 194], "coo": 191, "csr": 191, "14k": 192, "ux": 192, "xnnpackquant": [192, 193], "x86inductorquant": 192, "prepare_pt2": 192, "convert_pt2": 192, "executorch": 192, "aten_graph": 192, "quantize_pt2": 192, "get_symmetric_quantization_config": 192, "backendconfig": [192, 193], "fake_qu": 192, "embedding_byt": 192, "executorchquant": 192, "composed_quant": 192, "quantization_cap": 192, "minmax": 192, "torchdynamo": [192, 193], "exported_model": 192, "tracing_mod": 192, "xnnpack_quant": 192, "set_globa": 192, "themodel": 192, "quantizaiton": 192, "fp32_op": 192, "qauntiz": 192, "quantized_linear": 192, "x_int8": 192, "x_scale": 192, "x_zero_point": 192, "weight_int8": 192, "weight_scal": [192, 193], "weight_zero_point": 192, "bias_int32": 192, "bias_scal": 192, "bias_zero_point": 192, "output_scal": 192, "output_zero_point": 192, "x_int16": 192, "weight_int16": 192, "acc_int32": 192, "out_dtyp": 192, "acc_rescaled_int32": 192, "out_int8": 192, "clamp": [192, 199], "qmin": 192, "qmax": 192, "pt2e_quantized_model_file_path": 192, "resnet18_pt2e_quant": 192, "intial": [192, 195], "lesli": 193, "fang": 193, "weiwen": 193, "xia": 193, "kimish": 193, "patel": 193, "quantiat": 193, "qnnpackquant": 193, "convei": 193, "quantizationspec": 193, "quantizationannot": 193, "bitwidth": 193, "histogramobserv": 193, "dataclass": 193, "input_qspec_map": 193, "output_qspec": 193, "_annot": 193, "matcher": 193, "get_source_partit": 193, "add_partit": 193, "gm": 193, "add_nod": 193, "output_nod": 193, "act_quantization_spec": 193, "is_dynam": 193, "observer_or_fake_quant_ctr": 193, "input_act_qspec": 193, "output_act_qspec": 193, "input_act0": 193, "input_act1": 193, "quantization_annot": 193, "sharedquantizationspec": 193, "average_pool": 193, "edgeornod": 193, "share_qparams_with_input_act0_qspec": 193, "fixedqparamsquantizationspec": 193, "act_qspec": 193, "sigmoid_nod": 193, "input_act": 193, "derivedquantizationspec": 193, "derive_qparams_fn": 193, "observerorfakequant": 193, "observerbas": 193, "fakequantizebas": 193, "obejct": 193, "obs_or_fq": 193, "fq": 193, "act_obs_or_fq": 193, "weight_obs_or_fq": 193, "act_scal": 193, "act_zp": 193, "calculate_qparam": 193, "weight_zp": 193, "bias_qspec": 193, "derived_from": 193, "per_tensor_symmetr": 193, "weight_quantization_spec": 193, "backendquant": 193, "quantizationconfig": 193, "get_input_act_qspec": 193, "get_output_act_qspec": 193, "get_weight_qspec": 193, "get_bias_qspec": 193, "torchscript_freez": [194, 196], "vmap_recip": [194, 198], "orthogonal_": 195, "skip_init": 195, "param1": 195, "kaiming_uniform_": 195, "register_buff": 195, "some_buff": 195, "to_empti": 195, "0107": 196, "0048": 196, "chen": [197, 210], "lai": [197, 210], "cccclai": 197, "dhruv": 197, "matani": 197, "dhruvbird": 197, "scripted_modul": [197, 202, 210], "input_image_1": 197, "input_tensor_1": 197, "input_batch_1": 197, "input_image_2": 197, "input_tensor_2": 197, "input_batch_2": 197, "step2": 197, "bundled_model_input": 197, "bundled_model": [197, 202], "bundle_input": [197, 202], "deeplabv3_scripted_with_bundled_input": 197, "macosx_deployment_target": [197, 199], "max_job": 197, "tracing_bas": 197, "model_trac": 197, "model_input_path": 197, "build_yaml_path": 197, "armeabi": 197, "v7a": 197, "v8a": [197, 199, 207, 211], "selected_op_list": [197, 210], "build_pytorch_android": [197, 199, 210], "cmd": 197, "build_lite_interpret": 197, "chenlai": 197, "aar": [197, 199, 201], "xarg": 197, "ls": 197, "lah": 197, "rw": 197, "staff": 197, "13m": 197, "feb": 197, "pytorch_android": [197, 199, 201, 212], "36k": 197, "pytorch_android_torchvis": [197, 210, 212], "gradl": [197, 199, 210, 212, 215], "androidx": [197, 201, 210], "appcompat": [197, 201, 210], "constraintlayout": [197, 210], "testimplement": [197, 210], "junit": [197, 210], "androidtestimplement": [197, 210], "ext": [197, 208, 210, 245, 246], "espresso": [197, 210], "v7": [197, 201], "fbjni": [197, 201, 210], "allproject": [197, 201], "jcenter": [197, 201], "flatdir": 197, "ios_platform": [197, 210], "deintegr": 197, "all_load": 197, "bitcod": 197, "deeplabv3_on_android": 197, "42368": 198, "unsuccessfulli": 198, "rummag": 198, "batched_dot": [198, 219], "feature_s": 198, "shenanigin": 198, "feature_vec": 198, "unbind": 198, "8304": 198, "23475": 198, "basis_vector": 198, "jacobian_row": 198, "get_vjp": 198, "jacobian_vmap": 198, "performantli": 198, "7786": 198, "grad_sampl": 198, "batch_of_sampl": 198, "ivan": [199, 201], "kobzarev": [199, 201], "use_vulkan": 199, "vulkan_wrapp": 199, "use_vulkan_wrapp": 199, "libvulkan": 199, "vulkansdk": 199, "lunarg": 199, "vulkan_sdk": 199, "vulkan_sdk_root": 199, "install_vulkan": 199, "use_vulkan_shaderc_runtim": 199, "android_abi": [199, 201, 207, 211], "build_android": [199, 207, 211], "script_model": 199, "mobilenet2": 199, "32bit": 199, "script_model_vulkan": 199, "optimization_blocklist": 199, "mobileoptimizertyp": 199, "vulkan_automatic_gpu_transf": 199, "is_vulkan_avail": 199, "tensor_vulkan": 199, "tensor_output_vulkan": 199, "tensor_output": 199, "_adaptive_avg_pool2d": 199, "_cat": 199, "avg_pool2d": 199, "empty_strid": [199, 225], "hardtanh_": 199, "relu_": 199, "transpose_": 199, "upsample_nearest2d": 199, "allocatefloatbuff": [199, 211], "fromblob": [199, 211], "mmodul": [199, 210, 211], "test_app": 199, "testapp": [199, 211], "l133": 199, "apploc": 199, "installmbvulkanlocalbasedebug": 199, "mbq": 199, "swiftshad": 199, "tmul": 200, "4th": 200, "gen": 200, "10x": 200, "avx": [200, 208], "vnni": [200, 208], "autocast": [200, 208], "conv1d": [200, 234], "conv3d": [200, 234], "conv_transpose1d": 200, "conv_transpose2d": 200, "conv_transpose3d": 200, "baddbmm": 200, "addbmm": 200, "onednn_verbos": 200, "mkldnn": 200, "verbose_on": 200, "6dbeffbae1f23cbbeae17adb7b5b13f1f37c080": 200, "nthr": 200, "isa": [200, 234], "prim_templ": 200, "prop_kind": 200, "memory_descriptor": 200, "auxiliari": 200, "problem_desc": 200, "exec_tim": 200, "exec": 200, "undef": 200, "src_f32": 200, "f0": 200, "dst_f32": 200, "scratchpad": 200, "2561": 200, "avx512_core_amx_bf16": 200, "forward_train": 200, "src_bf16": 200, "acdb": 200, "wei_bf16": 200, "abcd16b16a2b": 200, "bia_f32": 200, "dst_bf16": 200, "alg": 200, "convolution_direct": 200, "mb7_ic2oc1_ih224oh111kh3sh2dh1ph1_iw224ow111kw3sw2dw1pw1": 200, "628906": 200, "brg": 200, "avx512_core_amx_int8": 200, "src_s8": 200, "wei_s8": 200, "ba16a64b4a": 200, "dst_s8": 200, "1x30522": 200, "30522x768": 200, "1x768": 200, "66382": 200, "r19c": 201, "android_ndk": 201, "sdk": [201, 215], "3859397": 201, "android_sdk": 201, "android_hom": 201, "gradle_hom": 201, "jdk": [201, 215], "java_hom": 201, "openjdk": 201, "opencv_android_sdk": 201, "registri": 201, "registeroper": 201, "cento": 201, "yum": 201, "devel": 201, "apt": 201, "libopencv": 201, "succeed": 201, "nativeapp": 201, "useandroidx": 201, "enablejetifi": 201, "buildscript": 201, "classpath": 201, "maven": [201, 210], "oss": [201, 210], "sonatyp": [201, 210], "extractfornativebuild": 201, "compilesdkvers": 201, "buildtoolsvers": 201, "defaultconfig": 201, "applicationid": 201, "minsdkvers": 201, "targetsdkvers": 201, "versioncod": 201, "versionnam": 201, "externalnativebuild": 201, "dandroid_stl": 201, "_share": 201, "buildtyp": 201, "minifyen": 201, "sourceset": 201, "jnilib": 201, "srcdir": 201, "extractaarfornativebuild": 201, "dolast": 201, "absolutefil": 201, "ziptre": 201, "builddir": 201, "jni": 201, "whentaskad": 201, "dependson": 201, "nexu": 201, "libpytorch_jni": 201, "libfbjni": 201, "stl": 201, "pytorch_nativeapp": 201, "build_dir": 201, "cmake_source_dir": 201, "pytorch_testapp_cpp_dir": 201, "cmake_current_list_dir": 201, "glob": 201, "pytorch_testapp_sourc": 201, "pytorch_include_dir": 201, "pytorch_link_dir": 201, "target_compile_opt": 201, "fexcept": 201, "build_subdir": 201, "find_librari": 201, "pytorch_librari": 201, "pytorch_jni": 201, "no_cmake_find_root_path": 201, "fbjni_librari": 201, "endif": 201, "opencv_include_dir": 201, "target_include_directori": 201, "opencv_lib_dir": 201, "opencv_librari": 201, "opencv_java4": 201, "libopencv_java4": 201, "logcat": 201, "torschscript": 201, "androidmanifest": 201, "xml": 201, "xmln": 201, "apk": 201, "allowbackup": 201, "pytorchnativeapp": 201, "supportsrtl": 201, "theme": 201, "darkactionbar": 201, "appcompatact": 201, "fileoutputstream": 201, "inputstream": 201, "outputstream": 201, "assetnam": 201, "getfilesdir": 201, "getabsolutepath": 201, "getasset": 201, "protect": [201, 210, 211], "savedinstancest": 201, "modelfileabsolutefilepath": 201, "nativecli": 201, "loadandforwardmodel": 201, "assertfilepath": 201, "nativep": 201, "libpytorch_nativeapp": 201, "modelpath": 201, "cassert": 201, "cmath": 201, "unistd": 201, "alogi": 201, "__android_log_print": 201, "android_log_info": 201, "__va_args__": 201, "alog": 201, "android_log_error": 201, "ostringstream": 201, "c_str": 201, "jitcallguard": 201, "no_autograd_guard": 201, "non_var_guard": 201, "graphoptimizerenabledguard": 201, "no_optimizer_guard": 201, "jnienv": 201, "jclass": 201, "jstring": 201, "jmodelpath": 201, "getstringutfchar": 201, "t_out": 201, "releasestringutfchar": 201, "jniexport": 201, "jint": 201, "jni_onload": 201, "javavm": 201, "vm": [201, 246], "getenv": [201, 219], "reinterpret_cast": 201, "jni_version_1_6": 201, "jni_ok": 201, "jni_err": 201, "findclass": 201, "jninativemethod": 201, "ljava": 201, "rc": 201, "registern": 201, "intermix": 201, "echo": [201, 245], "assembledebug": 201, "installdebug": 201, "adb": [201, 207, 211], "grep": 201, "26968": 201, "9484": 201, "1757": 201, "5832": 201, "9144": 201, "8867": 201, "0933": 201, "4004": 201, "3389": 201, "5200": [201, 219], "7625": 201, "5724": 201, "2073": 201, "4613": 201, "2730": 201, "6789": 201, "2247": 201, "2790": 201, "0067": 201, "9266": 201, "6034": 201, "1941": 201, "7021": 201, "5368": 201, "3803": 201, "0188": 201, "2021": [201, 209], "7412": 201, "2257": 201, "5044": 201, "6592": 201, "0826": 201, "0084": 201, "8733": 201, "5435": 201, "1087": 201, "1066": 201, "9926": 201, "1047": 201, "5311": 201, "9178": 201, "5451": 201, "0473": 201, "7571": 201, "3909": 201, "4039": 201, "5085": 201, "2776": 201, "4080": 201, "9203": 201, "3655": 201, "4395": 201, "4467": 201, "9837": 201, "0445": 201, "8039": 201, "2512": 201, "3122": 201, "6543": 201, "5819": 201, "5680": 201, "6442": 201, "6197": 201, "0773": 201, "5967": 201, "1105": 201, "0274": 201, "0330": 201, "0124": 201, "8644": 201, "0493": 201, "7633": 201, "9657": 201, "3469": 201, "3159": 201, "0683": 201, "4529": 201, "4559": 201, "7038": 201, "8396": 201, "9716": 201, "5279": 201, "1780": 201, "3849": 201, "4368": 201, "1480": 201, "jacob": 202, "szwejbka": 202, "sample_input": 202, "example_dict": 202, "all_info": 202, "get_bundled_inputs_functions_and_info": 202, "func_nam": 202, "input_func_nam": 202, "get_inputs_function_nam": 202, "func_to_run": 202, "model_funct": 202, "decompress": 202, "ie": 202, "bundle_randn": 202, "deflat": 202, "create_exampl": 202, "deflated_input": 202, "inflatablearg": 202, "randn_lik": 202, "bundle_optional_dict_of_randn": 202, "fmt_fn": 202, "d2h": 203, "h2d": 203, "set_device_map": 203, "worker0": 203, "payload": 203, "infiniband": 203, "shm": 203, "cma": 203, "comm_mod": 203, "lm": 203, "pend": [203, 211, 232], "current_stream": 203, "34x": 203, "3145179748535156": 203, "06867480278015137": 203, "image_classifi": 204, "kitten": 204, "index_to_nam": 204, "infil": 204, "input_transform": 204, "timg": 204, "models_": 204, "render_predict": 204, "prediction_idx": 204, "stridx": 204, "img_class_map": 204, "mapping_file_path": 204, "isfil": 204, "curl": [204, 245], "multipart": 204, "recevi": 204, "285": 204, "quasi": 205, "hyperbol": 205, "qhm": 205, "qhm_updat": 205, "dp_list": 205, "momentum_buffer_list": 205, "nu": [205, 245], "weight_decay_typ": 205, "d_p": 205, "momentum_buff": 205, "polymorph": 205, "functionalqhm": 205, "params_with_grad": 205, "preserve_format": 205, "functional_optim_map": 205, "remote_params_list": 205, "dist_optim": 205, "annotatedconvbnrelumodel": [207, 211], "prepare_sav": 207, "torchscript_model": [207, 211, 212, 213, 239], "torchscript_model_optim": [207, 211, 212, 213], "model_fus": 207, "bnrelu2d": 207, "build_pytorch_mobil": [207, 210, 211], "dbuild_binari": [207, 211], "input_typ": [207, 211], "6189": 207, "575": 207, "6216": 207, "858": 207, "avx512": 208, "amx": [208, 209], "xmx": 208, "xpu": 208, "claus": [208, 209, 241], "roialign": 208, "bertmodel": 208, "seq_length": 208, "check_trac": 208, "cache_en": 208, "memoryformat": 208, "channelslast": [208, 211], "intel_ext_pt_cpu": 208, "libpytorch_path": 208, "ldd": 208, "workspac": 208, "cmake_have_libc_pthread": 208, "0x00007f3cf98e0000": 208, "libc10": 208, "0x00007f3cf985a000": 208, "libintel": 208, "0x00007f3cf70fc000": 208, "libtorch_cpu": [208, 233], "0x00007f3ce16ac000": 208, "libdnnl_graph": 208, "0x00007f3cde954000": 208, "mitig": [209, 234], "conv2_drop": 209, "fc1_drop": 209, "lenet_mnist_model": 209, "conf": [209, 243, 250], "pytorch_fx": 209, "accuracy_criterion": 209, "neural_compressor": 209, "calib_dataload": 209, "q_model": 209, "top1metr": 209, "quant_aware_train": 209, "training_func": 209, "q_func": 209, "dummy_dataset": 209, "dummydataset": 209, "linearrelu": 209, "best_configur": 209, "best_model_weight": 209, "int8_model": 209, "martin": 210, "pytorchstreamread": 210, "pkl": 210, "regener": 210, "model_path": 210, "model_psth": 210, "_load_for_lite_interpret": [210, 211], "optimized_scripted_modul": 210, "pytorch_android_lit": 210, "litemoduleload": 210, "getapplicationcontext": 210, "prebuilt": [210, 238], "use_framework": 210, "libtorch_lit": 210, "nullabl": 210, "instancetyp": 210, "initwithfileatpath": 210, "nsstring": 210, "_load_for_mobil": [210, 211], "utf8str": 210, "nslog": 210, "architechtur": 210, "dsp": 211, "calibration_data": 211, "588kb": 211, "nio": 211, "suboptim": 211, "analysisresult": 211, "analyzeimag": 211, "imageproxi": 211, "rotationdegre": 211, "modulefileabsolutefilepath": 211, "minputtensorbuff": 211, "minputtensor": 211, "imageyuv420centercroptofloatbuff": 211, "getimag": 211, "flatbuff": 211, "_use_flatbuff": 211, "jit_model": 211, "ff": 211, "5387594579999999": 211, "038842832999999466": 211, "nake": 211, "rf": 211, "speedbenchark_torch": 211, "speedbenchmark": 211, "121318": 211, "24281": 211, "trace_model": 211, "rubi": 211, "iphonex": 211, "2121": 211, "722447": 211, "762": 211, "mobilenetv2_quant": [212, 213], "hackathon": [212, 213], "xcworkspac": 213, "your_project_nam": 213, "abnorm": 214, "unexpectedli": 214, "screenshot": 214, "path_of_launch": 214, "iteration_n": 214, "brown": 214, "percerntag": 214, "jitter": [214, 219], "enrich": 214, "ittsampl": 214, "292820": 214, "244": 214, "iteration_": 214, "basefold": 214, "bash_sourc": 214, "retrain": 215, "torchscipt": [215, 238], "ota": 216, "incept": 216, "v3": 216, "print_model_s": 216, "mdl": 216, "63": [216, 225], "till": 216, "model_dynamic_quant": 216, "qconfig_spec": 216, "model_static_quant": 216, "98mb": 216, "tra": 216, "model_qat": 216, "gradcam": 217, "283": 217, "occlus": 217, "guidedbackprop": 217, "deeplift": 217, "gradientshap": 217, "forward_func": 217, "pictori": 217, "textual": 217, "distractor": 217, "absenc": 217, "visualize_text": 217, "imdb_torchtext_interpret": 217, "gilbert": 217, "tanner": 217, "gilberttann": 217, "captum_recip": [217, 223, 231], "carilli": 218, "ture": 218, "kepler": 218, "maxwel": 218, "pascal": 218, "modest": 218, "in_siz": 218, "out_siz": 218, "num_lay": 218, "satur": 218, "underflow": 218, "scaler": 218, "unscal": 218, "unscale_": 218, "rough": 218, "binary_cross_entropy_with_logit": 218, "suspect": 218, "docstr": [218, 245, 246], "subregion": 218, "backtrac": 218, "torch_show_cpp_stacktrac": 218, "amp_recip": [218, 223, 231], "tediou": 219, "mistak": 219, "mul_sum": 219, "0x7fb10400d0f0": 219, "batched_dot_mul_sum": 219, "379": 219, "0x7fb103d67048": 219, "batched_dot_bmm": 219, "num_thread": 219, "sub_label": 219, "0x7fb103d54080": 219, "118": 219, "0x7fb16935d2e8": 219, "2775": 219, "0x7fb10400d080": 219, "232": 219, "blocked_autorang": 219, "min_run_tim": [219, 233], "reliabl": 219, "median": [219, 233], "162": 219, "274": 219, "432": 219, "22657": 219, "11899": 219, "609": 219, "23098": 219, "27246": 219, "267073": 219, "118823": 219, "189": 219, "849": 219, "2782": 219, "7471": 219, "11874": 219, "173": 219, "27824": 219, "100060": 219, "121499": 219, "2773": 219, "12833": 219, "6295": 219, "27062": 219, "71804": 219, "120365": 219, "103": 219, "2804": 219, "6764": 219, "11871": 219, "6640": 219, "27592": 219, "73003": 219, "120083": 219, "callgrindstat": [219, 233], "trip": [219, 233], "36000": 219, "40000": 219, "stark": 219, "fuzzer": 219, "10000000": 219, "k0": 219, "k1": 219, "discontigu": 219, "725": 219, "383": 219, "1468": 219, "5039": 219, "1200": 219, "2140": 219, "1296": 219, "41000": 219, "1598": 219, "519": 219, "763": 219, "141": 219, "473": 219, "16384": 219, "12642115": 219, "8192": 219, "4800": 219, "20400": 219, "110000": 219, "400000": 219, "493": 219, "1100": [219, 233], "2440": 219, "2030": 219, "23600": 219, "24000": [219, 233], "62374": 219, "90000": 219, "240372": 219, "16000": 219, "40156": 219, "2670": 219, "opac": 219, "complementari": 219, "insensit": 219, "environment": 219, "cpp_lib": 219, "batched_dot_src": 219, "extra_cflag": 219, "extra_include_path": 219, "batched_dot_mul_sum_v0": 219, "batched_dot_mul_sum_v1": 219, "module_import_str": 219, "67631": 219, "importlib": 219, "spec_from_file_loc": 219, "repr": 219, "module_from_spec": 219, "exec_modul": 219, "textwrap": 219, "pretty_print": 219, "t_baselin": 219, "stmt": 219, "stats_v0": 219, "collect_callgrind": 219, "stats_v1": 219, "as_standard": [219, 233], "denois": 219, "ing": 219, "wrap_pybind_function_impl_": 219, "set_printopt": 219, "linewidth": 219, "valgrind_wrapp": [219, 233], "timer_interfac": [219, 233], "0x7fb0f06e7630": 219, "2392671": 219, "4367": 219, "rel_with_deb_info": [219, 233], "0x7fb10400d208": 219, "2378978": 219, "functioncount": [219, 233], "0x7fb1000ab358": 219, "0x000000000020d9e0": 219, "0x000000000020db10": 219, "integer_sequ": 219, "0ul": 219, "1ul": 219, "undefinedtensorimpl": 219, "reset_": 219, "5935": 219, "0x000000000022c0e0": 219, "13693": 219, "changing_default_devic": [220, 231], "subsidiari": [221, 227, 228, 229, 230, 235, 236], "neighbor": [221, 234], "sharp": 221, "blurri": 221, "defining_a_neural_network": [221, 223, 231], "ballpark": 222, "postprocess": 222, "quanitz": 222, "__": 222, "_lstm": 222, "mileag": 222, "float_lstm": 222, "quantized_lstm": 222, "documentaion": 222, "dynamic_quant": [222, 223, 231], "loading_data_recip": [223, 224, 231], "what_is_state_dict": [223, 231, 236], "saving_and_loading_models_for_infer": [223, 229, 231], "custom_dataset_transforms_load": 223, "save_load_across_devic": [223, 227, 231], "saving_and_loading_a_general_checkpoint": [223, 228, 231], "saving_multiple_models_in_one_fil": [223, 230, 231], "warmstarting_model_using_parameters_from_a_different_model": [223, 231, 235], "zeroing_out_gradi": [223, 231, 237], "mobile_perf": 223, "syntaxerror": [223, 231], "yesno": 224, "sixti": 224, "hebrew": 224, "eight": 224, "sample_r": 224, "yesno_data": 224, "provis": 224, "profileract": 225, "model_infer": 225, "_fork": 225, "509m": 225, "503m": 225, "931m": 225, "597m": 225, "700m": 225, "585m": 225, "_convolut": 225, "450m": 225, "mkldnn_convolut": 225, "838m": 225, "114m": 225, "556m": 225, "693m": 225, "734": 225, "_batch_norm_impl_index": 225, "482m": 225, "724": 225, "100u": 225, "native_batch_norm": 225, "229m": 225, "109m": 225, "705": 225, "450u": 225, "332": 225, "631m": 225, "286u": 225, "668m": 225, "292m": 225, "988u": 225, "549m": 225, "dnn": 225, "group_by_input_shap": 225, "008m": 225, "956m": 225, "909m": 225, "834m": 225, "332m": 225, "303m": 225, "273m": 225, "233m": 225, "751m": 225, "occurr": 225, "666m": 225, "484m": 225, "_convolution_nogroup": 225, "thnn_conv2d": 225, "thnn_conv2d_forward": 225, "im2col_kernel": 225, "844m": 225, "sgemm_32x32x32_nn": 225, "206m": 225, "sgemm_32x32x32_nn_vec": 225, "093m": 225, "015m": 225, "max_pool2d_with_indic": 225, "kb": 225, "572": 225, "resize_": 225, "masked_select": 225, "122": 225, "064m": 225, "439": 225, "_conv_forward": 225, "1051": 225, "_call_impl": 225, "016m": 225, "659m": 225, "self_cuda_time_tot": 225, "export_stack": 225, "flamegraph": 225, "svg": 225, "brendangregg": 225, "pl": [225, 244], "countnam": 225, "profiler_stack": 225, "perf_viz": 225, "skip_first": 225, "step_num": 225, "profiler_recip": [225, 231], "reasoning_about_shap": [226, 231], "state_dict_model": 229, "entire_model": 229, "recipes_recip": 231, "tensorboard_with_pytorch": [231, 232], "timer_quick_start": [231, 233], "tuning_guid": [231, 234], "scalar_valu": 232, "walltim": 232, "tfevent": 232, "anyon": [232, 246], "adyd1tgetlalwxx6i8juba": 232, "hparam": 232, "0x7f1929a38ed0": 233, "iqr": 233, "424": 233, "0x7f192b019ed0": 233, "unsurprisingli": 233, "0x7f1929a35850": 233, "563600": 233, "tensormethod": 233, "ab_ref": 233, "0x7f192a6dfd90": 233, "47264": 233, "_int_fre": 233, "25963": 233, "_int_malloc": 233, "19900": 233, "tensorit": 233, "tensoriteratorconfig": 233, "18000": 233, "__tls_get_addr": 233, "13500": 233, "malloc": [233, 234], "11300": 233, "smallvector": 233, "10345": 233, "_int_memalign": 233, "9200": 233, "iteratorbas": 233, "get_strid": 233, "173472": 233, "collis": 233, "0x7f192995d750": 233, "118200": 233, "tensoriter": 233, "65000": 233, "20900": 233, "15900": 233, "15100": 233, "cpualloc": 233, "12500": 233, "352327": 233, "a0": 233, "b0": 233, "a1": 233, "a127": 233, "pickleabl": 233, "broadcasting_stat": 233, "17600": 233, "tensoriteratorbas": 233, "compute_strid": 233, "12700": 233, "allocate_or_resize_output": 233, "10200": 233, "smallvectorimpl": 233, "7400": 233, "infer_s": 233, "6200": 233, "invert_perm": 233, "6064": 233, "5100": 233, "reorder_dimens": 233, "4300": 233, "compatible_strid": 233, "check_tensor_options_and_extract_memory_format": 233, "__memcmp_avx2_movb": 233, "empty_cpu": 233, "1300": 233, "2400": 233, "6100": 233, "compute_fast_setup_typ": 233, "22600": 233, "fast_set_up": 233, "58091": 233, "580": 233, "0x7f19299544d0": 233, "compute_shap": 233, "2300": 233, "coalesce_dimens": 233, "promin": 233, "__add__": 233, "__sub__": 233, "dice": 233, "szymon": 234, "migacz": 234, "inexpens": 234, "conjunct": 234, "ssd": 234, "carefulli": 234, "anomali": 234, "detect_anomali": 234, "set_detect_anomali": 234, "emit_nvtx": 234, "nth": 234, "cpunodebind": 234, "membind": 234, "pytorch_script": 234, "thrash": 234, "gomp_cpu_affin": 234, "omp_proc_bind": 234, "omp_schedul": 234, "libgomp": 234, "sleep": 234, "jemalloc": 234, "tcmalloc": 234, "emphas": 234, "optimize_for_infer": 234, "avx512_bf16": 234, "ccl": 234, "alltoal": 234, "autotun": 234, "cuda_tensor": 234, "guidelin": 234, "slide": 234, "no_sync": 234, "judgment": 237, "itt": 238, "andriod": 238, "compressor": 238, "tensorpip": 238, "tracerwarn": 239, "scripted_cel": 239, "_0": 239, "WITH": 239, "input_lang": 239, "n_word": 239, "attndecoderrnn": 239, "output_lang": 239, "encoder_input": 239, "encoder_hidden": 239, "decoder_input1": 239, "decoder_input2": 239, "decoder_input3": 239, "scripted_encod": 239, "scripted_decod": 239, "luongattndecoderrnn": 239, "_decoder_n_lay": 239, "optimized_torchscript_model": 239, "hoist": 239, "blocklist": 239, "repl": 240, "r18": 240, "r18_script": 240, "unscripted_output": 240, "scripted_output": 240, "unscripted_top5": 240, "scripted_top5": 240, "463": 240, "ts": 240, "msg_without_backtrac": 240, "output_sm": 240, "softmaxfuncopt": 240, "top5_tensor": 240, "ndone": 240, "418": 240, "845": 240, "644": 240, "cpulongtyp": 240, "exposit": 240, "deepspe": 241, "marian": 241, "oftentim": 241, "exp_avg": 241, "exp_avg_sq": 241, "peer": 241, "print_peak_memori": 241, "max_memory_alloc": 241, "use_zero": 241, "optimizer_class": 241, "0mb": 241, "992": 241, "1361": 241, "3453": 241, "6123046875": 241, "1697": 241, "pytorch_sphinx_them": [243, 250], "html_theme_opt": 243, "canonical_url": 243, "analytics_id": 243, "logo_onli": 243, "display_vers": 243, "prev_next_buttons_loc": 243, "style_external_link": 243, "vcs_pageview_mod": 243, "collapse_navig": 243, "sticky_navig": [243, 247], "navigation_depth": 243, "includehidden": 243, "titles_onli": 243, "canon": 243, "slash": 243, "sidebar": [243, 249], "display_github": 243, "display_gitlab": 243, "gitlab": 243, "bitbucket": 243, "toctre": 243, "unlimit": 243, "github_url": 243, "bitbucket_url": 243, "gitlab_url": 243, "visitor": 243, "revert": 243, "misbuild": 243, "sticki": [243, 249], "nav": [243, 249], "django": 244, "payment": 244, "dotpai": 244, "dotpayprovid": 244, "seller_id": 244, "gatewai": 244, "purchas": 244, "seller": 244, "data_item_1": 244, "data_item_2": 244, "data_item_3": 244, "lorem": [244, 246, 248], "ipsum": [244, 246, 248], "dolor": [244, 246, 248], "amet": [244, 246, 248], "consectetur": [244, 246, 248], "adipisc": [244, 246, 248], "fusc": [244, 248], "congu": [244, 248], "eu": [244, 248], "hendrerit": [244, 248], "matti": [244, 246], "emphasi": 245, "hyperlink": 245, "uri": 245, "anonym": 245, "exceedingli": 245, "ugli": 245, "autodoc": [245, 246], "test_py_modul": [245, 249], "2822": 245, "subscript": 245, "superscript": 245, "interfer": 245, "mmb": 245, "menuselect": 245, "whitespac": 245, "hyphen": 245, "restructuredtext": [245, 246], "literal_block": 245, "spaces_and_linebreak": 245, "markup_process": 245, "eric": 245, "orchestra": 245, "leader": 245, "philosoph": 245, "ipso": 245, "facto": 245, "vi": 245, "ancient": 245, "sing": 245, "elk": 245, "brontosaurus": 245, "thin": 245, "thicker": 245, "ann": 245, "begun": 245, "someurl": 245, "pane": 245, "shell_command": 245, "window_nam": 245, "session_nam": 245, "some_funct": 245, "THE": 245, "heaven": 245, "hexagram": 245, "unbroken": 245, "weak": 245, "unrestrict": 245, "conceiv": 245, "motion": 245, "men": 245, "deiti": 245, "holi": 245, "sage": 245, "ruler": 245, "awaken": 245, "sphinx_rtd_them": [245, 246], "dt": 245, "tt": 245, "descnam": 245, "descclassnam": 245, "myclass": 245, "dothismethod": 245, "flox": 245, "unreferenc": 245, "nonexist": 245, "bold": 245, "ital": 245, "heck": 245, "backlink": 245, "indirect": 245, "docutil": [245, 246], "sourceforg": [245, 246], "clickabl": 245, "legend": 245, "revis": [245, 246], "structuredtext": 245, "nickel": 245, "mad": 245, "scientist": 245, "bread": 245, "wash": 245, "ear": 245, "closet": 245, "bathroom": 245, "trash": 245, "mother": 245, "rho_": 245, "thing1": 245, "thing2": 245, "thing3": 245, "prose": 245, "provok": 245, "mental": 245, "exert": 245, "advis": 245, "subtitl": 245, "border": 245, "disconnect": 245, "arab": 246, "iii": 246, "iv": 246, "goodger": 246, "street": 246, "ex": [246, 248], "a1b": 246, "2c3": 246, "myself": 246, "humankind": 246, "tue": 246, "jan": 246, "7302": 246, "redistribut": 246, "reattribut": 246, "sell": 246, "bui": 246, "leas": 246, "excerpt": 246, "stapl": 246, "mutil": 246, "bibliograph": 246, "markup": [246, 249], "literal": 246, "yahoo": 246, "oh": 246, "heh": 246, "beat": 246, "hehe": 246, "cackl": 246, "lone": 246, "guangzhou": 246, "destini": 246, "dream": 246, "sixth": 246, "donec": [246, 248], "porttitor": [246, 248], "odio": [246, 248], "posuer": [246, 248], "vita": [246, 248], "ornar": [246, 248], "libero": [246, 248], "loborti": [246, 248], "justo": [246, 248], "vestibulum": [246, 248], "nibh": [246, 248], "aliquet": [246, 248], "sed": [246, 248], "feugiat": [246, 248], "sagitti": [246, 248], "nequ": [246, 248], "qui": [246, 248], "eleifend": 246, "dui": [246, 248], "rutrum": [246, 248], "lectu": [246, 248], "suscipit": [246, 248], "nam": [246, 248], "mauri": [246, 248], "arcu": [246, 248], "interdum": 248, "nec": 248, "finibu": 248, "dictum": 248, "velit": 248, "ut": 248, "efficitur": 248, "aliquam": 248, "erat": 248, "diam": 248, "gravida": 248, "imperdiet": 248, "tellu": 248, "nisl": 248, "praesent": 248, "eget": 248, "elementum": 248, "rhoncu": 248, "tincidunt": 248, "suspendiss": 248, "volutpat": 248, "scelerisqu": 248, "tristiqu": 248, "aenean": 248, "condimentum": 248, "risu": 248, "accumsan": 248, "laoreet": 248, "maximu": 248, "sapien": 248, "ligula": 248, "fringilla": 248, "commodo": 248, "proin": 248, "pharetra": 248, "etiam": 248, "turpi": 248, "luctu": 248, "vel": 248, "malesuada": 248, "dignissim": 248, "nunc": 248, "augu": 248, "sem": 248, "cursu": 248, "nulla": 248, "pellentesqu": 248, "habit": 248, "morbi": 248, "senectu": 248, "netu": 248, "egesta": 248, "placerat": 248, "tortor": 248, "iaculi": 248, "venenati": 248, "cra": 248, "puru": 248, "ero": 248, "vehicula": 248, "auctor": 248, "phasellu": 248, "viverra": 248, "conval": 248, "faucibu": 248, "vulput": 248, "feli": 248, "sodal": 248, "maecena": 248, "semper": 248, "enim": 248, "blandit": 248, "sollicitudin": 248, "urna": 248, "orci": 248, "lacu": 248, "quisqu": 248, "facilisi": 248, "curabitur": 248, "variu": 248, "bibendum": 248, "massa": 248, "magna": 248, "tempu": 248, "metu": 248, "nisi": 248, "pretium": 248, "leo": 248, "euismod": 248, "ultric": 248, "dapibu": 248, "lacinia": 248, "vivamu": 248, "molesti": 248, "hac": 248, "habitass": 248, "platea": 248, "dictumst": 248, "changelog": 249, "submenu": 249, "symlink": 250, "subtre": 250, "_theme": 250, "html_theme": 250, "html_theme_path": 250}, "objects": {"": [[244, 0, 1, "", "Data_item_1"], [244, 0, 1, "", "Data_item_2"], [244, 0, 1, "", "Data_item_3"]], "payments.dotpay": [[244, 1, 1, "", "DotpayProvider"]]}, "objtypes": {"0": "py:data", "1": "py:class"}, "objnames": {"0": ["py", "data", "Python data"], "1": ["py", "class", "Python class"]}, "titleterms": {"onnx": [0, 18, 109], "live": 0, "tutori": [0, 33, 36, 40, 48, 49, 51, 53, 56, 77, 88, 90, 114, 117, 121, 122, 123, 151, 155, 156, 158, 159, 166, 171, 175, 176, 190, 208, 209], "what": [0, 6, 10, 11, 42, 51, 55, 56, 60, 91, 107, 111, 120, 130, 137, 146, 152, 198, 203, 204, 205, 214, 222, 236, 240, 241], "overview": [0, 1, 60, 61, 114, 143, 163, 172, 186, 209], "prepar": [0, 31, 48, 60, 113, 115, 127, 128, 138, 164, 168, 176, 179, 182, 183, 184, 185, 186, 189, 192, 199, 201, 211, 212, 213], "environ": [0, 1, 21, 52, 60, 145, 158, 182, 189], "download": [0, 136, 178, 181, 245, 250], "train": [0, 1, 3, 6, 7, 11, 17, 30, 31, 42, 48, 51, 52, 54, 61, 89, 91, 94, 97, 99, 101, 109, 111, 115, 117, 121, 123, 125, 127, 128, 131, 132, 134, 135, 145, 153, 156, 158, 159, 164, 166, 169, 178, 179, 192, 208, 209, 216, 234, 237], "pytorch": [0, 3, 4, 5, 6, 10, 12, 17, 18, 22, 41, 44, 49, 53, 56, 57, 61, 63, 64, 65, 67, 68, 69, 73, 84, 90, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 106, 108, 109, 110, 122, 135, 136, 138, 146, 157, 168, 173, 174, 176, 177, 183, 190, 191, 192, 193, 199, 200, 201, 202, 206, 208, 209, 211, 212, 213, 214, 215, 221, 223, 224, 225, 226, 227, 228, 229, 230, 232, 234, 235, 236, 237, 238], "style": [0, 12], "transfer": [0, 12, 117, 156], "model": [0, 1, 4, 6, 7, 9, 12, 16, 17, 18, 19, 22, 30, 34, 35, 36, 43, 48, 54, 58, 59, 60, 75, 76, 81, 86, 92, 94, 95, 97, 99, 104, 106, 111, 113, 115, 117, 118, 120, 123, 125, 131, 133, 134, 136, 137, 138, 142, 145, 146, 148, 149, 153, 155, 156, 157, 164, 166, 168, 169, 172, 175, 176, 178, 179, 181, 182, 183, 189, 190, 192, 196, 199, 201, 202, 207, 208, 209, 211, 212, 213, 214, 217, 221, 222, 225, 227, 229, 230, 234, 235, 236, 239, 240], "convert": [0, 4, 22, 58, 59, 60, 83, 146, 176, 179, 182, 189, 192], "coreml": 0, "run": [0, 6, 7, 18, 20, 33, 43, 48, 49, 52, 53, 54, 58, 59, 60, 75, 86, 90, 115, 118, 126, 127, 133, 153, 168, 181, 189, 204, 225, 232, 240], "io": [0, 59, 182, 183, 197, 210, 211, 213], "app": [0, 58, 59, 126, 182, 199, 201, 204, 212, 213], "conclus": [0, 1, 2, 3, 5, 6, 9, 17, 19, 20, 21, 48, 77, 114, 136, 142, 143, 145, 158, 163, 171, 173, 174, 178, 181, 182, 183, 184, 185, 186, 187, 190, 192, 193, 196, 197, 200, 210], "torchrl": [1, 158], "object": [1, 58, 59, 101, 126, 175], "code": [1, 2, 20, 33, 34, 53, 90, 180, 184, 199, 201, 214, 245], "ddpg": 1, "loss": [1, 12, 34, 42, 45, 48, 51, 95, 99, 100, 109, 128, 158, 218, 237], "prerequisit": [1, 34, 58, 59, 115, 156, 157, 174, 193], "import": [1, 12, 43, 54, 89, 109, 136, 192, 204, 221, 224, 225, 227, 228, 229, 230, 235, 236, 237, 240], "setup": [1, 16, 21, 89, 107, 116, 135, 136, 149, 157, 168, 169, 172, 176, 181, 182, 190, 201, 204, 211, 221, 224, 225, 227, 228, 229, 230, 235, 236, 237], "lossmodul": 1, "The": [1, 6, 89, 91, 99, 125, 134, 154, 164, 204, 214, 245], "__init__": [1, 31], "method": [1, 20, 135, 149, 174, 175, 187, 239], "valu": [1, 151, 158, 239], "estim": [1, 145], "actor": 1, "put": [1, 145, 157, 172, 175], "thing": 1, "togeth": [1, 145, 157, 172, 175, 218], "forward": [1, 5, 6, 19, 80, 108, 140, 144, 175, 202, 211], "call": 1, "transform": [1, 7, 39, 40, 50, 95, 118, 119, 120, 123, 136, 144, 152, 153, 158, 163, 166], "parallel": [1, 7, 19, 43, 53, 55, 61, 121, 123, 124, 133, 134, 148, 153, 234], "execut": [1, 4, 16, 160, 168, 225, 234], "normal": [1, 42, 158, 237], "observ": [1, 180], "stat": 1, "build": [1, 4, 5, 10, 20, 21, 30, 58, 59, 95, 101, 116, 141, 142, 154, 156, 197, 199, 201, 204, 207, 210, 237, 240, 243], "explor": [1, 4, 16], "data": [1, 6, 7, 9, 17, 23, 31, 35, 42, 43, 48, 49, 51, 53, 54, 55, 60, 61, 89, 95, 98, 107, 109, 115, 117, 118, 119, 123, 124, 127, 128, 133, 153, 156, 158, 164, 166, 168, 169, 178, 186, 190, 221, 224, 225, 227, 228, 229, 230, 234, 235, 236, 237, 244], "collector": [1, 158], "evalu": [1, 7, 48, 60, 115, 117, 118, 125, 126, 127, 136, 153, 156, 164, 179, 181, 192, 218], "your": [1, 4, 5, 10, 31, 60, 94, 97, 107, 108, 150, 175, 180, 204, 211, 221, 240], "record": [1, 168], "replai": [1, 158, 159], "buffer": [1, 158, 234], "storag": 1, "batch": [1, 7, 8, 115, 116, 118, 129, 141, 144, 153, 160, 234], "size": [1, 136, 181, 192, 222], "modul": [1, 4, 6, 22, 60, 67, 86, 95, 107, 108, 110, 134, 136, 140, 148, 151, 155, 190, 195, 207], "construct": [1, 16, 54, 186, 187], "target": [1, 7, 118, 145, 153, 234, 245], "network": [1, 6, 30, 42, 45, 51, 89, 101, 104, 109, 119, 127, 128, 145, 158, 159, 164, 166, 218, 221, 227, 228, 229, 230, 235, 236, 237], "updat": [1, 45, 145, 160, 195], "optim": [1, 34, 35, 42, 51, 69, 99, 101, 107, 109, 110, 120, 126, 162, 174, 205, 211, 212, 213, 228, 229, 230, 234, 236, 237, 239, 241], "time": [1, 15, 37, 46, 70, 74, 82, 87, 96, 105, 108, 112, 136, 157, 165, 194, 211, 225, 231, 233], "polici": [1, 123, 158], "experi": [1, 126, 176], "result": [1, 3, 43, 51, 75, 108, 115, 126, 127, 130, 158, 164, 166, 168, 181, 214, 217, 219], "next": [1, 42, 51, 75, 138, 157, 158], "step": [1, 4, 58, 59, 77, 114, 134, 138, 154, 157, 158, 168, 207, 212, 213, 219, 221, 222, 224, 225, 227, 228, 229, 230, 235, 236, 237], "autograd": [2, 8, 10, 29, 41, 63, 64, 78, 91, 110, 125, 140, 162], "c": [2, 3, 4, 5, 6, 8, 10, 20, 21, 199, 201, 208, 233, 240], "frontend": [2, 6, 86, 88], "basic": [2, 6, 19, 22, 32, 33, 133, 134, 140, 148, 154, 160, 171, 196], "oper": [2, 5, 8, 10, 20, 21, 38, 47, 91, 103, 174, 176, 186, 187, 188, 193, 200, 201, 211, 234], "comput": [2, 15, 29, 37, 41, 46, 70, 74, 82, 87, 96, 103, 105, 106, 112, 117, 144, 149, 156, 165, 194, 217, 231, 234], "higher": 2, "order": [2, 234], "gradient": [2, 12, 29, 75, 78, 92, 152, 186, 218, 234, 237], "us": [2, 3, 5, 6, 7, 11, 12, 13, 18, 20, 21, 22, 33, 41, 49, 52, 60, 107, 108, 111, 113, 116, 119, 120, 124, 129, 131, 133, 134, 137, 140, 152, 153, 154, 160, 161, 162, 163, 168, 169, 183, 186, 199, 201, 202, 203, 209, 210, 211, 214, 216, 217, 225, 230, 232, 234, 235, 239, 241], "custom": [2, 5, 10, 20, 21, 31, 50, 67, 110, 116, 117, 121, 129, 130, 140, 154, 155, 156, 175, 201, 205, 210], "function": [2, 7, 12, 17, 29, 34, 42, 45, 51, 64, 75, 80, 86, 89, 95, 99, 100, 101, 107, 109, 110, 115, 118, 129, 130, 136, 140, 144, 149, 152, 153, 155, 156, 158, 179, 192, 202, 219, 225, 234, 237], "translat": [2, 113, 119, 164], "from": [2, 17, 18, 20, 41, 49, 107, 111, 127, 128, 131, 164, 172, 173, 174, 175, 183, 235], "python": [2, 5, 20, 21, 58, 59, 86, 138, 154, 199, 239], "cuda": [3, 5, 83, 203], "graph": [3, 29, 41, 60, 97, 103, 171, 174, 178, 179, 180, 181, 225, 234], "api": [3, 4, 6, 91, 109, 138, 140, 146, 154, 181, 193, 199, 214, 234], "get": [3, 4, 10, 30, 58, 59, 106, 124, 133, 143, 150, 162, 204, 208, 209, 212, 213], "start": [3, 7, 97, 124, 133, 150, 162, 208, 209, 233], "load": [4, 6, 7, 9, 12, 20, 22, 31, 35, 36, 42, 48, 52, 58, 59, 60, 111, 117, 118, 131, 133, 136, 153, 156, 164, 166, 192, 211, 219, 221, 224, 227, 228, 229, 230, 234, 235, 236, 237, 240], "torchscript": [4, 19, 20, 21, 22, 60, 109, 111, 171, 196, 201, 205, 208, 234, 239, 240], "1": [4, 9, 17, 42, 58, 59, 80, 86, 134, 136, 149, 154, 156, 168, 169, 173, 175, 176, 178, 179, 181, 190, 193, 204, 207, 211, 212, 213, 216, 219, 221, 222, 224, 225, 227, 228, 229, 230, 233, 235, 236, 237, 239, 247], "torch": [4, 29, 41, 61, 83, 84, 95, 103, 107, 111, 133, 155, 163, 171, 173, 186, 192, 198, 211, 218, 219, 227], "script": [4, 21, 22, 52, 86, 120, 150, 181, 212, 213, 239], "via": [4, 138, 229, 250], "trace": [4, 21, 22, 86, 142, 171, 174, 180, 181, 197, 214, 225, 239], "annot": [4, 193], "2": [4, 9, 17, 42, 43, 58, 59, 80, 86, 134, 136, 149, 154, 156, 168, 169, 173, 174, 175, 176, 178, 179, 181, 190, 192, 193, 204, 207, 211, 212, 213, 216, 219, 221, 222, 224, 225, 227, 228, 229, 230, 233, 235, 236, 237, 239, 247, 248], "serial": [4, 20, 136, 155], "file": [4, 31, 48, 111, 131, 164, 201, 204, 230], "3": [4, 9, 17, 42, 43, 58, 59, 86, 134, 136, 154, 168, 169, 173, 176, 178, 179, 181, 190, 193, 207, 211, 212, 213, 216, 219, 221, 222, 224, 225, 227, 228, 229, 230, 233, 235, 236, 237, 239, 247], "A": [4, 21, 41, 44, 56, 91, 92, 100, 129, 193, 214, 218, 233, 235, 245], "minim": 4, "applic": [4, 6, 135, 154, 201], "depend": [4, 138, 163], "libtorch": [4, 183], "4": [4, 9, 17, 42, 58, 59, 86, 134, 136, 154, 157, 168, 169, 176, 179, 181, 193, 207, 211, 216, 219, 221, 222, 224, 225, 227, 228, 229, 230, 233, 235, 236, 237, 247], "5": [4, 17, 42, 58, 59, 168, 169, 176, 179, 181, 193, 211, 219, 222, 224, 225, 227, 228, 229, 233, 237, 247], "help": [4, 168], "extens": [5, 10, 13, 121, 154, 174, 200, 208], "motiv": [5, 6, 86, 179, 184, 192], "exampl": [5, 13, 19, 20, 58, 59, 75, 80, 81, 86, 91, 92, 101, 104, 106, 110, 111, 125, 193, 207, 208, 245, 247], "write": [5, 6, 50, 135, 169, 175, 180, 184, 193, 205], "setuptool": [5, 21], "op": [5, 8], "pass": [5, 11, 108, 141, 221], "backward": [5, 10, 19, 80, 123, 129, 130], "bind": [5, 20], "perform": [5, 108, 137, 142, 143, 146, 152, 157, 163, 168, 173, 174, 192, 209, 211, 234], "comparison": [5, 129, 133, 152, 171, 179], "gpu": [5, 6, 42, 43, 54, 81, 89, 98, 107, 109, 111, 183, 208, 227, 234], "devic": [5, 12, 30, 111, 123, 199, 203, 220, 227, 234], "jit": [5, 10, 21, 109, 157], "compil": [5, 21, 143, 163, 171], "mix": [5, 22, 123, 131, 218, 234], "accessor": 5, "integr": [5, 92, 138, 182, 189], "defin": [6, 7, 8, 9, 17, 20, 30, 42, 45, 48, 60, 64, 110, 115, 118, 126, 134, 136, 153, 158, 175, 176, 178, 179, 192, 207, 219, 221, 227, 228, 229, 230, 233, 235, 236, 237, 239], "neural": [6, 12, 30, 42, 45, 89, 107, 109, 145, 149, 209, 221, 227, 228, 229, 230, 235, 236, 237], "regist": [6, 8, 10, 21], "paramet": [6, 13, 30, 34, 35, 43, 60, 95, 111, 155, 158, 160, 161, 193, 195, 219, 234, 235, 244], "submodul": [6, 180], "travers": 6, "hierarchi": [6, 214], "mode": [6, 16, 17, 140, 144, 178, 179, 180, 181, 192, 208], "ownership": 6, "dcgan": [6, 51], "wa": 6, "gan": [6, 51], "agan": 6, "gener": [6, 7, 51, 75, 109, 111, 113, 115, 118, 126, 128, 153, 207, 219, 228, 234, 244], "discrimin": [6, 51, 100], "loop": [6, 34, 99, 134, 158, 159], "move": [6, 20, 98], "checkpoint": [6, 54, 111, 123, 133, 145, 228, 234], "recov": 6, "state": [6, 241], "inspect": [6, 151, 155, 169, 218], "imag": [6, 12, 18, 42, 58, 59, 97, 117, 120, 138, 156, 157, 204, 245, 246], "distribut": [7, 11, 14, 16, 52, 53, 54, 55, 61, 109, 121, 133, 134, 135, 161, 162, 172, 205, 234], "pipelin": [7, 115, 134, 148, 153], "multipl": [7, 42, 111, 155, 230], "process": [7, 52, 54, 58, 59, 115, 119, 133, 134, 154, 160, 204], "input": [7, 11, 51, 54, 58, 59, 60, 75, 118, 127, 130, 148, 153, 172, 190, 202, 219, 234, 239], "sequenc": [7, 104, 118, 153, 164], "scale": [7, 132, 153, 163], "pipe": [7, 153], "initi": [7, 38, 47, 51, 52, 115, 118, 133, 135, 145, 151, 153, 188, 195, 221, 227, 228, 229, 230, 235, 236], "test": [7, 9, 10, 42, 75, 89, 115, 118, 129, 141, 153, 175, 199, 207, 221, 233], "dataset": [7, 17, 24, 31, 43, 50, 94, 97, 99, 107, 109, 113, 115, 116, 118, 136, 153, 175, 179, 181, 192, 224, 237], "output": [7, 58, 59, 113, 130, 209], "dispatch": [8, 10, 163], "schema": 8, "backend": [8, 10, 135, 143, 154, 176, 192, 199, 234], "implement": [8, 20, 21, 34, 51, 75, 100, 129, 151, 154, 160, 161, 163, 184, 186, 195], "For": [8, 91], "do": [8, 42, 91, 130, 146, 222], "need": [8, 91, 180], "In": [8, 91, 98], "place": [8, 83, 91, 98], "view": [8, 168], "ad": [8, 89, 169, 201, 218], "support": [8, 10, 89, 97, 156, 163, 187, 195, 204, 205], "go": [8, 42, 51, 75], "beyond": [8, 202], "autocast": [8, 218], "tracer": 8, "beta": [9, 17, 136, 140, 141, 142, 146, 156, 163, 189, 202, 210], "dynam": [9, 19, 100, 136, 178, 181, 190, 216, 222], "quantiz": [9, 17, 120, 136, 156, 157, 176, 178, 179, 180, 181, 190, 192, 193, 209, 211, 212, 213, 216, 222], "an": [9, 10, 18, 42, 58, 59, 60, 104, 106, 115, 118, 125, 158, 175, 202, 249], "lstm": [9, 19, 100, 104], "word": [9, 101, 106], "languag": [9, 106, 118, 119], "introduct": [9, 12, 22, 41, 51, 58, 59, 61, 90, 92, 93, 94, 97, 98, 99, 103, 136, 151, 168, 172, 181, 182, 183, 184, 187, 189, 190, 193, 195, 197, 199, 200, 202, 207, 210, 211, 212, 213, 215, 216, 221, 222, 224, 225, 227, 228, 229, 230, 235, 236, 237, 239], "text": [9, 48, 115, 116, 170, 245], "pretrain": [9, 60, 175, 212, 213, 216], "extend": [10, 20, 21, 155], "new": [10, 58, 59, 64, 100, 110, 115, 129, 215], "s": [10, 52, 54, 60, 103, 145, 174, 185], "kei": 10, "full": [10, 34, 89, 204], "list": [10, 246], "kernel": [10, 149], "against": 10, "nativ": [10, 201], "compat": [10, 183], "known": 10, "issu": 10, "addit": [10, 40, 114, 122, 222], "note": [10, 60, 100, 217], "futur": 10, "work": [10, 11, 35, 123, 124, 146], "stai": 10, "touch": 10, "uneven": 11, "join": 11, "context": [11, 243], "manag": 11, "requir": [11, 125, 155, 203, 204, 205, 214, 240, 241], "distributeddataparallel": [11, 61, 133, 234], "zeroredundancyoptim": [11, 241], "keyword": 11, "argument": [11, 239], "how": [11, 33, 123, 124, 179, 192, 193, 203, 205, 210, 214, 221, 232, 240, 241, 243], "doe": [11, 125], "joinabl": 11, "joinhook": 11, "make": [11, 100, 116, 180, 201], "toi": [11, 193], "class": [11, 20, 30, 50, 151], "underli": 12, "principl": [12, 173, 174, 187], "packag": [12, 80], "select": [12, 197], "content": [12, 110, 243, 244, 245, 246, 247, 248], "descent": 12, "creat": [13, 31, 35, 43, 48, 98, 101, 103, 107, 126, 127, 128, 142, 149, 155, 234], "numpi": [13, 38, 47, 72, 83, 98, 110, 185], "scipi": 13, "less": 13, "parametr": [13, 151, 155], "combin": [14, 133], "dataparallel": [14, 43, 55, 61, 81, 89, 111, 133, 227], "rpc": [14, 61, 121, 134, 160, 161, 162, 177, 203, 206], "framework": [14, 161, 162], "torchrec": [16, 172], "shard": [16, 123, 124, 134, 241], "instal": [16, 77, 92, 136, 156, 157, 172, 209, 232, 250], "our": [16, 129, 135, 138, 141, 172, 221, 224, 227, 228, 229, 230, 235, 236, 237], "embed": [16, 97, 106], "distributedmodelparallel": [16, 172], "multiprocess": 16, "tabl": [16, 110, 243, 244, 245, 246, 247, 248], "wise": 16, "other": [16, 95, 97, 99, 168], "static": [17, 100, 179, 190, 192, 216], "eager": [17, 179, 181], "architectur": 17, "helper": [17, 136, 179, 187, 192], "loader": [17, 89], "imagenet": 17, "post": [17, 178, 179, 192, 204, 216], "awar": [17, 209, 216], "speedup": [17, 171, 218], "option": [18, 29, 41, 43, 114, 175, 199, 204, 221, 224, 243, 244, 246], "export": [18, 111, 192, 193, 240], "runtim": [18, 234], "syntax": [19, 86, 196], "appli": [19, 136, 148], "ensembl": [19, 137], "bidirect": 19, "layer": [19, 30, 92, 95, 129, 234], "asid": 19, "visual": [19, 31, 92, 97, 117, 156, 164, 166, 169, 214, 217, 224, 225], "project": [20, 243], "With": [20, 168, 201], "cmake": [20, 21, 201], "save": [20, 22, 35, 36, 52, 54, 60, 111, 123, 125, 130, 131, 133, 145, 192, 218, 219, 227, 228, 229, 230, 235], "To": [20, 204], "ivalu": 20, "deseri": 20, "take": 20, "return": [20, 125], "bound": [20, 174], "appendix": [21, 187], "more": [21, 29, 58, 59, 91, 98, 120, 125, 143, 144, 160, 168, 172, 182, 183, 189, 202, 207, 210, 212, 213, 215, 216, 219, 221, 222, 224, 225, 229, 232, 235, 236, 237, 239], "wai": [21, 152, 245], "author": 22, "further": [22, 29, 30, 31, 34, 39, 41, 52, 54, 55, 108, 114, 117, 131, 132, 176, 184, 186, 187], "read": [22, 29, 30, 31, 34, 39, 41, 52, 54, 55, 108, 114, 131, 132, 174, 176, 184, 186, 187, 214], "audio": [23, 24, 25, 26, 27, 28], "augment": [23, 25, 104, 234], "featur": [25, 26, 40, 92, 104, 117, 123, 156, 168, 208, 209], "extract": 26, "i": [27, 42], "o": 27, "resampl": 28, "automat": [29, 103, 140, 218], "differenti": [29, 41, 103, 140], "tensor": [29, 38, 47, 63, 73, 78, 83, 94, 98, 103, 109, 110, 125, 127, 163, 187, 188, 193, 211, 234, 239], "disabl": [29, 234], "track": [29, 78, 130, 169], "jacobian": [29, 144, 149], "product": [29, 144, 149, 163], "nn": [30, 61, 67, 68, 80, 86, 95, 107, 110, 111, 118, 119, 155, 172, 227], "flatten": 30, "linear": [30, 95, 101, 107], "relu": [30, 176], "sequenti": [30, 107], "softmax": [30, 101, 186], "dataload": [31, 50, 94, 99, 107, 109, 113], "iter": [31, 48, 50, 115, 155, 224], "__len__": 31, "__getitem__": 31, "through": [31, 50, 86, 176, 221], "learn": [32, 33, 44, 56, 57, 58, 59, 86, 100, 101, 102, 109, 110, 117, 120, 121, 136, 145, 156, 158, 159, 160, 162, 168, 173, 182, 183, 189, 202, 207, 210, 212, 213, 215, 216, 219, 221, 222, 224, 225, 229, 232, 235, 236, 237, 239], "thi": [33, 40, 56, 123, 246, 249], "guid": [33, 180, 234], "hyperparamet": [34, 89, 158, 159], "quickstart": 35, "weight": [36, 45, 51, 65, 110, 190], "shape": [36, 98, 226], "relat": [36, 174], "attribut": [38, 47, 92, 217, 239], "bridg": [38, 47, 83, 98], "arrai": [38, 47, 83], "totensor": 39, "lambda": 39, "fast": [40, 75], "infer": [40, 58, 59, 111, 117, 120, 136, 138, 157, 173, 202, 204, 208, 218, 229, 234, 239, 240], "better": 40, "inform": [40, 86, 143], "summari": [40, 43, 113, 123, 163, 215], "gentl": 41, "background": 41, "usag": [41, 109, 129, 140, 148, 171, 173, 199, 209], "vector": [41, 137, 144, 149], "calculu": 41, "exclus": 41, "dag": 41, "classifi": [42, 101, 120, 127, 156], "about": [42, 136, 226], "cifar10": 42, "convolut": [42, 95, 129, 141, 234], "where": [42, 51, 75, 186], "dummi": 43, "simpl": [43, 91, 138, 142, 164, 218, 225], "8": [43, 179, 219, 225, 233, 247], "deep": [44, 56, 57, 100, 101, 102, 109, 173], "60": [44, 56], "minut": [44, 56], "blitz": [44, 56], "backprop": 45, "chatbot": 48, "preprocess": [48, 116, 145, 157], "format": [48, 111, 146, 174, 211, 234], "trim": 48, "seq2seq": [48, 60, 119, 164], "encod": [48, 60, 106, 164], "decod": [48, 60, 164], "procedur": 48, "mask": [48, 186], "singl": [48, 148], "greedi": [48, 60], "my": 48, "googl": 49, "colab": 49, "version": [49, 149], "drive": 49, "compos": [50, 144], "afterword": 50, "torchvis": [50, 76, 175], "adversari": [51, 75], "fault": 52, "toler": 52, "torchrun": [52, 133], "why": [52, 55, 125, 186, 188], "grace": 52, "restart": 52, "diff": [52, 54], "multigpu": [52, 54], "py": [52, 54], "v": [52, 54], "multigpu_torchrun": 52, "group": [52, 54, 154], "provid": 52, "variabl": [52, 234], "snapshot": 52, "trainer": 52, "constructor": [52, 234], "resum": [52, 111, 218], "video": [53, 157], "section": [53, 248], "multi": [54, 81, 89, 126, 173], "ddp": [54, 55, 121, 131, 133, 234], "single_gpu": 54, "job": [54, 225], "you": [55, 97, 217], "should": 55, "prefer": [55, 211], "over": [55, 224], "dp": 55, "goal": 56, "nlp": [57, 102, 127, 128, 164], "segment": [58, 59, 175], "deeplabv3": [58, 59], "android": [58, 197, 199, 201, 207, 210, 211, 212], "deploy": [58, 59, 120, 209, 240], "reus": [58, 59, 211], "complet": [58, 59], "ui": [58, 59], "refactor": [58, 59, 107, 180], "recap": [58, 59, 123], "deploi": [60, 138, 204], "acknowledg": [60, 126, 173, 174], "handl": 60, "attent": [60, 163, 164], "search": [60, 89], "chang": [60, 98, 220], "host": [60, 189], "own": [60, 135, 180, 204], "greedysearchdecod": 60, "print": [60, 108], "elast": 61, "base": [61, 113, 156, 177, 197, 206, 243], "develop": 61, "control": [65, 110, 163, 234], "flow": [65, 110], "share": [65, 110, 193, 232], "warm": [72, 110], "up": [72, 110, 126, 148, 175, 176, 222, 233], "threat": 75, "sign": 75, "attack": 75, "under": 75, "fgsm": 75, "accuraci": [75, 89, 136, 143, 192, 209, 222], "vs": [75, 144, 185], "epsilon": 75, "sampl": [75, 128, 152, 214], "finetun": [76, 77, 117, 156, 175], "torchmultimod": 77, "flava": 77, "histori": 78, "convnet": [80, 117], "hook": [80, 125], "recurr": [80, 95], "net": [80, 107], "part": [81, 86, 104, 156, 174], "cpu": [81, 111, 123, 125, 142, 143, 173, 174, 200, 208, 227, 234], "inplac": 83, "out": [83, 129, 141, 237], "zero": [83, 237], "index": [83, 186, 244], "No": 83, "camel": 83, "case": [83, 133, 202, 234], "former": 84, "user": [84, 127, 180, 199], "hybrid": [86, 88], "pure": 86, "top": [86, 174], "level": [86, 91, 104, 127, 128, 243, 245, 246], "tune": [89, 123, 136, 174, 234], "rai": 89, "configur": [89, 126, 136, 174, 181, 192, 214, 243], "commun": [89, 135, 203], "set": [89, 126, 136, 173, 176, 179, 181, 192, 222, 234], "space": 89, "youtub": [90, 93], "seri": 90, "fundament": 91, "we": [91, 113], "turn": [91, 127], "off": 91, "On": 91, "profil": [91, 108, 142, 143, 168, 174, 177, 206, 214, 225], "advanc": [91, 100, 123, 135, 168, 174, 185, 200, 218], "topic": [91, 135, 218, 245], "detail": [91, 195], "high": [91, 163], "understand": 92, "captum": [92, 217], "first": [92, 151, 173, 174], "occlus": 92, "gradcam": 92, "insight": 92, "common": [95, 193, 202, 239], "type": [95, 98, 218, 239], "manipul": [95, 98], "activ": [95, 99, 109], "tensorboard": [97, 168, 169, 232], "befor": [97, 217], "show": 97, "scalar": [97, 232], "resourc": [97, 99, 122, 172, 204, 222, 240], "random": [98, 100, 115], "seed": 98, "math": [98, 245], "logic": [98, 173], "brief": 98, "broadcast": 98, "alter": 98, "copi": 98, "number": [98, 173, 245, 246], "dimens": 98, "per": [99, 152], "epoch": 99, "decis": 100, "bi": 100, "crf": 100, "versu": 100, "toolkit": 100, "condit": 100, "field": [100, 246], "discuss": 100, "exercis": [100, 104, 106, 114, 127, 128, 164, 174], "tag": [100, 104], "block": [101, 219, 245], "affin": 101, "map": 101, "non": [101, 180, 207, 234], "probabl": 101, "compon": [101, 143], "logist": 101, "regress": 101, "bag": [101, 106], "librari": [103, 115, 183, 201, 212, 213, 221, 224, 225, 227, 228, 229, 230, 234, 235, 236, 237], "reshap": 103, "long": [104, 225, 247, 249], "short": [104, 214], "term": 104, "memori": [104, 108, 125, 129, 146, 159, 173, 174, 211, 225, 234], "speech": [104, 167, 170], "tagger": 104, "charact": [104, 127, 128], "lexic": 106, "semant": [106, 184, 185], "dens": [106, 163], "n": 106, "gram": 106, "continu": 106, "realli": 107, "mnist": 107, "scratch": [107, 127, 128, 164], "without": [107, 199, 207], "add": [107, 175, 212, 213], "valid": [107, 234], "fit": 107, "get_data": 107, "switch": [107, 234], "cnn": 107, "wrap": [107, 123, 175, 233], "close": 107, "thought": 107, "debug": [108, 143, 179, 181, 192, 234], "improv": [108, 168], "cheat": 109, "sheet": 109, "vision": [109, 117, 120, 156, 234], "creation": 109, "dimension": 109, "algebra": 109, "rate": 109, "schedul": [109, 126], "util": [109, 155, 159, 200, 211, 219, 234], "datasampl": 109, "also": 109, "see": 109, "state_dict": [111, 229, 236], "recommend": [111, 127], "entir": [111, 229], "One": [111, 134], "warmstart": [111, 235], "differ": [111, 175, 235], "across": [111, 227], "t5": [113, 123], "summar": 113, "sentiment": 113, "classif": [113, 115], "generationutil": 113, "might": 113, "vari": 113, "sinc": 113, "shuffl": 113, "templat": 114, "torchtext": [115, 116, 118, 119], "access": [115, 173, 186, 224, 234, 236], "raw": 115, "instanc": [115, 118, 175], "split": 115, "vocabulari": 116, "numeric": 116, "sentenc": 116, "bucket": 116, "pad": 116, "few": [117, 156], "predict": [117, 138, 156], "fix": [117, 193, 239], "extractor": [117, 156], "best": [118, 148], "sourc": [119, 183, 201], "collat": 119, "refer": [119, 136, 176, 190, 245], "deit": 120, "lite": [120, 183], "interpret": [120, 142, 197, 210, 217], "compar": [120, 181, 190, 207, 219], "speed": [120, 133, 148], "fsdp": [121, 123, 124], "welcom": 122, "fulli": [123, 124], "fine": [123, 136], "hf": 123, "precis": [123, 131, 218, 234], "intial": 123, "strategi": [123, 126], "prefetch": 123, "stream": 123, "rank0": 123, "typic": 125, "than": [125, 173], "concept": 125, "pack": 125, "unpack": 125, "some": 125, "unconvent": 125, "int": 125, "tupl": 125, "str": 125, "disk": 125, "na": 126, "ax": 126, "torchx": 126, "runner": 126, "searchspac": 126, "metric": 126, "optimizationconfig": 126, "choos": 126, "name": [127, 128], "rnn": [127, 128, 162], "plot": [127, 128, 164], "fuse": [129, 141, 163, 207, 211, 234], "norm": [129, 141, 234], "formula": 129, "batchnorm": 129, "doubl": 130, "intermedi": [130, 234], "when": [130, 131, 186, 239], "real": [131, 157], "world": 131, "cloud": 131, "enough": 131, "multinod": 132, "local": [132, 173], "global": [132, 136, 155, 181], "rank": 132, "heteregen": 132, "troubleshoot": [132, 157, 218], "between": [133, 186], "skew": 133, "partit": 134, "resnet50": 134, "stitch": 134, "Into": 134, "launch": [134, 214], "point": [135, 190], "collect": [135, 158, 219], "ring": 135, "allreduc": 135, "bert": [136, 181], "huggingfac": 136, "necessari": [136, 221, 224, 225, 227, 228, 229, 230, 235, 236, 237], "token": 136, "check": [136, 181, 192], "vmap": [137, 198], "rest": 138, "flask": [138, 204], "definit": [138, 145, 246], "web": 138, "server": [138, 160, 161], "forc": 139, "align": 139, "wav2vec2": [139, 167], "fuser": 141, "fx": [141, 142, 171, 178, 179, 180], "fusion": [141, 176], "benchmark": [141, 181, 189, 207, 211, 219], "resnet18": [141, 142, 193], "captur": [142, 157], "symbol": [142, 180], "investig": 142, "inductor": 143, "log": [143, 145, 232], "determin": 143, "error": [143, 218, 239], "hessian": 144, "hvp": 144, "vhp": 144, "revers": 144, "jacrev": 144, "jacfwd": 144, "functorch": 144, "mario": 145, "plai": 145, "rl": 145, "agent": 145, "act": 145, "cach": [145, 151], "recal": 145, "td": 145, "all": [145, 172, 218, 225, 234, 239], "let": 145, "channel": [146, 174, 211], "last": [146, 174, 211], "gain": 146, "exist": [146, 148], "machin": 148, "practic": 148, "tangent": 149, "ntk": 149, "contract": 149, "acceler": 150, "nvfuser": 150, "hand": 151, "ar": 151, "citizen": 151, "concaten": 151, "remov": [151, 155], "grad": [152, 186, 234], "effici": [152, 173, 184, 210, 234], "cpp": 154, "subclass": 154, "expos": 154, "prune": 155, "re": 155, "0": [156, 186, 192, 193], "nightli": 156, "raspberri": 157, "pi": 157, "30": 157, "fp": 157, "opencv": 157, "choic": 157, "mobilenetv2": [157, 182, 189], "It": 157, "reinforc": [158, 159, 162], "ppo": 158, "dqn": 159, "algorithm": 159, "q": 159, "asynchron": [160, 234], "cartpol": 160, "solver": 160, "rref": 162, "dot": 163, "sdpa": 163, "explicit": 163, "hardwar": 163, "causal": 163, "self": 163, "nestedtensor": [163, 188], "spatial": 166, "depict": 166, "stn": 166, "recognit": 167, "event": 168, "analyz": [168, 225], "6": [168, 169, 176, 179, 211, 219, 225, 227, 233, 247], "projector": 169, "assess": 169, "tacotron2": 170, "demonstr": 171, "torchdynamo": 171, "embeddingbag": 172, "embeddingbagcollect": 172, "queri": 172, "vanilla": 172, "offset": 172, "repres": 172, "minibatch": 172, "keyedjaggedtensor": 172, "kjt": 172, "grok": [173, 174], "intel": [173, 174, 200, 208, 209, 214, 234], "avoid": [173, 234], "core": [173, 182], "alwai": 173, "faster": 173, "remot": 173, "pin": 173, "worker": 173, "default": [173, 218, 220], "torchserv": [173, 174], "set_num_thread": 173, "physic": 173, "launcher": [173, 174], "down": [174, 246], "microarchitectur": 174, "analysi": 174, "tma": 174, "back": 174, "end": 174, "vtune": [174, 214], "instrument": [174, 214], "technolog": [174, 214], "itt": [174, 214], "leverag": [174, 200], "alloc": [174, 234], "tcmalloc": 174, "jemalloc": 174, "ptmalloc": 174, "boost": 174, "detect": 175, "pennfudan": 175, "modifi": [175, 218], "backbon": 175, "everyth": 175, "prototyp": [176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 191, 192, 197], "backendconfig": 176, "deriv": [176, 193], "pattern": [176, 193], "each": 176, "dtypeconfig": 176, "constraint": 176, "conv": 176, "qconfigmap": [176, 179], "satisfi": 176, "7": [176, 179, 219, 225, 233, 247], "faulti": 176, "built": [176, 183], "workload": [177, 200, 206, 214, 234], "eval": [179, 192], "specifi": [179, 181, 221], "calibr": [179, 192], "9": [179, 247], "10": [179, 247], "baselin": 179, "float": [179, 190], "onli": [180, 202, 208, 209], "skip": [180, 195, 234], "traceabl": 180, "glue": 181, "qconfig_dict": 181, "one": [181, 230, 246], "line": [181, 245], "ml": 182, "maco": 182, "metal": 183, "spars": [184, 187], "adagrad": 184, "maskedtensor": [184, 185, 186, 187], "simpler": 184, "origin": 184, "maskedarrai": 185, "reduct": [185, 187], "slice": 186, "distinguish": 186, "nan": [186, 218], "anoth": 186, "x": 186, "yield": 186, "nansum": 186, "nanmean": 186, "safe": 186, "miss": 186, "sparsiti": 187, "coo": 187, "csr": 187, "unari": 187, "binari": 187, "nest": 188, "nnapi": 189, "numer": 190, "suit": 190, "correspond": 190, "locat": 190, "its": 190, "equival": 190, "same": 190, "recip": [191, 207, 211, 212, 213, 215, 216, 223, 238, 239], "specif": [192, 234], "lower": 192, "param": 193, "freez": 196, "mobil": [197, 210, 211, 212, 213, 215, 239], "so": 198, "vulkan": 199, "workflow": [199, 216], "wrapper": 199, "desktop": 199, "sdk": 199, "java": [199, 201], "upload": 199, "matrix": 200, "amx": 200, "guidelin": 200, "can": [200, 246], "confirm": 200, "being": 200, "prebuilt": 201, "gradl": 201, "manifest": [201, 218], "bundl": 202, "uncommon": 202, "retriev": 202, "inflat": 202, "arg": [202, 244], "direct": [203, 245], "tensorpip": 203, "both": 204, "quickli": 204, "bring": 204, "servic": 204, "pre": [204, 207, 212, 213, 215, 216, 239], "requisit": [207, 212, 213, 215, 216, 239], "two": 207, "fuse_modul": [207, 211], "tool": 207, "float32": 208, "bfloat16": 208, "imper": 208, "float16": 208, "zoo": 208, "eas": 209, "compressor": 209, "driven": 209, "mobile_optim": 211, "mobilenet": [212, 213, 216], "v2": [212, 213, 216], "showcas": 214, "begin": 217, "final": 217, "gradscal": 218, "e": 218, "g": 218, "clip": 218, "amp": [218, 234], "minor": 218, "inf": 218, "mismatch": 218, "mai": 218, "cudnn_status_bad_param": 218, "syntaxerror": 219, "timeit": 219, "timer": [219, 233], "autorang": 219, "fuzz": 219, "instruct": [219, 233], "count": [219, 233], "callgrind": [219, 233], "look": 222, "latenc": 222, "instanti": 225, "resnet": 225, "consumpt": 225, "examin": 225, "stack": 225, "flame": 225, "reason": 226, "dashboard": 232, "quick": 233, "wall": 233, "blocked_autorang": 233, "snippet": 233, "collect_callgrind": 233, "delv": 233, "deeper": [233, 246], "b": [233, 235], "footnot": [233, 245], "enabl": 234, "calcul": 234, "bia": 234, "directli": 234, "follow": 234, "none": 234, "instead": 234, "zero_grad": 234, "pointwis": 234, "channels_last": 234, "uniform": 234, "numa": 234, "openmp": 234, "libiomp": 234, "onednn": 234, "cudnn": 234, "auto": 234, "tuner": 234, "unnecessari": 234, "synchron": 234, "prealloc": 234, "length": 234, "reduc": 234, "accumul": 234, "match": 234, "dure": 234, "find_unused_paramet": 234, "true": 234, "balanc": 234, "while": 237, "convers": 239, "runtimeerror": 239, "lookup": 239, "cannot": 239, "rang": 239, "must": 239, "found": 239, "engin": 240, "changelog": 242, "wide": 243, "html": 243, "theme": [243, 249], "toc": 243, "page": 243, "test_py_modul": 244, "paragraph": [245, 248], "markup": 245, "inlin": 245, "meta": 245, "liter": 245, "quot": 245, "doctest": 245, "emphas": 245, "sidebar": 245, "ch": 245, "ien": 245, "creativ": 245, "citat": 245, "glossari": 245, "center": 245, "figur": 245, "admonit": 245, "And": 245, "rubric": 245, "titl": 245, "replac": 245, "compound": 245, "link": 245, "enumer": 246, "bullet": 246, "second": 246, "But": 246, "rabbit": 246, "hole": 246, "hlist": 246, "grid": 246, "giant": 246, "have": 246, "caption": [246, 249], "like": 246, "sticki": 247, "nav": 247, "menu": [247, 249], "11": 247, "12": 247, "13": 247, "14": 247, "15": 247, "16": 247, "17": 247, "18": 247, "19": 247, "20": 247, "submenu": 247, "subsubmenu": 247, "structur": 248, "element": 248, "document": [248, 249], "subsect": 248, "subsubsect": 248, "demo": 249, "incred": 249, "git": 250}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})